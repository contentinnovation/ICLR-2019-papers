{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "RESIDUAL NON-LOCAL ATTENTION NETWORKS FOR IMAGE RESTORATION",
        "author": "Yulun Zhang, Kunpeng Li, Kai Li, Bineng Zhong, & Yun Fu, 1Department of ECE, Northeastern University, Boston, MA 02115, USA 2School of Computer Science and Technology, Huaqiao University, Xiamen 362100, China 3College of CIS, Northeastern University, Boston, MA 02115, USA {yulun100,kinpeng.li.1994,li.kai.gml}@gmail.com, bnzhong@hqu.edu.cn,yunfu@ece.neu.edu",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=HkeGhoA5FX"
        },
        "abstract": "In this paper, we propose a residual non-local attention network for high-quality image restoration. Without considering the uneven distribution of information in the corrupted images, previous methods are restricted by local convolutional operation and equal treatment of spatial- and channel-wise features. To address this issue, we design local and non-local attention blocks to extract features that capture the long-range dependencies between pixels and pay more attention to the challenging parts. Specifically, we design trunk branch and (non-)local mask branch in each (non-)local attention block. The trunk branch is used to extract hierarchical features. Local and non-local mask branches aim to adaptively rescale these hierarchical features with mixed attentions. The local mask branch concentrates on more local structures with convolutional operations, while non-local attention considers more about long-range dependencies in the whole feature map. Furthermore, we propose residual local and non-local attention learning to train the very deep network, which further enhance the representation ability of the network. Our proposed method can be generalized for various image restoration applications, such as image denoising, demosaicing, compression artifacts reduction, and super-resolution. Experiments demonstrate that our method obtains comparable or better results compared with recently leading methods quantitatively and visually."
    },
    "keywords": [
        {
            "term": "deep network",
            "url": "https://en.wikipedia.org/wiki/deep_network"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        },
        {
            "term": "image restoration",
            "url": "https://en.wikipedia.org/wiki/image_restoration"
        },
        {
            "term": "image denoising",
            "url": "https://en.wikipedia.org/wiki/image_denoising"
        },
        {
            "term": "high quality",
            "url": "https://en.wikipedia.org/wiki/high_quality"
        }
    ],
    "abbreviations": {
        "CNN": "convolutional neural network",
        "MemNet": "memory network",
        "RNAN": "residual non-local attention network",
        "RBs": "residual blocks",
        "NLB": "non-local block"
    },
    "highlights": [
        "Image restoration aims to recover high-quality (HQ) images from their corrupted low-quality (LQ) observations and plays a fundamental role in various high-level vision tasks",
        "To address the above issues, we propose the very deep residual non-local attention networks (RNAN) for high-quality image restoration",
        "We demonstrate with extensive experiments that our residual non-local attention network is powerful for various image restoration tasks",
        "We find that such simplified residual blocks not only contributes to image super-resolution (<a class=\"ref-link\" id=\"cLim_et+al_2017_a\" href=\"#rLim_et+al_2017_a\">Lim et al, 2017</a>), but helps to construct very deep network for other image restoration tasks",
        "We propose residual non-local attention networks for high-quality image restoration",
        "We propose residual local and non-local attention learning to train very deep networks"
    ],
    "key_statements": [
        "Image restoration aims to recover high-quality (HQ) images from their corrupted low-quality (LQ) observations and plays a fundamental role in various high-level vision tasks",
        "To address the above issues, we propose the very deep residual non-local attention networks (RNAN) for high-quality image restoration",
        "We introduce residual block (<a class=\"ref-link\" id=\"cHe_et+al_2016_a\" href=\"#rHe_et+al_2016_a\">He et al, 2016</a>; <a class=\"ref-link\" id=\"cLim_et+al_2017_a\" href=\"#rLim_et+al_2017_a\">Lim et al, 2017</a>) for trunk branch and extract hierarchical features",
        "Extensive experiments show that our proposed residual non-local attention network achieves state-of-the-art results compared with other recent leading methods in all tasks",
        "The powerful networks are based on our proposed residual local and non-local attention blocks, which consist of trunk and mask branches",
        "We propose residual non-local attention learning to train very deep networks by preserving more low-level features, being more suitable for image restoration",
        "We demonstrate with extensive experiments that our residual non-local attention network is powerful for various image restoration tasks",
        "We propose residual local and non-local attention blocks to extract hierarchical attentionaware features",
        "We find that such simplified residual blocks not only contributes to image super-resolution (<a class=\"ref-link\" id=\"cLim_et+al_2017_a\" href=\"#rLim_et+al_2017_a\">Lim et al, 2017</a>), but helps to construct very deep network for other image restoration tasks",
        "We find that this form of attention learning is not suitable for image restoration tasks",
        "We show ablation study in Table 1 to investigate the effects of different components in residual non-local attention network",
        "We propose residual non-local attention networks for high-quality image restoration",
        "We propose residual local and non-local attention learning to train very deep networks",
        "We introduce the input feature into attention computation, being more suitable for image restoration"
    ],
    "summary": [
        "Image restoration aims to recover high-quality (HQ) images from their corrupted low-quality (LQ) observations and plays a fundamental role in various high-level vision tasks.",
        "To address the above issues, we propose the very deep residual non-local attention networks (RNAN) for high-quality image restoration.",
        "To the best of our knowledge, this is the first time to consider residual non-local attention for image restoration problems.",
        "We propose the very deep residual non-local networks for high-quality image restoration.",
        "The powerful networks are based on our proposed residual local and non-local attention blocks, which consist of trunk and mask branches.",
        "We propose residual non-local attention learning to train very deep networks by preserving more low-level features, being more suitable for image restoration.",
        "Using non-local lowlevel and high-level attention from the very deep network, we can pursue better network representational ability and obtain high-quality image restoration results.",
        "The framework of our proposed residual non-local attention network (RNAN) is shown in Figure 1.",
        "We only incorporate residual non-local attention block in low-level and high-level feature space.",
        "Inspired by classical non-local means method (<a class=\"ref-link\" id=\"cBuades_et+al_2005_a\" href=\"#rBuades_et+al_2005_a\">Buades et al, 2005</a>) and non-local neural networks (Wang et al, 2018a), we incorporate non-local block (NLB) into the mask branch to obtain non-local mixed attention.",
        "With non-local and local attention computation, feature maps in the mask branch are mapped by sigmoid function fmix",
        "How to train deep image restoration network with non-local mixed attention remains unclear.",
        "We propose a simple yet more suitable residual attention learning method by introducing input feature x directly.",
        "Such residual learning tends to preserve more low-level features and allows us to form very deep networks for high-quality image restoration tasks with stronger representation ability.",
        "With non-local information from low-level and high-level features, RNAN performs better image restoration.",
        "We can see that our proposed RNAN achieves 0.48, 0.30, and 1.06 dB PSNR gains over the second best method FFDNet. This comparison strongly shows the effectiveness of our proposed non-local mixed attention.",
        "With the learned non-local mixed attention, RNAN treats different image parts distinctively, alleviating over-smoothing artifacts obviously.",
        "RNAN obtains more details with consistent structures by considering non-local mixed attention.",
        "These comparisons further demonstrate the effectiveness of our proposed RNAN with the usage of non-local mixed attention.",
        "We propose residual non-local attention networks for high-quality image restoration.",
        "We propose residual local and non-local attention learning to train very deep networks.",
        "RNAN achieves state-of-the-art image restoration results with moderate model size and running time."
    ],
    "headline": "We propose a residual non-local attention network for high-quality image restoration",
    "reference_links": [
        {
            "id": "Agustsson_2017_a",
            "entry": "Eirikur Agustsson and Radu Timofte. Ntire 2017 challenge on single image super-resolution: Dataset and study. In CVPRW, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Eirikur%20Agustsson%20and%20Radu%20Timofte%20Ntire%202017%20challenge%20on%20single%20image%20superresolution%20Dataset%20and%20study%20In%20CVPRW%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Eirikur%20Agustsson%20and%20Radu%20Timofte%20Ntire%202017%20challenge%20on%20single%20image%20superresolution%20Dataset%20and%20study%20In%20CVPRW%202017"
        },
        {
            "id": "Ancuti_et+al_2018_a",
            "entry": "Cosmin Ancuti, Codruta O Ancuti, Radu Timofte, Luc Van Gool, Lei Zhang, Ming-Hsuan Yang, Vishal M Patel, He Zhang, Vishwanath A Sindagi, Ruhao Zhao, et al. Ntire 2018 challenge on image dehazing: Methods and results. In CVPRW, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ancuti%2C%20Cosmin%20Ancuti%2C%20Codruta%20O.%20Timofte%2C%20Radu%20Gool%2C%20Luc%20Van%20challenge%20on%20image%20dehazing%3A%20Methods%20and%20results%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ancuti%2C%20Cosmin%20Ancuti%2C%20Codruta%20O.%20Timofte%2C%20Radu%20Gool%2C%20Luc%20Van%20challenge%20on%20image%20dehazing%3A%20Methods%20and%20results%202018"
        },
        {
            "id": "Bevilacqua_et+al_2012_a",
            "entry": "Marco Bevilacqua, Aline Roumy, Christine Guillemot, and Marie Line Alberi-Morel. Lowcomplexity single-image super-resolution based on nonnegative neighbor embedding. In BMVC, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bevilacqua%2C%20Marco%20Roumy%2C%20Aline%20Guillemot%2C%20Christine%20Alberi-Morel%2C%20Marie%20Line%20Lowcomplexity%20single-image%20super-resolution%20based%20on%20nonnegative%20neighbor%20embedding%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bevilacqua%2C%20Marco%20Roumy%2C%20Aline%20Guillemot%2C%20Christine%20Alberi-Morel%2C%20Marie%20Line%20Lowcomplexity%20single-image%20super-resolution%20based%20on%20nonnegative%20neighbor%20embedding%202012"
        },
        {
            "id": "Blau_et+al_2018_a",
            "entry": "Yochai Blau, Roey Mechrez, Radu Timofte, Tomer Michaeli, and Lihi Zelnik-Manor. 2018 pirm challenge on perceptual image super-resolution. In ECCVW, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Blau%2C%20Yochai%20Mechrez%2C%20Roey%20Timofte%2C%20Radu%20Michaeli%2C%20Tomer%20pirm%20challenge%20on%20perceptual%20image%20super-resolution%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Blau%2C%20Yochai%20Mechrez%2C%20Roey%20Timofte%2C%20Radu%20Michaeli%2C%20Tomer%20pirm%20challenge%20on%20perceptual%20image%20super-resolution%202018"
        },
        {
            "id": "Buades_et+al_2005_a",
            "entry": "Antoni Buades, Bartomeu Coll, and J-M Morel. A non-local algorithm for image denoising. In CVPR, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Buades%2C%20Antoni%20Coll%2C%20Bartomeu%20Morel%2C%20J.-M.%20A%20non-local%20algorithm%20for%20image%20denoising%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Buades%2C%20Antoni%20Coll%2C%20Bartomeu%20Morel%2C%20J.-M.%20A%20non-local%20algorithm%20for%20image%20denoising%202005"
        },
        {
            "id": "Chen_2017_a",
            "entry": "Yunjin Chen and Thomas Pock. Trainable nonlinear reaction diffusion: A flexible framework for fast and effective image restoration. TPAMI, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Yunjin%20Pock%2C%20Thomas%20Trainable%20nonlinear%20reaction%20diffusion%3A%20A%20flexible%20framework%20for%20fast%20and%20effective%20image%20restoration%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Yunjin%20Pock%2C%20Thomas%20Trainable%20nonlinear%20reaction%20diffusion%3A%20A%20flexible%20framework%20for%20fast%20and%20effective%20image%20restoration%202017"
        },
        {
            "id": "Dabov_et+al_2007_a",
            "entry": "Kostadin Dabov, Alessandro Foi, Vladimir Katkovnik, and Karen Egiazarian. Color image denoising via sparse 3d collaborative filtering with grouping constraint in luminance-chrominance space. In ICIP, 2007a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dabov%2C%20Kostadin%20Foi%2C%20Alessandro%20Katkovnik%2C%20Vladimir%20Egiazarian%2C%20Karen%20Color%20image%20denoising%20via%20sparse%203d%20collaborative%20filtering%20with%20grouping%20constraint%20in%20luminance-chrominance%20space%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dabov%2C%20Kostadin%20Foi%2C%20Alessandro%20Katkovnik%2C%20Vladimir%20Egiazarian%2C%20Karen%20Color%20image%20denoising%20via%20sparse%203d%20collaborative%20filtering%20with%20grouping%20constraint%20in%20luminance-chrominance%20space%202007"
        },
        {
            "id": "Dabov_et+al_2007_b",
            "entry": "Kostadin Dabov, Alessandro Foi, Vladimir Katkovnik, and Karen Egiazarian. Image denoising by sparse 3-d transform-domain collaborative filtering. TIP, 2007b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dabov%2C%20Kostadin%20Foi%2C%20Alessandro%20Katkovnik%2C%20Vladimir%20Egiazarian%2C%20Karen%20Image%20denoising%20by%20sparse%203-d%20transform-domain%20collaborative%20filtering%202007"
        },
        {
            "id": "Deng_et+al_2009_a",
            "entry": "Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In CVPR, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Deng%2C%20Jia%20Dong%2C%20Wei%20Socher%2C%20Richard%20Li%2C%20Li-Jia%20Imagenet%3A%20A%20large-scale%20hierarchical%20image%20database%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Deng%2C%20Jia%20Dong%2C%20Wei%20Socher%2C%20Richard%20Li%2C%20Li-Jia%20Imagenet%3A%20A%20large-scale%20hierarchical%20image%20database%202009"
        },
        {
            "id": "Dong_et+al_2014_a",
            "entry": "Chao Dong, Chen Change Loy, Kaiming He, and Xiaoou Tang. Learning a deep convolutional network for image super-resolution. In ECCV, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dong%2C%20Chao%20Loy%2C%20Chen%20Change%20He%2C%20Kaiming%20Tang%2C%20Xiaoou%20Learning%20a%20deep%20convolutional%20network%20for%20image%20super-resolution%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dong%2C%20Chao%20Loy%2C%20Chen%20Change%20He%2C%20Kaiming%20Tang%2C%20Xiaoou%20Learning%20a%20deep%20convolutional%20network%20for%20image%20super-resolution%202014"
        },
        {
            "id": "Dong_et+al_2015_a",
            "entry": "Chao Dong, Yubin Deng, Chen Change Loy, and Xiaoou Tang. Compression artifacts reduction by a deep convolutional network. In ICCV, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dong%2C%20Chao%20Deng%2C%20Yubin%20Loy%2C%20Chen%20Change%20Tang%2C%20Xiaoou%20Compression%20artifacts%20reduction%20by%20a%20deep%20convolutional%20network%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dong%2C%20Chao%20Deng%2C%20Yubin%20Loy%2C%20Chen%20Change%20Tang%2C%20Xiaoou%20Compression%20artifacts%20reduction%20by%20a%20deep%20convolutional%20network%202015"
        },
        {
            "id": "Dong_et+al_2016_a",
            "entry": "Chao Dong, Chen Change Loy, Kaiming He, and Xiaoou Tang. Image super-resolution using deep convolutional networks. TPAMI, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dong%2C%20Chao%20Loy%2C%20Chen%20Change%20He%2C%20Kaiming%20Tang%2C%20Xiaoou%20Image%20super-resolution%20using%20deep%20convolutional%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dong%2C%20Chao%20Loy%2C%20Chen%20Change%20He%2C%20Kaiming%20Tang%2C%20Xiaoou%20Image%20super-resolution%20using%20deep%20convolutional%20networks%202016"
        },
        {
            "id": "Foi_et+al_2007_a",
            "entry": "Alessandro Foi, Vladimir Katkovnik, and Karen Egiazarian. Pointwise shape-adaptive dct for highquality denoising and deblocking of grayscale and color images. TIP, May 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Foi%2C%20Alessandro%20Katkovnik%2C%20Vladimir%20Egiazarian%2C%20Karen%20Pointwise%20shape-adaptive%20dct%20for%20highquality%20denoising%20and%20deblocking%20of%20grayscale%20and%20color%20images%202007-05",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Foi%2C%20Alessandro%20Katkovnik%2C%20Vladimir%20Egiazarian%2C%20Karen%20Pointwise%20shape-adaptive%20dct%20for%20highquality%20denoising%20and%20deblocking%20of%20grayscale%20and%20color%20images%202007-05"
        },
        {
            "id": "Haris_et+al_2018_a",
            "entry": "Muhammad Haris, Greg Shakhnarovich, and Norimichi Ukita. Deep back-projection networks for super-resolution. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Haris%2C%20Muhammad%20Shakhnarovich%2C%20Greg%20Ukita%2C%20Norimichi%20Deep%20back-projection%20networks%20for%20super-resolution%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Haris%2C%20Muhammad%20Shakhnarovich%2C%20Greg%20Ukita%2C%20Norimichi%20Deep%20back-projection%20networks%20for%20super-resolution%202018"
        },
        {
            "id": "He_et+al_2016_a",
            "entry": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "Hu_et+al_2017_a",
            "entry": "Jie Hu, Li Shen, and Gang Sun. Squeeze-and-excitation networks. arXiv preprint arXiv:1709.01507, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1709.01507"
        },
        {
            "id": "Huang_et+al_2015_a",
            "entry": "Jia-Bin Huang, Abhishek Singh, and Narendra Ahuja. Single image super-resolution from transformed self-exemplars. In CVPR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20Jia-Bin%20Singh%2C%20Abhishek%20Ahuja%2C%20Narendra%20Single%20image%20super-resolution%20from%20transformed%20self-exemplars%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20Jia-Bin%20Singh%2C%20Abhishek%20Ahuja%2C%20Narendra%20Single%20image%20super-resolution%20from%20transformed%20self-exemplars%202015"
        },
        {
            "id": "Ioffe_2015_a",
            "entry": "Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In ICML, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ioffe%2C%20Sergey%20Szegedy%2C%20Christian%20Batch%20normalization%3A%20Accelerating%20deep%20network%20training%20by%20reducing%20internal%20covariate%20shift%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ioffe%2C%20Sergey%20Szegedy%2C%20Christian%20Batch%20normalization%3A%20Accelerating%20deep%20network%20training%20by%20reducing%20internal%20covariate%20shift%202015"
        },
        {
            "id": "Kim_2016_a",
            "entry": "Jiwon Kim, Jung Kwon Lee, and Kyoung Mu Lee. Accurate image super-resolution using very deep convolutional networks. In CVPR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kim%2C%20Jiwon%20Lee%2C%20Jung%20Kwon%20and%20Kyoung%20Mu%20Lee.%20Accurate%20image%20super-resolution%20using%20very%20deep%20convolutional%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kim%2C%20Jiwon%20Lee%2C%20Jung%20Kwon%20and%20Kyoung%20Mu%20Lee.%20Accurate%20image%20super-resolution%20using%20very%20deep%20convolutional%20networks%202016"
        },
        {
            "id": "Kingma_2014_a",
            "entry": "Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Diederik%20Ba%2C%20Jimmy%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20Diederik%20Ba%2C%20Jimmy%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202014"
        },
        {
            "id": "Lai_et+al_2017_a",
            "entry": "Wei-Sheng Lai, Jia-Bin Huang, Narendra Ahuja, and Ming-Hsuan Yang. Deep laplacian pyramid networks for fast and accurate super-resolution. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lai%2C%20Wei-Sheng%20Huang%2C%20Jia-Bin%20Ahuja%2C%20Narendra%20Yang%2C%20Ming-Hsuan%20Deep%20laplacian%20pyramid%20networks%20for%20fast%20and%20accurate%20super-resolution%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lai%2C%20Wei-Sheng%20Huang%2C%20Jia-Bin%20Ahuja%2C%20Narendra%20Yang%2C%20Ming-Hsuan%20Deep%20laplacian%20pyramid%20networks%20for%20fast%20and%20accurate%20super-resolution%202017"
        },
        {
            "id": "Ledig_et+al_2017_a",
            "entry": "Christian Ledig, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, and Wenzhe Shi. Photorealistic single image super-resolution using a generative adversarial network. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ledig%2C%20Christian%20Theis%2C%20Lucas%20Huszar%2C%20Ferenc%20Caballero%2C%20Jose%20Photorealistic%20single%20image%20super-resolution%20using%20a%20generative%20adversarial%20network%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ledig%2C%20Christian%20Theis%2C%20Lucas%20Huszar%2C%20Ferenc%20Caballero%2C%20Jose%20Photorealistic%20single%20image%20super-resolution%20using%20a%20generative%20adversarial%20network%202017"
        },
        {
            "id": "Lim_et+al_2017_a",
            "entry": "Bee Lim, Sanghyun Son, Heewon Kim, Seungjun Nah, and Kyoung Mu Lee. Enhanced deep residual networks for single image super-resolution. In CVPRW, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lim%2C%20Bee%20Son%2C%20Sanghyun%20Kim%2C%20Heewon%20Seungjun%20Nah%2C%20and%20Kyoung%20Mu%20Lee.%20Enhanced%20deep%20residual%20networks%20for%20single%20image%20super-resolution%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lim%2C%20Bee%20Son%2C%20Sanghyun%20Kim%2C%20Heewon%20Seungjun%20Nah%2C%20and%20Kyoung%20Mu%20Lee.%20Enhanced%20deep%20residual%20networks%20for%20single%20image%20super-resolution%202017"
        },
        {
            "id": "Liu_et+al_2018_a",
            "entry": "Ding Liu, Bihan Wen, Yuchen Fan, Chen Change Loy, and Thomas S Huang. Non-local recurrent network for image restoration. In NIPS, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Ding%20Wen%2C%20Bihan%20Fan%2C%20Yuchen%20Loy%2C%20Chen%20Change%20Non-local%20recurrent%20network%20for%20image%20restoration%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Ding%20Wen%2C%20Bihan%20Fan%2C%20Yuchen%20Loy%2C%20Chen%20Change%20Non-local%20recurrent%20network%20for%20image%20restoration%202018"
        },
        {
            "id": "Ma_et+al_2017_a",
            "entry": "Kede Ma, Zhengfang Duanmu, Qingbo Wu, Zhou Wang, Hongwei Yong, Hongliang Li, and Lei Zhang. Waterloo exploration database: New challenges for image quality assessment models. TIP, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ma%2C%20Kede%20Duanmu%2C%20Zhengfang%20Wu%2C%20Qingbo%20Wang%2C%20Zhou%20Waterloo%20exploration%20database%3A%20New%20challenges%20for%20image%20quality%20assessment%20models%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ma%2C%20Kede%20Duanmu%2C%20Zhengfang%20Wu%2C%20Qingbo%20Wang%2C%20Zhou%20Waterloo%20exploration%20database%3A%20New%20challenges%20for%20image%20quality%20assessment%20models%202017"
        },
        {
            "id": "Mao_et+al_2016_a",
            "entry": "Xiaojiao Mao, Chunhua Shen, and Yu-Bin Yang. Image restoration using very deep convolutional encoder-decoder networks with symmetric skip connections. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mao%2C%20Xiaojiao%20Shen%2C%20Chunhua%20Yang%2C%20Yu-Bin%20Image%20restoration%20using%20very%20deep%20convolutional%20encoder-decoder%20networks%20with%20symmetric%20skip%20connections%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mao%2C%20Xiaojiao%20Shen%2C%20Chunhua%20Yang%2C%20Yu-Bin%20Image%20restoration%20using%20very%20deep%20convolutional%20encoder-decoder%20networks%20with%20symmetric%20skip%20connections%202016"
        },
        {
            "id": "Martin_et+al_2001_a",
            "entry": "David Martin, Charless Fowlkes, Doron Tal, and Jitendra Malik. A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics. In ICCV, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Martin%2C%20David%20Fowlkes%2C%20Charless%20Tal%2C%20Doron%20Malik%2C%20Jitendra%20A%20database%20of%20human%20segmented%20natural%20images%20and%20its%20application%20to%20evaluating%20segmentation%20algorithms%20and%20measuring%20ecological%20statistics%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Martin%2C%20David%20Fowlkes%2C%20Charless%20Tal%2C%20Doron%20Malik%2C%20Jitendra%20A%20database%20of%20human%20segmented%20natural%20images%20and%20its%20application%20to%20evaluating%20segmentation%20algorithms%20and%20measuring%20ecological%20statistics%202001"
        },
        {
            "id": "Matsui_et+al_2017_a",
            "entry": "Yusuke Matsui, Kota Ito, Yuji Aramaki, Azuma Fujimoto, Toru Ogawa, Toshihiko Yamasaki, and Kiyoharu Aizawa. Sketch-based manga retrieval using manga109 dataset. Multimedia Tools and Applications, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Matsui%2C%20Yusuke%20Ito%2C%20Kota%20Aramaki%2C%20Yuji%20Fujimoto%2C%20Azuma%20Sketch-based%20manga%20retrieval%20using%20manga109%20dataset.%20Multimedia%20Tools%20and%20Applications%202017"
        },
        {
            "id": "Nair_2010_a",
            "entry": "Vinod Nair and Geoffrey E Hinton. Rectified linear units improve restricted boltzmann machines. In ICML, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nair%2C%20Vinod%20Hinton%2C%20Geoffrey%20E.%20Rectified%20linear%20units%20improve%20restricted%20boltzmann%20machines%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nair%2C%20Vinod%20Hinton%2C%20Geoffrey%20E.%20Rectified%20linear%20units%20improve%20restricted%20boltzmann%20machines%202010"
        },
        {
            "id": "Paszke_et+al_2017_a",
            "entry": "Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Paszke%2C%20Adam%20Gross%2C%20Sam%20Chintala%2C%20Soumith%20Chanan%2C%20Gregory%20Automatic%20differentiation%20in%20pytorch%202017"
        },
        {
            "id": "Sheikh_et+al_2005_a",
            "entry": "Hamid R Sheikh, Zhou Wang, Lawrence Cormack, and Alan C Bovik. Live image quality assessment database release 2 (2005), 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hamid%20R%20Sheikh%20Zhou%20Wang%20Lawrence%20Cormack%20and%20Alan%20C%20Bovik%20Live%20image%20quality%20assessment%20database%20release%202%202005%202005"
        },
        {
            "id": "Tai_et+al_2017_a",
            "entry": "Ying Tai, Jian Yang, Xiaoming Liu, and Chunyan Xu. Memnet: A persistent memory network for image restoration. In ICCV, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tai%2C%20Ying%20Yang%2C%20Jian%20Liu%2C%20Xiaoming%20Xu%2C%20Chunyan%20Memnet%3A%20A%20persistent%20memory%20network%20for%20image%20restoration%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tai%2C%20Ying%20Yang%2C%20Jian%20Liu%2C%20Xiaoming%20Xu%2C%20Chunyan%20Memnet%3A%20A%20persistent%20memory%20network%20for%20image%20restoration%202017"
        },
        {
            "id": "Timofte_et+al_2017_a",
            "entry": "Radu Timofte, Eirikur Agustsson, Luc Van Gool, Ming-Hsuan Yang, Lei Zhang, Bee Lim, Sanghyun Son, Heewon Kim, Seungjun Nah, Kyoung Mu Lee, et al. Ntire 2017 challenge on single image super-resolution: Methods and results. In CVPRW, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Timofte%2C%20Radu%20Agustsson%2C%20Eirikur%20Gool%2C%20Luc%20Van%20Yang%2C%20Ming-Hsuan%20Seungjun%20Nah%2C%20Kyoung%20Mu%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Timofte%2C%20Radu%20Agustsson%2C%20Eirikur%20Gool%2C%20Luc%20Van%20Yang%2C%20Ming-Hsuan%20Seungjun%20Nah%2C%20Kyoung%20Mu%202017"
        },
        {
            "id": "Vincent_et+al_2008_a",
            "entry": "Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol. Extracting and composing robust features with denoising autoencoders. In ICML, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vincent%2C%20Pascal%20Larochelle%2C%20Hugo%20Bengio%2C%20Yoshua%20Manzagol%2C%20Pierre-Antoine%20Extracting%20and%20composing%20robust%20features%20with%20denoising%20autoencoders%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vincent%2C%20Pascal%20Larochelle%2C%20Hugo%20Bengio%2C%20Yoshua%20Manzagol%2C%20Pierre-Antoine%20Extracting%20and%20composing%20robust%20features%20with%20denoising%20autoencoders%202008"
        },
        {
            "id": "Wang_et+al_2017_a",
            "entry": "Fei Wang, Mengqing Jiang, Chen Qian, Shuo Yang, Cheng Li, Honggang Zhang, Xiaogang Wang, and Xiaoou Tang. Residual attention network for image classification. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Fei%20Jiang%2C%20Mengqing%20Qian%2C%20Chen%20Yang%2C%20Shuo%20Xiaogang%20Wang%2C%20and%20Xiaoou%20Tang.%20Residual%20attention%20network%20for%20image%20classification%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Fei%20Jiang%2C%20Mengqing%20Qian%2C%20Chen%20Yang%2C%20Shuo%20Xiaogang%20Wang%2C%20and%20Xiaoou%20Tang.%20Residual%20attention%20network%20for%20image%20classification%202017"
        },
        {
            "id": "Wang_2018_a",
            "entry": "Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He. Non-local neural networks. In CVPR, 2018a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Xiaolong%20Girshick%2C%20Ross%20Abhinav%20Gupta%2C%20and%20Kaiming%20He.%20Non-local%20neural%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Xiaolong%20Girshick%2C%20Ross%20Abhinav%20Gupta%2C%20and%20Kaiming%20He.%20Non-local%20neural%20networks%202018"
        },
        {
            "id": "Wang_et+al_2018_b",
            "entry": "Xintao Wang, Ke Yu, Shixiang Wu, Jinjin Gu, Yihao Liu, Chao Dong, Chen Change Loy, Yu Qiao, and Xiaoou Tang. Esrgan: Enhanced super-resolution generative adversarial networks. In ECCVW, 2018b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Xintao%20Yu%2C%20Ke%20Wu%2C%20Shixiang%20Gu%2C%20Jinjin%20Esrgan%3A%20Enhanced%20super-resolution%20generative%20adversarial%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Xintao%20Yu%2C%20Ke%20Wu%2C%20Shixiang%20Gu%2C%20Jinjin%20Esrgan%3A%20Enhanced%20super-resolution%20generative%20adversarial%20networks%202018"
        },
        {
            "id": "Wang_et+al_2018_c",
            "entry": "Yifan Wang, Federico Perazzi, Brian McWilliams, Alexander Sorkine-Hornung, Olga SorkineHornung, and Christopher Schroers. A fully progressive approach to single-image superresolution. In CVPRW, 2018c.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Yifan%20Perazzi%2C%20Federico%20McWilliams%2C%20Brian%20Sorkine-Hornung%2C%20Alexander%20A%20fully%20progressive%20approach%20to%20single-image%20superresolution%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Yifan%20Perazzi%2C%20Federico%20McWilliams%2C%20Brian%20Sorkine-Hornung%2C%20Alexander%20A%20fully%20progressive%20approach%20to%20single-image%20superresolution%202018"
        },
        {
            "id": "Wang_et+al_2004_a",
            "entry": "Zhou Wang, Alan C Bovik, Hamid R Sheikh, and Eero P Simoncelli. Image quality assessment: from error visibility to structural similarity. TIP, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Zhou%20Bovik%2C%20Alan%20C.%20Sheikh%2C%20Hamid%20R.%20Simoncelli%2C%20Eero%20P.%20Image%20quality%20assessment%3A%20from%20error%20visibility%20to%20structural%20similarity%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Zhou%20Bovik%2C%20Alan%20C.%20Sheikh%2C%20Hamid%20R.%20Simoncelli%2C%20Eero%20P.%20Image%20quality%20assessment%3A%20from%20error%20visibility%20to%20structural%20similarity%202004"
        },
        {
            "id": "Yang_et+al_2008_a",
            "entry": "Jianchao Yang, John Wright, Thomas Huang, and Yi Ma. Image super-resolution as sparse representation of raw image patches. In CVPR, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Jianchao%20Wright%2C%20John%20Huang%2C%20Thomas%20Ma%2C%20Yi%20Image%20super-resolution%20as%20sparse%20representation%20of%20raw%20image%20patches%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20Jianchao%20Wright%2C%20John%20Huang%2C%20Thomas%20Ma%2C%20Yi%20Image%20super-resolution%20as%20sparse%20representation%20of%20raw%20image%20patches%202008"
        },
        {
            "id": "All_2001_a",
            "entry": "All the results shown in the main paper are based on DIV2K training data. Here, we retrain our RNAN on small training sets for 5 tasks. In Table 8, for each task, we only refer the second best method from our main paper to compare. For training data, we use BSD400 (Martin et al., 2001) for color/gray-scale image denoising and demosaicing. We use 91 images in Yang et al. (2008) and 200 images in Martin et al. (2001) (denoted as SR291) for image compression artifacts reduction and super-resolution. FFDNet used BSD400 (Martin et al., 2001), 400 images from ImageNet Deng et al. (2009), and 4,744 images in Waterloo Exploration Database Ma et al. (2017). Here, \u2018BSD400+\u2019 is used to denote \u2018BSD400+ImageNet400+WED4744\u2019. According to Table 8, we use the same or even smaller training set for our RNAN and obtain better results for 5 tasks. These experiments demonstrate the effectiveness of our RNAN for general image restoration tasks.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=All%20the%20results%20shown%20in%20the%20main%20paper%20are%20based%20on%20DIV2K%20training%20data%20Here%20we%20retrain%20our%20RNAN%20on%20small%20training%20sets%20for%205%20tasks%20In%20Table%208%20for%20each%20task%20we%20only%20refer%20the%20second%20best%20method%20from%20our%20main%20paper%20to%20compare%20For%20training%20data%20we%20use%20BSD400%20Martin%20et%20al%202001%20for%20colorgrayscale%20image%20denoising%20and%20demosaicing%20We%20use%2091%20images%20in%20Yang%20et%20al%202008%20and%20200%20images%20in%20Martin%20et%20al%202001%20denoted%20as%20SR291%20for%20image%20compression%20artifacts%20reduction%20and%20superresolution%20FFDNet%20used%20BSD400%20Martin%20et%20al%202001%20400%20images%20from%20ImageNet%20Deng%20et%20al%202009%20and%204744%20images%20in%20Waterloo%20Exploration%20Database%20Ma%20et%20al%202017%20Here%20BSD400%20is%20used%20to%20denote%20BSD400ImageNet400WED4744%20According%20to%20Table%208%20we%20use%20the%20same%20or%20even%20smaller%20training%20set%20for%20our%20RNAN%20and%20obtain%20better%20results%20for%205%20tasks%20These%20experiments%20demonstrate%20the%20effectiveness%20of%20our%20RNAN%20for%20general%20image%20restoration%20tasks",
            "oa_query": "https://api.scholarcy.com/oa_version?query=All%20the%20results%20shown%20in%20the%20main%20paper%20are%20based%20on%20DIV2K%20training%20data%20Here%20we%20retrain%20our%20RNAN%20on%20small%20training%20sets%20for%205%20tasks%20In%20Table%208%20for%20each%20task%20we%20only%20refer%20the%20second%20best%20method%20from%20our%20main%20paper%20to%20compare%20For%20training%20data%20we%20use%20BSD400%20Martin%20et%20al%202001%20for%20colorgrayscale%20image%20denoising%20and%20demosaicing%20We%20use%2091%20images%20in%20Yang%20et%20al%202008%20and%20200%20images%20in%20Martin%20et%20al%202001%20denoted%20as%20SR291%20for%20image%20compression%20artifacts%20reduction%20and%20superresolution%20FFDNet%20used%20BSD400%20Martin%20et%20al%202001%20400%20images%20from%20ImageNet%20Deng%20et%20al%202009%20and%204744%20images%20in%20Waterloo%20Exploration%20Database%20Ma%20et%20al%202017%20Here%20BSD400%20is%20used%20to%20denote%20BSD400ImageNet400WED4744%20According%20to%20Table%208%20we%20use%20the%20same%20or%20even%20smaller%20training%20set%20for%20our%20RNAN%20and%20obtain%20better%20results%20for%205%20tasks%20These%20experiments%20demonstrate%20the%20effectiveness%20of%20our%20RNAN%20for%20general%20image%20restoration%20tasks"
        }
    ]
}

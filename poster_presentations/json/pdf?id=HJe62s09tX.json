{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "UNSUPERVISED HYPERALIGNMENT FOR MULTILINGUAL WORD EMBEDDINGS",
        "date": 2018,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=HJe62s09tX"
        },
        "abstract": "We consider the problem of aligning continuous word representations, learned in multiple languages, to a common space. It was recently shown that, in the case of two languages, it is possible to learn such a mapping without supervision. This paper extends this line of work to the problem of aligning multiple languages to a common space. A solution is to independently map all languages to a pivot language. Unfortunately, this degrades the quality of indirect word translation. We thus propose a novel formulation that ensures composable mappings, leading to better alignments. We evaluate our method by jointly aligning word vectors in eleven languages, showing consistent improvement with indirect mappings while maintaining competitive performance on direct word translation."
    },
    "keywords": [
        {
            "term": "word embedding",
            "url": "https://en.wikipedia.org/wiki/word_embedding"
        },
        {
            "term": "nearest neighbor",
            "url": "https://en.wikipedia.org/wiki/nearest_neighbor"
        },
        {
            "term": "common space",
            "url": "https://en.wikipedia.org/wiki/common_space"
        },
        {
            "term": "stochastic gradient descent",
            "url": "https://en.wikipedia.org/wiki/stochastic_gradient_descent"
        },
        {
            "term": "word vector",
            "url": "https://en.wikipedia.org/wiki/word_vector"
        }
    ],
    "abbreviations": {
        "NN": "nearest neighbor",
        "UMH": "Unsupervised Multilingual Hyperalignment",
        "OT": "Optimal Transport",
        "SGD": "stochastic gradient descent"
    },
    "highlights": [
        "Pre-trained continuous representations of words are standard building blocks of many natural language processing and machine learning systems (<a class=\"ref-link\" id=\"cMikolov_et+al_2013_b\" href=\"#rMikolov_et+al_2013_b\"><a class=\"ref-link\" id=\"cMikolov_et+al_2013_b\" href=\"#rMikolov_et+al_2013_b\"><a class=\"ref-link\" id=\"cMikolov_et+al_2013_b\" href=\"#rMikolov_et+al_2013_b\">Mikolov et al, 2013b</a></a></a>)",
        "There has been an increasing interest in mapping these pre-trained vectors in a common space (Xing et al, 2015b; <a class=\"ref-link\" id=\"cArtetxe_et+al_2017_a\" href=\"#rArtetxe_et+al_2017_a\">Artetxe et al, 2017</a>), resulting in many publicly available embeddings in many languages mapped into a single common vector space (<a class=\"ref-link\" id=\"cSmith_et+al_2017_a\" href=\"#rSmith_et+al_2017_a\">Smith et al, 2017</a>; Conneau et al, 2017; <a class=\"ref-link\" id=\"cJoulin_et+al_2018_a\" href=\"#rJoulin_et+al_2018_a\">Joulin et al, 2018</a>)",
        "We use normalized fastText word vectors trained on the Wikipedia Corpus (Bojanowski et al, 2016)",
        "Table 3 shows the performance on indirect word translation with English as a pivot language",
        "This paper introduces an unsupervised multilingual alignment method that maps every language into a common space while minimizing the impact on indirect word translation",
        "We show that a simple extension of a bilingual formulation significantly reduces the drop of performance of indirect word translation"
    ],
    "key_statements": [
        "Pre-trained continuous representations of words are standard building blocks of many natural language processing and machine learning systems (<a class=\"ref-link\" id=\"cMikolov_et+al_2013_b\" href=\"#rMikolov_et+al_2013_b\"><a class=\"ref-link\" id=\"cMikolov_et+al_2013_b\" href=\"#rMikolov_et+al_2013_b\"><a class=\"ref-link\" id=\"cMikolov_et+al_2013_b\" href=\"#rMikolov_et+al_2013_b\">Mikolov et al, 2013b</a></a></a>)",
        "There has been an increasing interest in mapping these pre-trained vectors in a common space (Xing et al, 2015b; <a class=\"ref-link\" id=\"cArtetxe_et+al_2017_a\" href=\"#rArtetxe_et+al_2017_a\">Artetxe et al, 2017</a>), resulting in many publicly available embeddings in many languages mapped into a single common vector space (<a class=\"ref-link\" id=\"cSmith_et+al_2017_a\" href=\"#rSmith_et+al_2017_a\">Smith et al, 2017</a>; Conneau et al, 2017; <a class=\"ref-link\" id=\"cJoulin_et+al_2018_a\" href=\"#rJoulin_et+al_2018_a\">Joulin et al, 2018</a>)",
        "We propose a novel approach to align multiple languages simultaneously in a common space in a way that enforces transitive translations",
        "Our method relies on constraining word translations to be coherent between languages when mapped to the common space",
        "We use normalized fastText word vectors trained on the Wikipedia Corpus (Bojanowski et al, 2016)",
        "Table 3 shows the performance on indirect word translation with English as a pivot language",
        "We compute a minimum spanning tree on the matrix of losses given by Unsupervised Multilingual Hyperalignment between every pairs of languages, except English",
        "This paper introduces an unsupervised multilingual alignment method that maps every language into a common space while minimizing the impact on indirect word translation",
        "We show that a simple extension of a bilingual formulation significantly reduces the drop of performance of indirect word translation"
    ],
    "summary": [
        "Pre-trained continuous representations of words are standard building blocks of many natural language processing and machine learning systems (<a class=\"ref-link\" id=\"cMikolov_et+al_2013_b\" href=\"#rMikolov_et+al_2013_b\"><a class=\"ref-link\" id=\"cMikolov_et+al_2013_b\" href=\"#rMikolov_et+al_2013_b\"><a class=\"ref-link\" id=\"cMikolov_et+al_2013_b\" href=\"#rMikolov_et+al_2013_b\">Mikolov et al, 2013b</a></a></a>).",
        "Two sets of pre-trained vectors in different languages can be aligned to some extent: a linear mapping between the two sets of embeddings is enough to produce decent word translations.",
        "Joulin et al (2018) has shown that directly minimizing a loss inspired by the CSLS criterion significantly improve the quality of the retrieved word translations.",
        "In the setting of unsupervised bilingual alignment, the assignment matrix P is unknown and must be learned jointly with the mapping Q.",
        "We propose an unsupervised approach to jointly align N sets of vectors to a unique common space while preserving the quality of word translation between every pair of languages.",
        "Since the work of <a class=\"ref-link\" id=\"cMikolov_et+al_2013_a\" href=\"#rMikolov_et+al_2013_a\">Mikolov et al (2013a</a>), many have proposed different approaches to align word vectors with different degrees of supervision, from fully supervised (<a class=\"ref-link\" id=\"cDinu_et+al_2014_a\" href=\"#rDinu_et+al_2014_a\">Dinu et al, 2014</a>; <a class=\"ref-link\" id=\"cXing_et+al_2015_a\" href=\"#rXing_et+al_2015_a\">Xing et al, 2015a</a>; <a class=\"ref-link\" id=\"cArtetxe_et+al_2016_a\" href=\"#rArtetxe_et+al_2016_a\">Artetxe et al, 2016</a>; <a class=\"ref-link\" id=\"cJoulin_et+al_2018_a\" href=\"#rJoulin_et+al_2018_a\"><a class=\"ref-link\" id=\"cJoulin_et+al_2018_a\" href=\"#rJoulin_et+al_2018_a\">Joulin et al, 2018</a></a>) to little supervision (<a class=\"ref-link\" id=\"cSmith_et+al_2017_a\" href=\"#rSmith_et+al_2017_a\">Smith et al, 2017</a>; <a class=\"ref-link\" id=\"cArtetxe_et+al_2017_a\" href=\"#rArtetxe_et+al_2017_a\">Artetxe et al, 2017</a>) and even fully unsupervised (Zhang et al, 2017a; Conneau et al, 2017; <a class=\"ref-link\" id=\"cHoshen_2018_a\" href=\"#rHoshen_2018_a\"><a class=\"ref-link\" id=\"cHoshen_2018_a\" href=\"#rHoshen_2018_a\">Hoshen and Wolf, 2018</a></a>).",
        "<a class=\"ref-link\" id=\"cNakashole_2017_a\" href=\"#rNakashole_2017_a\">Nakashole and Flauger (2017</a>) showed that constraining coherent word alignments between triplets of nearby languages improves the quality of induced bilingual lexicons.",
        "We consider as baselines several bilingual alignment methods that are either supervised, i.e., Orthogonal Procrustes, GeoMM (<a class=\"ref-link\" id=\"cJawanpuria_et+al_2018_a\" href=\"#rJawanpuria_et+al_2018_a\">Jawanpuria et al, 2018</a>) and RCSLS (<a class=\"ref-link\" id=\"cJoulin_et+al_2018_a\" href=\"#rJoulin_et+al_2018_a\"><a class=\"ref-link\" id=\"cJoulin_et+al_2018_a\" href=\"#rJoulin_et+al_2018_a\">Joulin et al, 2018</a></a>), or unsupervised, i.e., Adversarial (Conneau et al, 2017), ICP (<a class=\"ref-link\" id=\"cHoshen_2018_a\" href=\"#rHoshen_2018_a\"><a class=\"ref-link\" id=\"cHoshen_2018_a\" href=\"#rHoshen_2018_a\">Hoshen and Wolf, 2018</a></a>), Gromov-Wasserstein (GW) (<a class=\"ref-link\" id=\"cAlvarez-Melis_2018_a\" href=\"#rAlvarez-Melis_2018_a\">Alvarez-Melis and Jaakkola, 2018</a>) and Wasserstein Procrustes (\u201cWass Proc.\u201d) (<a class=\"ref-link\" id=\"cGrave_et+al_2018_a\" href=\"#rGrave_et+al_2018_a\">Grave et al, 2018</a>).",
        "Table 3 shows the performance on indirect word translation with English as a pivot language.",
        "We compare UMH with uniform weights on direct and indirect word translation with a NN criterion.",
        "Table 5 shows the impact of our initialization on the performance of UMH for direct and indirect bilingual alignment.",
        "Our initialization (Gromov-Wasserstein) outperforms the convex relaxation on what it is optimized for but this leads to a drop of performance on indirect translation.",
        "We compute a minimum spanning tree on the matrix of losses given by UMH between every pairs of languages, except English.",
        "This paper introduces an unsupervised multilingual alignment method that maps every language into a common space while minimizing the impact on indirect word translation.",
        "We show that a simple extension of a bilingual formulation significantly reduces the drop of performance of indirect word translation.",
        "Our current approach scales relatively well with the number of languages, but it is not clear if such a simple approach would be enough to jointly learn the alignment of hundreds of languages"
    ],
    "headline": "This paper extends this line of work to the problem of aligning multiple languages to a common space",
    "reference_links": [
        {
            "id": "Altschuler_et+al_2017_a",
            "entry": "Jason Altschuler, Jonathan Weed, and Philippe Rigollet. Near-linear time approximation algorithms for optimal transport via sinkhorn iteration. In Advances in Neural Information Processing Systems, pages 1964\u20131974, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Altschuler%2C%20Jason%20Weed%2C%20Jonathan%20Rigollet%2C%20Philippe%20Near-linear%20time%20approximation%20algorithms%20for%20optimal%20transport%20via%20sinkhorn%20iteration%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Altschuler%2C%20Jason%20Weed%2C%20Jonathan%20Rigollet%2C%20Philippe%20Near-linear%20time%20approximation%20algorithms%20for%20optimal%20transport%20via%20sinkhorn%20iteration%202017"
        },
        {
            "id": "Alvarez-Melis_2018_a",
            "entry": "David Alvarez-Melis and Tommi Jaakkola. Gromov-wasserstein alignment of word embedding spaces. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Alvarez-Melis%2C%20David%20Jaakkola%2C%20Tommi%20Gromov-wasserstein%20alignment%20of%20word%20embedding%20spaces%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Alvarez-Melis%2C%20David%20Jaakkola%2C%20Tommi%20Gromov-wasserstein%20alignment%20of%20word%20embedding%20spaces%202018"
        },
        {
            "id": "Artetxe_et+al_2016_a",
            "entry": "Mikel Artetxe, Gorka Labaka, and Eneko Agirre. Learning principled bilingual mappings of word embeddings while preserving monolingual invariance. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2289\u20132294, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Artetxe%2C%20Mikel%20Labaka%2C%20Gorka%20Agirre%2C%20Eneko%20Learning%20principled%20bilingual%20mappings%20of%20word%20embeddings%20while%20preserving%20monolingual%20invariance%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Artetxe%2C%20Mikel%20Labaka%2C%20Gorka%20Agirre%2C%20Eneko%20Learning%20principled%20bilingual%20mappings%20of%20word%20embeddings%20while%20preserving%20monolingual%20invariance%202016"
        },
        {
            "id": "Artetxe_et+al_2017_a",
            "entry": "Mikel Artetxe, Gorka Labaka, and Eneko Agirre. Learning bilingual word embeddings with (almost) no bilingual data. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), volume 1, pages 451\u2013462, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Artetxe%2C%20Mikel%20Labaka%2C%20Gorka%20Agirre%2C%20Eneko%20Learning%20bilingual%20word%20embeddings%20with%20%28almost%29%20no%20bilingual%20data%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Artetxe%2C%20Mikel%20Labaka%2C%20Gorka%20Agirre%2C%20Eneko%20Learning%20bilingual%20word%20embeddings%20with%20%28almost%29%20no%20bilingual%20data%202017"
        },
        {
            "id": "Artetxe_et+al_2018_a",
            "entry": "Mikel Artetxe, Gorka Labaka, and Eneko Agirre. A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings. arXiv preprint arXiv:1805.06297, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1805.06297"
        },
        {
            "id": "Bojanowski_et+al_1607_a",
            "entry": "P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov. Enriching word vectors with subword information. arXiv preprint, arXiv:1607.04606, 2016. URL https://arxiv.org/abs/1607.04606.",
            "url": "https://arxiv.org/abs/1607.04606",
            "arxiv_url": "https://arxiv.org/pdf/1607.04606"
        },
        {
            "id": "Bronstein_et+al_2006_a",
            "entry": "Alexander M Bronstein, Michael M Bronstein, and Ron Kimmel. Generalized multidimensional scaling: a framework for isometry-invariant partial surface matching. Proceedings of the National Academy of Sciences, 103(5):1168\u20131172, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bronstein%2C%20Alexander%20M.%20Bronstein%2C%20Michael%20M.%20Kimmel%2C%20Ron%20Generalized%20multidimensional%20scaling%3A%20a%20framework%20for%20isometry-invariant%20partial%20surface%20matching%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bronstein%2C%20Alexander%20M.%20Bronstein%2C%20Michael%20M.%20Kimmel%2C%20Ron%20Generalized%20multidimensional%20scaling%3A%20a%20framework%20for%20isometry-invariant%20partial%20surface%20matching%202006"
        },
        {
            "id": "Cao_et+al_2016_a",
            "entry": "Hailong Cao, Tiejun Zhao, Shu Zhang, and Yao Meng. A distribution-based model to learn bilingual word embeddings. In Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 1818\u20131827, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cao%2C%20Hailong%20Zhao%2C%20Tiejun%20Zhang%2C%20Shu%20Meng%2C%20Yao%20A%20distribution-based%20model%20to%20learn%20bilingual%20word%20embeddings%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cao%2C%20Hailong%20Zhao%2C%20Tiejun%20Zhang%2C%20Shu%20Meng%2C%20Yao%20A%20distribution-based%20model%20to%20learn%20bilingual%20word%20embeddings%202016"
        },
        {
            "id": "Chen_2018_a",
            "entry": "Xilun Chen and Claire Cardie. Unsupervised multilingual word embeddings. arXiv preprint arXiv:1808.08933, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1808.08933"
        },
        {
            "id": "Collobert_et+al_2011_a",
            "entry": "Ronan Collobert, Jason Weston, Leon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. Natural language processing (almost) from scratch. Journal of Machine Learning Research, 12(Aug):2493\u20132537, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Collobert%2C%20Ronan%20Weston%2C%20Jason%20Bottou%2C%20Leon%20Karlen%2C%20Michael%20Natural%20language%20processing%20%28almost%29%20from%20scratch%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Collobert%2C%20Ronan%20Weston%2C%20Jason%20Bottou%2C%20Leon%20Karlen%2C%20Michael%20Natural%20language%20processing%20%28almost%29%20from%20scratch%202011"
        },
        {
            "id": "Alexis_2017_a",
            "entry": "Alexis Conneau, Guillaume Lample, Marc\u2019Aurelio Ranzato, Ludovic Denoyer, and Herve Jegou. Word translation without parallel data. arXiv preprint arXiv:1710.04087, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.04087"
        },
        {
            "id": "Cuturi_2013_a",
            "entry": "M. Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. Advances in neural information processing systems, pages 22922300, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cuturi%2C%20M.%20Sinkhorn%20distances%3A%20Lightspeed%20computation%20of%20optimal%20transport.%20Advances%20in%20neural%20information%20processing%20systems%202013"
        },
        {
            "id": "Deerwester_et+al_1990_a",
            "entry": "Scott Deerwester, Susan T Dumais, George W Furnas, Thomas K Landauer, and Richard Harshman. Indexing by latent semantic analysis. Journal of the American society for information science, 41 (6):391\u2013407, 1990.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Deerwester%2C%20Scott%20Dumais%2C%20Susan%20T.%20Furnas%2C%20George%20W.%20Landauer%2C%20Thomas%20K.%20Indexing%20by%20latent%20semantic%20analysis%201990",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Deerwester%2C%20Scott%20Dumais%2C%20Susan%20T.%20Furnas%2C%20George%20W.%20Landauer%2C%20Thomas%20K.%20Indexing%20by%20latent%20semantic%20analysis%201990"
        },
        {
            "id": "Dinu_et+al_2014_a",
            "entry": "Georgiana Dinu, Angeliki Lazaridou, and Marco Baroni. Improving zero-shot learning by mitigating the hubness problem. arXiv preprint arXiv:1412.6568, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6568"
        },
        {
            "id": "Edelman_et+al_1998_a",
            "entry": "Alan Edelman, Tomas A Arias, and Steven T Smith. The geometry of algorithms with orthogonality constraints. SIAM journal on Matrix Analysis and Applications, 20(2):303\u2013353, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Edelman%2C%20Alan%20Arias%2C%20Tomas%20A.%20Smith%2C%20Steven%20T.%20The%20geometry%20of%20algorithms%20with%20orthogonality%20constraints%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Edelman%2C%20Alan%20Arias%2C%20Tomas%20A.%20Smith%2C%20Steven%20T.%20The%20geometry%20of%20algorithms%20with%20orthogonality%20constraints%201998"
        },
        {
            "id": "Goodall_1991_a",
            "entry": "C. Goodall. Procrustes methods in the statistical analysis of shape. Journal of the Royal Statistical Society. Series B (Methodological), pages 285339, 1991.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodall%2C%20C.%20Procrustes%20methods%20in%20the%20statistical%20analysis%20of%20shape%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodall%2C%20C.%20Procrustes%20methods%20in%20the%20statistical%20analysis%20of%20shape%201991"
        },
        {
            "id": "Goodfellow_et+al_2014_a",
            "entry": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems, pages 2672\u20132680, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "Gower_2004_a",
            "entry": "John C Gower, Garmt B Dijksterhuis, et al. Procrustes problems, volume 30. Oxford University Press on Demand, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=John%20C%20Gower%20Garmt%20B%20Dijksterhuis%20et%20al%20Procrustes%20problems%20volume%2030%20Oxford%20University%20Press%20on%20Demand%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=John%20C%20Gower%20Garmt%20B%20Dijksterhuis%20et%20al%20Procrustes%20problems%20volume%2030%20Oxford%20University%20Press%20on%20Demand%202004"
        },
        {
            "id": "Grave_et+al_2018_a",
            "entry": "Edouard Grave, Armand Joulin, and Quentin Berthet. Unsupervised alignment of embeddings with wasserstein procrustes. CoRR, abs/1805.11222, 2018. URL http://arxiv.org/abs/1805.11222.",
            "url": "http://arxiv.org/abs/1805.11222",
            "arxiv_url": "https://arxiv.org/pdf/1805.11222"
        },
        {
            "id": "Gromov_2007_a",
            "entry": "Mikhail Gromov. Metric structures for Riemannian and non-Riemannian spaces. Springer Science & Business Media, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gromov%2C%20Mikhail%20Metric%20structures%20for%20Riemannian%20and%20non-Riemannian%20spaces%202007"
        },
        {
            "id": "Hoshen_2018_a",
            "entry": "Yedid Hoshen and Lior Wolf. An iterative closest point method for unsupervised word translation. arXiv preprint arXiv:1801.06126, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1801.06126"
        },
        {
            "id": "Huang_et+al_2007_a",
            "entry": "Gary B Huang, Vidit Jain, and Erik Learned-Miller. Unsupervised joint alignment of complex images. In 2007 IEEE 11th International Conference on Computer Vision, pages 1\u20138. IEEE, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20Gary%20B.%20Jain%2C%20Vidit%20Learned-Miller%2C%20Erik%20Unsupervised%20joint%20alignment%20of%20complex%20images%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20Gary%20B.%20Jain%2C%20Vidit%20Learned-Miller%2C%20Erik%20Unsupervised%20joint%20alignment%20of%20complex%20images%202007"
        },
        {
            "id": "Jawanpuria_et+al_2018_a",
            "entry": "Pratik Jawanpuria, Arjun Balgovind, Anoop Kunchukuttan, and Bamdev Mishra. Learning multilingual word embeddings in latent metric space: a geometric approach. arXiv preprint arXiv:1808.08773, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1808.08773"
        },
        {
            "id": "Joulin_et+al_2018_a",
            "entry": "Armand Joulin, Piotr Bojanowski, Tomas Mikolov, Herve Jegou, and Edouard Grave. Loss in translation: Learning bilingual word mapping with a retrieval criterion. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Joulin%2C%20Armand%20Bojanowski%2C%20Piotr%20Mikolov%2C%20Tomas%20Jegou%2C%20Herve%20Loss%20in%20translation%3A%20Learning%20bilingual%20word%20mapping%20with%20a%20retrieval%20criterion%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Joulin%2C%20Armand%20Bojanowski%2C%20Piotr%20Mikolov%2C%20Tomas%20Jegou%2C%20Herve%20Loss%20in%20translation%3A%20Learning%20bilingual%20word%20mapping%20with%20a%20retrieval%20criterion%202018"
        },
        {
            "id": "Lorbert_2012_a",
            "entry": "Alexander Lorbert and Peter J Ramadge. Kernel hyperalignment. In Advances in Neural Information Processing Systems, pages 1790\u20131798, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lorbert%2C%20Alexander%20Ramadge%2C%20Peter%20J.%20Kernel%20hyperalignment%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lorbert%2C%20Alexander%20Ramadge%2C%20Peter%20J.%20Kernel%20hyperalignment%202012"
        },
        {
            "id": "Memoli_2007_a",
            "entry": "Facundo Memoli. On the use of gromov-hausdorff distances for shape comparison. 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Memoli%2C%20Facundo%20On%20the%20use%20of%20gromov-hausdorff%20distances%20for%20shape%20comparison%202007"
        },
        {
            "id": "Memoli_2011_a",
            "entry": "Facundo Memoli. Gromov\u2013wasserstein distances and the metric approach to object matching. Foundations of computational mathematics, 11(4):417\u2013487, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Memoli%2C%20Facundo%20Gromov%E2%80%93wasserstein%20distances%20and%20the%20metric%20approach%20to%20object%20matching.%20Foundations%20of%20computational%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Memoli%2C%20Facundo%20Gromov%E2%80%93wasserstein%20distances%20and%20the%20metric%20approach%20to%20object%20matching.%20Foundations%20of%20computational%202011"
        },
        {
            "id": "Mikolov_et+al_2013_a",
            "entry": "T. Mikolov, Q. V. Le, and I Sutskever. Exploiting similarities among languages for machine translation. arXiv preprint, arXiv:1309.4168v, 2013a. URL https://arxiv.org/abs/1309.4168.",
            "url": "https://arxiv.org/abs/1309.4168",
            "arxiv_url": "https://arxiv.org/pdf/1309.4168"
        },
        {
            "id": "Mikolov_et+al_2013_b",
            "entry": "Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems, pages 3111\u20133119, 2013b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mikolov%2C%20Tomas%20Sutskever%2C%20Ilya%20Chen%2C%20Kai%20Corrado%2C%20Greg%20S.%20Distributed%20representations%20of%20words%20and%20phrases%20and%20their%20compositionality%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mikolov%2C%20Tomas%20Sutskever%2C%20Ilya%20Chen%2C%20Kai%20Corrado%2C%20Greg%20S.%20Distributed%20representations%20of%20words%20and%20phrases%20and%20their%20compositionality%202013"
        },
        {
            "id": "Nakashole_2017_a",
            "entry": "Ndapandula Nakashole and Raphael Flauger. Knowledge distillation for bilingual dictionary induction. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2497\u20132506, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nakashole%2C%20Ndapandula%20Flauger%2C%20Raphael%20Knowledge%20distillation%20for%20bilingual%20dictionary%20induction%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nakashole%2C%20Ndapandula%20Flauger%2C%20Raphael%20Knowledge%20distillation%20for%20bilingual%20dictionary%20induction%202017"
        },
        {
            "id": "Peyre_2016_a",
            "entry": "Gabriel Peyre, Marco Cuturi, and Justin Solomon. Gromov-wasserstein averaging of kernel and distance matrices. In Proceedings of ICML, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Peyre%2C%20Gabriel%20Cuturi%2C%20Marco%20and%20Justin%20Solomon.%20Gromov-wasserstein%20averaging%20of%20kernel%20and%20distance%20matrices%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Peyre%2C%20Gabriel%20Cuturi%2C%20Marco%20and%20Justin%20Solomon.%20Gromov-wasserstein%20averaging%20of%20kernel%20and%20distance%20matrices%202016"
        },
        {
            "id": "Peyre_2017_a",
            "entry": "Gabriel Peyre, Marco Cuturi, et al. Computational optimal transport. Technical report, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Peyre%2C%20Gabriel%20Cuturi%2C%20Marco%20Computational%20optimal%20transport%202017"
        },
        {
            "id": "Santambrogio_2015_a",
            "entry": "Filippo Santambrogio. Optimal transport for applied mathematicians. Birkauser, NY, pages 99\u2013102, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Santambrogio%2C%20Filippo%20Optimal%20transport%20for%20applied%20mathematicians%202015"
        },
        {
            "id": "Schnemann_1966_a",
            "entry": "P. H. Schnemann. A generalized solution of the orthogonal procrustes problem. Psychome- trika, 31(1):110, 1966.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schnemann%2C%20P.H.%20A%20generalized%20solution%20of%20the%20orthogonal%20procrustes%20problem%201966",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schnemann%2C%20P.H.%20A%20generalized%20solution%20of%20the%20orthogonal%20procrustes%20problem%201966"
        },
        {
            "id": "Smith_et+al_2017_a",
            "entry": "Samuel L Smith, David HP Turban, Steven Hamblin, and Nils Y Hammerla. Offline bilingual word vectors, orthogonal transformations and the inverted softmax. arXiv preprint arXiv:1702.03859, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.03859"
        },
        {
            "id": "Solomon_et+al_2016_a",
            "entry": "Justin Solomon, Gabriel Peyre, Vladimir G Kim, and Suvrit Sra. Entropic metric alignment for correspondence problems. ACM Transactions on Graphics (TOG), 35(4):72, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Solomon%2C%20Justin%20Peyre%2C%20Gabriel%20Kim%2C%20Vladimir%20G.%20Sra%2C%20Suvrit%20Entropic%20metric%20alignment%20for%20correspondence%20problems%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Solomon%2C%20Justin%20Peyre%2C%20Gabriel%20Kim%2C%20Vladimir%20G.%20Sra%2C%20Suvrit%20Entropic%20metric%20alignment%20for%20correspondence%20problems%202016"
        },
        {
            "id": "Villani_2003_a",
            "entry": "Cedric Villani. Topics in optimal transportation. Number 58. American Mathematical Soc., 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Villani%2C%20Cedric%20Topics%20in%20optimal%20transportation.%20Number%2058%202003"
        },
        {
            "id": "Xing_et+al_2015_a",
            "entry": "Chao Xing, Dong Wang, Chao Liu, and Yiye Lin. Normalized word embedding and orthogonal transform for bilingual word translation. In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1006\u20131011, 2015a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xing%2C%20Chao%20Wang%2C%20Dong%20Liu%2C%20Chao%20Lin%2C%20Yiye%20Normalized%20word%20embedding%20and%20orthogonal%20transform%20for%20bilingual%20word%20translation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xing%2C%20Chao%20Wang%2C%20Dong%20Liu%2C%20Chao%20Lin%2C%20Yiye%20Normalized%20word%20embedding%20and%20orthogonal%20transform%20for%20bilingual%20word%20translation%202015"
        },
        {
            "id": "Xing_et+al_1959_a",
            "entry": "Under review as a conference paper at ICLR 2019 D. Xing, C.and Wang, C. Liu, and Y Lin. Normalized word embedding and orthogonal transform for bilingual word translation. Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 10061011, 2015b. M. Zhang, Y. Liu, H. Luan, and M. Sun. Earth movers distance minimization for unsupervised bilingual lexicon induction. Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 19341945, 2017a. Meng Zhang, Yang Liu, Huanbo Luan, and Maosong Sun. Adversarial training for unsupervised bilingual lexicon induction. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), volume 1, pages 1959\u20131970, 2017b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xing%2C%20D.%20Wang%2C%20Cand%20Liu%2C%20C.%20Lin%2C%20Y.%20Under%20review%20as%20a%20conference%20paper%201959"
        }
    ]
}

{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "GRAPH WAVELET NEURAL NETWORK",
        "author": "Bingbing Xu, Huawei Shen, Qi Cao, Yunqi Qiu, & Xueqi Cheng, 1CAS Key Laboratory of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences; 2School of Computer and Control Engineering, University of Chinese Academy of Sciences Beijing, China {xubingbing,shenhuawei,caoqi,qiuyunqi,cxq}@ict.ac.cn",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=H1ewdiR5tQ"
        },
        "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed."
    },
    "keywords": [
        {
            "term": "speech recognition",
            "url": "https://en.wikipedia.org/wiki/speech_recognition"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        },
        {
            "term": "manifold regularization",
            "url": "https://en.wikipedia.org/wiki/manifold_regularization"
        }
    ],
    "abbreviations": {
        "GWNN": "graph wavelet neural network",
        "CNN": "convolutional neural network",
        "CNNs": "Convolutional neural networks",
        "GAT": "Graph attention network",
        "LP": "label propagation",
        "ManiReg": "manifold regularization",
        "ICA": "iterative classification algorithm"
    },
    "highlights": [
        "Convolutional neural networks (CNNs) (<a class=\"ref-link\" id=\"cLecun_et+al_1998_a\" href=\"#rLecun_et+al_1998_a\"><a class=\"ref-link\" id=\"cLecun_et+al_1998_a\" href=\"#rLecun_et+al_1998_a\">LeCun et al, 1998</a></a>) have been successfully used in many machine learning problems, such as image classification (<a class=\"ref-link\" id=\"cHe_et+al_2016_a\" href=\"#rHe_et+al_2016_a\"><a class=\"ref-link\" id=\"cHe_et+al_2016_a\" href=\"#rHe_et+al_2016_a\">He et al, 2016</a></a>) and speech recognition (<a class=\"ref-link\" id=\"cHinton_et+al_2012_a\" href=\"#rHinton_et+al_2012_a\"><a class=\"ref-link\" id=\"cHinton_et+al_2012_a\" href=\"#rHinton_et+al_2012_a\">Hinton et al, 2012</a></a>), where there is an underlying Euclidean structure",
        "The success of convolutional neural network lies in their ability to leverage the statistical properties of Euclidean data, e.g., translation invariance",
        "Spectral methods leverage graph Fourier transform to convert signals defined in vertex domain into spectral domain, e.g., the space spanned by the eigenvectors of the graph Laplacian matrix, and filter is defined in spectral domain, maintaining the weight sharing property of convolutional neural network",
        "I=1 where \u03c8s is wavelet bases, \u03c8s\u22121 is the graph wavelet transform matrix at scale s which projects signal in vertex domain into spectral domain, X[m:,i] with dimensions n \u00d7 1 is the i-th column of Xm, Fim,j is a diagonal filter matrix learned in spectral domain, and h is a non-linear activation function",
        "The large improvement could be explained from two perspectives: (1) Convolution in Spectral convolutional neural network is non-local in vertex domain, and the range of feature diffusion is not restricted to neighboring nodes; (2) The scaling parameter s of wavelet transform is flexible to adjust the diffusion range to suit different applications and different networks",
        "Replacing graph Fourier transform with graph wavelet transform, we proposed graph wavelet neural network"
    ],
    "key_statements": [
        "Convolutional neural networks (CNNs) (<a class=\"ref-link\" id=\"cLecun_et+al_1998_a\" href=\"#rLecun_et+al_1998_a\"><a class=\"ref-link\" id=\"cLecun_et+al_1998_a\" href=\"#rLecun_et+al_1998_a\">LeCun et al, 1998</a></a>) have been successfully used in many machine learning problems, such as image classification (<a class=\"ref-link\" id=\"cHe_et+al_2016_a\" href=\"#rHe_et+al_2016_a\"><a class=\"ref-link\" id=\"cHe_et+al_2016_a\" href=\"#rHe_et+al_2016_a\">He et al, 2016</a></a>) and speech recognition (<a class=\"ref-link\" id=\"cHinton_et+al_2012_a\" href=\"#rHinton_et+al_2012_a\"><a class=\"ref-link\" id=\"cHinton_et+al_2012_a\" href=\"#rHinton_et+al_2012_a\">Hinton et al, 2012</a></a>), where there is an underlying Euclidean structure",
        "The success of convolutional neural network lies in their ability to leverage the statistical properties of Euclidean data, e.g., translation invariance",
        "Existing methods attempting to generalize convolutional neural network to graph data fall into two categories, spatial methods and spectral methods, according to the way that convolution is defined",
        "Spectral methods leverage graph Fourier transform to convert signals defined in vertex domain into spectral domain, e.g., the space spanned by the eigenvectors of the graph Laplacian matrix, and filter is defined in spectral domain, maintaining the weight sharing property of convolutional neural network",
        "Graph wavelet transform employs a set of wavelets as bases, defined as \u03c8s =, where each wavelet \u03c8si corresponds to a signal on graph diffused away from node i and s is a scaling parameter",
        "I=1 where \u03c8s is wavelet bases, \u03c8s\u22121 is the graph wavelet transform matrix at scale s which projects signal in vertex domain into spectral domain, X[m:,i] with dimensions n \u00d7 1 is the i-th column of Xm, Fim,j is a diagonal filter matrix learned in spectral domain, and h is a non-linear activation function",
        "<a class=\"ref-link\" id=\"cBoscaini_et+al_2015_a\" href=\"#rBoscaini_et+al_2015_a\">Boscaini et al (2015</a>) developed a local spectral convolutional neural network approach based on the graph Windowed Fourier Transform",
        "The large improvement could be explained from two perspectives: (1) Convolution in Spectral convolutional neural network is non-local in vertex domain, and the range of feature diffusion is not restricted to neighboring nodes; (2) The scaling parameter s of wavelet transform is flexible to adjust the diffusion range to suit different applications and different networks",
        "Replacing graph Fourier transform with graph wavelet transform, we proposed graph wavelet neural network"
    ],
    "summary": [
        "Convolutional neural networks (CNNs) (<a class=\"ref-link\" id=\"cLecun_et+al_1998_a\" href=\"#rLecun_et+al_1998_a\"><a class=\"ref-link\" id=\"cLecun_et+al_1998_a\" href=\"#rLecun_et+al_1998_a\">LeCun et al, 1998</a></a>) have been successfully used in many machine learning problems, such as image classification (<a class=\"ref-link\" id=\"cHe_et+al_2016_a\" href=\"#rHe_et+al_2016_a\"><a class=\"ref-link\" id=\"cHe_et+al_2016_a\" href=\"#rHe_et+al_2016_a\">He et al, 2016</a></a>) and speech recognition (<a class=\"ref-link\" id=\"cHinton_et+al_2012_a\" href=\"#rHinton_et+al_2012_a\"><a class=\"ref-link\" id=\"cHinton_et+al_2012_a\" href=\"#rHinton_et+al_2012_a\">Hinton et al, 2012</a></a>), where there is an underlying Euclidean structure.",
        "Spectral methods define convolution via graph Fourier transform and convolution theorem.",
        "Graph wavelet transform employs a set of wavelets as bases, defined as \u03c8s =, where each wavelet \u03c8si corresponds to a signal on graph diffused away from node i and s is a scaling parameter.",
        "3. Localized convolution: each wavelet corresponds to a signal on graph diffused away from a centered node, highly localized in vertex domain.",
        "It is the localization property that explains why graph wavelet transform outperforms Fourier transform in defining graph convolution and the associated tasks like graph-based semisupervised learning.",
        "I=1 where \u03c8s is wavelet bases, \u03c8s\u22121 is the graph wavelet transform matrix at scale s which projects signal in vertex domain into spectral domain, X[m:,i] with dimensions n \u00d7 1 is the i-th column of Xm, Fim,j is a diagonal filter matrix learned in spectral domain, and h is a non-linear activation function.",
        "After detaching feature transformation from graph convolution, the parameter complexity is reduced from O(n \u00d7 p \u00d7 q) to O(n + p \u00d7 q).",
        "Spectral CNN (<a class=\"ref-link\" id=\"cBruna_et+al_2014_a\" href=\"#rBruna_et+al_2014_a\">Bruna et al, 2014</a>) is the first attempt at implementing CNNs on graphs, leveraging graph Fourier transform and defining convolution kernel in spectral domain.",
        "We train a two-layer graph wavelet neural network with 16 hidden units, and prediction accuracy is evaluated on a test set of 1000 labeled samples.",
        "For ChebyNet of detaching feature transformation from graph convolution, the number of parameters is reduced to O(K + p \u00d7 q).",
        "By detaching feature transformation from convolution, the parameter complexity is significantly reduced, alleviating overfitting in semi-supervised learning and remarkably improving prediction accuracy.",
        "Replacing Fourier transform with wavelet transform, the proposed GWNN is comfortably ahead of Spectral CNN, achieving 10% improvement on Cora and Citeseer, and 5% improvement on Pubmed.",
        "The large improvement could be explained from two perspectives: (1) Convolution in Spectral CNN is non-local in vertex domain, and the range of feature diffusion is not restricted to neighboring nodes; (2) The scaling parameter s of wavelet transform is flexible to adjust the diffusion range to suit different applications and different networks.",
        "Besides the improvement on prediction accuracy, wavelet transform with localized and sparse transform matrix holds sparsity in both spatial domain and spectral domain.",
        "4.7 ANALYSIS ON INTERPRETABILITY Compare with graph convolution network using Fourier transform, GWNN provides good interpretability.",
        "To reduce the number of parameters and the dependence on huge training data, we detached the feature transformation from convolution.",
        "This practice makes GWNN applicable to large graphs, with remarkable performance improvement on graph-based semi-supervised learning"
    ],
    "headline": "We present graph wavelet neural network, a novel graph convolutional neural network, leveraging graph wavelet transform to address the shortcomings of previous spectral graph convolutional neural network methods that depend on graph Fourier transform",
    "reference_links": [
        {
            "id": "Belkin_et+al_2006_a",
            "entry": "Mikhail Belkin, Partha Niyogi, and Vikas Sindhwani. Manifold regularization: A geometric framework for learning from labeled and unlabeled examples. Journal of machine learning research, 7 (Nov):2399\u20132434, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Belkin%2C%20Mikhail%20Niyogi%2C%20Partha%20Sindhwani%2C%20Vikas%20Manifold%20regularization%3A%20A%20geometric%20framework%20for%20learning%20from%20labeled%20and%20unlabeled%20examples%202006-11-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Belkin%2C%20Mikhail%20Niyogi%2C%20Partha%20Sindhwani%2C%20Vikas%20Manifold%20regularization%3A%20A%20geometric%20framework%20for%20learning%20from%20labeled%20and%20unlabeled%20examples%202006-11-07"
        },
        {
            "id": "Boscaini_et+al_2015_a",
            "entry": "Davide Boscaini, Jonathan Masci, Simone Melzi, Michael M Bronstein, Umberto Castellani, and Pierre Vandergheynst. Learning class-specific descriptors for deformable shapes using localized spectral convolutional networks. In Computer Graphics Forum, volume 34, pp. 13\u201323. Wiley Online Library, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Boscaini%2C%20Davide%20Masci%2C%20Jonathan%20Melzi%2C%20Simone%20Bronstein%2C%20Michael%20M.%20Learning%20class-specific%20descriptors%20for%20deformable%20shapes%20using%20localized%20spectral%20convolutional%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Boscaini%2C%20Davide%20Masci%2C%20Jonathan%20Melzi%2C%20Simone%20Bronstein%2C%20Michael%20M.%20Learning%20class-specific%20descriptors%20for%20deformable%20shapes%20using%20localized%20spectral%20convolutional%20networks%202015"
        },
        {
            "id": "Bronstein_et+al_2017_a",
            "entry": "Michael M Bronstein, Joan Bruna, Yann LeCun, Arthur Szlam, and Pierre Vandergheynst. Geometric deep learning: going beyond euclidean data. IEEE Signal Processing Magazine, 34(4):18\u201342, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bronstein%2C%20Michael%20M.%20Bruna%2C%20Joan%20LeCun%2C%20Yann%20Szlam%2C%20Arthur%20Geometric%20deep%20learning%3A%20going%20beyond%20euclidean%20data%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bronstein%2C%20Michael%20M.%20Bruna%2C%20Joan%20LeCun%2C%20Yann%20Szlam%2C%20Arthur%20Geometric%20deep%20learning%3A%20going%20beyond%20euclidean%20data%202017"
        },
        {
            "id": "Bruna_et+al_2014_a",
            "entry": "Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann Lecun. Spectral networks and locally connected networks on graphs. In International Conference on Learning Representations (ICLR2014), CBLS, April 2014, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bruna%2C%20Joan%20Zaremba%2C%20Wojciech%20Szlam%2C%20Arthur%20Lecun%2C%20Yann%20Spectral%20networks%20and%20locally%20connected%20networks%20on%20graphs%202014-04",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bruna%2C%20Joan%20Zaremba%2C%20Wojciech%20Szlam%2C%20Arthur%20Lecun%2C%20Yann%20Spectral%20networks%20and%20locally%20connected%20networks%20on%20graphs%202014-04"
        },
        {
            "id": "Defferrard_et+al_2016_a",
            "entry": "Michael Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional neural networks on graphs with fast localized spectral filtering. In Advances in Neural Information Processing Systems, pp. 3844\u20133852, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Defferrard%2C%20Michael%20Bresson%2C%20Xavier%20Vandergheynst%2C%20Pierre%20Convolutional%20neural%20networks%20on%20graphs%20with%20fast%20localized%20spectral%20filtering%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Defferrard%2C%20Michael%20Bresson%2C%20Xavier%20Vandergheynst%2C%20Pierre%20Convolutional%20neural%20networks%20on%20graphs%20with%20fast%20localized%20spectral%20filtering%202016"
        },
        {
            "id": "Ding_et+al_2018_a",
            "entry": "Ming Ding, Jie Tang, and Jie Zhang. Semi-supervised learning on graphs with generative adversarial nets. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management, pp. 913\u2013922. ACM, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ding%2C%20Ming%20Tang%2C%20Jie%20Zhang%2C%20Jie%20Semi-supervised%20learning%20on%20graphs%20with%20generative%20adversarial%20nets%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ding%2C%20Ming%20Tang%2C%20Jie%20Zhang%2C%20Jie%20Semi-supervised%20learning%20on%20graphs%20with%20generative%20adversarial%20nets%202018"
        },
        {
            "id": "Donnat_et+al_2018_a",
            "entry": "Claire Donnat, Marinka Zitnik, David Hallac, and Jure Leskovec. Learning structural node embeddings via diffusion wavelets. 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Donnat%2C%20Claire%20Zitnik%2C%20Marinka%20Hallac%2C%20David%20Leskovec%2C%20Jure%20Learning%20structural%20node%20embeddings%20via%20diffusion%20wavelets%202018"
        },
        {
            "id": "Glorot_2010_a",
            "entry": "Xavier Glorot and Yoshua Bengio. Understanding the difficulty of training deep feedforward neural networks. In Proceedings of the thirteenth international conference on artificial intelligence and statistics, pp. 249\u2013256, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Glorot%2C%20Xavier%20Bengio%2C%20Yoshua%20Understanding%20the%20difficulty%20of%20training%20deep%20feedforward%20neural%20networks%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Glorot%2C%20Xavier%20Bengio%2C%20Yoshua%20Understanding%20the%20difficulty%20of%20training%20deep%20feedforward%20neural%20networks%202010"
        },
        {
            "id": "Hamilton_et+al_2017_a",
            "entry": "Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs. In Advances in Neural Information Processing Systems, pp. 1024\u20131034, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hamilton%2C%20Will%20Ying%2C%20Zhitao%20Leskovec%2C%20Jure%20Inductive%20representation%20learning%20on%20large%20graphs%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hamilton%2C%20Will%20Ying%2C%20Zhitao%20Leskovec%2C%20Jure%20Inductive%20representation%20learning%20on%20large%20graphs%202017"
        },
        {
            "id": "Hammond_et+al_2011_a",
            "entry": "David K Hammond, Pierre Vandergheynst, and Remi Gribonval. Wavelets on graphs via spectral graph theory. Applied and Computational Harmonic Analysis, 30(2):129\u2013150, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hammond%2C%20David%20K.%20Vandergheynst%2C%20Pierre%20Gribonval%2C%20Remi%20Wavelets%20on%20graphs%20via%20spectral%20graph%20theory%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hammond%2C%20David%20K.%20Vandergheynst%2C%20Pierre%20Gribonval%2C%20Remi%20Wavelets%20on%20graphs%20via%20spectral%20graph%20theory%202011"
        },
        {
            "id": "He_et+al_2016_a",
            "entry": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770\u2013778, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "Hinton_et+al_2012_a",
            "entry": "Geoffrey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel-rahman Mohamed, Navdeep Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara N Sainath, et al. Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. IEEE Signal processing magazine, 29(6):82\u201397, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hinton%2C%20Geoffrey%20Deng%2C%20Li%20Yu%2C%20Dong%20Dahl%2C%20George%20E.%20Deep%20neural%20networks%20for%20acoustic%20modeling%20in%20speech%20recognition%3A%20The%20shared%20views%20of%20four%20research%20groups%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hinton%2C%20Geoffrey%20Deng%2C%20Li%20Yu%2C%20Dong%20Dahl%2C%20George%20E.%20Deep%20neural%20networks%20for%20acoustic%20modeling%20in%20speech%20recognition%3A%20The%20shared%20views%20of%20four%20research%20groups%202012"
        },
        {
            "id": "Khasanova_2017_a",
            "entry": "Renata Khasanova and Pascal Frossard. Graph-based isometry invariant representation learning. In International Conference on Machine Learning, pp. 1847\u20131856, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Khasanova%2C%20Renata%20Frossard%2C%20Pascal%20Graph-based%20isometry%20invariant%20representation%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Khasanova%2C%20Renata%20Frossard%2C%20Pascal%20Graph-based%20isometry%20invariant%20representation%20learning%202017"
        },
        {
            "id": "Kingma_2014_a",
            "entry": "Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6980"
        },
        {
            "id": "Kipf_2017_a",
            "entry": "Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kipf%2C%20Thomas%20N.%20Welling%2C%20Max%20Semi-supervised%20classification%20with%20graph%20convolutional%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kipf%2C%20Thomas%20N.%20Welling%2C%20Max%20Semi-supervised%20classification%20with%20graph%20convolutional%20networks%202017"
        },
        {
            "id": "Lecun_et+al_1998_a",
            "entry": "Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278\u20132324, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=LeCun%2C%20Yann%20Bottou%2C%20Leon%20Bengio%2C%20Yoshua%20Haffner%2C%20Patrick%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=LeCun%2C%20Yann%20Bottou%2C%20Leon%20Bengio%2C%20Yoshua%20Haffner%2C%20Patrick%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998"
        },
        {
            "id": "Levie_et+al_2017_a",
            "entry": "Ron Levie, Federico Monti, Xavier Bresson, and Michael M Bronstein. Cayleynets: Graph convolutional neural networks with complex rational spectral filters. arXiv preprint arXiv:1705.07664, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.07664"
        },
        {
            "id": "Lu_2003_a",
            "entry": "Qing Lu and Lise Getoor. Link-based classification. In Proceedings of the 20th International Conference on Machine Learning (ICML-03), pp. 496\u2013503, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lu%2C%20Qing%20Getoor%2C%20Lise%20Link-based%20classification%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lu%2C%20Qing%20Getoor%2C%20Lise%20Link-based%20classification%202003"
        },
        {
            "id": "Shawn_et+al_2011_a",
            "entry": "Shawn Martin, W Michael Brown, Richard Klavans, and Kevin W Boyack. Openord: an opensource toolbox for large graph layout. In Visualization and Data Analysis 2011, volume 7868, pp. 786806. International Society for Optics and Photonics, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shawn%20Martin%2C%20W.Michael%20Brown%20Klavans%2C%20Richard%20Boyack%2C%20Kevin%20W.%20Openord%3A%20an%20opensource%20toolbox%20for%20large%20graph%20layout.%20In%20Visualization%20and%20Data%20Analysis%202011"
        },
        {
            "id": "Monti_et+al_2017_a",
            "entry": "Federico Monti, Davide Boscaini, Jonathan Masci, Emanuele Rodola, Jan Svoboda, and Michael M Bronstein. Geometric deep learning on graphs and manifolds using mixture model cnns. In Proc. CVPR, volume 1, pp. 3, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Monti%2C%20Federico%20Boscaini%2C%20Davide%20Masci%2C%20Jonathan%20Rodola%2C%20Emanuele%20Geometric%20deep%20learning%20on%20graphs%20and%20manifolds%20using%20mixture%20model%20cnns%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Monti%2C%20Federico%20Boscaini%2C%20Davide%20Masci%2C%20Jonathan%20Rodola%2C%20Emanuele%20Geometric%20deep%20learning%20on%20graphs%20and%20manifolds%20using%20mixture%20model%20cnns%202017"
        },
        {
            "id": "Monti_et+al_2018_a",
            "entry": "Federico Monti, Oleksandr Shchur, Aleksandar Bojchevski, Or Litany, Stephan Gunnemann, and Michael M Bronstein. Dual-primal graph convolutional networks. arXiv preprint arXiv:1806.00770, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1806.00770"
        },
        {
            "id": "Perozzi_et+al_2014_a",
            "entry": "Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 701\u2013710. ACM, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Perozzi%2C%20Bryan%20Al-Rfou%2C%20Rami%20Skiena%2C%20Steven%20Deepwalk%3A%20Online%20learning%20of%20social%20representations%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Perozzi%2C%20Bryan%20Al-Rfou%2C%20Rami%20Skiena%2C%20Steven%20Deepwalk%3A%20Online%20learning%20of%20social%20representations%202014"
        },
        {
            "id": "Perraudin_et+al_2014_a",
            "entry": "Nathanael Perraudin, Johan Paratte, David Shuman, Lionel Martin, Vassilis Kalofolias, Pierre Vandergheynst, and David K Hammond. Gspbox: A toolbox for signal processing on graphs. arXiv preprint arXiv:1408.5781, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1408.5781"
        },
        {
            "id": "Sen_et+al_2008_a",
            "entry": "Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and Tina Eliassi-Rad. Collective classification in network data. AI magazine, 29(3):93, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sen%2C%20Prithviraj%20Namata%2C%20Galileo%20Bilgic%2C%20Mustafa%20Getoor%2C%20Lise%20Collective%20classification%20in%20network%20data%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sen%2C%20Prithviraj%20Namata%2C%20Galileo%20Bilgic%2C%20Mustafa%20Getoor%2C%20Lise%20Collective%20classification%20in%20network%20data%202008"
        },
        {
            "id": "Shuman_et+al_2013_a",
            "entry": "David I Shuman, Sunil K Narang, Pascal Frossard, Antonio Ortega, and Pierre Vandergheynst. The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains. IEEE Signal Processing Magazine, 30(3):83\u201398, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shuman%2C%20David%20I.%20Narang%2C%20Sunil%20K.%20Frossard%2C%20Pascal%20Ortega%2C%20Antonio%20The%20emerging%20field%20of%20signal%20processing%20on%20graphs%3A%20Extending%20high-dimensional%20data%20analysis%20to%20networks%20and%20other%20irregular%20domains%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shuman%2C%20David%20I.%20Narang%2C%20Sunil%20K.%20Frossard%2C%20Pascal%20Ortega%2C%20Antonio%20The%20emerging%20field%20of%20signal%20processing%20on%20graphs%3A%20Extending%20high-dimensional%20data%20analysis%20to%20networks%20and%20other%20irregular%20domains%202013"
        },
        {
            "id": "Srivastava_et+al_2014_a",
            "entry": "Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, 15(1):1929\u20131958, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Srivastava%2C%20Nitish%20Hinton%2C%20Geoffrey%20Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Dropout%3A%20a%20simple%20way%20to%20prevent%20neural%20networks%20from%20overfitting%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Srivastava%2C%20Nitish%20Hinton%2C%20Geoffrey%20Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Dropout%3A%20a%20simple%20way%20to%20prevent%20neural%20networks%20from%20overfitting%202014"
        },
        {
            "id": "Sweldens_1998_a",
            "entry": "Wim Sweldens. The lifting scheme: A construction of second generation wavelets. SIAM journal on mathematical analysis, 29(2):511\u2013546, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sweldens%2C%20Wim%20The%20lifting%20scheme%3A%20A%20construction%20of%20second%20generation%20wavelets%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sweldens%2C%20Wim%20The%20lifting%20scheme%3A%20A%20construction%20of%20second%20generation%20wavelets%201998"
        },
        {
            "id": "Tremblay_2014_a",
            "entry": "Nicolas Tremblay and Pierre Borgnat. Graph wavelets for multiscale community mining. IEEE Transactions on Signal Processing, 62(20):5227\u20135239, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tremblay%2C%20Nicolas%20Borgnat%2C%20Pierre%20Graph%20wavelets%20for%20multiscale%20community%20mining%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tremblay%2C%20Nicolas%20Borgnat%2C%20Pierre%20Graph%20wavelets%20for%20multiscale%20community%20mining%202014"
        },
        {
            "id": "Velickovic_et+al_2017_a",
            "entry": "Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. Graph attention networks. arXiv preprint arXiv:1710.10903, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.10903"
        },
        {
            "id": "Yang_et+al_2016_a",
            "entry": "Zhilin Yang, William Cohen, and Ruslan Salakhudinov. Revisiting semi-supervised learning with graph embeddings. In International Conference on Machine Learning, pp. 40\u201348, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Zhilin%20Cohen%2C%20William%20Salakhudinov%2C%20Ruslan%20Revisiting%20semi-supervised%20learning%20with%20graph%20embeddings%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20Zhilin%20Cohen%2C%20William%20Salakhudinov%2C%20Ruslan%20Revisiting%20semi-supervised%20learning%20with%20graph%20embeddings%202016"
        },
        {
            "id": "Zhu_et+al_2003_a",
            "entry": "Xiaojin Zhu, Zoubin Ghahramani, and John D Lafferty. Semi-supervised learning using gaussian fields and harmonic functions. In Proceedings of the 20th International conference on Machine learning (ICML-03), pp. 912\u2013919, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20Xiaojin%20Ghahramani%2C%20Zoubin%20Lafferty%2C%20John%20D.%20Semi-supervised%20learning%20using%20gaussian%20fields%20and%20harmonic%20functions%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20Xiaojin%20Ghahramani%2C%20Zoubin%20Lafferty%2C%20John%20D.%20Semi-supervised%20learning%20using%20gaussian%20fields%20and%20harmonic%20functions%202003"
        }
    ]
}

{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "Deep Anomaly Detection with Outlier Exposure",
        "author": "Dan Hendrycks and Mantas Mazeika and Thomas Dietterich",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=HyxCxhRcY7"
        },
        "abstract": "It is important to detect anomalous inputs when deploying machine learning systems. The use of larger and more complex inputs in deep learning magnifies the difficulty of distinguishing between anomalous and in-distribution examples. At the same time, diverse image and text data are available in enormous quantities. We propose leveraging these data to improve deep anomaly detection by training anomaly detectors against an auxiliary dataset of outliers, an approach we call Outlier Exposure (OE). This enables anomaly detectors to generalize and detect unseen anomalies. In extensive experiments on natural language processing and small- and large-scale vision tasks, we find that Outlier Exposure significantly improves detection performance. We also observe that cutting-edge generative models trained on CIFAR-10 may assign higher likelihoods to SVHN images than to CIFAR-10 images; we use OE to mitigate this issue. We also analyze the flexibility and robustness of Outlier Exposure, and identify characteristics of the auxiliary dataset that improve performance."
    },
    "keywords": [
        {
            "term": "anomaly",
            "url": "https://en.wikipedia.org/wiki/anomaly"
        },
        {
            "term": "confidence",
            "url": "https://en.wikipedia.org/wiki/confidence"
        },
        {
            "term": "density estimation",
            "url": "https://en.wikipedia.org/wiki/density_estimation"
        },
        {
            "term": "machine learning",
            "url": "https://en.wikipedia.org/wiki/machine_learning"
        },
        {
            "term": "deep neural network",
            "url": "https://en.wikipedia.org/wiki/deep_neural_network"
        },
        {
            "term": "bits per pixel",
            "url": "https://en.wikipedia.org/wiki/bits_per_pixel"
        },
        {
            "term": "CIFAR-10",
            "url": "https://en.wikipedia.org/wiki/CIFAR-10"
        },
        {
            "term": "deep learning",
            "url": "https://en.wikipedia.org/wiki/deep_learning"
        },
        {
            "term": "natural language",
            "url": "https://en.wikipedia.org/wiki/natural_language"
        },
        {
            "term": "convolutional neural networks",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_networks"
        },
        {
            "term": "outlier",
            "url": "https://en.wikipedia.org/wiki/outlier"
        },
        {
            "term": "open set",
            "url": "https://en.wikipedia.org/wiki/open_set"
        },
        {
            "term": "unsupervised learning",
            "url": "https://en.wikipedia.org/wiki/unsupervised_learning"
        },
        {
            "term": "calibration",
            "url": "https://en.wikipedia.org/wiki/calibration"
        },
        {
            "term": "anomaly detection",
            "url": "https://en.wikipedia.org/wiki/anomaly_detection"
        },
        {
            "term": "outlier detection",
            "url": "https://en.wikipedia.org/wiki/outlier_detection"
        },
        {
            "term": "safety",
            "url": "https://en.wikipedia.org/wiki/safety"
        },
        {
            "term": "neural networks",
            "url": "https://en.wikipedia.org/wiki/neural_networks"
        }
    ],
    "abbreviations": {
        "OE": "Outlier Exposure",
        "AUPR": "area under the precision-recall curve",
        "MSP": "Maximum Softmax Probability",
        "BPP": "bits per pixel",
        "BPC": "bits per character",
        "BPW": "bits per word"
    },
    "highlights": [
        "Machine Learning systems in deployment often encounter data that is unlike the model\u2019s training data",
        "We demonstrate that Outlier Exposure provides gains over several existing approaches to out-of-distribution detection",
        "We demonstrate that Outlier Exposure improves the calibration of neural network classifiers in the realistic setting where a fraction of the data is OOD",
        "Outlier Exposure uses an auxiliary dataset entirely disjoint from test-time data in order to teach the network better representations for anomaly detection",
        "We proposed Outlier Exposure, a simple technique that enhances many current OOD detectors across various settings",
        "We showed that this method is broadly applicable in vision and natural language settings, even for large-scale image tasks"
    ],
    "key_statements": [
        "Machine Learning systems in deployment often encounter data that is unlike the model\u2019s training data",
        "Behind many machine learning systems are deep learning models (<a class=\"ref-link\" id=\"cKrizhevsky_et+al_2012_a\" href=\"#rKrizhevsky_et+al_2012_a\">Krizhevsky et al, 2012</a>) which can provide high performance in a variety of applications, so long as the data seen at test time is similar to the training data",
        "Realistic datasets for this purpose, with a method we call Outlier Exposure (OE)",
        "We extensively evaluate the broad applicability of Outlier Exposure",
        "We demonstrate that Outlier Exposure provides gains over several existing approaches to out-of-distribution detection",
        "Our results show the flexibility of Outlier Exposure, as we can train various models with different sources of outlier distributions",
        "We demonstrate that Outlier Exposure improves the calibration of neural network classifiers in the realistic setting where a fraction of the data is OOD",
        "Outlier Exposure uses an auxiliary dataset entirely disjoint from test-time data in order to teach the network better representations for anomaly detection",
        "Given a parametrized OOD detector and an Outlier Exposure (OE) dataset DoOuEt , disjoint from Doteustt, we train the model to discover signals and learn heuristics to detect whether a query is sampled from Din or DoOuEt",
        "We show that Outlier Exposure can help detectors generalize to new text and image anomalies",
        "In the confidence branch experiment, we show that Outlier Exposure is flexible and complements a binary anomaly detector",
        "We evaluate out-of-distribution detection methods on their ability to detect OOD points",
        "We treat the OOD examples as the positive class, and we evaluate three metrics: area under the receiver operating characteristic curve (AUROC), area under the precision-recall curve (AUPR), and the false positive rate at N % true positive rate (FPRN )",
        "We use Outlier Exposure to enhance the performance of existing OOD detection techniques with multiclass classification as the original task",
        "We perform Outlier Exposure by fine-tuning a pre-trained classifier f so that its posterior is more uniform on DoOuEt samples",
        "We explore using Outlier Exposure on language models",
        "Outlier Exposure can work in more classification regimes than just those considered above",
        "A multilabel classifier trained on CIFAR-10 obtains an 88.8% mean AUROC when using the maximum prediction probability as the OOD score",
        "By training with Outlier Exposure to decrease the classifier\u2019s output probabilities on OOD samples, the mean AUROC increases to 97.1%. This is slightly less than the AUROC for a multiclass model tuned with Outlier Exposure",
        "Outlier Exposure is flexible enough to improve performance in this setting, but we find that even with Outlier Exposure, classifiers with the reject option or multilabel outputs are not as competitive as OOD detectors with multiclass outputs",
        "Adding Gaussian noise to samples from Din to create DoOuEt does not teach the network to generalize to unseen anomaly distributions for complex Din",
        "We proposed Outlier Exposure, a simple technique that enhances many current OOD detectors across various settings",
        "We showed that this method is broadly applicable in vision and natural language settings, even for large-scale image tasks"
    ],
    "summary": [
        "Machine Learning systems in deployment often encounter data that is unlike the model\u2019s training data.",
        "Outlier Exposure uses an auxiliary dataset entirely disjoint from test-time data in order to teach the network better representations for anomaly detection.",
        "Given a parametrized OOD detector and an Outlier Exposure (OE) dataset DoOuEt , disjoint from Doteustt, we train the model to discover signals and learn heuristics to detect whether a query is sampled from Din or DoOuEt .",
        "Each evaluation consists of an in-distribution dataset Din used to train an initial model, a dataset of anomalous examples DoOuEt , and a baseline detector to which we apply OE.",
        "We use Outlier Exposure to enhance the performance of existing OOD detection techniques with multiclass classification as the original task.",
        "We perform Outlier Exposure by fine-tuning a pre-trained classifier f so that its posterior is more uniform on DoOuEt samples.",
        "Note that we made an attempt to distort images with noise and use these as outliers for OE, but the classifier quickly memorized this statistical pattern and did not detect new OOD examples any better than before (<a class=\"ref-link\" id=\"cHafner_et+al_2018_a\" href=\"#rHafner_et+al_2018_a\">Hafner et al, 2018</a>).",
        "A multilabel classifier trained on CIFAR-10 obtains an 88.8% mean AUROC when using the maximum prediction probability as the OOD score.",
        "Outlier Exposure is flexible enough to improve performance in this setting, but we find that even with OE, classifiers with the reject option or multilabel outputs are not as competitive as OOD detectors with multiclass outputs.",
        "Adding Gaussian noise to samples from Din to create DoOuEt does not teach the network to generalize to unseen anomaly distributions for complex Din. we found in Section 4.3 that synthetic anomalies do not work as well as real data for DoOuEt .",
        "Our experiments demonstrate that the large datasets of realistic anomalies described in Section 4.2.2 do generalize to unseen Doteustt distributions.",
        "In Appendix A, we observe that an OOD detector for SVHN has its performance improve with Outlier Exposure even though (1) DoOuEt samples are images of natural scenes rather than digits, and (2) Doteustt includes unnatural examples such as emojis.",
        "In the NLP experiments, preprocessing DoOuEt to be closer to Din improves OOD detection performance significantly.",
        "The classifier should have low-confidence predic- Figure 3: Root Mean Square Calibration Error tions on these OOD examples, since they do not values with temperature tuning and temperature have a class.",
        "Outlier Exposure is an effective and complementary approach for enhancing out-of-distribution detection systems"
    ],
    "headline": "We propose leveraging these data to improve deep anomaly detection by training anomaly detectors against an auxiliary dataset of outliers, an approach we call Outlier Exposure",
    "reference_links": [
        {
            "id": "Balntas_et+al_2016_a",
            "entry": "Vassileios Balntas, Edgar Riba, Daniel Ponsa, and Krystian Mikolajczyk. Learning local feature descriptors with triplets and shallow convolutional neural networks. British Machine Vision Conference, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Balntas%2C%20Vassileios%20Riba%2C%20Edgar%20Ponsa%2C%20Daniel%20Mikolajczyk%2C%20Krystian%20Learning%20local%20feature%20descriptors%20with%20triplets%20and%20shallow%20convolutional%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Balntas%2C%20Vassileios%20Riba%2C%20Edgar%20Ponsa%2C%20Daniel%20Mikolajczyk%2C%20Krystian%20Learning%20local%20feature%20descriptors%20with%20triplets%20and%20shallow%20convolutional%20neural%20networks%202016"
        },
        {
            "id": "Bartlett_2008_a",
            "entry": "Peter L Bartlett and Marten H Wegkamp. Classification with a reject option using a hinge loss. Journal of Machine Learning Research, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bartlett%2C%20Peter%20L.%20Wegkamp%2C%20Marten%20H.%20Classification%20with%20a%20reject%20option%20using%20a%20hinge%20loss%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bartlett%2C%20Peter%20L.%20Wegkamp%2C%20Marten%20H.%20Classification%20with%20a%20reject%20option%20using%20a%20hinge%20loss%202008"
        },
        {
            "id": "Bevandic_et+al_2018_a",
            "entry": "Petra Bevandic, Sinisa Segvic, Ivan Kreso, and Marin Orsic. Discriminative out-of-distribution detection for semantic segmentation. arXiv preprint, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bevandic%2C%20Petra%20Segvic%2C%20Sinisa%20Kreso%2C%20Ivan%20Orsic%2C%20Marin%20Discriminative%20out-of-distribution%20detection%20for%20semantic%20segmentation.%20arXiv%20p%202018"
        },
        {
            "id": "Bies_et+al_2012_a",
            "entry": "Ann Bies, Justin Mott, Colin Warner, and Seth Kulick. English web treebank, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ann%20Bies%20Justin%20Mott%20Colin%20Warner%20and%20Seth%20Kulick%20English%20web%20treebank%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ann%20Bies%20Justin%20Mott%20Colin%20Warner%20and%20Seth%20Kulick%20English%20web%20treebank%202012"
        },
        {
            "id": "Chen_2015_a",
            "entry": "Xinlei Chen and Abhinav Gupta. Webly supervised learning of convolutional networks. In International Conference on Computer Vision, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Xinlei%20Gupta%2C%20Abhinav%20Webly%20supervised%20learning%20of%20convolutional%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Xinlei%20Gupta%2C%20Abhinav%20Webly%20supervised%20learning%20of%20convolutional%20networks%202015"
        },
        {
            "id": "Cho_et+al_2014_a",
            "entry": "Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. Empirical Methods in Natural Language Processing, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cho%2C%20Kyunghyun%20van%20Merrienboer%2C%20Bart%20Gulcehre%2C%20Caglar%20Bahdanau%2C%20Dzmitry%20Learning%20phrase%20representations%20using%20rnn%20encoder-decoder%20for%20statistical%20machine%20translation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cho%2C%20Kyunghyun%20van%20Merrienboer%2C%20Bart%20Gulcehre%2C%20Caglar%20Bahdanau%2C%20Dzmitry%20Learning%20phrase%20representations%20using%20rnn%20encoder-decoder%20for%20statistical%20machine%20translation%202014"
        },
        {
            "id": "Chrabaszcz_et+al_2017_a",
            "entry": "Patryk Chrabaszcz, Ilya Loshchilov, and Frank Hutter. A downsampled variant of imagenet as an alternative to the cifar datasets. arXiv preprint, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chrabaszcz%2C%20Patryk%20Loshchilov%2C%20Ilya%20Hutter%2C%20Frank%20A%20downsampled%20variant%20of%20imagenet%20as%20an%20alternative%20to%20the%20cifar%20datasets.%20arXiv%20p%202017"
        },
        {
            "id": "Cimpoi_et+al_2014_a",
            "entry": "Mircea Cimpoi, Subhransu Maji, Iasonas Kokkinos, Sammy Mohamed, and Andrea Vedaldi. Describing textures in the wild. Computer Vision and Pattern Recognition, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cimpoi%2C%20Mircea%20Maji%2C%20Subhransu%20Kokkinos%2C%20Iasonas%20Mohamed%2C%20Sammy%20Describing%20textures%20in%20the%20wild%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cimpoi%2C%20Mircea%20Maji%2C%20Subhransu%20Kokkinos%2C%20Iasonas%20Mohamed%2C%20Sammy%20Describing%20textures%20in%20the%20wild%202014"
        },
        {
            "id": "Davis_2006_a",
            "entry": "Jesse Davis and Mark Goadrich. The relationship between precision-recall and ROC curves. In International Conference on Machine Learning, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Davis%2C%20Jesse%20Goadrich%2C%20Mark%20The%20relationship%20between%20precision-recall%20and%20ROC%20curves%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Davis%2C%20Jesse%20Goadrich%2C%20Mark%20The%20relationship%20between%20precision-recall%20and%20ROC%20curves%202006"
        },
        {
            "id": "De_et+al_2016_a",
            "entry": "Harm de Vries, Roland Memisevic, and Aaron Courville. Deep learning vector quantization. In European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=de%20Vries%2C%20Harm%20Memisevic%2C%20Roland%20Courville%2C%20Aaron%20Deep%20learning%20vector%20quantization%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=de%20Vries%2C%20Harm%20Memisevic%2C%20Roland%20Courville%2C%20Aaron%20Deep%20learning%20vector%20quantization%202016"
        },
        {
            "id": "Devries_2018_a",
            "entry": "Terrance DeVries and Graham W Taylor. Learning confidence for out-of-distribution detection in neural networks. arXiv preprint arXiv:1802.04865, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.04865"
        },
        {
            "id": "Emmott_et+al_2013_a",
            "entry": "Andrew F Emmott, Shubhomoy Das, Thomas Dietterich, Alan Fern, and Weng-Keen Wong. Systematic construction of anomaly detection benchmarks from real data. In Proceedings of the ACM SIGKDD workshop on outlier detection and description. ACM, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Emmott%2C%20Andrew%20F.%20Das%2C%20Shubhomoy%20Dietterich%2C%20Thomas%20Fern%2C%20Alan%20Systematic%20construction%20of%20anomaly%20detection%20benchmarks%20from%20real%20data%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Emmott%2C%20Andrew%20F.%20Das%2C%20Shubhomoy%20Dietterich%2C%20Thomas%20Fern%2C%20Alan%20Systematic%20construction%20of%20anomaly%20detection%20benchmarks%20from%20real%20data%202013"
        },
        {
            "id": "Goodfellow_et+al_2014_a",
            "entry": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks. Neural Information Processing Systems, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ian%20Goodfellow%20Jean%20PougetAbadie%20Mehdi%20Mirza%20Bing%20Xu%20David%20WardeFarley%20Sherjil%20Ozair%20Aaron%20Courville%20and%20Yoshua%20Bengio%20Generative%20adversarial%20networks%20Neural%20Information%20Processing%20Systems%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ian%20Goodfellow%20Jean%20PougetAbadie%20Mehdi%20Mirza%20Bing%20Xu%20David%20WardeFarley%20Sherjil%20Ozair%20Aaron%20Courville%20and%20Yoshua%20Bengio%20Generative%20adversarial%20networks%20Neural%20Information%20Processing%20Systems%202014"
        },
        {
            "id": "Goodfellow_et+al_2015_a",
            "entry": "Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. In International Conference on Machine Learning, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20J.%20Shlens%2C%20Jonathon%20Szegedy%2C%20Christian%20Explaining%20and%20harnessing%20adversarial%20examples%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20J.%20Shlens%2C%20Jonathon%20Szegedy%2C%20Christian%20Explaining%20and%20harnessing%20adversarial%20examples%202015"
        },
        {
            "id": "Guo_et+al_2017_a",
            "entry": "Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. On calibration of modern neural networks. International Conference on Machine Learning, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Guo%2C%20Chuan%20Pleiss%2C%20Geoff%20Sun%2C%20Yu%20Weinberger%2C%20Kilian%20Q.%20On%20calibration%20of%20modern%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Guo%2C%20Chuan%20Pleiss%2C%20Geoff%20Sun%2C%20Yu%20Weinberger%2C%20Kilian%20Q.%20On%20calibration%20of%20modern%20neural%20networks%202017"
        },
        {
            "id": "Hafner_et+al_2018_a",
            "entry": "Danijar Hafner, Dustin Tran, Alex Irpan, Timothy Lillicrap, and James Davidson. Reliable uncertainty estimates in deep neural networks using noise contrastive priors. International Conference on Machine Learning Workshop, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hafner%2C%20Danijar%20Tran%2C%20Dustin%20Irpan%2C%20Alex%20Lillicrap%2C%20Timothy%20Reliable%20uncertainty%20estimates%20in%20deep%20neural%20networks%20using%20noise%20contrastive%20priors%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hafner%2C%20Danijar%20Tran%2C%20Dustin%20Irpan%2C%20Alex%20Lillicrap%2C%20Timothy%20Reliable%20uncertainty%20estimates%20in%20deep%20neural%20networks%20using%20noise%20contrastive%20priors%202018"
        },
        {
            "id": "Hendrycks_2019_a",
            "entry": "Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. International Conference on Learning Representations, 2019.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hendrycks%2C%20Dan%20Dietterich%2C%20Thomas%20Benchmarking%20neural%20network%20robustness%20to%20common%20corruptions%20and%20perturbations%202019",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hendrycks%2C%20Dan%20Dietterich%2C%20Thomas%20Benchmarking%20neural%20network%20robustness%20to%20common%20corruptions%20and%20perturbations%202019"
        },
        {
            "id": "Hendrycks_2017_a",
            "entry": "Dan Hendrycks and Kevin Gimpel. A baseline for detecting misclassified and out-of-distribution examples in neural networks. International Conference on Learning Representations, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hendrycks%2C%20Dan%20Gimpel%2C%20Kevin%20A%20baseline%20for%20detecting%20misclassified%20and%20out-of-distribution%20examples%20in%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hendrycks%2C%20Dan%20Gimpel%2C%20Kevin%20A%20baseline%20for%20detecting%20misclassified%20and%20out-of-distribution%20examples%20in%20neural%20networks%202017"
        },
        {
            "id": "Johnson_0000_a",
            "entry": "Johnson et al. Tiny imagenet visual recognition challenge. URL https://tiny-imagenet.herokuapp.com.",
            "url": "https://tiny-imagenet.herokuapp.com"
        },
        {
            "id": "Krizhevsky_2009_a",
            "entry": "Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images. Technical report, University of Toronto, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Hinton%2C%20Geoffrey%20Learning%20multiple%20layers%20of%20features%20from%20tiny%20images%202009"
        },
        {
            "id": "Krizhevsky_et+al_2012_a",
            "entry": "Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. Neural Information Processing Systems, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Hinton%2C%20Geoffrey%20E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Hinton%2C%20Geoffrey%20E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012"
        },
        {
            "id": "Kuleshov_2015_a",
            "entry": "Volodymyr Kuleshov and Percy Liang. Calibrated structured prediction. Neural Information Processing Systems, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kuleshov%2C%20Volodymyr%20Liang%2C%20Percy%20Calibrated%20structured%20prediction%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kuleshov%2C%20Volodymyr%20Liang%2C%20Percy%20Calibrated%20structured%20prediction%202015"
        },
        {
            "id": "Kumar_et+al_2016_a",
            "entry": "Vijay Kumar, Gustavo Carneiro, and Ian Reid. Learning local image descriptors with deep siamese and triplet convolutional networks by minimizing global loss functions. Computer Vision and Pattern Recognition, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kumar%2C%20Vijay%20Carneiro%2C%20Gustavo%20Reid%2C%20Ian%20Learning%20local%20image%20descriptors%20with%20deep%20siamese%20and%20triplet%20convolutional%20networks%20by%20minimizing%20global%20loss%20functions%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kumar%2C%20Vijay%20Carneiro%2C%20Gustavo%20Reid%2C%20Ian%20Learning%20local%20image%20descriptors%20with%20deep%20siamese%20and%20triplet%20convolutional%20networks%20by%20minimizing%20global%20loss%20functions%202016"
        },
        {
            "id": "Lee_et+al_2018_a",
            "entry": "Kimin Lee, Honglak Lee, Kibok Lee, and Jinwoo Shin. Training confidence-calibrated classifiers for detecting out-of-distribution samples. International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lee%2C%20Kimin%20Lee%2C%20Honglak%20Lee%2C%20Kibok%20Shin%2C%20Jinwoo%20Training%20confidence-calibrated%20classifiers%20for%20detecting%20out-of-distribution%20samples%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lee%2C%20Kimin%20Lee%2C%20Honglak%20Lee%2C%20Kibok%20Shin%2C%20Jinwoo%20Training%20confidence-calibrated%20classifiers%20for%20detecting%20out-of-distribution%20samples%202018"
        },
        {
            "id": "Liang_et+al_2018_a",
            "entry": "Shiyu Liang, Yixuan Li, and R. Srikant. Enhancing the reliability of out-of-distribution image detection in neural networks. International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liang%2C%20Shiyu%20Li%2C%20Yixuan%20Srikant%2C%20R.%20Enhancing%20the%20reliability%20of%20out-of-distribution%20image%20detection%20in%20neural%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liang%2C%20Shiyu%20Li%2C%20Yixuan%20Srikant%2C%20R.%20Enhancing%20the%20reliability%20of%20out-of-distribution%20image%20detection%20in%20neural%20networks%202018"
        },
        {
            "id": "Liu_et+al_2018_a",
            "entry": "Si Liu, Risheek Garrepalli, Thomas Dietterich, Alan Fern, and Dan Hendrycks. Open category detection with PAC guarantees. In Proceedings of International Conference on Machine Learning, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Si%20Garrepalli%2C%20Risheek%20Dietterich%2C%20Thomas%20Fern%2C%20Alan%20Open%20category%20detection%20with%20PAC%20guarantees%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Si%20Garrepalli%2C%20Risheek%20Dietterich%2C%20Thomas%20Fern%2C%20Alan%20Open%20category%20detection%20with%20PAC%20guarantees%202018"
        },
        {
            "id": "Loshchilov_2017_a",
            "entry": "Ilya Loshchilov and Frank Hutter. Sgdr: Stochastic gradient descent with warm restarts, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Loshchilov%2C%20Ilya%20Hutter%2C%20Frank%20Sgdr%3A%20Stochastic%20gradient%20descent%20with%20warm%20restarts%202017"
        },
        {
            "id": "Mahajan_et+al_2018_a",
            "entry": "Dhruv Mahajan, Ross Girshick, Vignesh Ramanathan, Kaiming He, Manohar Paluri, Yixuan Li, Ashwin Bharambe, and Laurens van der Maaten. Exploring the limits of weakly supervised pretraining. arXiv preprint, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mahajan%2C%20Dhruv%20Girshick%2C%20Ross%20Ramanathan%2C%20Vignesh%20He%2C%20Kaiming%20Exploring%20the%20limits%20of%20weakly%20supervised%20pretraining.%20arXiv%20p%202018"
        },
        {
            "id": "Malinin_2018_a",
            "entry": "Andrey Malinin and Mark Gales. Predictive uncertainty estimation via prior networks. Neural Information Processing Systems, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Malinin%2C%20Andrey%20Gales%2C%20Mark%20Predictive%20uncertainty%20estimation%20via%20prior%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Malinin%2C%20Andrey%20Gales%2C%20Mark%20Predictive%20uncertainty%20estimation%20via%20prior%20networks%202018"
        },
        {
            "id": "Manning_1999_a",
            "entry": "Chris Manning and Hinrich Schutze. Foundations of Statistical Natural Language Processing. MIT Press, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chris%20Manning%20and%20Hinrich%20Schutze%20Foundations%20of%20Statistical%20Natural%20Language%20Processing%20MIT%20Press%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chris%20Manning%20and%20Hinrich%20Schutze%20Foundations%20of%20Statistical%20Natural%20Language%20Processing%20MIT%20Press%201999"
        },
        {
            "id": "Merity_et+al_2018_a",
            "entry": "Stephen Merity, Nitish Shirish Keskar, and Richard Socher. Regularizing and Optimizing LSTM Language Models. International Conference on Learning Representations, 2018a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Merity%2C%20Stephen%20Keskar%2C%20Nitish%20Shirish%20Socher%2C%20Richard%20Regularizing%20and%20Optimizing%20LSTM%20Language%20Models%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Merity%2C%20Stephen%20Keskar%2C%20Nitish%20Shirish%20Socher%2C%20Richard%20Regularizing%20and%20Optimizing%20LSTM%20Language%20Models%202018"
        },
        {
            "id": "Merity_et+al_2018_b",
            "entry": "Stephen Merity, Nitish Shirish Keskar, and Richard Socher. An Analysis of Neural Language Modeling at Multiple Scales. arXiv preprint, 2018b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Merity%2C%20Stephen%20Keskar%2C%20Nitish%20Shirish%20Socher%2C%20Richard%20An%20Analysis%20of%20Neural%20Language%20Modeling%20at%20Multiple%20Scales.%20arXiv%20p%202018"
        },
        {
            "id": "Nalisnick_et+al_2019_a",
            "entry": "Eric Nalisnick, Akihiro Matsukawa, Yee Whye Teh, Dilan Gorur, and Balaji Lakshminarayanan. Do deep generative models know what they don\u2019t know? International Conference on Learning Representations, 2019.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nalisnick%2C%20Eric%20Matsukawa%2C%20Akihiro%20Teh%2C%20Yee%20Whye%20Gorur%2C%20Dilan%20Do%20deep%20generative%20models%20know%20what%20they%20don%E2%80%99t%20know%3F%202019",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nalisnick%2C%20Eric%20Matsukawa%2C%20Akihiro%20Teh%2C%20Yee%20Whye%20Gorur%2C%20Dilan%20Do%20deep%20generative%20models%20know%20what%20they%20don%E2%80%99t%20know%3F%202019"
        },
        {
            "id": "Netzer_et+al_2011_a",
            "entry": "Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y. Ng. Reading digits in natural images with unsupervised feature learning. In NIPS Workshop on Deep Learning and Unsupervised Feature Learning, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Netzer%2C%20Yuval%20Wang%2C%20Tao%20Coates%2C%20Adam%20Bissacco%2C%20Alessandro%20Reading%20digits%20in%20natural%20images%20with%20unsupervised%20feature%20learning%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Netzer%2C%20Yuval%20Wang%2C%20Tao%20Coates%2C%20Adam%20Bissacco%2C%20Alessandro%20Reading%20digits%20in%20natural%20images%20with%20unsupervised%20feature%20learning%202011"
        },
        {
            "id": "Nguyen_et+al_2015_a",
            "entry": "Anh Nguyen, Jason Yosinski, and Jeff Clune. Deep neural networks are easily fooled: High confidence predictions for unrecognizable images. In Computer Vision and Pattern Recognition, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nguyen%2C%20Anh%20Yosinski%2C%20Jason%20Clune%2C%20Jeff%20Deep%20neural%20networks%20are%20easily%20fooled%3A%20High%20confidence%20predictions%20for%20unrecognizable%20images%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nguyen%2C%20Anh%20Yosinski%2C%20Jason%20Clune%2C%20Jeff%20Deep%20neural%20networks%20are%20easily%20fooled%3A%20High%20confidence%20predictions%20for%20unrecognizable%20images%202015"
        },
        {
            "id": "Nguyen_2015_b",
            "entry": "Khanh Nguyen and Brendan O\u2019Connor. Posterior calibration and exploratory analysis for natural language processing models. Empirical Methods in Natural Language Processing, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nguyen%2C%20Khanh%20O%E2%80%99Connor%2C%20Brendan%20Posterior%20calibration%20and%20exploratory%20analysis%20for%20natural%20language%20processing%20models%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nguyen%2C%20Khanh%20O%E2%80%99Connor%2C%20Brendan%20Posterior%20calibration%20and%20exploratory%20analysis%20for%20natural%20language%20processing%20models%202015"
        },
        {
            "id": "Joan_2013_a",
            "entry": "Joan Pastor-Pellicer, Francisco Zamora-Mart\u0131nez, Salvador Espana-Boquera, and Mar\u0131a Jose CastroBleda. F-measure as the error function to train neural networks. In International Work-Conference on Artificial Neural Networks (IWANN), 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Joan%20Pastor-Pellicer%2C%20Francisco%20Zamora-Mart%C4%B1nez%2C%20Salvador%20Espana-Boquera%20CastroBleda%2C%20Mar%C4%B1a%20Jose%20F-measure%20as%20the%20error%20function%20to%20train%20neural%20networks%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Joan%20Pastor-Pellicer%2C%20Francisco%20Zamora-Mart%C4%B1nez%2C%20Salvador%20Espana-Boquera%20CastroBleda%2C%20Mar%C4%B1a%20Jose%20F-measure%20as%20the%20error%20function%20to%20train%20neural%20networks%202013"
        },
        {
            "id": "Radford_et+al_2016_a",
            "entry": "Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. International Conference on Machine Learning, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Radford%2C%20Alec%20Metz%2C%20Luke%20Chintala%2C%20Soumith%20Unsupervised%20representation%20learning%20with%20deep%20convolutional%20generative%20adversarial%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Radford%2C%20Alec%20Metz%2C%20Luke%20Chintala%2C%20Soumith%20Unsupervised%20representation%20learning%20with%20deep%20convolutional%20generative%20adversarial%20networks%202016"
        },
        {
            "id": "Radford_et+al_2017_a",
            "entry": "Alec Radford, Rafal Jozefowicz, and Ilya Sutskever. Learning to generate reviews and discovering sentiment. arXiv preprint, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Radford%2C%20Alec%20Jozefowicz%2C%20Rafal%20Sutskever%2C%20Ilya%20Learning%20to%20generate%20reviews%20and%20discovering%20sentiment.%20arXiv%20p%202017"
        },
        {
            "id": "Russakovsky_et+al_2015_a",
            "entry": "Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual recognition challenge. International Journal of Computer Vision, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Russakovsky%2C%20Olga%20Deng%2C%20Jia%20Su%2C%20Hao%20Krause%2C%20Jonathan%20Imagenet%20large%20scale%20visual%20recognition%20challenge%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Russakovsky%2C%20Olga%20Deng%2C%20Jia%20Su%2C%20Hao%20Krause%2C%20Jonathan%20Imagenet%20large%20scale%20visual%20recognition%20challenge%202015"
        },
        {
            "id": "Salakhutdinov_et+al_2011_a",
            "entry": "Ruslan Salakhutdinov, Joshua Tenenbaum, and Antonio Torralba. Learning to learn with compound hd models. In Neural Information Processing Systems, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Salakhutdinov%2C%20Ruslan%20Tenenbaum%2C%20Joshua%20Torralba%2C%20Antonio%20Learning%20to%20learn%20with%20compound%20hd%20models%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Salakhutdinov%2C%20Ruslan%20Tenenbaum%2C%20Joshua%20Torralba%2C%20Antonio%20Learning%20to%20learn%20with%20compound%20hd%20models%202011"
        },
        {
            "id": "Salimans_2016_a",
            "entry": "Tim Salimans and Diederik Kingma. Weight normalization: A simple reparameterization to accelerate training of deep neural networks. NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Salimans%2C%20Tim%20Kingma%2C%20Diederik%20Weight%20normalization%3A%20A%20simple%20reparameterization%20to%20accelerate%20training%20of%20deep%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Salimans%2C%20Tim%20Kingma%2C%20Diederik%20Weight%20normalization%3A%20A%20simple%20reparameterization%20to%20accelerate%20training%20of%20deep%20neural%20networks%202016"
        },
        {
            "id": "Salimans_et+al_2017_a",
            "entry": "Tim Salimans, Andrej Karpathy, Xi Chen, and Diederik P Kingma. PixelCNN++: Improving the PixelCNN with discretized logistic mixture likelihood and other modifications. International Conference on Learning Representations, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Salimans%2C%20Tim%20Karpathy%2C%20Andrej%20Chen%2C%20Xi%20Kingma%2C%20Diederik%20P.%20PixelCNN%2B%2B%3A%20Improving%20the%20PixelCNN%20with%20discretized%20logistic%20mixture%20likelihood%20and%20other%20modifications%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Salimans%2C%20Tim%20Karpathy%2C%20Andrej%20Chen%2C%20Xi%20Kingma%2C%20Diederik%20P.%20PixelCNN%2B%2B%3A%20Improving%20the%20PixelCNN%20with%20discretized%20logistic%20mixture%20likelihood%20and%20other%20modifications%202017"
        },
        {
            "id": "Socher_et+al_2013_a",
            "entry": "Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher Manning, Andrew Ng, and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In Conference on Empirical Methods in Natural Language Processing, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Socher%2C%20Richard%20Perelygin%2C%20Alex%20Wu%2C%20Jean%20Chuang%2C%20Jason%20Andrew%20Ng%2C%20and%20Christopher%20Potts.%20Recursive%20deep%20models%20for%20semantic%20compositionality%20over%20a%20sentiment%20treebank%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Socher%2C%20Richard%20Perelygin%2C%20Alex%20Wu%2C%20Jean%20Chuang%2C%20Jason%20Andrew%20Ng%2C%20and%20Christopher%20Potts.%20Recursive%20deep%20models%20for%20semantic%20compositionality%20over%20a%20sentiment%20treebank%202013"
        },
        {
            "id": "Subramanya_et+al_2017_a",
            "entry": "Akshayvarun Subramanya, Suraj Srinivas, and R.Venkatesh Babu. Confidence estimation in deep neural networks via density modelling. arXiv preprint, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Subramanya%2C%20Akshayvarun%20Srinivas%2C%20Suraj%20Babu%2C%20R.Venkatesh%20Confidence%20estimation%20in%20deep%20neural%20networks%20via%20density%20modelling.%20arXiv%20p%202017"
        },
        {
            "id": "Sun_et+al_2018_a",
            "entry": "Chen Sun, Abhinav Shrivastava, Saurabh Singh, and Abhinav Gupta. Large scale fine-grained categorization and the effectiveness of domain-specific transfer learning. Yin Cui and Yang Song and Chen Sun and Andrew Howard and Serge Belongie, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sun%2C%20Chen%20Shrivastava%2C%20Abhinav%20Singh%2C%20Saurabh%20Gupta%2C%20Abhinav%20Large%20scale%20fine-grained%20categorization%20and%20the%20effectiveness%20of%20domain-specific%20transfer%20learning.%20Yin%20Cui%20and%20Yang%20Song%20and%20Chen%20Sun%20and%20Andrew%20Howard%20and%20Serge%20Belongie%202018"
        },
        {
            "id": "Torralba_et+al_2008_a",
            "entry": "Antonio Torralba, Rob Fergus, and William T Freeman. 80 million tiny images: A large data set for nonparametric object and scene recognition. Pattern Analysis and Machine Intelligence, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Torralba%2C%20Antonio%20Fergus%2C%20Rob%20Freeman%2C%20William%20T.%20million%20tiny%20images%3A%20A%20large%20data%20set%20for%20nonparametric%20object%20and%20scene%20recognition%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Torralba%2C%20Antonio%20Fergus%2C%20Rob%20Freeman%2C%20William%20T.%20million%20tiny%20images%3A%20A%20large%20data%20set%20for%20nonparametric%20object%20and%20scene%20recognition%202008"
        },
        {
            "id": "Yu_et+al_2015_a",
            "entry": "Fisher Yu, Yinda Zhang, Shuran Song, Ari Seff, and Jianxiong Xiao. LSUN: construction of a large-scale image dataset using deep learning with humans in the loop. CoRR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yu%2C%20Fisher%20Zhang%2C%20Yinda%20Song%2C%20Shuran%20Seff%2C%20Ari%20LSUN%3A%20construction%20of%20a%20large-scale%20image%20dataset%20using%20deep%20learning%20with%20humans%20in%20the%20loop%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yu%2C%20Fisher%20Zhang%2C%20Yinda%20Song%2C%20Shuran%20Seff%2C%20Ari%20LSUN%3A%20construction%20of%20a%20large-scale%20image%20dataset%20using%20deep%20learning%20with%20humans%20in%20the%20loop%202015"
        },
        {
            "id": "Zagoruyko_2016_a",
            "entry": "Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. British Machine Vision Conference, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zagoruyko%2C%20Sergey%20Komodakis%2C%20Nikos%20Wide%20residual%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zagoruyko%2C%20Sergey%20Komodakis%2C%20Nikos%20Wide%20residual%20networks%202016"
        },
        {
            "id": "Zeiler_2014_a",
            "entry": "Matthew D Zeiler and Rob Fergus. Visualizing and understanding convolutional networks. In European Conference on Computer Vision. Springer, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zeiler%2C%20Matthew%20D.%20Fergus%2C%20Rob%20Visualizing%20and%20understanding%20convolutional%20networks%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zeiler%2C%20Matthew%20D.%20Fergus%2C%20Rob%20Visualizing%20and%20understanding%20convolutional%20networks%202014"
        },
        {
            "id": "Zhou_et+al_2017_a",
            "entry": "Bolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva, and Antonio Torralba. Places: A 10 million image database for scene recognition. Pattern Analysis and Machine Intelligence, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhou%2C%20Bolei%20Lapedriza%2C%20Agata%20Khosla%2C%20Aditya%20Oliva%2C%20Aude%20Places%3A%20A%2010%20million%20image%20database%20for%20scene%20recognition%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhou%2C%20Bolei%20Lapedriza%2C%20Agata%20Khosla%2C%20Aditya%20Oliva%2C%20Aude%20Places%3A%20A%2010%20million%20image%20database%20for%20scene%20recognition%202017"
        },
        {
            "id": "Zong_et+al_2018_a",
            "entry": "Bo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Daeki Cho, and Haifeng Chen. Deep autoencoding gaussian mixture model for unsupervised anomaly detection. International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zong%2C%20Bo%20Song%2C%20Qi%20Min%2C%20Martin%20Renqiang%20Cheng%2C%20Wei%20Deep%20autoencoding%20gaussian%20mixture%20model%20for%20unsupervised%20anomaly%20detection%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zong%2C%20Bo%20Song%2C%20Qi%20Min%2C%20Martin%20Renqiang%20Cheng%2C%20Wei%20Deep%20autoencoding%20gaussian%20mixture%20model%20for%20unsupervised%20anomaly%20detection%202018"
        }
    ]
}

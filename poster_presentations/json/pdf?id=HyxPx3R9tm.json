{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "VARIATIONAL DISCRIMINATOR BOTTLENECK: IMPROVING IMITATION LEARNING, INVERSE RL, AND GANS BY CONSTRAINING INFORMATION FLOW",
        "author": "Xue Bin Peng & Angjoo Kanazawa & Sam Toyer & Pieter Abbeel & Sergey Levine University of California, Berkeley {xbpeng,kanazawa,sdt,pabbeel,svlevine}@berkeley.edu",
        "date": 2018,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=HyxPx3R9tm"
        },
        "abstract": "Adversarial learning methods have been proposed for a wide range of applications, but the training of adversarial models can be notoriously unstable. Effectively balancing the performance of the generator and discriminator is critical, since a discriminator that achieves very high accuracy will produce relatively uninformative gradients. In this work, we propose a simple and general technique to constrain information flow in the discriminator by means of an information bottleneck. By enforcing a constraint on the mutual information between the observations and the discriminator\u2019s internal representation, we can effectively modulate the discriminator\u2019s accuracy and maintain useful and informative gradients. We demonstrate that our proposed variational discriminator bottleneck (VDB) leads to significant improvements across three distinct application areas for adversarial learning algorithms. Our primary evaluation studies the applicability of the VDB to imitation learning of dynamic continuous control skills, such as running. We show that our method can learn such skills directly from raw video demonstrations, substantially outperforming prior adversarial imitation learning methods. The VDB can also be combined with adversarial inverse reinforcement learning to learn parsimonious reward functions that can be transferred and re-optimized in new settings. Finally, we demonstrate that VDB can train GANs more effectively for image generation, improving upon a number of prior stabilization methods. (Video1)"
    },
    "keywords": [
        {
            "term": "inverse reinforcement learning",
            "url": "https://en.wikipedia.org/wiki/inverse_reinforcement_learning"
        },
        {
            "term": "mutual information",
            "url": "https://en.wikipedia.org/wiki/mutual_information"
        },
        {
            "term": "generative adversarial networks",
            "url": "https://en.wikipedia.org/wiki/generative_adversarial_networks"
        },
        {
            "term": "physics",
            "url": "https://en.wikipedia.org/wiki/physics"
        },
        {
            "term": "equilibrium",
            "url": "https://en.wikipedia.org/wiki/equilibrium"
        },
        {
            "term": "adversarial learning",
            "url": "https://en.wikipedia.org/wiki/adversarial_learning"
        }
    ],
    "abbreviations": {
        "VDB": "variational discriminator bottleneck",
        "GANs": "generative adversarial networks",
        "IRL": "inverse reinforcement learning",
        "VAE": "variational autoencoders",
        "D(x)": "(x) [\u2212log",
        "VGAN": "variational generative adversarial network",
        "GAIL": "generative adversarial imitation learning",
        "VAIL": "variational adversarial imitation learning",
        "VAIRL": "variational adversarial inverse reinforcement learning",
        "SN": "spectral normalization",
        "GP": "gradient penalty",
        "FID": "Frechet Inception Distance"
    },
    "highlights": [
        "Adversarial learning methods provide a promising approach to modeling distributions over highdimensional data with complex internal correlation structures",
        "We propose a simple regularization technique for adversarial learning, which constrains the information flow from the inputs to the discriminator using a variational approximation to the information bottleneck",
        "In the case of imitation learning, we show that the variational discriminator bottleneck enables agents to learn complex motion skills from a single demonstration, including visual demonstrations provided in the form of video clips",
        "Figure 6 compares learning curves of policies trained with variational adversarial imitation learning, generative adversarial imitation learning, and policies trained using a reward function defined by the average pixel-wise difference between the frame Mt\u2217 from the video demonstration and a rendered image Mt of the agent at each timestep t, rt",
        "Unlike the discriminator learned by variational adversarial imitation learning, the reward function recovered by variational adversarial inverse reinforcement learning can be re-optimized to train new policies from scratch in the same environment",
        "We present the variational discriminator bottleneck, a general regularization technique for adversarial learning"
    ],
    "key_statements": [
        "Adversarial learning methods provide a promising approach to modeling distributions over highdimensional data with complex internal correlation structures",
        "A particular instantiation is generative adversarial networks, which can be used for high-fidelity generation of images (<a class=\"ref-link\" id=\"cGoodfellow_et+al_2014_a\" href=\"#rGoodfellow_et+al_2014_a\">Goodfellow et al, 2014</a>; <a class=\"ref-link\" id=\"cKarras_et+al_2017_a\" href=\"#rKarras_et+al_2017_a\">Karras et al, 2017</a>) and other highdimensional data (Vondrick et al, 2016; Xie et al, 2018; <a class=\"ref-link\" id=\"cDonahue_et+al_2018_a\" href=\"#rDonahue_et+al_2018_a\">Donahue et al, 2018</a>)",
        "We propose a simple regularization technique for adversarial learning, which constrains the information flow from the inputs to the discriminator using a variational approximation to the information bottleneck",
        "While instance noise is widely used in modern architectures (<a class=\"ref-link\" id=\"cSalimans_et+al_2016_a\" href=\"#rSalimans_et+al_2016_a\">Salimans et al, 2016</a>; S\u00f8nderby et al, 2016; <a class=\"ref-link\" id=\"cArjovsky_2017_a\" href=\"#rArjovsky_2017_a\">Arjovsky & Bottou, 2017</a>), we show that explicitly enforcing an information bottleneck leads to improved performance over adding noise for a variety of applications",
        "In variational adversarial inverse reinforcement learning, we introduce stochastic encoders Eg, Eh, and g, h are modified to be functions of the encoding",
        "We evaluate our method on adversarial learning problems in imitation learning, inverse reinforcement learning, and image generation",
        "In the case of imitation learning, we show that the variational discriminator bottleneck enables agents to learn complex motion skills from a single demonstration, including visual demonstrations provided in the form of video clips",
        "We show that the variational discriminator bottleneck improves the performance of inverse RL methods",
        "Figure 6 compares learning curves of policies trained with variational adversarial imitation learning, generative adversarial imitation learning, and policies trained using a reward function defined by the average pixel-wise difference between the frame Mt\u2217 from the video demonstration and a rendered image Mt of the agent at each timestep t, rt",
        "Unlike the discriminator learned by variational adversarial imitation learning, the reward function recovered by variational adversarial inverse reinforcement learning can be re-optimized to train new policies from scratch in the same environment",
        "In Figure 7, we show the results of applying variational adversarial inverse reinforcement learning to the C-maze from <a class=\"ref-link\" id=\"cFu_et+al_2017_a\" href=\"#rFu_et+al_2017_a\">Fu et al (2017</a>), and a more complex S-maze; the simple 2D observation spaces of these tasks make it easy to interpret the recovered reward functions",
        "On the C-maze, we found that plain AIRL\u2014without a gradient penalty\u2014 would sometimes overfit and fail to transfer to the new environment, as evidenced by the reward visualization in Figure 7 and the higher return variance in Figure 7",
        "We report the Frechet Inception Distance (FID) (<a class=\"ref-link\" id=\"cHeusel_et+al_2017_a\" href=\"#rHeusel_et+al_2017_a\">Heusel et al, 2017</a>), which has been shown to be more consistent with human evaluation",
        "We present the variational discriminator bottleneck, a general regularization technique for adversarial learning"
    ],
    "summary": [
        "Adversarial learning methods provide a promising approach to modeling distributions over highdimensional data with complex internal correlation structures.",
        "We propose a simple regularization technique for adversarial learning, which constrains the information flow from the inputs to the discriminator using a variational approximation to the information bottleneck.",
        "The main contribution of this work is the variational discriminator bottleneck (VDB), an adaptive stochastic regularization method for adversarial learning that substantially improves performance across a range of different application domains, examples of which are available in Figure 1.",
        "We further evaluate the effectiveness of the technique for inverse reinforcement learning, which recovers a reward function from demonstrations in order to train future policies.",
        "Instead of explicit regularization of gradients or architecture-specific constraints, we apply a general information bottleneck to the discriminator, which previous works have shown to encourage networks to ignore irrelevant cues (<a class=\"ref-link\" id=\"cAchille_2017_a\" href=\"#rAchille_2017_a\">Achille & Soatto, 2017</a>).",
        "Adversarial techniques have been applied to inverse reinforcement learning (<a class=\"ref-link\" id=\"cFu_et+al_2017_a\" href=\"#rFu_et+al_2017_a\">Fu et al, 2017</a>), where a reward function is recovered from demonstrations, which can be used to train policies to reproduce a desired skill.",
        "We show that our method can significantly improve upon previous works that use adversarial techniques, and produces results of comparable quality to those from state-of-the-art approaches that utilize manually engineered reward functions.",
        "To extend the VDB to imitation learning, we start with the generative adversarial imitation learning (GAIL) framework (<a class=\"ref-link\" id=\"cHo_2016_a\" href=\"#rHo_2016_a\">Ho & Ermon, 2016</a>), where the discriminator\u2019s objective is to differentiate between the state distribution induced by a target policy \u03c0\u2217(s) and the state distribution of the agent\u2019s policy \u03c0(s), max min \u03c0D",
        "Similar to the GAN framework, we can incorporate a VDB into the discriminator, J (D, E) = min max Es\u223c\u03c0\u2217(s) Ez\u223cE(z|s) [\u2212log (D(z))] + Es\u223c\u03c0(s) Ez\u223cE(z|s) [\u2212log (1 \u2212 D(z))]",
        "Inverse RL aims to reconstruct a reward function from a set demonstrations, which can used to perform the task in new environments, in contrast to imitation learning, which aims to recover a policy directly.",
        "Figure 6 compares learning curves of policies trained with VAIL, GAIL, and policies trained using a reward function defined by the average pixel-wise difference between the frame Mt\u2217 from the video demonstration and a rendered image Mt of the agent at each timestep t, rt",
        "Unlike the discriminator learned by VAIL, the reward function recovered by VAIRL can be re-optimized to train new policies from scratch in the same environment.",
        "We present the variational discriminator bottleneck, a general regularization technique for adversarial learning.",
        "Another exciting direction for future work is a more in-depth theoretical analysis of the method, to derive convergence and stability results or conditions"
    ],
    "headline": "We propose a simple and general technique to constrain information flow in the discriminator by means of an information bottleneck",
    "reference_links": [
        {
            "id": "Achille_2017_a",
            "entry": "Alessandro Achille and Stefano Soatto. Information dropout: Learning optimal representations through noisy computation. IEEE Transactions on Pattern Analysis & Machine Intelligence, 40 (12):2897\u20132905, 2017. ISSN 0162-8828. doi: 10.1109/TPAMI.2017.2784440.",
            "crossref": "https://dx.doi.org/10.1109/TPAMI.2017.2784440",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/TPAMI.2017.2784440"
        },
        {
            "id": "Alemi_et+al_2016_a",
            "entry": "Alexander A. Alemi, Ian Fischer, Joshua V. Dillon, and Kevin Murphy. Deep variational information bottleneck. CoRR, abs/1612.00410, 2016. URL http://arxiv.org/abs/1612.00410.",
            "url": "http://arxiv.org/abs/1612.00410",
            "arxiv_url": "https://arxiv.org/pdf/1612.00410"
        },
        {
            "id": "Arjovsky_2017_a",
            "entry": "Mart\u0131n Arjovsky and Leon Bottou. Towards principled methods for training generative adversarial networks. CoRR, abs/1701.04862, 2017. URL http://arxiv.org/abs/1701.04862.",
            "url": "http://arxiv.org/abs/1701.04862",
            "arxiv_url": "https://arxiv.org/pdf/1701.04862"
        },
        {
            "id": "Arjovsky_et+al_2017_b",
            "entry": "Martin Arjovsky, Soumith Chintala, and Leon Bottou. Wasserstein generative adversarial networks. In Doina Precup and Yee Whye Teh (eds.), Proceedings of the 34th International Conference on Machine Learning, volume 70 of Proceedings of Machine Learning Research, pp. 214\u2013223, International Convention Centre, Sydney, Australia, 06\u201311 Aug 2017. PMLR. URL http://proceedings.mlr.press/v70/arjovsky17a.html.",
            "url": "http://proceedings.mlr.press/v70/arjovsky17a.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arjovsky%2C%20Martin%20Chintala%2C%20Soumith%20Bottou%2C%20Leon%20Wasserstein%20generative%20adversarial%20networks%202017-08"
        },
        {
            "id": "Berthelot_et+al_2017_a",
            "entry": "David Berthelot, Tom Schumm, and Luke Metz. BEGAN: boundary equilibrium generative adversarial networks. CoRR, abs/1703.10717, 2017. URL http://arxiv.org/abs/1703.10717.",
            "url": "http://arxiv.org/abs/1703.10717",
            "arxiv_url": "https://arxiv.org/pdf/1703.10717"
        },
        {
            "id": "Boyd_2004_a",
            "entry": "Stephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge University Press, New York, NY, USA, 2004. ISBN 0521833787.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Boyd%2C%20Stephen%20Vandenberghe%2C%20Lieven%20Convex%20Optimization%202004"
        },
        {
            "id": "Bullet_2015_a",
            "entry": "Bullet. Bullet physics library, 2015. http://bulletphysics.org.",
            "url": "http://bulletphysics.org"
        },
        {
            "id": "Che_et+al_2016_a",
            "entry": "Tong Che, Yanran Li, Athul Paul Jacob, Yoshua Bengio, and Wenjie Li. Mode regularized generative adversarial networks. CoRR, abs/1612.02136, 2016. URL http://arxiv.org/abs/1612.02136.",
            "url": "http://arxiv.org/abs/1612.02136",
            "arxiv_url": "https://arxiv.org/pdf/1612.02136"
        },
        {
            "id": "Chen_et+al_2018_a",
            "entry": "Liqun Chen, Shuyang Dai, Yunchen Pu, Erjin Zhou, Chunyuan Li, Qinliang Su, Changyou Chen, and Lawrence Carin. Symmetric variational autoencoder and connections to adversarial learning. In Amos Storkey and Fernando Perez-Cruz (eds.), Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics, volume 84 of Proceedings of Machine Learning Research, pp. 661\u2013669, Playa Blanca, Lanzarote, Canary Islands, 09\u201311 Apr 2018. PMLR. URL http://proceedings.mlr.press/v84/chen18b.html.",
            "url": "http://proceedings.mlr.press/v84/chen18b.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Liqun%20Dai%2C%20Shuyang%20Pu%2C%20Yunchen%20Zhou%2C%20Erjin%20Symmetric%20variational%20autoencoder%20and%20connections%20to%20adversarial%20learning%202018-04"
        },
        {
            "id": "Donahue_et+al_2018_a",
            "entry": "Chris Donahue, Julian McAuley, and Miller Puckette. Synthesizing audio with generative adversarial networks. CoRR, abs/1802.04208, 2018. URL http://arxiv.org/abs/1802.04208.",
            "url": "http://arxiv.org/abs/1802.04208",
            "arxiv_url": "https://arxiv.org/pdf/1802.04208"
        },
        {
            "id": "Finn_et+al_2016_a",
            "entry": "Chelsea Finn, Paul F. Christiano, Pieter Abbeel, and Sergey Levine. A connection between generative adversarial networks, inverse reinforcement learning, and energy-based models. CoRR, abs/1611.03852, 2016a. URL http://arxiv.org/abs/1611.03852.",
            "url": "http://arxiv.org/abs/1611.03852",
            "arxiv_url": "https://arxiv.org/pdf/1611.03852"
        },
        {
            "id": "Finn_et+al_2016_b",
            "entry": "Chelsea Finn, Sergey Levine, and Pieter Abbeel. Guided cost learning: Deep inverse optimal control via policy optimization. In Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016, pp. 49\u201358, 2016b. URL http://jmlr.org/proceedings/papers/v48/finn16.html.",
            "url": "http://jmlr.org/proceedings/papers/v48/finn16.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Finn%2C%20Chelsea%20Levine%2C%20Sergey%20Abbeel%2C%20Pieter%20Guided%20cost%20learning%3A%20Deep%20inverse%20optimal%20control%20via%20policy%20optimization%202016-06-19"
        },
        {
            "id": "Fu_et+al_2017_a",
            "entry": "Justin Fu, Katie Luo, and Sergey Levine. Learning robust rewards with adversarial inverse reinforcement learning. CoRR, abs/1710.11248, 2017. URL http://arxiv.org/abs/1710.11248.",
            "url": "http://arxiv.org/abs/1710.11248",
            "arxiv_url": "https://arxiv.org/pdf/1710.11248"
        },
        {
            "id": "Goodfellow_et+al_2014_a",
            "entry": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger (eds.), Advances in Neural Information Processing Systems 27, pp. 2672\u20132680. Curran Associates, Inc., 2014. URL http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf.",
            "url": "http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "Gulrajani_et+al_2017_a",
            "entry": "Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville. Improved training of wasserstein gans. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems 30, pp. 5767\u20135777. Curran Associates, Inc., 2017a. URL http://papers.nips.cc/paper/7159-improved-training-of-wasserstein-gans.pdf.",
            "url": "http://papers.nips.cc/paper/7159-improved-training-of-wasserstein-gans.pdf",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gulrajani%2C%20Ishaan%20Ahmed%2C%20Faruk%20Arjovsky%2C%20Martin%20Dumoulin%2C%20Vincent%20Improved%20training%20of%20wasserstein%202017"
        },
        {
            "id": "Gulrajani_et+al_2017_b",
            "entry": "Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville. Improved training of wasserstein gans. In Advances in Neural Information Processing Systems, pp. 5767\u20135777, 2017b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gulrajani%2C%20Ishaan%20Ahmed%2C%20Faruk%20Arjovsky%2C%20Martin%20Dumoulin%2C%20Vincent%20Improved%20training%20of%20wasserstein%20gans%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gulrajani%2C%20Ishaan%20Ahmed%2C%20Faruk%20Arjovsky%2C%20Martin%20Dumoulin%2C%20Vincent%20Improved%20training%20of%20wasserstein%20gans%202017"
        },
        {
            "id": "Heusel_et+al_2017_a",
            "entry": "Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilibrium. In Advances in Neural Information Processing Systems, pp. 6626\u20136637, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Heusel%2C%20Martin%20Ramsauer%2C%20Hubert%20Unterthiner%2C%20Thomas%20Nessler%2C%20Bernhard%20Gans%20trained%20by%20a%20two%20time-scale%20update%20rule%20converge%20to%20a%20local%20nash%20equilibrium%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Heusel%2C%20Martin%20Ramsauer%2C%20Hubert%20Unterthiner%2C%20Thomas%20Nessler%2C%20Bernhard%20Gans%20trained%20by%20a%20two%20time-scale%20update%20rule%20converge%20to%20a%20local%20nash%20equilibrium%202017"
        },
        {
            "id": "Higgins_et+al_2017_a",
            "entry": "Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. \u03b2-VAE: Learning basic visual concepts with a constrained variational framework. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Higgins%2C%20Irina%20Matthey%2C%20Loic%20Pal%2C%20Arka%20Burgess%2C%20Christopher%20%CE%B2-VAE%3A%20Learning%20basic%20visual%20concepts%20with%20a%20constrained%20variational%20framework%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Higgins%2C%20Irina%20Matthey%2C%20Loic%20Pal%2C%20Arka%20Burgess%2C%20Christopher%20%CE%B2-VAE%3A%20Learning%20basic%20visual%20concepts%20with%20a%20constrained%20variational%20framework%202017"
        },
        {
            "id": "Ho_2016_a",
            "entry": "Jonathan Ho and Stefano Ermon. Generative adversarial imitation learning. In Advances in Neural Information Processing Systems 29, pp. 4565\u20134573. Curran Associates, Inc., 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ho%2C%20Jonathan%20Ermon%2C%20Stefano%20Generative%20adversarial%20imitation%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ho%2C%20Jonathan%20Ermon%2C%20Stefano%20Generative%20adversarial%20imitation%20learning%202016"
        },
        {
            "id": "Holden_et+al_2017_a",
            "entry": "Daniel Holden, Taku Komura, and Jun Saito. Phase-functioned neural networks for character control. ACM Trans. Graph., 36(4):42:1\u201342:13, July 2017. ISSN 0730-0301. doi: 10.1145/3072959. 3073663. URL http://doi.acm.org/10.1145/3072959.3073663.",
            "crossref": "https://dx.doi.org/10.1145/3072959.3073663",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/3072959.3073663"
        },
        {
            "id": "Karras_et+al_2017_a",
            "entry": "Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. CoRR, abs/1710.10196, 2017. URL http://arxiv.org/abs/1710.10196.",
            "url": "http://arxiv.org/abs/1710.10196",
            "arxiv_url": "https://arxiv.org/pdf/1710.10196"
        },
        {
            "id": "Karras_et+al_2018_a",
            "entry": "Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of GANs for improved quality, stability, and variation. In International Conference on Learning Representations, 2018. URL https://openreview.net/forum?id=Hk99zCeAb.",
            "url": "https://openreview.net/forum?id=Hk99zCeAb",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Karras%2C%20Tero%20Aila%2C%20Timo%20Laine%2C%20Samuli%20Lehtinen%2C%20Jaakko%20Progressive%20growing%20of%20GANs%20for%20improved%20quality%2C%20stability%2C%20and%20variation%202018"
        },
        {
            "id": "Kingma_2013_a",
            "entry": "Diederik P. Kingma and Max Welling. Auto-encoding variational bayes. CoRR, abs/1312.6114, 2013. URL http://dblp.uni-trier.de/db/journals/corr/corr1312.html# KingmaW13.",
            "url": "http://dblp.uni-trier.de/db/journals/corr/corr1312.html#",
            "arxiv_url": "https://arxiv.org/pdf/1312.6114"
        },
        {
            "id": "Kodali_et+al_2017_a",
            "entry": "Naveen Kodali, Jacob D. Abernethy, James Hays, and Zsolt Kira. How to train your DRAGAN. CoRR, abs/1705.07215, 2017. URL http://arxiv.org/abs/1705.07215.",
            "url": "http://arxiv.org/abs/1705.07215",
            "arxiv_url": "https://arxiv.org/pdf/1705.07215"
        },
        {
            "id": "Krizhevsky_et+al_0000_a",
            "entry": "Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. Cifar-10 (canadian institute for advanced research). URL http://www.cs.toronto.edu/\u0303kriz/cifar.html.",
            "url": "http://www.cs.toronto.edu/\u0303kriz/cifar.html"
        },
        {
            "id": "Krizhevsky_et+al_2012_a",
            "entry": "Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. In F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger (eds.), Advances in Neural Information Processing Systems 25, pp. 1097\u2013 1105. Curran Associates, Inc., 2012. URL http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf.",
            "url": "http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Hinton%2C%20Geoffrey%20E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012"
        },
        {
            "id": "Larsen_et+al_2016_a",
            "entry": "Anders Boesen Lindbo Larsen, Sren Kaae Snderby, Hugo Larochelle, and Ole Winther. Autoencoding beyond pixels using a learned similarity metric. In Maria Florina Balcan and Kilian Q. Weinberger (eds.), Proceedings of The 33rd International Conference on Machine Learning, volume 48 of Proceedings of Machine Learning Research, pp. 1558\u20131566, New York, New York, USA, 20\u2013 22 Jun 2016. PMLR. URL http://proceedings.mlr.press/v48/larsen16.html.",
            "url": "http://proceedings.mlr.press/v48/larsen16.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Larsen%2C%20Anders%20Boesen%20Lindbo%20Snderby%2C%20Sren%20Kaae%20Larochelle%2C%20Hugo%20Winther%2C%20Ole%20Autoencoding%20beyond%20pixels%20using%20a%20learned%20similarity%20metric%202016-06-20"
        },
        {
            "id": "Liu_et+al_2015_a",
            "entry": "Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In Proceedings of the IEEE International Conference on Computer Vision, pp. 3730\u20133738, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Ziwei%20Luo%2C%20Ping%20Wang%2C%20Xiaogang%20Tang%2C%20Xiaoou%20Deep%20learning%20face%20attributes%20in%20the%20wild%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Ziwei%20Luo%2C%20Ping%20Wang%2C%20Xiaogang%20Tang%2C%20Xiaoou%20Deep%20learning%20face%20attributes%20in%20the%20wild%202015"
        },
        {
            "id": "Lucic_et+al_2017_a",
            "entry": "Mario Lucic, Karol Kurach, Marcin Michalski, Sylvain Gelly, and Olivier Bousquet. Are gans created equal? a large-scale study. arXiv preprint arXiv:1711.10337, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.10337"
        },
        {
            "id": "Makhzani_et+al_2016_a",
            "entry": "Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, and Ian Goodfellow. Adversarial autoencoders. In International Conference on Learning Representations, 2016. URL http://arxiv.org/abs/1511.05644.",
            "url": "http://arxiv.org/abs/1511.05644",
            "arxiv_url": "https://arxiv.org/pdf/1511.05644"
        },
        {
            "id": "Mao_et+al_2016_a",
            "entry": "Xudong Mao, Qing Li, Haoran Xie, Raymond Y. K. Lau, and Zhen Wang. Multi-class generative adversarial networks with the L2 loss function. CoRR, abs/1611.04076, 2016. URL http://arxiv.org/abs/1611.04076.",
            "url": "http://arxiv.org/abs/1611.04076",
            "arxiv_url": "https://arxiv.org/pdf/1611.04076"
        },
        {
            "id": "Merel_et+al_2017_a",
            "entry": "Josh Merel, Yuval Tassa, Dhruva TB, Sriram Srinivasan, Jay Lemmon, Ziyu Wang, Greg Wayne, and Nicolas Heess. Learning human behaviors from motion capture by adversarial imitation. CoRR, abs/1707.02201, 2017. URL http://arxiv.org/abs/1707.02201.",
            "url": "http://arxiv.org/abs/1707.02201",
            "arxiv_url": "https://arxiv.org/pdf/1707.02201"
        },
        {
            "id": "Mescheder_et+al_2018_a",
            "entry": "Lars Mescheder, Andreas Geiger, and Sebastian Nowozin. Which training methods for GANs do actually converge? In Jennifer Dy and Andreas Krause (eds.), Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pp. 3481\u20133490, Stockholmsmssan, Stockholm Sweden, 10\u201315 Jul 2018. PMLR. URL http://proceedings.mlr.press/v80/mescheder18a.html.",
            "url": "http://proceedings.mlr.press/v80/mescheder18a.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mescheder%2C%20Lars%20Geiger%2C%20Andreas%20Nowozin%2C%20Sebastian%20Which%20training%20methods%20for%20GANs%20do%20actually%20converge%3F%202018-07"
        },
        {
            "id": "Mescheder_et+al_2017_a",
            "entry": "Lars M. Mescheder, Sebastian Nowozin, and Andreas Geiger. Adversarial variational bayes: Unifying variational autoencoders and generative adversarial networks. CoRR, abs/1701.04722, 2017. URL http://arxiv.org/abs/1701.04722.",
            "url": "http://arxiv.org/abs/1701.04722",
            "arxiv_url": "https://arxiv.org/pdf/1701.04722"
        },
        {
            "id": "Miyato_et+al_2018_a",
            "entry": "Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for generative adversarial networks. In International Conference on Learning Representations, 2018. URL https://openreview.net/forum?id=B1QRgziT-.",
            "url": "https://openreview.net/forum?id=B1QRgziT-",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Miyato%2C%20Takeru%20Kataoka%2C%20Toshiki%20Koyama%2C%20Masanori%20Yoshida%2C%20Yuichi%20Spectral%20normalization%20for%20generative%20adversarial%20networks%202018"
        },
        {
            "id": "Peng_et+al_2018_a",
            "entry": "Xue Bin Peng, Pieter Abbeel, Sergey Levine, and Michiel van de Panne. Deepmimic: Exampleguided deep reinforcement learning of physics-based character skills. ACM Trans. Graph., 37 (4):143:1\u2013143:14, July 2018. ISSN 0730-0301. doi: 10.1145/3197517.3201311. URL http://doi.acm.org/10.1145/3197517.3201311.",
            "crossref": "https://dx.doi.org/10.1145/3197517.3201311",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/3197517.3201311"
        },
        {
            "id": "Radford_et+al_2015_a",
            "entry": "Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. CoRR, abs/1511.06434, 2015. URL http://arxiv.org/abs/1511.06434.",
            "url": "http://arxiv.org/abs/1511.06434",
            "arxiv_url": "https://arxiv.org/pdf/1511.06434"
        },
        {
            "id": "Rajeswaran_et+al_2017_a",
            "entry": "Aravind Rajeswaran, Vikash Kumar, Abhishek Gupta, John Schulman, Emanuel Todorov, and Sergey Levine. Learning complex dexterous manipulation with deep reinforcement learning and demonstrations. CoRR, abs/1709.10087, 2017. URL http://arxiv.org/abs/1709.10087.",
            "url": "http://arxiv.org/abs/1709.10087",
            "arxiv_url": "https://arxiv.org/pdf/1709.10087"
        },
        {
            "id": "Salimans_et+al_2016_a",
            "entry": "Tim Salimans, Ian J. Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. CoRR, abs/1606.03498, 2016. URL http://arxiv.org/abs/1606.03498.",
            "url": "http://arxiv.org/abs/1606.03498",
            "arxiv_url": "https://arxiv.org/pdf/1606.03498"
        },
        {
            "id": "Schulman_et+al_2015_a",
            "entry": "John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp Moritz. Trust region policy optimization. In International Conference on Machine Learning, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schulman%2C%20John%20Levine%2C%20Sergey%20Abbeel%2C%20Pieter%20Jordan%2C%20Michael%20Trust%20region%20policy%20optimization%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schulman%2C%20John%20Levine%2C%20Sergey%20Abbeel%2C%20Pieter%20Jordan%2C%20Michael%20Trust%20region%20policy%20optimization%202015"
        },
        {
            "id": "Schulman_et+al_2017_a",
            "entry": "John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms. CoRR, abs/1707.06347, 2017. URL http://arxiv.org/abs/1707.06347.",
            "url": "http://arxiv.org/abs/1707.06347",
            "arxiv_url": "https://arxiv.org/pdf/1707.06347"
        },
        {
            "id": "S_et+al_2016_a",
            "entry": "Casper Kaae S\u00f8nderby, Jose Caballero, Lucas Theis, Wenzhe Shi, and Ferenc Huszar. Amortised MAP inference for image super-resolution. CoRR, abs/1610.04490, 2016. URL http://arxiv.org/abs/1610.04490.",
            "url": "http://arxiv.org/abs/1610.04490",
            "arxiv_url": "https://arxiv.org/pdf/1610.04490"
        },
        {
            "id": "Published_2019_a",
            "entry": "Published as a conference paper at ICLR 2019 Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Published%20as%20a%20conference%20paper%20at%20ICLR%202019%20Nitish%20Srivastava%20Geoffrey%20Hinton%20Alex%20Krizhevsky%20Ilya%20Sutskever%20and%20Ruslan%20Salakhutdinov"
        },
        {
            "id": "Tishby_2014_a",
            "entry": "Dropout: A simple way to prevent neural networks from overfitting. J. Mach. Learn. Res., 15 (1):1929\u20131958, January 2014. ISSN 1532-4435. URL http://dl.acm.org/citation.cfm?id=2627435.2670313. Naftali Tishby and Noga Zaslavsky. Deep learning and the information bottleneck principle. CoRR, abs/1503.02406, 2015. URL http://arxiv.org/abs/1503.02406. Carl Vondrick, Hamed Pirsiavash, and Antonio Torralba. Generating videos with scene dynamics. CoRR, abs/1609.02612, 2016. URL http://arxiv.org/abs/1609.02612. You Xie, Erik Franz, Mengyu Chu, and Nils Thuerey.tempogan: A temporally coherent, volumetric gan for super-resolution fluid flow. ACM Transactions on Graphics (TOG), 37(4):95, 2018. Junbo Jake Zhao, Michael Mathieu, and Yann LeCun. Energy-based generative adversarial network. CoRR, abs/1609.03126, 2016. URL http://arxiv.org/abs/1609.03126.",
            "url": "http://dl.acm.org/citation.cfm?id=2627435.2670313",
            "arxiv_url": "https://arxiv.org/pdf/1503.02406"
        }
    ]
}

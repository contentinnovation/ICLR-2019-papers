{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "LEARNING TO DESCRIBE SCENES WITH PROGRAMS",
        "author": "Yunchao Liu",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=SyNPk2R9K7"
        },
        "abstract": "Human scene perception goes beyond recognizing a collection of objects and their pairwise relations. We understand higher-level, abstract regularities within the scene such as symmetry and repetition. Current vision recognition modules and scene representations fall short in this dimension. In this paper, we present scene programs, representing a scene via a symbolic program for its objects, attributes, and their relations. We also propose a model that infers such scene programs by exploiting a hierarchical, object-based scene representation. Experiments demonstrate that our model works well on synthetic data and transfers to real images with such compositional structure. The use of scene programs has enabled a number of applications, such as complex visual analogy-making and scene extrapolation."
    },
    "keywords": [
        {
            "term": "high level",
            "url": "https://en.wikipedia.org/wiki/high_level"
        },
        {
            "term": "real image",
            "url": "https://en.wikipedia.org/wiki/real_image"
        },
        {
            "term": "Domain Specific Language",
            "url": "https://en.wikipedia.org/wiki/Domain_Specific_Language"
        },
        {
            "term": "synthesis",
            "url": "https://en.wikipedia.org/wiki/synthesis"
        },
        {
            "term": "neural machine translation",
            "url": "https://en.wikipedia.org/wiki/neural_machine_translation"
        }
    ],
    "abbreviations": {
        "DSL": "Domain Specific Language",
        "HG": "heuristic grouping method"
    },
    "highlights": [
        "When examining the image in Figure 1a, we instantly recognize the shape, color, and material of the objects it depicts",
        "Our ability to imagine unseen objects arises from holistic scene perception: we not only recognize individual objects from an image, but naturally perceive how they should be organized into higher-level structure (<a class=\"ref-link\" id=\"cRock_1990_a\" href=\"#rRock_1990_a\">Rock & Palmer, 1990</a>)",
        "Since our neural program synthesizer is independent from visual recognition, only the vision systems need to be retrained for our entire model to work on real images",
        "We propose scene programs as a structured representation of complex scenes with high-level regularities",
        "We present a novel method that infers scene programs from 2D images in a hierarchical bottom-up manner",
        "The representation power of programs allows our model to be applied to other tasks in computer vision, such as image editing and analogy making, on both synthetic and photographic images"
    ],
    "key_statements": [
        "When examining the image in Figure 1a, we instantly recognize the shape, color, and material of the objects it depicts",
        "Our ability to imagine unseen objects arises from holistic scene perception: we not only recognize individual objects from an image, but naturally perceive how they should be organized into higher-level structure (<a class=\"ref-link\" id=\"cRock_1990_a\" href=\"#rRock_1990_a\">Rock & Palmer, 1990</a>)",
        "While a few recent papers have attempted to produce a holistic scene representation for scenes with a variable number of objects (<a class=\"ref-link\" id=\"cBa_et+al_2015_a\" href=\"#rBa_et+al_2015_a\">Ba et al, 2015</a>; <a class=\"ref-link\" id=\"cHuang_2015_a\" href=\"#rHuang_2015_a\">Huang & Murphy, 2015</a>; <a class=\"ref-link\" id=\"cEslami_et+al_2016_a\" href=\"#rEslami_et+al_2016_a\">Eslami et al, 2016</a>; <a class=\"ref-link\" id=\"cWu_et+al_2017_a\" href=\"#rWu_et+al_2017_a\">Wu et al, 2017</a>), the relationships among these objects are not captured in these models",
        "Figure 2 shows an example of synthesizing programs from an input image, where a sphere is selected at random and the group that this object belongs to is predicted, which consists of six spheres",
        "When an image lies within the space defined by our Domain Specific Language, it can be efficiently edited using the program representation generated by our model",
        "An advantage of our method which uses object attributes as a connection between vision and program synthesis is to generalize to real images",
        "Since our neural program synthesizer is independent from visual recognition, only the vision systems need to be retrained for our entire model to work on real images",
        "We propose scene programs as a structured representation of complex scenes with high-level regularities",
        "We present a novel method that infers scene programs from 2D images in a hierarchical bottom-up manner",
        "The representation power of programs allows our model to be applied to other tasks in computer vision, such as image editing and analogy making, on both synthetic and photographic images"
    ],
    "summary": [
        "When examining the image in Figure 1a, we instantly recognize the shape, color, and material of the objects it depicts.",
        "Our model applies deep neural networks for each stage of this process and is able to generate programs describing the input image with high accuracy.",
        "When testing on scenes that are more complex than those used for training, our hierarchical inference process achieves better generalization performance than baseline methods that attempt to infer a program directly from the image.",
        "Our model performs program induction in 3D and infers high-level structural patterns both in object layout and color.",
        "Figure 2 shows an example of synthesizing programs from an input image, where a sphere is selected at random and the group that this object belongs to is predicted, which consists of six spheres.",
        "With the object attributes and groups obtained from the vision models, the final step in our model is to generate program sequences describing the input image.",
        "Our model generates accurate results in the REGULAR setting and is able to recognize the two groups from neighbouring objects (Figure 3a).",
        "These objects form the partial observation of our model, from which the program synthesizer generates a program block which correctly describes the scene, including occluded objects.",
        "With the expressive power of the program representation, our model can be applied to tasks that require a high-level structural knowledge of the scene.",
        "When an image lies within the space defined by our DSL, it can be efficiently edited using the program representation generated by our model.",
        "The structural form of our program representation allows various types of high-level editing, including spacial extrapolation (Figure 6b, c), changing color patterns (Figure 6d) and shapes (Figure 6e).",
        "An advantage of our method which uses object attributes as a connection between vision and program synthesis is to generalize to real images.",
        "Since our neural program synthesizer is independent from visual recognition, only the vision systems need to be retrained for our entire model to work on real images.",
        "Even with a small amount of real data for fine-tuning, our model generalizes well and correctly predicts the programs for each test image.",
        "We generate the program describing the image and extract object patches with Mask R-CNN.",
        "Our original method uses a graphics engine to render new images from edited programs (Figure 6), which is not applicable for real images.",
        "The representation power of programs allows our model to be applied to other tasks in computer vision, such as image editing and analogy making, on both synthetic and photographic images."
    ],
    "headline": "We present scene programs, representing a scene via a symbolic program for its objects, attributes, and their relations",
    "reference_links": [
        {
            "id": "Ba_et+al_2015_a",
            "entry": "Jimmy Ba, Volodymyr Mnih, and Koray Kavukcuoglu. Multiple object recognition with visual attention. In ICLR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ba%2C%20Jimmy%20Mnih%2C%20Volodymyr%20Kavukcuoglu%2C%20Koray%20Multiple%20object%20recognition%20with%20visual%20attention%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ba%2C%20Jimmy%20Mnih%2C%20Volodymyr%20Kavukcuoglu%2C%20Koray%20Multiple%20object%20recognition%20with%20visual%20attention%202015"
        },
        {
            "id": "Bahdanau_et+al_2015_a",
            "entry": "Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate. In ICLR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bahdanau%2C%20Dzmitry%20Cho%2C%20Kyunghyun%20Bengio%2C%20Yoshua%20Neural%20machine%20translation%20by%20jointly%20learning%20to%20align%20and%20translate%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bahdanau%2C%20Dzmitry%20Cho%2C%20Kyunghyun%20Bengio%2C%20Yoshua%20Neural%20machine%20translation%20by%20jointly%20learning%20to%20align%20and%20translate%202015"
        },
        {
            "id": "Beltramelli_2018_a",
            "entry": "Tony Beltramelli. Pix2code: Generating code from a graphical user interface screenshot. In ACM SIGCHI Symposium on Engineering Interactive Computing Systems, EICS, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Beltramelli%2C%20Tony%20Pix2code%3A%20Generating%20code%20from%20a%20graphical%20user%20interface%20screenshot%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Beltramelli%2C%20Tony%20Pix2code%3A%20Generating%20code%20from%20a%20graphical%20user%20interface%20screenshot%202018"
        },
        {
            "id": "Bunel_et+al_2018_a",
            "entry": "Rudy Bunel, Matthew Hausknecht, Jacob Devlin, Rishabh Singh, and Pushmeet Kohli. Leveraging grammar and reinforcement learning for neural program synthesis. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bunel%2C%20Rudy%20Hausknecht%2C%20Matthew%20Devlin%2C%20Jacob%20Singh%2C%20Rishabh%20Leveraging%20grammar%20and%20reinforcement%20learning%20for%20neural%20program%20synthesis%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bunel%2C%20Rudy%20Hausknecht%2C%20Matthew%20Devlin%2C%20Jacob%20Singh%2C%20Rishabh%20Leveraging%20grammar%20and%20reinforcement%20learning%20for%20neural%20program%20synthesis%202018"
        },
        {
            "id": "Deng_et+al_2017_a",
            "entry": "Yuntian Deng, Anssi Kanervisto, Jeffrey Ling, and Alexander M Rush. Image-to-markup generation with coarse-to-fine attention. In ICML, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Deng%2C%20Yuntian%20Kanervisto%2C%20Anssi%20Ling%2C%20Jeffrey%20Rush%2C%20Alexander%20M.%20Image-to-markup%20generation%20with%20coarse-to-fine%20attention%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Deng%2C%20Yuntian%20Kanervisto%2C%20Anssi%20Ling%2C%20Jeffrey%20Rush%2C%20Alexander%20M.%20Image-to-markup%20generation%20with%20coarse-to-fine%20attention%202017"
        },
        {
            "id": "Devlin_et+al_2017_a",
            "entry": "Jacob Devlin, Jonathan Uesato, Surya Bhupatiraju, Rishabh Singh, Abdel-rahman Mohamed, and Pushmeet Kohli. Robustfill: Neural program learning under noisy i/o. In ICML, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Devlin%2C%20Jacob%20Uesato%2C%20Jonathan%20Bhupatiraju%2C%20Surya%20Singh%2C%20Rishabh%20Robustfill%3A%20Neural%20program%20learning%20under%20noisy%20i/o%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Devlin%2C%20Jacob%20Uesato%2C%20Jonathan%20Bhupatiraju%2C%20Surya%20Singh%2C%20Rishabh%20Robustfill%3A%20Neural%20program%20learning%20under%20noisy%20i/o%202017"
        },
        {
            "id": "Ellis_et+al_2018_a",
            "entry": "Kevin Ellis, Daniel Ritchie, Armando Solar-Lezama, and Josh Tenenbaum. Learning to infer graphics programs from hand-drawn images. In NeurIPS, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ellis%2C%20Kevin%20Ritchie%2C%20Daniel%20Solar-Lezama%2C%20Armando%20Tenenbaum%2C%20Josh%20Learning%20to%20infer%20graphics%20programs%20from%20hand-drawn%20images%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ellis%2C%20Kevin%20Ritchie%2C%20Daniel%20Solar-Lezama%2C%20Armando%20Tenenbaum%2C%20Josh%20Learning%20to%20infer%20graphics%20programs%20from%20hand-drawn%20images%202018"
        },
        {
            "id": "Eslami_et+al_2016_a",
            "entry": "SM Eslami, Nicolas Heess, Theophane Weber, Yuval Tassa, Koray Kavukcuoglu, and Geoffrey E Hinton. Attend, infer, repeat: Fast scene understanding with generative models. In NeurIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Eslami%2C%20S.M.%20Heess%2C%20Nicolas%20Weber%2C%20Theophane%20Tassa%2C%20Yuval%20Attend%2C%20infer%2C%20repeat%3A%20Fast%20scene%20understanding%20with%20generative%20models%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Eslami%2C%20S.M.%20Heess%2C%20Nicolas%20Weber%2C%20Theophane%20Tassa%2C%20Yuval%20Attend%2C%20infer%2C%20repeat%3A%20Fast%20scene%20understanding%20with%20generative%20models%202016"
        },
        {
            "id": "Ganin_et+al_2018_a",
            "entry": "Yaroslav Ganin, Tejas Kulkarni, Igor Babuschkin, S. M. Ali Eslami, and Oriol Vinyals. Synthesizing programs for images using reinforced adversarial learning. In ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ganin%2C%20Yaroslav%20Kulkarni%2C%20Tejas%20Igor%20Babuschkin%2C%20S.M.Ali%20Eslami%20Vinyals%2C%20Oriol%20Synthesizing%20programs%20for%20images%20using%20reinforced%20adversarial%20learning%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ganin%2C%20Yaroslav%20Kulkarni%2C%20Tejas%20Igor%20Babuschkin%2C%20S.M.Ali%20Eslami%20Vinyals%2C%20Oriol%20Synthesizing%20programs%20for%20images%20using%20reinforced%20adversarial%20learning%202018"
        },
        {
            "id": "He_et+al_2015_a",
            "entry": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202015"
        },
        {
            "id": "He_et+al_2017_a",
            "entry": "Kaiming He, Georgia Gkioxari, Piotr Dollar, and Ross Girshick. Mask r-cnn. In ICCV, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kaiming%20He%20Georgia%20Gkioxari%20Piotr%20Dollar%20and%20Ross%20Girshick%20Mask%20rcnn%20In%20ICCV%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kaiming%20He%20Georgia%20Gkioxari%20Piotr%20Dollar%20and%20Ross%20Girshick%20Mask%20rcnn%20In%20ICCV%202017"
        },
        {
            "id": "Hinton_2006_a",
            "entry": "Geoffrey E Hinton and Ruslan R Salakhutdinov. Reducing the dimensionality of data with neural networks. Science, 313(5786):504\u2013507, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hinton%2C%20Geoffrey%20E.%20Salakhutdinov%2C%20Ruslan%20R.%20Reducing%20the%20dimensionality%20of%20data%20with%20neural%20networks%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hinton%2C%20Geoffrey%20E.%20Salakhutdinov%2C%20Ruslan%20R.%20Reducing%20the%20dimensionality%20of%20data%20with%20neural%20networks%202006"
        },
        {
            "id": "Huang_2015_a",
            "entry": "Jonathan Huang and Kevin Murphy. Efficient inference in occlusion-aware generative models of images. In ICLR Workshop, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20Jonathan%20Murphy%2C%20Kevin%20Efficient%20inference%20in%20occlusion-aware%20generative%20models%20of%20images%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20Jonathan%20Murphy%2C%20Kevin%20Efficient%20inference%20in%20occlusion-aware%20generative%20models%20of%20images%202015"
        },
        {
            "id": "Isola_et+al_2017_a",
            "entry": "Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with conditional adversarial networks. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Isola%2C%20Phillip%20Zhu%2C%20Jun-Yan%20Zhou%2C%20Tinghui%20and%20Alexei%20A%20Efros.%20Image-to-image%20translation%20with%20conditional%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Isola%2C%20Phillip%20Zhu%2C%20Jun-Yan%20Zhou%2C%20Tinghui%20and%20Alexei%20A%20Efros.%20Image-to-image%20translation%20with%20conditional%20adversarial%20networks%202017"
        },
        {
            "id": "Johnson_et+al_2015_a",
            "entry": "Justin Johnson, Ranjay Krishna, Michael Stark, Li-Jia Li, David Shamma, Michael Bernstein, and Li Fei-Fei. Image retrieval using scene graphs. In CVPR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Justin%20Krishna%2C%20Ranjay%20Stark%2C%20Michael%20Li%2C%20Li-Jia%20Image%20retrieval%20using%20scene%20graphs%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20Justin%20Krishna%2C%20Ranjay%20Stark%2C%20Michael%20Li%2C%20Li-Jia%20Image%20retrieval%20using%20scene%20graphs%202015"
        },
        {
            "id": "Johnson_et+al_2017_a",
            "entry": "Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei, C Lawrence Zitnick, and Ross Girshick. Clevr: A diagnostic dataset for compositional language and elementary visual reasoning. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Justin%20Hariharan%2C%20Bharath%20van%20der%20Maaten%2C%20Laurens%20Li%20Fei-Fei%2C%20C.Lawrence%20Zitnick%20Clevr%3A%20A%20diagnostic%20dataset%20for%20compositional%20language%20and%20elementary%20visual%20reasoning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20Justin%20Hariharan%2C%20Bharath%20van%20der%20Maaten%2C%20Laurens%20Li%20Fei-Fei%2C%20C.Lawrence%20Zitnick%20Clevr%3A%20A%20diagnostic%20dataset%20for%20compositional%20language%20and%20elementary%20visual%20reasoning%202017"
        },
        {
            "id": "Kipf_et+al_2018_a",
            "entry": "Thomas N Kipf, Ethan Fetaya, Kuan-Chieh Wang, Max Welling, and Richard S Zemel. Neural relational inference for interacting systems. In ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kipf%2C%20Thomas%20N.%20Fetaya%2C%20Ethan%20Wang%2C%20Kuan-Chieh%20Welling%2C%20Max%20Neural%20relational%20inference%20for%20interacting%20systems%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kipf%2C%20Thomas%20N.%20Fetaya%2C%20Ethan%20Wang%2C%20Kuan-Chieh%20Welling%2C%20Max%20Neural%20relational%20inference%20for%20interacting%20systems%202018"
        },
        {
            "id": "Li_et+al_2017_a",
            "entry": "Jun Li, Kai Xu, Siddhartha Chaudhuri, Ersin Yumer, Hao Zhang, and Leonidas Guibas. GRASS: Generative Recursive Autoencoders for Shape Structures. In SIGGRAPH, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Jun%20Xu%2C%20Kai%20Chaudhuri%2C%20Siddhartha%20Yumer%2C%20Ersin%20GRASS%3A%20Generative%20Recursive%20Autoencoders%20for%20Shape%20Structures%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Jun%20Xu%2C%20Kai%20Chaudhuri%2C%20Siddhartha%20Yumer%2C%20Ersin%20GRASS%3A%20Generative%20Recursive%20Autoencoders%20for%20Shape%20Structures%202017"
        },
        {
            "id": "Li_et+al_2019_a",
            "entry": "Manyi Li, Akshay Gadi Patil, Kai Xu, Siddhartha Chaudhuri, Owais Khan, Ariel Shamir, Changhe Tu, Baoquan Chen, Daniel Cohen-Or, and Hao Zhang. Grains: Generative recursive autoencoders for indoor scenes. ACM TOG, 38(2):12:1\u201312:16, 2019.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Manyi%20Patil%2C%20Akshay%20Gadi%20Xu%2C%20Kai%20Chaudhuri%2C%20Siddhartha%20Grains%3A%20Generative%20recursive%20autoencoders%20for%20indoor%20scenes%202019",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Manyi%20Patil%2C%20Akshay%20Gadi%20Xu%2C%20Kai%20Chaudhuri%2C%20Siddhartha%20Grains%3A%20Generative%20recursive%20autoencoders%20for%20indoor%20scenes%202019"
        },
        {
            "id": "Luong_et+al_2015_a",
            "entry": "Thang Luong, Hieu Pham, and Christopher D. Manning. Effective approaches to attention-based neural machine translation. In EMNLP, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Luong%2C%20Thang%20Pham%2C%20Hieu%20Manning%2C%20Christopher%20D.%20Effective%20approaches%20to%20attention-based%20neural%20machine%20translation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Luong%2C%20Thang%20Pham%2C%20Hieu%20Manning%2C%20Christopher%20D.%20Effective%20approaches%20to%20attention-based%20neural%20machine%20translation%202015"
        },
        {
            "id": "Niu_et+al_2018_a",
            "entry": "Chengjie Niu, Jun Li, and Kai Xu. Im2Struct: Recovering 3D Shape Structure from a Single RGB Image. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Niu%2C%20Chengjie%20Li%2C%20Jun%20Xu%2C%20Kai%20Im2Struct%3A%20Recovering%203D%20Shape%20Structure%20from%20a%20Single%20RGB%20Image%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Niu%2C%20Chengjie%20Li%2C%20Jun%20Xu%2C%20Kai%20Im2Struct%3A%20Recovering%203D%20Shape%20Structure%20from%20a%20Single%20RGB%20Image%202018"
        },
        {
            "id": "Parisotto_et+al_2017_a",
            "entry": "Emilio Parisotto, Abdel-rahman Mohamed, Rishabh Singh, Lihong Li, Dengyong Zhou, and Pushmeet Kohli. Neuro-symbolic program synthesis. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Parisotto%2C%20Emilio%20Mohamed%2C%20Abdel-rahman%20Singh%2C%20Rishabh%20Li%2C%20Lihong%20Neuro-symbolic%20program%20synthesis%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Parisotto%2C%20Emilio%20Mohamed%2C%20Abdel-rahman%20Singh%2C%20Rishabh%20Li%2C%20Lihong%20Neuro-symbolic%20program%20synthesis%202017"
        },
        {
            "id": "Reed_et+al_2015_a",
            "entry": "Scott E Reed, Yi Zhang, Yuting Zhang, and Honglak Lee. Deep visual analogy-making. In NeurIPS, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Reed%2C%20Scott%20E.%20Zhang%2C%20Yi%20Zhang%2C%20Yuting%20Lee%2C%20Honglak%20Deep%20visual%20analogy-making%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Reed%2C%20Scott%20E.%20Zhang%2C%20Yi%20Zhang%2C%20Yuting%20Lee%2C%20Honglak%20Deep%20visual%20analogy-making%202015"
        },
        {
            "id": "Rock_1990_a",
            "entry": "Irvin Rock and Stephen Palmer. The legacy of gestalt psychology. Sci. Amer., 263(6):84\u201391, 1990.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rock%2C%20Irvin%20Palmer%2C%20Stephen%20The%20legacy%20of%20gestalt%20psychology%201990",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rock%2C%20Irvin%20Palmer%2C%20Stephen%20The%20legacy%20of%20gestalt%20psychology%201990"
        },
        {
            "id": "Sharma_et+al_2018_a",
            "entry": "Gopal Sharma, Rishabh Goyal, Difan Liu, Evangelos Kalogerakis, and Subhransu Maji. Csgnet: Neural shape parser for constructive solid geometry. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sharma%2C%20Gopal%20Goyal%2C%20Rishabh%20Liu%2C%20Difan%20Kalogerakis%2C%20Evangelos%20Csgnet%3A%20Neural%20shape%20parser%20for%20constructive%20solid%20geometry%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sharma%2C%20Gopal%20Goyal%2C%20Rishabh%20Liu%2C%20Difan%20Kalogerakis%2C%20Evangelos%20Csgnet%3A%20Neural%20shape%20parser%20for%20constructive%20solid%20geometry%202018"
        },
        {
            "id": "Sun_et+al_2018_a",
            "entry": "Shao-Hua Sun, Hyeonwoo Noh, Sriram Somasundaram, and Joseph Lim. Neural program synthesis from diverse demonstration videos. In ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sun%2C%20Shao-Hua%20Noh%2C%20Hyeonwoo%20Somasundaram%2C%20Sriram%20Lim%2C%20Joseph%20Neural%20program%20synthesis%20from%20diverse%20demonstration%20videos%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sun%2C%20Shao-Hua%20Noh%2C%20Hyeonwoo%20Somasundaram%2C%20Sriram%20Lim%2C%20Joseph%20Neural%20program%20synthesis%20from%20diverse%20demonstration%20videos%202018"
        },
        {
            "id": "Tulsiani_et+al_2017_a",
            "entry": "Shubham Tulsiani, Hao Su, Leonidas J. Guibas, Alexei A. Efros, and Jitendra Malik. Learning shape abstractions by assembling volumetric primitives. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tulsiani%2C%20Shubham%20Su%2C%20Hao%20Guibas%2C%20Leonidas%20J.%20Efros%2C%20Alexei%20A.%20Learning%20shape%20abstractions%20by%20assembling%20volumetric%20primitives%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tulsiani%2C%20Shubham%20Su%2C%20Hao%20Guibas%2C%20Leonidas%20J.%20Efros%2C%20Alexei%20A.%20Learning%20shape%20abstractions%20by%20assembling%20volumetric%20primitives%202017"
        },
        {
            "id": "Van_et+al_2018_a",
            "entry": "Sjoerd van Steenkiste, Michael Chang, Klaus Greff, and Jurgen Schmidhuber. Relational neural expectation maximization: Unsupervised discovery of objects and their interactions. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=van%20Steenkiste%2C%20Sjoerd%20Chang%2C%20Michael%20Greff%2C%20Klaus%20Schmidhuber%2C%20Jurgen%20Relational%20neural%20expectation%20maximization%3A%20Unsupervised%20discovery%20of%20objects%20and%20their%20interactions%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=van%20Steenkiste%2C%20Sjoerd%20Chang%2C%20Michael%20Greff%2C%20Klaus%20Schmidhuber%2C%20Jurgen%20Relational%20neural%20expectation%20maximization%3A%20Unsupervised%20discovery%20of%20objects%20and%20their%20interactions%202018"
        },
        {
            "id": "Wang_2011_a",
            "entry": "Yanzhen Wang, Kai Xu, Jun Li, Hao Zhang, Ariel Shamir, Ligang Liu, Zhi-Quan Cheng, and Yueshan Xiong. Symmetry Hierarchy of Man-Made Objects. Computer Graphics Forum, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Yanzhen%20Xu%2C%20Kai%20Symmetry%20Hierarchy%20of%20Man-Made%20Objects%202011-06"
        },
        {
            "id": "Wu_et+al_2017_a",
            "entry": "Jiajun Wu, Joshua B Tenenbaum, and Pushmeet Kohli. Neural scene de-rendering. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jiajun%20Wu%20Joshua%20B%20Tenenbaum%20and%20Pushmeet%20Kohli%20Neural%20scene%20derendering%20In%20CVPR%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jiajun%20Wu%20Joshua%20B%20Tenenbaum%20and%20Pushmeet%20Kohli%20Neural%20scene%20derendering%20In%20CVPR%202017"
        },
        {
            "id": "Xu_et+al_2015_a",
            "entry": "Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, Richard S Zemel, and Yoshua Bengio. Show, attend and tell: Neural image caption generation with visual attention. In ICML, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kelvin%20Xu%20Jimmy%20Ba%20Ryan%20Kiros%20Kyunghyun%20Cho%20Aaron%20Courville%20Ruslan%20Salakhutdinov%20Richard%20S%20Zemel%20and%20Yoshua%20Bengio%20Show%20attend%20and%20tell%20Neural%20image%20caption%20generation%20with%20visual%20attention%20In%20ICML%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kelvin%20Xu%20Jimmy%20Ba%20Ryan%20Kiros%20Kyunghyun%20Cho%20Aaron%20Courville%20Ruslan%20Salakhutdinov%20Richard%20S%20Zemel%20and%20Yoshua%20Bengio%20Show%20attend%20and%20tell%20Neural%20image%20caption%20generation%20with%20visual%20attention%20In%20ICML%202015"
        }
    ]
}

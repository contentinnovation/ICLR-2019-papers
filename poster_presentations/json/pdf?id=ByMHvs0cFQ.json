{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "QUATERNION RECURRENT NEURAL NETWORKS",
        "author": "Titouan Parcollet, Mirco Ravanelli, Mohamed Morchid, Georges Linar\u00e8s, Chiheb Trabelsi, Renato De Mori, Yoshua Bengio",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=ByMHvs0cFQ"
        },
        "abstract": "Recurrent neural networks (RNNs) are powerful architectures to model sequential data, due to their capability to learn short and long-term dependencies between the basic elements of a sequence. Nonetheless, popular tasks such as speech or images recognition, involve multi-dimensional input features that are characterized by strong internal dependencies between the dimensions of the input vector. We propose a novel quaternion recurrent neural network (QRNN), alongside with a quaternion long-short term memory neural network (QLSTM), that take into account both the external relations and these internal structural dependencies with the quaternion algebra. Similarly to capsules, quaternions allow the QRNN to code internal dependencies by composing and processing multidimensional features as single entities, while the recurrent operation reveals correlations between the elements composing the sequence. We show that both QRNN and QLSTM achieve better performances than RNN and LSTM in a realistic application of automatic speech recognition. Finally, we show that QRNN and QLSTM reduce by a maximum factor of 3.3x the number of free parameters needed, compared to real-valued RNNs and LSTMs to reach better results, leading to a more compact representation of the relevant information."
    },
    "keywords": [
        {
            "term": "Wall Street Journal",
            "url": "https://en.wikipedia.org/wiki/Wall_Street_Journal"
        },
        {
            "term": "backpropagation through time",
            "url": "https://en.wikipedia.org/wiki/backpropagation_through_time"
        },
        {
            "term": "deep neural networks",
            "url": "https://en.wikipedia.org/wiki/deep_neural_networks"
        },
        {
            "term": "Recurrent neural networks",
            "url": "https://en.wikipedia.org/wiki/Recurrent_neural_networks"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "long short term memory",
            "url": "https://en.wikipedia.org/wiki/long_short_term_memory"
        },
        {
            "term": "speech recognition",
            "url": "https://en.wikipedia.org/wiki/speech_recognition"
        },
        {
            "term": "quaternion algebra",
            "url": "https://en.wikipedia.org/wiki/quaternion_algebra"
        }
    ],
    "abbreviations": {
        "RNNs": "Recurrent neural networks",
        "QRNN": "quaternion recurrent neural network",
        "DNN": "deep neural networks",
        "RNN": "recurrent neural network",
        "BPTT": "backpropagation through time",
        "WFST": "weighted finite state transducers",
        "LSTM": "long-short term memory neural networks",
        "WSJ": "Wall Street Journal"
    },
    "highlights": [
        "In the last few years, deep neural networks (DNN) have encountered a wide success in different domains due to their capability to learn highly complex input to output mapping",
        "This paper proposes to integrate local spectral features in a novel model called quaternion recurrent neural network1 (QRNN), and its gated extension called quaternion long-short term memory neural network (QLSTM)",
        "Based on the above motivations and the results observed on previous works about quaternion neural networks, we hypothesize that quaternion Recurrent neural networks naturally provide a more suitable representation of the input sequence, since these multiple views can be directly embedded in the multiple dimensions space of the quaternion, leading to better generalization.\n3 QUATERNION RECURRENT NEURAL NETWORKS",
        "We propose to extend the quaternion recurrent neural network to state-of-the-art models such as long-short term memory neural networks (LSTM), to support and improve the results already observed with the quaternion recurrent neural network compared to the Recurrent neural networks in more realistic conditions",
        "We first point out that the best PER observed is 15.1% and 15.3% on the test set for QLSTMs and long-short term memory neural networks models respectively with an absolute improvement of 0.2% obtained with QLSTM using 3.3 times fewer parameters compared to long-short term memory neural networks",
        "This paper proposes to process sequences of multidimensional features with a novel quaternion recurrent neural network (QRNN) and quaternion long-short term memory neural network (QLSTM)"
    ],
    "key_statements": [
        "In the last few years, deep neural networks (DNN) have encountered a wide success in different domains due to their capability to learn highly complex input to output mapping",
        "This paper proposes to integrate local spectral features in a novel model called quaternion recurrent neural network1 (QRNN), and its gated extension called quaternion long-short term memory neural network (QLSTM)",
        "Based on the above motivations and the results observed on previous works about quaternion neural networks, we hypothesize that quaternion Recurrent neural networks naturally provide a more suitable representation of the input sequence, since these multiple views can be directly embedded in the multiple dimensions space of the quaternion, leading to better generalization.\n3 QUATERNION RECURRENT NEURAL NETWORKS",
        "We propose to extend the quaternion recurrent neural network to state-of-the-art models such as long-short term memory neural networks (LSTM), to support and improve the results already observed with the quaternion recurrent neural network compared to the Recurrent neural networks in more realistic conditions",
        "We first point out that the best PER observed is 15.1% and 15.3% on the test set for QLSTMs and long-short term memory neural networks models respectively with an absolute improvement of 0.2% obtained with QLSTM using 3.3 times fewer parameters compared to long-short term memory neural networks",
        "This paper proposes to process sequences of multidimensional features with a novel quaternion recurrent neural network (QRNN) and quaternion long-short term memory neural network (QLSTM)"
    ],
    "summary": [
        "In the last few years, deep neural networks (DNN) have encountered a wide success in different domains due to their capability to learn highly complex input to output mapping.",
        "Among the different DNN-based models, the recurrent neural network (RNN) is well adapted to process sequential data.",
        "Thereby, quaternion numbers allow neural network based models to code latent inter-dependencies between groups of input features during the learning process with fewer parameters than RNNs, by taking advantage of the Hamilton product as the equivalent of the ordinary product, but between quaternions.",
        "We detail the motivations to employ a quaternion-valued RNN instead of a real-valued one to code inter and intra features dependencies with fewer parameters.",
        "Based on the above motivations and the results observed on previous works about quaternion neural networks, we hypothesize that quaternion RNNs naturally provide a more suitable representation of the input sequence, since these multiple views can be directly embedded in the multiple dimensions space of the quaternion, leading to better generalization.",
        "Based on the forward propagation of the real-valued RNN (<a class=\"ref-link\" id=\"cMedsker_2001_a\" href=\"#rMedsker_2001_a\">Medsker & Jain, 2001</a>), the QRNN forward equations are extended as follows: ht = \u03b1(Whh \u2297 ht\u22121 + Whx \u2297 xt + bh), (6)",
        "Conversaly to real-valued backpropagation, QBPTT must defines the dynamic of the loss w.r.t to each component of the quaternion neural parameters.",
        "This Section proposes a procedure reported in Algorithm 1 to initialize a matrix W of quaternion-valued weights.",
        "Such PERs are obtained with models that employ the same internal dimensionality corresponding to 1, 024 real-valued neurons and 256 quaternion-valued ones, resulting in a number of parameters of 3.8M for QRNN against the 9.4M used in the real-valued RNN.",
        "We propose to extend the QRNN to state-of-the-art models such as long-short term memory neural networks (LSTM), to support and improve the results already observed with the QRNN compared to the RNN in more realistic conditions.",
        "We first point out that the best PER observed is 15.1% and 15.3% on the test set for QLSTMs and LSTM models respectively with an absolute improvement of 0.2% obtained with QLSTM using 3.3 times fewer parameters compared to LSTM.",
        "The experiments conducted on the TIMIT phoneme recognition task show that QRNNs and QLSTMs are more effective to learn a compact representation of multidimensional information by outperforming RNNs and LSTMs with 2 to 3 times less free parameters.",
        "Our initial intuition that the quaternion algebra offers a better and more compact representation for multidimensional features, alongside with a better learning capability of feature internal dependencies through the Hamilton product, have been demonstrated."
    ],
    "headline": "We propose a novel quaternion recurrent neural network, alongside with a quaternion long-short term memory neural network, that take into account both the external relations and these internal structural dependencies with the quaternion algebra",
    "reference_links": [
        {
            "id": "Amodei_et+al_2016_a",
            "entry": "Dario Amodei, Sundaram Ananthanarayanan, Rishita Anubhai, Jingliang Bai, Eric Battenberg, Carl Case, Jared Casper, Bryan Catanzaro, Qiang Cheng, Guoliang Chen, et al. Deep speech 2: Endto-end speech recognition in english and mandarin. In International Conference on Machine Learning, pp. 173\u2013182, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Amodei%2C%20Dario%20Ananthanarayanan%2C%20Sundaram%20Anubhai%2C%20Rishita%20Bai%2C%20Jingliang%20Deep%20speech%202%3A%20Endto-end%20speech%20recognition%20in%20english%20and%20mandarin%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Amodei%2C%20Dario%20Ananthanarayanan%2C%20Sundaram%20Anubhai%2C%20Rishita%20Bai%2C%20Jingliang%20Deep%20speech%202%3A%20Endto-end%20speech%20recognition%20in%20english%20and%20mandarin%202016"
        },
        {
            "id": "Arena_et+al_1994_a",
            "entry": "Paolo Arena, Luigi Fortuna, Luigi Occhipinti, and Maria Gabriella Xibilia. Neural networks for quaternion-valued function approximation. In Circuits and Systems, ISCAS\u201994., IEEE International Symposium on, volume 6, pp. 307\u2013310. IEEE, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arena%2C%20Paolo%20Fortuna%2C%20Luigi%20Occhipinti%2C%20Luigi%20Xibilia%2C%20Maria%20Gabriella%20Neural%20networks%20for%20quaternion-valued%20function%20approximation%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arena%2C%20Paolo%20Fortuna%2C%20Luigi%20Occhipinti%2C%20Luigi%20Xibilia%2C%20Maria%20Gabriella%20Neural%20networks%20for%20quaternion-valued%20function%20approximation%201994"
        },
        {
            "id": "Arena_et+al_1997_a",
            "entry": "Paolo Arena, Luigi Fortuna, Giovanni Muscato, and Maria Gabriella Xibilia. Multilayer perceptrons to approximate quaternion valued functions. Neural Networks, 10(2):335\u2013342, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arena%2C%20Paolo%20Fortuna%2C%20Luigi%20Muscato%2C%20Giovanni%20Xibilia%2C%20Maria%20Gabriella%20Multilayer%20perceptrons%20to%20approximate%20quaternion%20valued%20functions%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arena%2C%20Paolo%20Fortuna%2C%20Luigi%20Muscato%2C%20Giovanni%20Xibilia%2C%20Maria%20Gabriella%20Multilayer%20perceptrons%20to%20approximate%20quaternion%20valued%20functions%201997"
        },
        {
            "id": "Aspragathos_1998_a",
            "entry": "Nicholas A Aspragathos and John K Dimitros. A comparative study of three methods for robot kinematics. Systems, Man, and Cybernetics, Part B: Cybernetics, IEEE Transactions on, 28(2): 135\u2013145, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Aspragathos%2C%20Nicholas%20A.%20Dimitros%2C%20John%20K.%20A%20comparative%20study%20of%20three%20methods%20for%20robot%20kinematics%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Aspragathos%2C%20Nicholas%20A.%20Dimitros%2C%20John%20K.%20A%20comparative%20study%20of%20three%20methods%20for%20robot%20kinematics%201998"
        },
        {
            "id": "Chakraborty_et+al_2018_a",
            "entry": "Rudrasis Chakraborty, Jose Bouza, Jonathan Manton, and Baba C. Vemuri. Manifoldnet: A deep network framework for manifold-valued data. arXiv preprint arXiv:1809.06211, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1809.06211"
        },
        {
            "id": "Chan_2015_a",
            "entry": "William Chan and Ian Lane. Deep recurrent neural networks for acoustic modelling. arXiv preprint arXiv:1504.01482, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1504.01482"
        },
        {
            "id": "Chen_et+al_2014_a",
            "entry": "G. Chen, C. Parada, and G. Heigold. Small-footprint keyword spotting using deep neural networks. In 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 4087\u20134091, May 2014. doi: 10.1109/ICASSP.2014.6854370.",
            "crossref": "https://dx.doi.org/10.1109/ICASSP.2014.6854370",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/ICASSP.2014.6854370"
        },
        {
            "id": "Chiu_et+al_2018_a",
            "entry": "Chung-Cheng Chiu, Tara N Sainath, Yonghui Wu, Rohit Prabhavalkar, Patrick Nguyen, Zhifeng Chen, Anjuli Kannan, Ron J Weiss, Kanishka Rao, Ekaterina Gonina, et al. State-of-the-art speech recognition with sequence-to-sequence models. In 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 4774\u20134778. IEEE, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chiu%2C%20Chung-Cheng%20Sainath%2C%20Tara%20N.%20Wu%2C%20Yonghui%20Prabhavalkar%2C%20Rohit%20State-of-the-art%20speech%20recognition%20with%20sequence-to-sequence%20models%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chiu%2C%20Chung-Cheng%20Sainath%2C%20Tara%20N.%20Wu%2C%20Yonghui%20Prabhavalkar%2C%20Rohit%20State-of-the-art%20speech%20recognition%20with%20sequence-to-sequence%20models%202018"
        },
        {
            "id": "Conneau_et+al_2018_a",
            "entry": "Alexis Conneau, German Kruszewski, Guillaume Lample, Lo\u00efc Barrault, and Marco Baroni. What you can cram into a single vector: Probing sentence embeddings for linguistic properties, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Conneau%2C%20Alexis%20Kruszewski%2C%20German%20Lample%2C%20Guillaume%20Barrault%2C%20Lo%C3%AFc%20What%20you%20can%20cram%20into%20a%20single%20vector%3A%20Probing%20sentence%20embeddings%20for%20linguistic%20properties%202018"
        },
        {
            "id": "Danihelka_et+al_2016_a",
            "entry": "Ivo Danihelka, Greg Wayne, Benigno Uria, Nal Kalchbrenner, and Alex Graves. Associative long short-term memory. arXiv preprint arXiv:1602.03032, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1602.03032"
        },
        {
            "id": "Furui_1986_a",
            "entry": "Sadaoki Furui. Speaker-independent isolated word recognition based on emphasized spectral dynamics. In Acoustics, Speech, and Signal Processing, IEEE International Conference on ICASSP\u201986., volume 11, pp. 1991\u20131994. IEEE, 1986.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Furui%2C%20Sadaoki%20Speaker-independent%20isolated%20word%20recognition%20based%20on%20emphasized%20spectral%20dynamics%201986",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Furui%2C%20Sadaoki%20Speaker-independent%20isolated%20word%20recognition%20based%20on%20emphasized%20spectral%20dynamics%201986"
        },
        {
            "id": "Garofolo_et+al_1993_a",
            "entry": "John S Garofolo, Lori F Lamel, William M Fisher, Jonathan G Fiscus, and David S Pallett. Darpa timit acoustic-phonetic continous speech corpus cd-rom. nist speech disc 1-1.1. NASA STI/Recon technical report n, 93, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Garofolo%2C%20John%20S.%20Lamel%2C%20Lori%20F.%20Fisher%2C%20William%20M.%20Fiscus%2C%20Jonathan%20G.%20Darpa%20timit%20acoustic-phonetic%20continous%20speech%20corpus%20cd-rom.%20nist%20speech%20disc%201-1.1%201993"
        },
        {
            "id": "Gaudet_2018_a",
            "entry": "Chase J Gaudet and Anthony S Maida. Deep quaternion networks. In 2018 International Joint Conference on Neural Networks (IJCNN), pp. 1\u20138. IEEE, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gaudet%2C%20Chase%20J.%20Maida%2C%20Anthony%20S.%20Deep%20quaternion%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gaudet%2C%20Chase%20J.%20Maida%2C%20Anthony%20S.%20Deep%20quaternion%20networks%202018"
        },
        {
            "id": "Glorot_2010_a",
            "entry": "Xavier Glorot and Yoshua Bengio. Understanding the difficulty of training deep feedforward neural networks. In International conference on artificial intelligence and statistics, pp. 249\u2013256, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Glorot%2C%20Xavier%20Bengio%2C%20Yoshua%20Understanding%20the%20difficulty%20of%20training%20deep%20feedforward%20neural%20networks%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Glorot%2C%20Xavier%20Bengio%2C%20Yoshua%20Understanding%20the%20difficulty%20of%20training%20deep%20feedforward%20neural%20networks%202010"
        },
        {
            "id": "Graves_et+al_2013_a",
            "entry": "Alex Graves, Navdeep Jaitly, and Abdel-rahman Mohamed. Hybrid speech recognition with deep bidirectional lstm. In Automatic Speech Recognition and Understanding (ASRU), 2013 IEEE Workshop on, pp. 273\u2013278. IEEE, 2013a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Graves%2C%20Alex%20Jaitly%2C%20Navdeep%20Mohamed%2C%20Abdel-rahman%20Hybrid%20speech%20recognition%20with%20deep%20bidirectional%20lstm%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Graves%2C%20Alex%20Jaitly%2C%20Navdeep%20Mohamed%2C%20Abdel-rahman%20Hybrid%20speech%20recognition%20with%20deep%20bidirectional%20lstm%202013"
        },
        {
            "id": "Graves_et+al_2013_b",
            "entry": "Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton. Speech recognition with deep recurrent neural networks. In Acoustics, speech and signal processing (icassp), 2013 ieee international conference on, pp. 6645\u20136649. IEEE, 2013b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Graves%2C%20Alex%20Mohamed%2C%20Abdel-rahman%20Hinton%2C%20Geoffrey%20Speech%20recognition%20with%20deep%20recurrent%20neural%20networks%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Graves%2C%20Alex%20Mohamed%2C%20Abdel-rahman%20Hinton%2C%20Geoffrey%20Speech%20recognition%20with%20deep%20recurrent%20neural%20networks%202013"
        },
        {
            "id": "He_et+al_2015_a",
            "entry": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. In Proceedings of the IEEE international conference on computer vision, pp. 1026\u20131034, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Delving%20deep%20into%20rectifiers%3A%20Surpassing%20human-level%20performance%20on%20imagenet%20classification%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Delving%20deep%20into%20rectifiers%3A%20Surpassing%20human-level%20performance%20on%20imagenet%20classification%202015"
        },
        {
            "id": "Hirose_2012_a",
            "entry": "Akira Hirose and Shotaro Yoshida. Generalization characteristics of complex-valued feedforward neural networks in relation to signal coherence. IEEE Transactions on Neural Networks and learning systems, 23(4):541\u2013551, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hirose%2C%20Akira%20Yoshida%2C%20Shotaro%20Generalization%20characteristics%20of%20complex-valued%20feedforward%20neural%20networks%20in%20relation%20to%20signal%20coherence%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hirose%2C%20Akira%20Yoshida%2C%20Shotaro%20Generalization%20characteristics%20of%20complex-valued%20feedforward%20neural%20networks%20in%20relation%20to%20signal%20coherence%202012"
        },
        {
            "id": "Hochreiter_1997_a",
            "entry": "Sepp Hochreiter and J\u00fcrgen Schmidhuber. Long short-term memory. Neural computation, 9(8): 1735\u20131780, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hochreiter%2C%20Sepp%20Schmidhuber%2C%20J%C3%BCrgen%20Long%20short-term%20memory%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hochreiter%2C%20Sepp%20Schmidhuber%2C%20J%C3%BCrgen%20Long%20short-term%20memory%201997"
        },
        {
            "id": "Hu_2012_a",
            "entry": "Jin Hu and Jun Wang. Global stability of complex-valued recurrent neural networks with time-delays. IEEE Transactions on Neural Networks and Learning Systems, 23(6):853\u2013865, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hu%2C%20Jin%20Wang%2C%20Jun%20Global%20stability%20of%20complex-valued%20recurrent%20neural%20networks%20with%20time-delays%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hu%2C%20Jin%20Wang%2C%20Jun%20Global%20stability%20of%20complex-valued%20recurrent%20neural%20networks%20with%20time-delays%202012"
        },
        {
            "id": "Isokawa_et+al_2009_a",
            "entry": "Teijiro Isokawa, Nobuyuki Matsui, and Haruhiko Nishimura. Quaternionic neural networks: Fundamental properties and applications. Complex-Valued Neural Networks: Utilizing High-Dimensional Parameters, pp. 411\u2013439, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Isokawa%2C%20Teijiro%20Matsui%2C%20Nobuyuki%20Nishimura%2C%20Haruhiko%20Quaternionic%20neural%20networks%3A%20Fundamental%20properties%20and%20applications%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Isokawa%2C%20Teijiro%20Matsui%2C%20Nobuyuki%20Nishimura%2C%20Haruhiko%20Quaternionic%20neural%20networks%3A%20Fundamental%20properties%20and%20applications%202009"
        },
        {
            "id": "Kingma_2014_a",
            "entry": "Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6980"
        },
        {
            "id": "Kusamichi_et+al_2004_a",
            "entry": "Hiromi Kusamichi, Teijiro Isokawa, Nobuyuki Matsui, Yuzo Ogawa, and Kazuaki Maeda. A new scheme for color night vision by quaternion neural network. In Proceedings of the 2nd International Conference on Autonomous Robots and Agents, volume 1315, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kusamichi%2C%20Hiromi%20Isokawa%2C%20Teijiro%20Matsui%2C%20Nobuyuki%20Ogawa%2C%20Yuzo%20A%20new%20scheme%20for%20color%20night%20vision%20by%20quaternion%20neural%20network%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kusamichi%2C%20Hiromi%20Isokawa%2C%20Teijiro%20Matsui%2C%20Nobuyuki%20Ogawa%2C%20Yuzo%20A%20new%20scheme%20for%20color%20night%20vision%20by%20quaternion%20neural%20network%202004"
        },
        {
            "id": "Matsui_et+al_2004_a",
            "entry": "Nobuyuki Matsui, Teijiro Isokawa, Hiromi Kusamichi, Ferdinand Peper, and Haruhiko Nishimura. Quaternion neural network with geometrical operators. Journal of Intelligent & Fuzzy Systems, 15 (3, 4):149\u2013164, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Matsui%2C%20Nobuyuki%20Isokawa%2C%20Teijiro%20Kusamichi%2C%20Hiromi%20Peper%2C%20Ferdinand%20Quaternion%20neural%20network%20with%20geometrical%20operators%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Matsui%2C%20Nobuyuki%20Isokawa%2C%20Teijiro%20Kusamichi%2C%20Hiromi%20Peper%2C%20Ferdinand%20Quaternion%20neural%20network%20with%20geometrical%20operators%202004"
        },
        {
            "id": "Medsker_2001_a",
            "entry": "Larry R. Medsker and Lakhmi J. Jain. Recurrent neural networks. Design and Applications, 5, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Medsker%2C%20Larry%20R.%20Jain%2C%20Lakhmi%20J.%20Recurrent%20neural%20networks%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Medsker%2C%20Larry%20R.%20Jain%2C%20Lakhmi%20J.%20Recurrent%20neural%20networks%202001"
        },
        {
            "id": "Minemoto_et+al_2017_a",
            "entry": "Toshifumi Minemoto, Teijiro Isokawa, Haruhiko Nishimura, and Nobuyuki Matsui. Feed forward neural network with random quaternionic neurons. Signal Processing, 136:59\u201368, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Minemoto%2C%20Toshifumi%20Isokawa%2C%20Teijiro%20Nishimura%2C%20Haruhiko%20Matsui%2C%20Nobuyuki%20Feed%20forward%20neural%20network%20with%20random%20quaternionic%20neurons%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Minemoto%2C%20Toshifumi%20Isokawa%2C%20Teijiro%20Nishimura%2C%20Haruhiko%20Matsui%2C%20Nobuyuki%20Feed%20forward%20neural%20network%20with%20random%20quaternionic%20neurons%202017"
        },
        {
            "id": "Mohri_et+al_2002_a",
            "entry": "Mehryar Mohri, Fernando Pereira, and Michael Riley. Weighted finite-state transducers in speech recognition. Computer Speech and Language, 16(1):69 \u2013 88, 2002. ISSN 0885-2308. doi: https://doi.org/10.1006/csla.2001.0184. URL http://www.sciencedirect.com/science/article/pii/S0885230801901846.",
            "crossref": "https://dx.doi.org/10.1006/csla.2001.0184",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1006/csla.2001.0184"
        },
        {
            "id": "Morchid_2018_a",
            "entry": "Mohamed Morchid. Parsimonious memory unit for recurrent neural networks with application to natural language processing. Neurocomputing, 314:48\u201364, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Morchid%2C%20Mohamed%20Parsimonious%20memory%20unit%20for%20recurrent%20neural%20networks%20with%20application%20to%20natural%20language%20processing%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Morchid%2C%20Mohamed%20Parsimonious%20memory%20unit%20for%20recurrent%20neural%20networks%20with%20application%20to%20natural%20language%20processing%202018"
        },
        {
            "id": "Nitta_1995_a",
            "entry": "Tohru Nitta. A quaternary version of the back-propagation algorithm. In Neural Networks, 1995. Proceedings., IEEE International Conference on, volume 5, pp. 2753\u20132756. IEEE, 1995.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nitta%2C%20Tohru%20A%20quaternary%20version%20of%20the%20back-propagation%20algorithm%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nitta%2C%20Tohru%20A%20quaternary%20version%20of%20the%20back-propagation%20algorithm%201995"
        },
        {
            "id": "Parcollet_et+al_2016_a",
            "entry": "Titouan Parcollet, Mohamed Morchid, Pierre-Michel Bousquet, Richard Dufour, Georges Linar\u00e8s, and Renato De Mori. Quaternion neural networks for spoken language understanding. In Spoken Language Technology Workshop (SLT), 2016 IEEE, pp. 362\u2013368. IEEE, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Parcollet%2C%20Titouan%20Morchid%2C%20Mohamed%20Bousquet%2C%20Pierre-Michel%20Dufour%2C%20Richard%20Quaternion%20neural%20networks%20for%20spoken%20language%20understanding%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Parcollet%2C%20Titouan%20Morchid%2C%20Mohamed%20Bousquet%2C%20Pierre-Michel%20Dufour%2C%20Richard%20Quaternion%20neural%20networks%20for%20spoken%20language%20understanding%202016"
        },
        {
            "id": "Parcollet_et+al_2017_a",
            "entry": "Titouan Parcollet, Morchid Mohamed, and Georges Linar\u00e8s. Quaternion denoising encoder-decoder for theme identification of telephone conversations. Proc. Interspeech 2017, pp. 3325\u20133328, 2017a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Parcollet%2C%20Titouan%20Mohamed%2C%20Morchid%20Linar%C3%A8s%2C%20Georges%20Quaternion%20denoising%20encoder-decoder%20for%20theme%20identification%20of%20telephone%20conversations%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Parcollet%2C%20Titouan%20Mohamed%2C%20Morchid%20Linar%C3%A8s%2C%20Georges%20Quaternion%20denoising%20encoder-decoder%20for%20theme%20identification%20of%20telephone%20conversations%202017"
        },
        {
            "id": "Parcollet_et+al_2017_b",
            "entry": "Titouan Parcollet, Mohamed Morchid, and Georges Linares. Deep quaternion neural networks for spoken language understanding. In Automatic Speech Recognition and Understanding Workshop (ASRU), 2017 IEEE, pp. 504\u2013511. IEEE, 2017b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Parcollet%2C%20Titouan%20Morchid%2C%20Mohamed%20Linares%2C%20Georges%20Deep%20quaternion%20neural%20networks%20for%20spoken%20language%20understanding%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Parcollet%2C%20Titouan%20Morchid%2C%20Mohamed%20Linares%2C%20Georges%20Deep%20quaternion%20neural%20networks%20for%20spoken%20language%20understanding%202017"
        },
        {
            "id": "Parcollet_et+al_2018_a",
            "entry": "Titouan Parcollet, Ying Zhang, Mohamed Morchid, Chiheb Trabelsi, Georges Linar\u00e8s, Renato de Mori, and Yoshua Bengio. Quaternion convolutional neural networks for end-to-end automatic speech recognition. In Interspeech 2018, 19th Annual Conference of the International Speech Communication Association, Hyderabad, India, 2-6 September 2018., pp. 22\u201326, 2018. doi: 10.21437/Interspeech.2018-1898. URL https://doi.org/10.21437/Interspeech.2018-1898.",
            "crossref": "https://dx.doi.org/10.21437/Interspeech.2018-1898",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.21437/Interspeech.2018-1898"
        },
        {
            "id": "Soo-Chang_1999_a",
            "entry": "Soo-Chang Pei and Ching-Min Cheng. Color image processing by using binary quaternion-momentpreserving thresholding technique. IEEE Transactions on Image Processing, 8(5):614\u2013628, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=SooChang%20Pei%20and%20ChingMin%20Cheng%20Color%20image%20processing%20by%20using%20binary%20quaternionmomentpreserving%20thresholding%20technique%20IEEE%20Transactions%20on%20Image%20Processing%2085614628%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=SooChang%20Pei%20and%20ChingMin%20Cheng%20Color%20image%20processing%20by%20using%20binary%20quaternionmomentpreserving%20thresholding%20technique%20IEEE%20Transactions%20on%20Image%20Processing%2085614628%201999"
        },
        {
            "id": "Povey_et+al_2011_a",
            "entry": "Daniel Povey, Arnab Ghoshal, Gilles Boulianne, Lukas Burget, Ondrej Glembek, Nagendra Goel, Mirko Hannemann, Petr Motlicek, Yanmin Qian, Petr Schwarz, Jan Silovsky, Georg Stemmer, and Karel Vesely. The kaldi speech recognition toolkit. In IEEE 2011 Workshop on Automatic Speech Recognition and Understanding. IEEE Signal Processing Society, December 2011. IEEE Catalog No.: CFP11SRW-USB.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Povey%2C%20Daniel%20Ghoshal%2C%20Arnab%20Boulianne%2C%20Gilles%20Burget%2C%20Lukas%20The%20kaldi%20speech%20recognition%20toolkit%202011-12",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Povey%2C%20Daniel%20Ghoshal%2C%20Arnab%20Boulianne%2C%20Gilles%20Burget%2C%20Lukas%20The%20kaldi%20speech%20recognition%20toolkit%202011-12"
        },
        {
            "id": "Povey_et+al_2016_a",
            "entry": "Daniel Povey, Vijayaditya Peddinti, Daniel Galvez, Pegah Ghahremani, Vimal Manohar, Xingyu Na, Yiming Wang, and Sanjeev Khudanpur. Purely sequence-trained neural networks for asr based on lattice-free mmi. In Interspeech, pp. 2751\u20132755, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Povey%2C%20Daniel%20Peddinti%2C%20Vijayaditya%20Galvez%2C%20Daniel%20Ghahremani%2C%20Pegah%20Vimal%20Manohar%2C%20Xingyu%20Na%2C%20Yiming%20Wang%2C%20and%20Sanjeev%20Khudanpur.%20Purely%20sequence-trained%20neural%20networks%20for%20asr%20based%20on%20lattice-free%20mmi%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Povey%2C%20Daniel%20Peddinti%2C%20Vijayaditya%20Galvez%2C%20Daniel%20Ghahremani%2C%20Pegah%20Vimal%20Manohar%2C%20Xingyu%20Na%2C%20Yiming%20Wang%2C%20and%20Sanjeev%20Khudanpur.%20Purely%20sequence-trained%20neural%20networks%20for%20asr%20based%20on%20lattice-free%20mmi%202016"
        },
        {
            "id": "Ravanelli_et+al_2018_a",
            "entry": "Mirco Ravanelli, Philemon Brakel, Maurizio Omologo, and Yoshua Bengio. Light gated recurrent units for speech recognition. IEEE Transactions on Emerging Topics in Computational Intelligence, 2(2):92\u2013102, 2018a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ravanelli%2C%20Mirco%20Brakel%2C%20Philemon%20Omologo%2C%20Maurizio%20Bengio%2C%20Yoshua%20Light%20gated%20recurrent%20units%20for%20speech%20recognition%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ravanelli%2C%20Mirco%20Brakel%2C%20Philemon%20Omologo%2C%20Maurizio%20Bengio%2C%20Yoshua%20Light%20gated%20recurrent%20units%20for%20speech%20recognition%202018"
        },
        {
            "id": "Ravanelli_et+al_0000_a",
            "entry": "Mirco Ravanelli, Titouan Parcollet, and Yoshua Bengio. The pytorch-kaldi speech recognition toolkit. arXiv preprint arXiv:1811.07453, 2018b.",
            "arxiv_url": "https://arxiv.org/pdf/1811.07453"
        },
        {
            "id": "Sabour_et+al_2017_a",
            "entry": "Sara Sabour, Nicholas Frosst, and Geoffrey E Hinton. Dynamic routing between capsules. arXiv preprint arXiv:1710.09829v2, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.09829v2"
        },
        {
            "id": "Sangwine_1996_a",
            "entry": "Stephen John Sangwine. Fourier transforms of colour images using quaternion or hypercomplex, numbers. Electronics letters, 32(21):1979\u20131980, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sangwine%2C%20Stephen%20John%20Fourier%20transforms%20of%20colour%20images%20using%20quaternion%20or%20hypercomplex%2C%20numbers%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sangwine%2C%20Stephen%20John%20Fourier%20transforms%20of%20colour%20images%20using%20quaternion%20or%20hypercomplex%2C%20numbers%201996"
        },
        {
            "id": "Song_1998_a",
            "entry": "Jingyan Song and Yeung Yam. Complex recurrent neural network for computing the inverse and pseudo-inverse of the complex matrix. Applied mathematics and computation, 93(2-3):195\u2013205, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Song%2C%20Jingyan%20Yam%2C%20Yeung%20Complex%20recurrent%20neural%20network%20for%20computing%20the%20inverse%20and%20pseudo-inverse%20of%20the%20complex%20matrix%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Song%2C%20Jingyan%20Yam%2C%20Yeung%20Complex%20recurrent%20neural%20network%20for%20computing%20the%20inverse%20and%20pseudo-inverse%20of%20the%20complex%20matrix%201998"
        },
        {
            "id": "Srivastava_et+al_2014_a",
            "entry": "Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: A simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, 15(1):1929\u20131958, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Srivastava%2C%20Nitish%20Hinton%2C%20Geoffrey%20Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Dropout%3A%20A%20simple%20way%20to%20prevent%20neural%20networks%20from%20overfitting%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Srivastava%2C%20Nitish%20Hinton%2C%20Geoffrey%20Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Dropout%3A%20A%20simple%20way%20to%20prevent%20neural%20networks%20from%20overfitting%202014"
        },
        {
            "id": "Sutskever_et+al_2013_a",
            "entry": "Ilya Sutskever, James Martens, George Dahl, and Geoffrey Hinton. On the importance of initialization and momentum in deep learning. In International conference on machine learning, pp. 1139\u20131147, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sutskever%2C%20Ilya%20Martens%2C%20James%20Dahl%2C%20George%20Hinton%2C%20Geoffrey%20On%20the%20importance%20of%20initialization%20and%20momentum%20in%20deep%20learning%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sutskever%2C%20Ilya%20Martens%2C%20James%20Dahl%2C%20George%20Hinton%2C%20Geoffrey%20On%20the%20importance%20of%20initialization%20and%20momentum%20in%20deep%20learning%202013"
        },
        {
            "id": "Tokuda_et+al_2003_a",
            "entry": "Keiichi Tokuda, Heiga Zen, and Tadashi Kitamura. Trajectory modeling based on hmms with the explicit relationship between static and dynamic features. In Eighth European Conference on Speech Communication and Technology, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tokuda%2C%20Keiichi%20Zen%2C%20Heiga%20Kitamura%2C%20Tadashi%20Trajectory%20modeling%20based%20on%20hmms%20with%20the%20explicit%20relationship%20between%20static%20and%20dynamic%20features%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tokuda%2C%20Keiichi%20Zen%2C%20Heiga%20Kitamura%2C%20Tadashi%20Trajectory%20modeling%20based%20on%20hmms%20with%20the%20explicit%20relationship%20between%20static%20and%20dynamic%20features%202003"
        },
        {
            "id": "Trabelsi_et+al_2017_a",
            "entry": "Chiheb Trabelsi, Olexa Bilaniuk, Dmitriy Serdyuk, Sandeep Subramanian, Jo\u00e3o Felipe Santos, Soroush Mehri, Negar Rostamzadeh, Yoshua Bengio, and Christopher J Pal. Deep complex networks. arXiv preprint arXiv:1705.09792, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.09792"
        },
        {
            "id": "Tripathi_2016_a",
            "entry": "Bipin Kumar Tripathi. High Dimensional Neurocomputing. Springer, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tripathi%2C%20Bipin%20Kumar%20High%20Dimensional%20Neurocomputing%202016"
        },
        {
            "id": "Tygert_et+al_2016_a",
            "entry": "Mark Tygert, Joan Bruna, Soumith Chintala, Yann LeCun, Serkan Piantino, and Arthur Szlam. A mathematical motivation for complex-valued convolutional networks. Neural computation, 28(5): 815\u2013825, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tygert%2C%20Mark%20Bruna%2C%20Joan%20Chintala%2C%20Soumith%20LeCun%2C%20Yann%20A%20mathematical%20motivation%20for%20complex-valued%20convolutional%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tygert%2C%20Mark%20Bruna%2C%20Joan%20Chintala%2C%20Soumith%20LeCun%2C%20Yann%20A%20mathematical%20motivation%20for%20complex-valued%20convolutional%20networks%202016"
        },
        {
            "id": "Wisdom_et+al_2016_a",
            "entry": "Scott Wisdom, Thomas Powers, John Hershey, Jonathan Le Roux, and Les Atlas. Full-capacity unitary recurrent neural networks. In Advances in Neural Information Processing Systems, pp. 4880\u20134888, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wisdom%2C%20Scott%20Powers%2C%20Thomas%20Hershey%2C%20John%20Jonathan%20Le%20Roux%2C%20and%20Les%20Atlas.%20Full-capacity%20unitary%20recurrent%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wisdom%2C%20Scott%20Powers%2C%20Thomas%20Hershey%2C%20John%20Jonathan%20Le%20Roux%2C%20and%20Les%20Atlas.%20Full-capacity%20unitary%20recurrent%20neural%20networks%202016"
        },
        {
            "id": "Xu_et+al_2017_a",
            "entry": "D Xu, L Zhang, and H Zhang. Learning alogrithms in quaternion neural networks using ghr calculus. Neural Network World, 27(3):271, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xu%2C%20D.%20Zhang%2C%20L.%20Zhang%2C%20H.%20Learning%20alogrithms%20in%20quaternion%20neural%20networks%20using%20ghr%20calculus%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xu%2C%20D.%20Zhang%2C%20L.%20Zhang%2C%20H.%20Learning%20alogrithms%20in%20quaternion%20neural%20networks%20using%20ghr%20calculus%202017"
        }
    ]
}

{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "STROKENET: A NEURAL PAINTING ENVIRONMENT",
        "author": "Ningyuan Zheng, Yifan Jiang & Dingjiang Huang School of Data Science and Engineering, East China Normal University {10165101164, 10153903133}@stu.ecnu.edu.cn, djhuang@dase.ecnu.edu.cn",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=HJxwDiActX"
        },
        "abstract": "We\u2019ve seen tremendous success of image generating models these years. Generating images through a neural network is usually pixel-based, which is fundamentally different from how humans create artwork using brushes. To imitate human drawing, interactions between the environment and the agent is required to allow trials. However, the environment is usually non-differentiable, leading to slow convergence and massive computation. In this paper we try to address the discrete nature of software environment with an intermediate, differentiable simulation. We present StrokeNet, a novel model where the agent is trained upon a wellcrafted neural approximation of the painting environment. With this approach, our agent was able to learn to write characters such as MNIST digits faster than reinforcement learning approaches in an unsupervised manner. Our primary contribution is the neural simulation of a real-world environment. Furthermore, the agent trained with the emulated environment is able to directly transfer its skills to real-world software. 1"
    },
    "keywords": [
        {
            "term": "recurrent neural network",
            "url": "https://en.wikipedia.org/wiki/recurrent_neural_network"
        },
        {
            "term": "generative adversarial network",
            "url": "https://en.wikipedia.org/wiki/generative_adversarial_network"
        },
        {
            "term": "real world",
            "url": "https://en.wikipedia.org/wiki/real_world"
        },
        {
            "term": "MNIST",
            "url": "https://en.wikipedia.org/wiki/MNIST"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "reinforcement learning",
            "url": "https://en.wikipedia.org/wiki/reinforcement_learning"
        }
    ],
    "abbreviations": {},
    "highlights": [
        "To learn drawing or writing, a person first observes the target image visually and uses a pen or a brush to scribble, to reconstruct the original image",
        "Stroke-based image generation is fairly different from traditional image generation problems due to the intermediate rendering program",
        "For the recurrent version of StrokeNet, two separate CNNs are trained for the target image and the drawing frame, as shown in Figure 2",
        "In this paper we bring a proof-of-concept that an agent is able to learn from its neural simulation of an environment",
        "Our primary contribution is that we devised a model-based method to approximate non-differentiable environment with neural network, and the agent trained with our method converges quickly on several datasets",
        "It is able to adapt its skills to real world. Such approaches can be useful when dealing with more difficult reinforcement learning problems"
    ],
    "key_statements": [
        "To learn drawing or writing, a person first observes the target image visually and uses a pen or a brush to scribble, to reconstruct the original image",
        "Stroke-based image generation is fairly different from traditional image generation problems due to the intermediate rendering program",
        "For the recurrent version of StrokeNet, two separate CNNs are trained for the target image and the drawing frame, as shown in Figure 2",
        "For MNIST and Omniglot, we trained an agent to draw the characters within one stroke",
        "For a quantitative evaluation of the model, we trained a classifier on MNIST, and tested the classifier with images generated by the agent",
        "The recurrent structure adopted here is of the simplest form. We use this setup because we consider drawing as a Markov process, where the current action only depends on what the agent sees, the target image and the previous frame",
        "A stop sign can be introduced to determine when to stop drawing, which can be useful in character reconstruction",
        "In this paper we bring a proof-of-concept that an agent is able to learn from its neural simulation of an environment",
        "Our primary contribution is that we devised a model-based method to approximate non-differentiable environment with neural network, and the agent trained with our method converges quickly on several datasets",
        "It is able to adapt its skills to real world. Such approaches can be useful when dealing with more difficult reinforcement learning problems"
    ],
    "summary": [
        "To learn drawing or writing, a person first observes the target image visually and uses a pen or a brush to scribble, to reconstruct the original image.",
        "While for stroke-based approaches, rather than learning to generate the image, it is more of learning to manipulate the painting program.",
        "We tested the generator by training a vanilla CNN as an agent that encodes the image into \u201cstroke\u201d data as an input for the environment.",
        "An agent is trained to write and draw pictures of several popular datasets upon the generator.",
        "We later showed that a single stroke with only 16 anchors is able to fit most MNIST digits and generate twisted lines in Section 5.",
        "For the recurrent version of StrokeNet, two separate CNNs are trained for the target image and the drawing frame, as shown in Figure 2.",
        "Denote the generator output at time-step t by q(t) \u2208 R256\u00d7256, the frame image by r(t) \u2208 R3\u00d7256\u00d7256, RGB color of the brush by c \u2208 R3, the blending process is approximated as follows, n(t) =",
        "To prove the effectivess of our neural environment, we trained an agent to perform drawing task on several popular datasets, from characters to drawings, with the generator part frozen.",
        "For MNIST and Omniglot, we trained an agent to draw the characters within one stroke.",
        "We freeze the position encoder and train the other parts of the generator, again with l2 loss to measure the performance on the three-body dataset.",
        "If we drop this term, the agent fails to learn the correct order of the points in a stroke because the generator itself is, after all, not robust to all cases of input, and is very likely to produce wrong results for sequences with large gaps between neighbouring points.",
        "For a quantitative evaluation of the model, we trained a classifier on MNIST, and tested the classifier with images generated by the agent.",
        "To convert the agent into a latent space generative model, we experimented with the VAE version of the agent, where the feature obtained from the last layer of CNN is projected into two vectors representing the means \u03bc and standard deviations \u03c3, both of 1024 dimensions.",
        "The classifier is used to evaluate the paired test-set image generated by the agent.",
        "After a period of training, sample images from the real environment with the stroke data just collected, and train the generator with the data.",
        "Our primary contribution is that we devised a model-based method to approximate non-differentiable environment with neural network, and the agent trained with our method converges quickly on several datasets.",
        "Such approaches can be useful when dealing with more difficult reinforcement learning problems"
    ],
    "headline": "We present StrokeNet, a novel model where the agent is trained upon a wellcrafted neural approximation of the painting environment",
    "reference_links": [
        {
            "id": "Arjovsky_et+al_2017_a",
            "entry": "Martin Arjovsky, Soumith Chintala, and Leon Bottou. Wasserstein generative adversarial networks. In Doina Precup and Yee Whye Teh (eds.), Proceedings of the 34th International Conference on Machine Learning, volume 70 of Proceedings of Machine Learning Research, pp. 214\u2013223, International Convention Centre, Sydney, Australia, 06\u201311 Aug 2017. PMLR.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arjovsky%2C%20Martin%20Chintala%2C%20Soumith%20Bottou%2C%20Leon%20Wasserstein%20generative%20adversarial%20networks%202017-08",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arjovsky%2C%20Martin%20Chintala%2C%20Soumith%20Bottou%2C%20Leon%20Wasserstein%20generative%20adversarial%20networks%202017-08"
        },
        {
            "id": "Barry_1988_a",
            "entry": "Phillip J. Barry and Ronald N. Goldman. A recursive evaluation algorithm for a class of catmullrom splines. SIGGRAPH Comput. Graph., 22(4):199\u2013204, June 1988. ISSN 0097-8930. doi: 10.1145/378456.378511.",
            "crossref": "https://dx.doi.org/10.1145/378456.378511",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/378456.378511"
        },
        {
            "id": "Catmull_1974_a",
            "entry": "Edwin Catmull and Raphael Rom. A class of local interpolating splines. Computer Aided Geometric Design, pp. 317\u2013326, 1974.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Catmull%2C%20Edwin%20Rom%2C%20Raphael%20A%20class%20of%20local%20interpolating%20splines%201974",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Catmull%2C%20Edwin%20Rom%2C%20Raphael%20A%20class%20of%20local%20interpolating%20splines%201974"
        },
        {
            "id": "Chung_et+al_2014_a",
            "entry": "Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.3555"
        },
        {
            "id": "Ganin_et+al_2018_a",
            "entry": "Yaroslav Ganin, Tejas Kulkarni, Igor Babuschkin, S. M. Ali Eslami, and Oriol Vinyals. Synthesizing programs for images using reinforced adversarial learning. CoRR, abs/1804.01118, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.01118"
        },
        {
            "id": "Goodfellow_et+al_2014_a",
            "entry": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger (eds.), Advances in Neural Information Processing Systems 27, pp. 2672\u20132680. Curran Associates, Inc., 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "Graves_2013_a",
            "entry": "Alex Graves. Generating sequences with recurrent neural networks. CoRR, abs/1308.0850, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1308.0850"
        },
        {
            "id": "Ha_2017_a",
            "entry": "David Ha and Douglas Eck. A neural representation of sketch drawings. CoRR, abs/1704.03477, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.03477"
        },
        {
            "id": "Ha_2018_a",
            "entry": "David Ha and Jurgen Schmidhuber. World models. CoRR, abs/1803.10122, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.10122"
        },
        {
            "id": "Hertzmann_2003_a",
            "entry": "Aaron Hertzmann. A survey of stroke-based rendering. IEEE Computer Graphics and Applications, 23:70\u201381, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hertzmann%2C%20Aaron%20A%20survey%20of%20stroke-based%20rendering%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hertzmann%2C%20Aaron%20A%20survey%20of%20stroke-based%20rendering%202003"
        },
        {
            "id": "Hochreiter_1997_a",
            "entry": "Sepp Hochreiter and Jurgen Schmidhuber. Long short-term memory. Neural computation, 9(8): 1735\u20131780, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hochreiter%2C%20Sepp%20Schmidhuber%2C%20Jurgen%20Long%20short-term%20memory%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hochreiter%2C%20Sepp%20Schmidhuber%2C%20Jurgen%20Long%20short-term%20memory%201997"
        },
        {
            "id": "Huang_et+al_2018_a",
            "entry": "Zhewei Huang, Wen Heng, Yuanzheng Tao, and Shuchang Zhou. Stroke-based character reconstruction. arXiv preprint arXiv:1806.08990, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1806.08990"
        },
        {
            "id": "Ioffe_2015_a",
            "entry": "Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. CoRR, abs/1502.03167, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1502.03167"
        },
        {
            "id": "Kingma_2013_a",
            "entry": "Diederik P. Kingma and Max Welling. Auto-encoding variational bayes. CoRR, abs/1312.6114, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1312.6114"
        },
        {
            "id": "Lake_et+al_2015_a",
            "entry": "Brenden M. Lake, Ruslan Salakhutdinov, and Joshua B. Tenenbaum. Human-level concept learning through probabilistic program induction. Science, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lake%2C%20Brenden%20M.%20Salakhutdinov%2C%20Ruslan%20Tenenbaum%2C%20Joshua%20B.%20Human-level%20concept%20learning%20through%20probabilistic%20program%20induction%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lake%2C%20Brenden%20M.%20Salakhutdinov%2C%20Ruslan%20Tenenbaum%2C%20Joshua%20B.%20Human-level%20concept%20learning%20through%20probabilistic%20program%20induction%202015"
        },
        {
            "id": "Lecun_2010_a",
            "entry": "Yann LeCun and Corinna Cortes. MNIST handwritten digit database. 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=LeCun%2C%20Yann%20Cortes%2C%20Corinna%20MNIST%20handwritten%20digit%20database%202010"
        },
        {
            "id": "Loper_2014_a",
            "entry": "Matthew M. Loper and Michael J. Black. OpenDR: An approximate differentiable renderer. In Computer Vision \u2013 ECCV 2014, volume 8695 of Lecture Notes in Computer Science, pp. 154\u2013 169. Springer International Publishing, September 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Loper%2C%20Matthew%20M.%20Black%2C%20Michael%20J.%20OpenDR%3A%20An%20approximate%20differentiable%20renderer%202014-09",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Loper%2C%20Matthew%20M.%20Black%2C%20Michael%20J.%20OpenDR%3A%20An%20approximate%20differentiable%20renderer%202014-09"
        },
        {
            "id": "Mirza_2014_a",
            "entry": "Mehdi Mirza and Simon Osindero. Conditional generative adversarial nets. CoRR, abs/1411.1784, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1411.1784"
        },
        {
            "id": "Nguyen-Phuoc_et+al_2018_a",
            "entry": "Thu Nguyen-Phuoc, Chuan Li, Stephen Balaban, and Yong-Liang Yang. Rendernet: A deep convolutional network for differentiable rendering from 3d shapes. arXiv preprint arXiv, abs/1806.06575, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1806.06575"
        },
        {
            "id": "Nielsen_et+al_2001_a",
            "entry": "E. Nielsen, D.V. Fedorov, A.S. Jensen, and E. Garrido. The three-body problem with short-range interactions. Physics Reports, 347(5):373 \u2013 459, 2001. ISSN 0370-1573. doi: https://doi.org/10.1016/S0370-1573(00)00107-1.",
            "crossref": "https://dx.doi.org/10.1016/S0370-1573(00)00107-1",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1016/S0370-1573%2800%2900107-1"
        },
        {
            "id": "Ofusa_et+al_2017_a",
            "entry": "Kenichiro Ofusa, Tomo Miyazaki, Yoshihiro Sugaya, and Shinichiro Omachi. Glyph-based data augmentation for accurate kanji character recognition. In 14th IAPR International Conference on Document Analysis and Recognition, ICDAR 2017, Kyoto, Japan, November 9-15, 2017, pp. 597\u2013602. IEEE, 2017. ISBN 978-1-5386-3586-5. doi: https://doi.org/10.1109/ICDAR.2017.103.",
            "crossref": "https://dx.doi.org/10.1109/ICDAR.2017.103",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/ICDAR.2017.103"
        },
        {
            "id": "Radford_et+al_2015_a",
            "entry": "Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. CoRR, abs/1511.06434, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06434"
        },
        {
            "id": "Schmidhuber_1990_a",
            "entry": "Jurgen Schmidhuber. Making the world differentiable: On using self-supervised fully recurrent neural networks for dynamic reinforcement learning and planning in non-stationary environments. Technical report, 1990.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schmidhuber%2C%20Jurgen%20Making%20the%20world%20differentiable%3A%20On%20using%20self-supervised%20fully%20recurrent%20neural%20networks%20for%20dynamic%20reinforcement%20learning%20and%20planning%20in%20non-stationary%20environments%201990"
        }
    ]
}

{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "LAYOUTGAN: GENERATING GRAPHIC LAYOUTS WITH WIREFRAME DISCRIMINATORS",
        "author": "Jianan Li,\u2217 Jimei Yang, Aaron Hertzmann, Jianming Zhang, Tingfa Xu",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=HJxB5sRcFQ"
        },
        "abstract": "Layout is important for graphic design and scene generation. We propose a novel Generative Adversarial Network, called LayoutGAN, that synthesizes layouts by modeling geometric relations of different types of 2D elements. The generator of LayoutGAN takes as input a set of randomly-placed 2D graphic elements and uses self-attention modules to refine their labels and geometric parameters jointly to produce a realistic layout. Accurate alignment is critical for good layouts. We thus propose a novel differentiable wireframe rendering layer that maps the generated layout to a wireframe image, upon which a CNN-based discriminator is used to optimize the layouts in image space. We validate the effectiveness of LayoutGAN in various experiments including MNIST digit generation, document layout generation, clipart abstract scene generation and tangram graphic design."
    },
    "keywords": [
        {
            "term": "Generative Adversarial Networks",
            "url": "https://en.wikipedia.org/wiki/Generative_Adversarial_Networks"
        },
        {
            "term": "Convolutional Neural Networks",
            "url": "https://en.wikipedia.org/wiki/Convolutional_Neural_Network"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "graphic element",
            "url": "https://en.wikipedia.org/wiki/graphic_element"
        },
        {
            "term": "web design",
            "url": "https://en.wikipedia.org/wiki/web_design"
        },
        {
            "term": "synthesis",
            "url": "https://en.wikipedia.org/wiki/synthesis"
        },
        {
            "term": "graphic design",
            "url": "https://en.wikipedia.org/wiki/graphic_design"
        }
    ],
    "abbreviations": {
        "GANs": "Generative Adversarial Networks",
        "CNNs": "Convolutional Neural Networks",
        "NMS": "Non-Maximum Suppression"
    },
    "highlights": [
        "Graphic design is an important visual communication tool in our modern world, encompassing everything from book covers to magazine layouts to web design",
        "This paper introduces LayoutGAN, a novel Generative Adversarial Networks which directly synthesizes a set of graphical elements in a design",
        "We propose a novel differentiable wireframe rendering layer that rasterizes both synthesized and real structured data of graphic elements into wireframe images, upon which a standard Convolutional Neural Networks can be used to optimize the layout across the visual and the graphic domain",
        "We have proposed a novel LayoutGAN for generating layouts of relational graphic elements",
        "Different from traditional Generative Adversarial Networks that generate images in pixel-level, the LayoutGAN can directly output a set of relational graphic elements"
    ],
    "key_statements": [
        "Graphic design is an important visual communication tool in our modern world, encompassing everything from book covers to magazine layouts to web design",
        "Graphic designs are normally composed of vector representations of primitive objects, such as polygons, curves and ellipses, instead of pixels laid on a regular lattice",
        "Training from images of designs using conventional Generative Adversarial Networks synthesizes the layouts in pixel space, and mixes up layout and its rendering, and would be unlikely to capture layout styles well",
        "Modeling such highly-structured data using neural networks is of great interest as they usually represent human abstract knowledge about the visual world (<a class=\"ref-link\" id=\"cZitnick_2013_a\" href=\"#rZitnick_2013_a\">Zitnick & Parikh, 2013</a>; <a class=\"ref-link\" id=\"cSong_et+al_2017_a\" href=\"#rSong_et+al_2017_a\">Song et al, 2017</a>) and how this knowledge are expressed via documents and designs (<a class=\"ref-link\" id=\"cDeka_et+al_2017_a\" href=\"#rDeka_et+al_2017_a\">Deka et al, 2017</a>; <a class=\"ref-link\" id=\"cYang_et+al_2017_a\" href=\"#rYang_et+al_2017_a\">Yang et al, 2017</a>)",
        "This paper introduces LayoutGAN, a novel Generative Adversarial Networks which directly synthesizes a set of graphical elements in a design",
        "We propose a novel differentiable wireframe rendering layer that rasterizes both synthesized and real structured data of graphic elements into wireframe images, upon which a standard Convolutional Neural Networks can be used to optimize the layout across the visual and the graphic domain",
        "We evaluate the LayoutGAN for several different tasks, including a sanity test on MNIST digits, generating page layouts from labeled bounding boxes, generating clipart abstract scenes, tangram graphic design, and mobile app design layouts",
        "A Generator that directly synthesizes structured data, represented as a resolution-independent set of labeled graphic elements in a design.\n2",
        "To synthesize a reasonable abstract scene, we first use LayoutGAN to generate the layout of inner scene elements by representing each of them as a labeled bounding box with normalized center coordinates, width and height, and flip indicator",
        "We have proposed a novel LayoutGAN for generating layouts of relational graphic elements",
        "Different from traditional Generative Adversarial Networks that generate images in pixel-level, the LayoutGAN can directly output a set of relational graphic elements"
    ],
    "summary": [
        "Graphic design is an important visual communication tool in our modern world, encompassing everything from book covers to magazine layouts to web design.",
        "We propose a novel differentiable wireframe rendering layer that rasterizes both synthesized and real structured data of graphic elements into wireframe images, upon which a standard CNN can be used to optimize the layout across the visual and the graphic domain.",
        "A Generator that directly synthesizes structured data, represented as a resolution-independent set of labeled graphic elements in a design.",
        "In the LayoutGAN, the Generator is a function G(z) that takes a layout as input, where z = {(p1, \u03b81), \u00b7 \u00b7 \u00b7 ,} consisting of initial graphic elements with randomly-sampled geometric parameters \u03b8i, and one-hot encoding of a randomly-sampled class pi.",
        "The Discriminator learns to capture the geometric relations among different types of elements for layout optimization from both the graphic and the visual domain.",
        "As illustrated in Figure 1, the generator takes as input a set of graphic elements with random class probabilities and geometric parameters sampled from Uniform and Gaussian distribution respectively.",
        "A decoder consisting of another multilayer perceptron network followed by two branches of fully connected layer with a sigmoid activation function is used to map the refined feature of each element back to class probabilities and geometric parameters respectively.",
        "The Relation-Based Discriminator takes as input a set of graphic elements represented by class probabilities and geometric parameters, and feeds them to an encoder consisting of a multilayer perceptron network for feature embedding f.",
        "The left and middle images are the generated samples from the LayoutGAN with a relation-based discriminator and a wireframe rendering discriminator, respectively.",
        "To synthesize a reasonable abstract scene, we first use LayoutGAN to generate the layout of inner scene elements by representing each of them as a labeled bounding box with normalized center coordinates, width and height, and flip indicator.",
        "In Figure 5, the first three rows shows the generated layouts and corresponding rendered scenes by DCGAN, LayoutGAN with relation-based discriminator and LayoutGAN with wireframe rendering discriminator respectively.",
        "Given the seven pieces with each initialized by random location and ground-truth pose and class, the LayoutGAN with wireframe rendering discriminator is trained to refine their configurations jointly to form reasonable layouts.",
        "Different from traditional GANs that generate images in pixel-level, the LayoutGAN can directly output a set of relational graphic elements.",
        "A novel differentiable wireframe rendering layer was proposed to rasterize the generated graphic elements to wireframe images, making it feasible to leverage CNNs as discriminator for better layout optimization from visual domain.",
        "Future works include adding a content representation, such as text, icon and picture to each graphic element"
    ],
    "headline": "We propose a novel Generative Adversarial Network, called LayoutGAN, that synthesizes layouts by modeling geometric relations of different types of 2D elements",
    "reference_links": [
        {
            "id": "Abadi_et+al_2016_a",
            "entry": "Mart\u0131n Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al. Tensorflow: a system for largescale machine learning. In Proceedings of the 12th USENIX conference on Operating Systems Design and Implementation, pp. 265\u2013283, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abadi%2C%20Mart%C4%B1n%20Barham%2C%20Paul%20Chen%2C%20Jianmin%20Chen%2C%20Zhifeng%20Tensorflow%3A%20a%20system%20for%20largescale%20machine%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abadi%2C%20Mart%C4%B1n%20Barham%2C%20Paul%20Chen%2C%20Jianmin%20Chen%2C%20Zhifeng%20Tensorflow%3A%20a%20system%20for%20largescale%20machine%20learning%202016"
        },
        {
            "id": "Achlioptas_et+al_2017_a",
            "entry": "Panos Achlioptas, Olga Diamanti, Ioannis Mitliagkas, and Leonidas Guibas. Learning representations and generative models for 3d point clouds. arXiv preprint arXiv:1707.02392, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1707.02392"
        },
        {
            "id": "Bahdanau_et+al_2014_a",
            "entry": "Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1409.0473"
        },
        {
            "id": "Zoya_2017_a",
            "entry": "Zoya Bylinskii, Nam Wook Kim, Peter O\u2019Donovan, Sami Alsheikh, Spandan Madan, Hanspeter Pfister, Fredo Durand, Bryan Russell, and Aaron Hertzmann. Learning visual importance for graphic designs and data visualizations. In Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology, pp. 57\u201369. ACM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zoya%20Bylinskii%20Nam%20Wook%20Kim%20Peter%20ODonovan%20Sami%20Alsheikh%20Spandan%20Madan%20Hanspeter%20Pfister%20Fredo%20Durand%20Bryan%20Russell%20and%20Aaron%20Hertzmann%20Learning%20visual%20importance%20for%20graphic%20designs%20and%20data%20visualizations%20In%20Proceedings%20of%20the%2030th%20Annual%20ACM%20Symposium%20on%20User%20Interface%20Software%20and%20Technology%20pp%205769%20ACM%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zoya%20Bylinskii%20Nam%20Wook%20Kim%20Peter%20ODonovan%20Sami%20Alsheikh%20Spandan%20Madan%20Hanspeter%20Pfister%20Fredo%20Durand%20Bryan%20Russell%20and%20Aaron%20Hertzmann%20Learning%20visual%20importance%20for%20graphic%20designs%20and%20data%20visualizations%20In%20Proceedings%20of%20the%2030th%20Annual%20ACM%20Symposium%20on%20User%20Interface%20Software%20and%20Technology%20pp%205769%20ACM%202017"
        },
        {
            "id": "Charles_et+al_2017_a",
            "entry": "R Qi Charles, Hao Su, Mo Kaichun, and Leonidas J Guibas. Pointnet: Deep learning on point sets for 3d classification and segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 77\u201385, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Charles%2C%20R.Qi%20Su%2C%20Hao%20Kaichun%2C%20Mo%20Guibas%2C%20Leonidas%20J.%20Pointnet%3A%20Deep%20learning%20on%20point%20sets%20for%203d%20classification%20and%20segmentation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Charles%2C%20R.Qi%20Su%2C%20Hao%20Kaichun%2C%20Mo%20Guibas%2C%20Leonidas%20J.%20Pointnet%3A%20Deep%20learning%20on%20point%20sets%20for%203d%20classification%20and%20segmentation%202017"
        },
        {
            "id": "Deka_et+al_2017_a",
            "entry": "Biplab Deka, Zifeng Huang, Chad Franzen, Joshua Hibschman, Daniel Afergan, Yang Li, Jeffrey Nichols, and Ranjitha Kumar. Rico: A mobile app dataset for building data-driven design applications. In Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology, pp. 845\u2013854. ACM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Deka%2C%20Biplab%20Huang%2C%20Zifeng%20Franzen%2C%20Chad%20Hibschman%2C%20Joshua%20Rico%3A%20A%20mobile%20app%20dataset%20for%20building%20data-driven%20design%20applications%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Deka%2C%20Biplab%20Huang%2C%20Zifeng%20Franzen%2C%20Chad%20Hibschman%2C%20Joshua%20Rico%3A%20A%20mobile%20app%20dataset%20for%20building%20data-driven%20design%20applications%202017"
        },
        {
            "id": "Donahue_et+al_2015_a",
            "entry": "Jeffrey Donahue, Lisa Anne Hendricks, Sergio Guadarrama, Marcus Rohrbach, Subhashini Venugopalan, Kate Saenko, and Trevor Darrell. Long-term recurrent convolutional networks for visual recognition and description. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2625\u20132634, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Donahue%2C%20Jeffrey%20Hendricks%2C%20Lisa%20Anne%20Guadarrama%2C%20Sergio%20Rohrbach%2C%20Marcus%20Long-term%20recurrent%20convolutional%20networks%20for%20visual%20recognition%20and%20description%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Donahue%2C%20Jeffrey%20Hendricks%2C%20Lisa%20Anne%20Guadarrama%2C%20Sergio%20Rohrbach%2C%20Marcus%20Long-term%20recurrent%20convolutional%20networks%20for%20visual%20recognition%20and%20description%202015"
        },
        {
            "id": "Fan_et+al_2017_a",
            "entry": "Haoqiang Fan, Hao Su, and Leonidas J Guibas. A point set generation network for 3d object reconstruction from a single image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, volume 2, pp. 6, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fan%2C%20Haoqiang%20Su%2C%20Hao%20Guibas%2C%20Leonidas%20J.%20A%20point%20set%20generation%20network%20for%203d%20object%20reconstruction%20from%20a%20single%20image%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fan%2C%20Haoqiang%20Su%2C%20Hao%20Guibas%2C%20Leonidas%20J.%20A%20point%20set%20generation%20network%20for%203d%20object%20reconstruction%20from%20a%20single%20image%202017"
        },
        {
            "id": "Fisher_et+al_2012_a",
            "entry": "Matthew Fisher, Daniel Ritchie, Manolis Savva, Thomas Funkhouser, and Pat Hanrahan. Examplebased synthesis of 3d object arrangements. ACM Transactions on Graphics (TOG), 31(6):135, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fisher%2C%20Matthew%20Ritchie%2C%20Daniel%20Savva%2C%20Manolis%20Funkhouser%2C%20Thomas%20Examplebased%20synthesis%20of%203d%20object%20arrangements%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fisher%2C%20Matthew%20Ritchie%2C%20Daniel%20Savva%2C%20Manolis%20Funkhouser%2C%20Thomas%20Examplebased%20synthesis%20of%203d%20object%20arrangements%202012"
        },
        {
            "id": "Graves_et+al_2014_a",
            "entry": "Alex Graves, Greg Wayne, and Ivo Danihelka. Neural turing machines. arXiv preprint arXiv:1410.5401, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1410.5401"
        },
        {
            "id": "Hurst_et+al_2009_a",
            "entry": "Nathan Hurst, Wilmot Li, and Kim Marriott. Review of automatic document formatting. In Proceedings of the 9th ACM symposium on Document engineering, pp. 99\u2013108. ACM, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hurst%2C%20Nathan%20Li%2C%20Wilmot%20Marriott%2C%20Kim%20Review%20of%20automatic%20document%20formatting%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hurst%2C%20Nathan%20Li%2C%20Wilmot%20Marriott%2C%20Kim%20Review%20of%20automatic%20document%20formatting%202009"
        },
        {
            "id": "Jaderberg_et+al_2017_a",
            "entry": "Max Jaderberg, Karen Simonyan, Andrew Zisserman, et al. Spatial transformer networks. In Advances in Neural Information Processing Systems, pp. 2017\u20132025, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jaderberg%2C%20Max%20Simonyan%2C%20Karen%20Zisserman%2C%20Andrew%20Spatial%20transformer%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jaderberg%2C%20Max%20Simonyan%2C%20Karen%20Zisserman%2C%20Andrew%20Spatial%20transformer%20networks%202017"
        },
        {
            "id": "Johnson_et+al_2016_a",
            "entry": "Justin Johnson, Andrej Karpathy, and Li Fei-Fei. Densecap: Fully convolutional localization networks for dense captioning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4565\u20134574, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Justin%20Karpathy%2C%20Andrej%20Fei-Fei%2C%20Li%20Densecap%3A%20Fully%20convolutional%20localization%20networks%20for%20dense%20captioning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20Justin%20Karpathy%2C%20Andrej%20Fei-Fei%2C%20Li%20Densecap%3A%20Fully%20convolutional%20localization%20networks%20for%20dense%20captioning%202016"
        },
        {
            "id": "Karras_et+al_2018_a",
            "entry": "Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of GANs for improved quality, stability, and variation. In International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Karras%2C%20Tero%20Aila%2C%20Timo%20Laine%2C%20Samuli%20Lehtinen%2C%20Jaakko%20Progressive%20growing%20of%20GANs%20for%20improved%20quality%2C%20stability%2C%20and%20variation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Karras%2C%20Tero%20Aila%2C%20Timo%20Laine%2C%20Samuli%20Lehtinen%2C%20Jaakko%20Progressive%20growing%20of%20GANs%20for%20improved%20quality%2C%20stability%2C%20and%20variation%202018"
        },
        {
            "id": "Kingma_2014_a",
            "entry": "Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6980"
        },
        {
            "id": "Kipf_2017_a",
            "entry": "Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In International Conference on Learning Representations, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kipf%2C%20Thomas%20N.%20Welling%2C%20Max%20Semi-supervised%20classification%20with%20graph%20convolutional%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kipf%2C%20Thomas%20N.%20Welling%2C%20Max%20Semi-supervised%20classification%20with%20graph%20convolutional%20networks%202017"
        },
        {
            "id": "Merrell_et+al_2011_a",
            "entry": "Paul Merrell, Eric Schkufza, Zeyang Li, Maneesh Agrawala, and Vladlen Koltun. Interactive furniture layout using interior design guidelines. ACM Transactions on Graphics (TOG), 30(4):87, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Merrell%2C%20Paul%20Schkufza%2C%20Eric%20Li%2C%20Zeyang%20Agrawala%2C%20Maneesh%20Interactive%20furniture%20layout%20using%20interior%20design%20guidelines%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Merrell%2C%20Paul%20Schkufza%2C%20Eric%20Li%2C%20Zeyang%20Agrawala%2C%20Maneesh%20Interactive%20furniture%20layout%20using%20interior%20design%20guidelines%202011"
        },
        {
            "id": "O_et+al_2011_a",
            "entry": "Peter O\u2019Donovan, Aseem Agarwala, and Aaron Hertzmann. Color compatibility from large datasets. In ACM Transactions on Graphics (TOG), volume 30, pp. 63. ACM, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=O%E2%80%99Donovan%2C%20Peter%20Agarwala%2C%20Aseem%20Hertzmann%2C%20Aaron%20Color%20compatibility%20from%20large%20datasets%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=O%E2%80%99Donovan%2C%20Peter%20Agarwala%2C%20Aseem%20Hertzmann%2C%20Aaron%20Color%20compatibility%20from%20large%20datasets%202011"
        },
        {
            "id": "Peter_2014_a",
            "entry": "Peter O\u2019Donovan, Janis L\u0131beks, Aseem Agarwala, and Aaron Hertzmann. Exploratory font selection using crowdsourced attributes. ACM Transactions on Graphics (TOG), 33(4):92, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Peter%20O%E2%80%99Donovan%2C%20Janis%20L%C4%B1beks%2C%20Aseem%20Agarwala%20Hertzmann%2C%20Aaron%20Exploratory%20font%20selection%20using%20crowdsourced%20attributes%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Peter%20O%E2%80%99Donovan%2C%20Janis%20L%C4%B1beks%2C%20Aseem%20Agarwala%20Hertzmann%2C%20Aaron%20Exploratory%20font%20selection%20using%20crowdsourced%20attributes%202014"
        },
        {
            "id": "O_et+al_2015_a",
            "entry": "Peter O\u2019Donovan, Aseem Agarwala, and Aaron Hertzmann. Designscape: Design with interactive layout suggestions. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, pp. 1221\u20131224. ACM, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=O%E2%80%99Donovan%2C%20Peter%20Agarwala%2C%20Aseem%20Hertzmann%2C%20Aaron%20Designscape%3A%20Design%20with%20interactive%20layout%20suggestions%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=O%E2%80%99Donovan%2C%20Peter%20Agarwala%2C%20Aseem%20Hertzmann%2C%20Aaron%20Designscape%3A%20Design%20with%20interactive%20layout%20suggestions%202015"
        },
        {
            "id": "Van_et+al_2016_a",
            "entry": "Aaron van den Oord, Nal Kalchbrenner, Oriol Vinyals, Lasse Espeholt, Alex Graves, and Koray Kavukcuoglu. Conditional image generation with pixelcnn decoders. In Advances in Neural Information Processing Systems, pp. 4797\u20134805, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=van%20den%20Oord%2C%20Aaron%20Kalchbrenner%2C%20Nal%20Vinyals%2C%20Oriol%20Espeholt%2C%20Lasse%20Conditional%20image%20generation%20with%20pixelcnn%20decoders%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=van%20den%20Oord%2C%20Aaron%20Kalchbrenner%2C%20Nal%20Vinyals%2C%20Oriol%20Espeholt%2C%20Lasse%20Conditional%20image%20generation%20with%20pixelcnn%20decoders%202016"
        },
        {
            "id": "O_et+al_2014_a",
            "entry": "Peter O\u2019Donovan, Aseem Agarwala, and Aaron Hertzmann. Learning layouts for single-page graphic designs. IEEE Transactions on Visualization and Computer Graphics, 20(8):1200\u20131213, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=O%E2%80%99Donovan%2C%20Peter%20Agarwala%2C%20Aseem%20Hertzmann%2C%20Aaron%20Learning%20layouts%20for%20single-page%20graphic%20designs%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=O%E2%80%99Donovan%2C%20Peter%20Agarwala%2C%20Aseem%20Hertzmann%2C%20Aaron%20Learning%20layouts%20for%20single-page%20graphic%20designs%202014"
        },
        {
            "id": "Pang_et+al_2016_a",
            "entry": "Xufang Pang, Ying Cao, Rynson WH Lau, and Antoni B Chan. Directing user attention via visual flow on web designs. ACM Transactions on Graphics (TOG), 35(6):240, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pang%2C%20Xufang%20Cao%2C%20Ying%20Lau%2C%20Rynson%20W.H.%20Chan%2C%20Antoni%20B.%20Directing%20user%20attention%20via%20visual%20flow%20on%20web%20designs%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pang%2C%20Xufang%20Cao%2C%20Ying%20Lau%2C%20Rynson%20W.H.%20Chan%2C%20Antoni%20B.%20Directing%20user%20attention%20via%20visual%20flow%20on%20web%20designs%202016"
        },
        {
            "id": "Radford_et+al_2015_a",
            "entry": "Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06434"
        },
        {
            "id": "Reed_2015_a",
            "entry": "Scott Reed and Nando De Freitas. Neural programmer-interpreters. arXiv preprint arXiv:1511.06279, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06279"
        },
        {
            "id": "Salimans_et+al_2016_a",
            "entry": "Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. In Advances in Neural Information Processing Systems, pp. 2234\u20132242, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Salimans%2C%20Tim%20Goodfellow%2C%20Ian%20Zaremba%2C%20Wojciech%20Cheung%2C%20Vicki%20Improved%20techniques%20for%20training%20gans%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Salimans%2C%20Tim%20Goodfellow%2C%20Ian%20Zaremba%2C%20Wojciech%20Cheung%2C%20Vicki%20Improved%20techniques%20for%20training%20gans%202016"
        },
        {
            "id": "Song_et+al_2017_a",
            "entry": "Shuran Song, Fisher Yu, Andy Zeng, Angel X Chang, Manolis Savva, and Thomas Funkhouser. Semantic scene completion from a single depth image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 190\u2013198, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Song%2C%20Shuran%20Yu%2C%20Fisher%20Zeng%2C%20Andy%20Chang%2C%20Angel%20X.%20Semantic%20scene%20completion%20from%20a%20single%20depth%20image%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Song%2C%20Shuran%20Yu%2C%20Fisher%20Zeng%2C%20Andy%20Chang%2C%20Angel%20X.%20Semantic%20scene%20completion%20from%20a%20single%20depth%20image%202017"
        },
        {
            "id": "Sutskever_et+al_2014_a",
            "entry": "Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks. In Advances in Neural Information Processing Systems, pp. 3104\u20133112, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sutskever%2C%20Ilya%20Vinyals%2C%20Oriol%20Le%2C%20Quoc%20V.%20Sequence%20to%20sequence%20learning%20with%20neural%20networks%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sutskever%2C%20Ilya%20Vinyals%2C%20Oriol%20Le%2C%20Quoc%20V.%20Sequence%20to%20sequence%20learning%20with%20neural%20networks%202014"
        },
        {
            "id": "Swearngin_et+al_2018_a",
            "entry": "Amanda Swearngin, Mira Dontcheva, Wilmot Li, Joel Brandt, Morgan Dixon, and Andrew J Ko. Rewire: Interface design assistance from examples. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, pp. 504. ACM, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Swearngin%2C%20Amanda%20Dontcheva%2C%20Mira%20Li%2C%20Wilmot%20Brandt%2C%20Joel%20Rewire%3A%20Interface%20design%20assistance%20from%20examples%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Swearngin%2C%20Amanda%20Dontcheva%2C%20Mira%20Li%2C%20Wilmot%20Brandt%2C%20Joel%20Rewire%3A%20Interface%20design%20assistance%20from%20examples%202018"
        },
        {
            "id": "Van_et+al_2016_b",
            "entry": "Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. Wavenet: A generative model for raw audio. In 9th ISCA Speech Synthesis Workshop, pp. 125\u2013125, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=van%20den%20Oord%2C%20Aaron%20Dieleman%2C%20Sander%20Zen%2C%20Heiga%20Simonyan%2C%20Karen%20Wavenet%3A%20A%20generative%20model%20for%20raw%20audio%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=van%20den%20Oord%2C%20Aaron%20Dieleman%2C%20Sander%20Zen%2C%20Heiga%20Simonyan%2C%20Karen%20Wavenet%3A%20A%20generative%20model%20for%20raw%20audio%202016"
        },
        {
            "id": "Vinyals_et+al_2015_a",
            "entry": "Oriol Vinyals, Samy Bengio, and Manjunath Kudlur. Order matters: Sequence to sequence for sets. arXiv preprint arXiv:1511.06391, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06391"
        },
        {
            "id": "Vondrick_et+al_2016_a",
            "entry": "Carl Vondrick, Hamed Pirsiavash, and Antonio Torralba. Generating videos with scene dynamics. In Advances In Neural Information Processing Systems, pp. 613\u2013621, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vondrick%2C%20Carl%20Pirsiavash%2C%20Hamed%20Torralba%2C%20Antonio%20Generating%20videos%20with%20scene%20dynamics%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vondrick%2C%20Carl%20Pirsiavash%2C%20Hamed%20Torralba%2C%20Antonio%20Generating%20videos%20with%20scene%20dynamics%202016"
        },
        {
            "id": "Wang_et+al_2018_a",
            "entry": "Kai Wang, Manolis Savva, Angel X Chang, and Daniel Ritchie. Deep convolutional priors for indoor scene synthesis. ACM Transactions on Graphics (TOG), 37(4):70, 2018a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Kai%20Savva%2C%20Manolis%20Chang%2C%20Angel%20X.%20Ritchie%2C%20Daniel%20Deep%20convolutional%20priors%20for%20indoor%20scene%20synthesis%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Kai%20Savva%2C%20Manolis%20Chang%2C%20Angel%20X.%20Ritchie%2C%20Daniel%20Deep%20convolutional%20priors%20for%20indoor%20scene%20synthesis%202018"
        },
        {
            "id": "Wang_et+al_2018_b",
            "entry": "Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He. Non-local neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, volume 1, pp. 4, 2018b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Xiaolong%20Girshick%2C%20Ross%20Gupta%2C%20Abhinav%20He%2C%20Kaiming%20Non-local%20neural%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Xiaolong%20Girshick%2C%20Ross%20Gupta%2C%20Abhinav%20He%2C%20Kaiming%20Non-local%20neural%20networks%202018"
        },
        {
            "id": "Wu_et+al_2016_a",
            "entry": "Jiajun Wu, Chengkai Zhang, Tianfan Xue, Bill Freeman, and Josh Tenenbaum. Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling. In Advances in Neural Information Processing Systems, pp. 82\u201390, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20Jiajun%20Zhang%2C%20Chengkai%20Xue%2C%20Tianfan%20Freeman%2C%20Bill%20Learning%20a%20probabilistic%20latent%20space%20of%20object%20shapes%20via%203d%20generative-adversarial%20modeling%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20Jiajun%20Zhang%2C%20Chengkai%20Xue%2C%20Tianfan%20Freeman%2C%20Bill%20Learning%20a%20probabilistic%20latent%20space%20of%20object%20shapes%20via%203d%20generative-adversarial%20modeling%202016"
        },
        {
            "id": "Yan_et+al_2016_a",
            "entry": "Xinchen Yan, Jimei Yang, Ersin Yumer, Yijie Guo, and Honglak Lee. Perspective transformer nets: Learning single-view 3d object reconstruction without 3d supervision. In Advances in Neural Information Processing Systems, pp. 1696\u20131704, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yan%2C%20Xinchen%20Yang%2C%20Jimei%20Yumer%2C%20Ersin%20Guo%2C%20Yijie%20Perspective%20transformer%20nets%3A%20Learning%20single-view%203d%20object%20reconstruction%20without%203d%20supervision%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yan%2C%20Xinchen%20Yang%2C%20Jimei%20Yumer%2C%20Ersin%20Guo%2C%20Yijie%20Perspective%20transformer%20nets%3A%20Learning%20single-view%203d%20object%20reconstruction%20without%203d%20supervision%202016"
        },
        {
            "id": "Yang_et+al_2017_a",
            "entry": "Xiao Yang, Ersin Yumer, Paul Asente, Mike Kraley, Daniel Kifer, and C Lee Giles. Learning to extract semantic structure from documents using multimodal fully convolutional neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5315\u2013 5324, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Xiao%20Yumer%2C%20Ersin%20Asente%2C%20Paul%20Kraley%2C%20Mike%20Learning%20to%20extract%20semantic%20structure%20from%20documents%20using%20multimodal%20fully%20convolutional%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20Xiao%20Yumer%2C%20Ersin%20Asente%2C%20Paul%20Kraley%2C%20Mike%20Learning%20to%20extract%20semantic%20structure%20from%20documents%20using%20multimodal%20fully%20convolutional%20neural%20networks%202017"
        },
        {
            "id": "Zitnick_2013_a",
            "entry": "C Lawrence Zitnick and Devi Parikh. Bringing semantics into focus using visual abstraction. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3009\u2013 3016, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zitnick%2C%20C.Lawrence%20Parikh%2C%20Devi%20Bringing%20semantics%20into%20focus%20using%20visual%20abstraction%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zitnick%2C%20C.Lawrence%20Parikh%2C%20Devi%20Bringing%20semantics%20into%20focus%20using%20visual%20abstraction%202013"
        },
        {
            "id": "Zitnick_et+al_2016_a",
            "entry": "C Lawrence Zitnick, Ramakrishna Vedantam, and Devi Parikh. Adopting abstract images for semantic scene understanding. IEEE Transactions on Pattern Analysis and Machine Intelligence, 38(4):627\u2013638, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zitnick%2C%20C.Lawrence%20Vedantam%2C%20Ramakrishna%20Parikh%2C%20Devi%20Adopting%20abstract%20images%20for%20semantic%20scene%20understanding%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zitnick%2C%20C.Lawrence%20Vedantam%2C%20Ramakrishna%20Parikh%2C%20Devi%20Adopting%20abstract%20images%20for%20semantic%20scene%20understanding%202016"
        }
    ]
}

{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "OFF-POLICY EVALUATION AND LEARNING FROM LOGGED BANDIT FEEDBACK: ERROR REDUCTION VIA SURROGATE POLICY",
        "author": "Yuan Xie, Indiana University Bloomington xieyuan@umail.iu.edu",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=HklKui0ct7"
        },
        "abstract": "When learning from a batch of logged bandit feedback, the discrepancy between the policy to be learned and the off-policy training data imposes statistical and computational challenges. Unlike classical supervised learning and online learning settings, in batch contextual bandit learning, one only has access to a collection of logged feedback from the actions taken by a historical policy, and expect to learn a policy that takes good actions in possibly unseen contexts. Such a batch learning setting is ubiquitous in online and interactive systems, such as ad platforms and recommendation systems. Existing approaches based on inverse propensity weights, such as Inverse Propensity Scoring (IPS) and Policy Optimizer for Exponential Models (POEM), enjoy unbiasedness but often suffer from large mean squared error. In this work, we introduce a new approach named Maximum Likelihood Inverse Propensity Scoring (MLIPS) for batch learning from logged bandit feedback. Instead of using the given historical policy as the proposal in inverse propensity weights, we estimate a maximum likelihood surrogate policy based on the logged action-context pairs, and then use this surrogate policy as the proposal. We prove that MLIPS is asymptotically unbiased, and moreover, has a smaller nonasymptotic mean squared error than IPS. Such an error reduction phenomenon is somewhat surprising as the estimated surrogate policy is less accurate than the given historical policy. Results on multi-label classification problems and a large-scale ad placement dataset demonstrate the empirical effectiveness of MLIPS. Furthermore, the proposed surrogate policy technique is complementary to existing error reduction techniques, and when combined, is able to consistently boost the performance of several widely used approaches."
    },
    "keywords": [
        {
            "term": "interactive system",
            "url": "https://en.wikipedia.org/wiki/interactive_system"
        },
        {
            "term": "Conditional Random Field",
            "url": "https://en.wikipedia.org/wiki/Conditional_Random_Field"
        },
        {
            "term": "e commerce",
            "url": "https://en.wikipedia.org/wiki/e_commerce"
        },
        {
            "term": "maximum likelihood",
            "url": "https://en.wikipedia.org/wiki/maximum_likelihood"
        },
        {
            "term": "mean squared error",
            "url": "https://en.wikipedia.org/wiki/mean_squared_error"
        },
        {
            "term": "online learning",
            "url": "https://en.wikipedia.org/wiki/online_learning"
        }
    ],
    "abbreviations": {
        "IPS": "Inverse Propensity Scoring",
        "POEM": "Policy Optimizer for Exponential Models",
        "MLIPS": "Maximum Likelihood Inverse Propensity Scoring",
        "PMS": "POEM algorithm jointly optimizes VI",
        "tD": "the joint event ED",
        "CRF": "Conditional Random Field"
    },
    "highlights": [
        "While maintaining online and interactive systems for information retrieval, news recommendation, ad placement, and e-commerce, we collect large batches of logs during testing phases and past deployment periods (<a class=\"ref-link\" id=\"cLi_et+al_2010_a\" href=\"#rLi_et+al_2010_a\"><a class=\"ref-link\" id=\"cLi_et+al_2010_a\" href=\"#rLi_et+al_2010_a\">Li et al, 2010</a></a>)",
        "Swaminathan & Joachims (2015a) proposed Policy Optimizer for Exponential Models (POEM), which introduces a mean squared error regularizer based on the counterfactual risk minimization principle",
        "We evaluate the Maximum Likelihood Inverse Propensity Scoring estimator on several multi-label classification problems and a large-scale ad placement dataset to demonstrate its empirical effectiveness on mean squared error reduction for policy evaluation and optimization",
        "We find that our surrogate policy technique is complementary to existing mean squared error reduction techniques and achieves consistently improved performance.\n2 OFF-POLICY EVALUATION AND LEARNING FROM LOGGED BANDIT FEEDBACK",
        "We introduce a new but simple approach for mean squared error reduction in policy evaluation and optimization",
        "Theoretical analysis illustrates that the proposed Maximum Likelihood Inverse Propensity Scoring estimator is asymptotically unbiased, and has a smaller mean squared error than the classical Inverse Propensity Scoring estimator"
    ],
    "key_statements": [
        "While maintaining online and interactive systems for information retrieval, news recommendation, ad placement, and e-commerce, we collect large batches of logs during testing phases and past deployment periods (<a class=\"ref-link\" id=\"cLi_et+al_2010_a\" href=\"#rLi_et+al_2010_a\"><a class=\"ref-link\" id=\"cLi_et+al_2010_a\" href=\"#rLi_et+al_2010_a\">Li et al, 2010</a></a>)",
        "Swaminathan & Joachims (2015a) proposed Policy Optimizer for Exponential Models (POEM), which introduces a mean squared error regularizer based on the counterfactual risk minimization principle",
        "We provide theoretical justification for this approach, which is named Maximum Likelihood Inverse Propensity Scoring (MLIPS)",
        "We evaluate the Maximum Likelihood Inverse Propensity Scoring estimator on several multi-label classification problems and a large-scale ad placement dataset to demonstrate its empirical effectiveness on mean squared error reduction for policy evaluation and optimization",
        "We find that our surrogate policy technique is complementary to existing mean squared error reduction techniques and achieves consistently improved performance.\n2 OFF-POLICY EVALUATION AND LEARNING FROM LOGGED BANDIT FEEDBACK",
        "Instead of comparing the estimation of the value function, we focus on comparing the performance of Maximum Likelihood Inverse Propensity Scoring and Inverse Propensity Scoring on off-policy gradient estimation, whose accuracy is crucial to policy optimization",
        "We evaluate the performance of our method on the preprocessed data used in Table 1: Evaluations of the Hamming losses for policy the NIPS 2017 Workshop Criteo ad place- optimizations performed by importance weighed polment challenge",
        "We introduce a new but simple approach for mean squared error reduction in policy evaluation and optimization",
        "Theoretical analysis illustrates that the proposed Maximum Likelihood Inverse Propensity Scoring estimator is asymptotically unbiased, and has a smaller mean squared error than the classical Inverse Propensity Scoring estimator"
    ],
    "summary": [
        "While maintaining online and interactive systems for information retrieval, news recommendation, ad placement, and e-commerce, we collect large batches of logs during testing phases and past deployment periods (<a class=\"ref-link\" id=\"cLi_et+al_2010_a\" href=\"#rLi_et+al_2010_a\"><a class=\"ref-link\" id=\"cLi_et+al_2010_a\" href=\"#rLi_et+al_2010_a\">Li et al, 2010</a></a>).",
        "Swaminathan & Joachims (2015a) proposed Policy Optimizer for Exponential Models (POEM), which introduces a mean squared error regularizer based on the counterfactual risk minimization principle.",
        "We evaluate the MLIPS estimator on several multi-label classification problems and a large-scale ad placement dataset to demonstrate its empirical effectiveness on mean squared error reduction for policy evaluation and optimization.",
        "Instead of directly using the logging policy propensities, we propose to refit a surrogate policy and use it to obtain the inverse propensity weights in the IPS estimator defined in (2.2).",
        "We have the access to \u03bc(a | x; \u03b2\u2217), we choose to use the maximum likelihood estimator of \u03b2\u2217 based on {}ni=1 as a surrogate policy parameter, which is denoted as \u03b2, to replace \u03b2\u2217 and obtain a more accurate estimator of the value function V defined in (2.1).",
        "Condition 3.8 states that, in addition to the upper bound on the estimation error defined in Definition 3.5, the sample versions of the score function defined in (3.3) and the deviation function defined in (3.4) as well as their derivatives all well concentrate to their population versions.",
        "The following theorem compares the mean squared errors of the MLIPS and IPS estimators defined in (3.1) and (2.2).",
        "The mean squared error of the MLIPS estimator is at least smaller than that of the IPS estimator by a margin of 1/(2n) \u00b7 Var(\u03a0(r, x, a; \u03b2\u2217)), where Var(\u03a0(r, x, a; \u03b2\u2217)) is a population quantity that does not scale with n.",
        "In practice we may not know the class of logging policies that generate the logs, in which cases we can use universal function approximators such as neural networks to estimate such surrogate policies.",
        "MLIPS is orthogonal to other existing approaches for mean squared error reduction in policy evaluation and optimization.",
        "We apply IPS, MLIPS, POEM and MLPOEM to policy optimization and compare their performance on several datasets.",
        "To evaluate the effectiveness of our method on policy optimization, we train logistic regression policies with IPS, POEM, Norm-POEM objective functions, and the IPS and POEM versions with maximum likelihood surrogate policies (MLIPS and MLPOEM).",
        "This indicates that our surrogate policy technique provides a complementary mean squared error reduction effect for existing methods in this field.",
        "We introduce a new but simple approach for mean squared error reduction in policy evaluation and optimization.",
        "Theoretical analysis illustrates that the proposed MLIPS estimator is asymptotically unbiased, and has a smaller mean squared error than the classical IPS estimator.",
        "Our technique can be combined with existing approaches and further improves the performance"
    ],
    "headline": "We introduce a new approach named Maximum Likelihood Inverse Propensity Scoring for batch learning from logged bandit feedback",
    "reference_links": [
        {
            "id": "Bottou_2013_a",
            "entry": "Leon Bottou, Jonas Peters, Joaquin Quinonero-Candela, Denis X Charles, D Max Chickering, Elon Portugaly, Dipankar Ray, Patrice Simard, and Ed Snelson. Counterfactual reasoning and learning systems: The example of computational advertising. The Journal of Machine Learning Research, 14(1):3207\u20133260, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Leon%20Bottou%20Jonas%20Peters%20Joaquin%20QuinoneroCandela%20Denis%20X%20Charles%20D%20Max%20Chickering%20Elon%20Portugaly%20Dipankar%20Ray%20Patrice%20Simard%20and%20Ed%20Snelson%20Counterfactual%20reasoning%20and%20learning%20systems%20The%20example%20of%20computational%20advertising%20The%20Journal%20of%20Machine%20Learning%20Research%2014132073260%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Leon%20Bottou%20Jonas%20Peters%20Joaquin%20QuinoneroCandela%20Denis%20X%20Charles%20D%20Max%20Chickering%20Elon%20Portugaly%20Dipankar%20Ray%20Patrice%20Simard%20and%20Ed%20Snelson%20Counterfactual%20reasoning%20and%20learning%20systems%20The%20example%20of%20computational%20advertising%20The%20Journal%20of%20Machine%20Learning%20Research%2014132073260%202013"
        },
        {
            "id": "Cortes_et+al_2010_a",
            "entry": "Corinna Cortes, Yishay Mansour, and Mehryar Mohri. Learning bounds for importance weighting. In Advances in Neural Information Processing Systems, pp. 442\u2013450, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cortes%2C%20Corinna%20Mansour%2C%20Yishay%20Mohri%2C%20Mehryar%20Learning%20bounds%20for%20importance%20weighting%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cortes%2C%20Corinna%20Mansour%2C%20Yishay%20Mohri%2C%20Mehryar%20Learning%20bounds%20for%20importance%20weighting%202010"
        },
        {
            "id": "Crowdai_2017_a",
            "entry": "CrowdAI. CrowdAI NIPS 2017 Criteo Ad Placement Challenge Starter Kit. https://github.com/crowdai/crowdai-criteo-ad-placement-challenge-starter-kit, 2017.",
            "url": "https://github.com/crowdai/crowdai-criteo-ad-placement-challenge-starter-kit"
        },
        {
            "id": "Delyon_2016_a",
            "entry": "Bernard Delyon and Francois Portier. Integral approximation by kernel smoothing. Bernoulli, 22(4): 2177\u20132208, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Delyon%2C%20Bernard%20Portier%2C%20Francois%20Integral%20approximation%20by%20kernel%20smoothing%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Delyon%2C%20Bernard%20Portier%2C%20Francois%20Integral%20approximation%20by%20kernel%20smoothing%202016"
        },
        {
            "id": "Duchi_et+al_2011_a",
            "entry": "John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research, 12(Jul):2121\u20132159, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Duchi%2C%20John%20Hazan%2C%20Elad%20Singer%2C%20Yoram%20Adaptive%20subgradient%20methods%20for%20online%20learning%20and%20stochastic%20optimization%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Duchi%2C%20John%20Hazan%2C%20Elad%20Singer%2C%20Yoram%20Adaptive%20subgradient%20methods%20for%20online%20learning%20and%20stochastic%20optimization%202011"
        },
        {
            "id": "Dud_et+al_2014_a",
            "entry": "Miroslav Dud\u0131k, Dumitru Erhan, John Langford, and Lihong Li. Doubly robust policy evaluation and optimization. Statistical Science, pp. 485\u2013511, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dud%C4%B1k%2C%20Miroslav%20Erhan%2C%20Dumitru%20Langford%2C%20John%20Li%2C%20Lihong%20Doubly%20robust%20policy%20evaluation%20and%20optimization%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dud%C4%B1k%2C%20Miroslav%20Erhan%2C%20Dumitru%20Langford%2C%20John%20Li%2C%20Lihong%20Doubly%20robust%20policy%20evaluation%20and%20optimization%202014"
        },
        {
            "id": "Henmi_et+al_2007_a",
            "entry": "Masayuki Henmi, Ryo Yoshida, and Shinto Eguchi. Importance sampling via the estimated sampler. Biometrika, 94(4):985\u2013991, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Henmi%2C%20Masayuki%20Yoshida%2C%20Ryo%20Eguchi%2C%20Shinto%20Importance%20sampling%20via%20the%20estimated%20sampler%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Henmi%2C%20Masayuki%20Yoshida%2C%20Ryo%20Eguchi%2C%20Shinto%20Importance%20sampling%20via%20the%20estimated%20sampler%202007"
        },
        {
            "id": "Hesterberg_1995_a",
            "entry": "Tim Hesterberg. Weighted average importance sampling and defensive mixture distributions. Technometrics, 37(2):185\u2013194, 1995.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hesterberg%2C%20Tim%20Weighted%20average%20importance%20sampling%20and%20defensive%20mixture%20distributions%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hesterberg%2C%20Tim%20Weighted%20average%20importance%20sampling%20and%20defensive%20mixture%20distributions%201995"
        },
        {
            "id": "Hirano_et+al_2003_a",
            "entry": "Keisuke Hirano, Guido W Imbens, and Geert Ridder. Efficient estimation of average treatment effects using the estimated propensity score. Econometrica, 71(4):1161\u20131189, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hirano%2C%20Keisuke%20Imbens%2C%20Guido%20W.%20Ridder%2C%20Geert%20Efficient%20estimation%20of%20average%20treatment%20effects%20using%20the%20estimated%20propensity%20score%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hirano%2C%20Keisuke%20Imbens%2C%20Guido%20W.%20Ridder%2C%20Geert%20Efficient%20estimation%20of%20average%20treatment%20effects%20using%20the%20estimated%20propensity%20score%202003"
        },
        {
            "id": "Ionides_2008_a",
            "entry": "Edward L Ionides. Truncated importance sampling. Journal of Computational and Graphical Statistics, 17(2):295\u2013311, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ionides%2C%20Edward%20L.%20Truncated%20importance%20sampling%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ionides%2C%20Edward%20L.%20Truncated%20importance%20sampling%202008"
        },
        {
            "id": "Lefortier_et+al_2016_a",
            "entry": "Damien Lefortier, Adith Swaminathan, Xiaotao Gu, Thorsten Joachims, and Maarten de Rijke. Largescale validation of counterfactual learning methods: A test-bed. arXiv preprint arXiv:1612.00367, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1612.00367"
        },
        {
            "id": "Li_et+al_2010_a",
            "entry": "Lihong Li, Wei Chu, John Langford, and Robert E Schapire. A contextual-bandit approach to personalized news article recommendation. In Proceedings of the 19th International Conference on World Wide Web, pp. 661\u2013670. ACM, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Lihong%20Chu%2C%20Wei%20Langford%2C%20John%20Schapire%2C%20Robert%20E.%20A%20contextual-bandit%20approach%20to%20personalized%20news%20article%20recommendation%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Lihong%20Chu%2C%20Wei%20Langford%2C%20John%20Schapire%2C%20Robert%20E.%20A%20contextual-bandit%20approach%20to%20personalized%20news%20article%20recommendation%202010"
        },
        {
            "id": "Li_et+al_2011_a",
            "entry": "Lihong Li, Wei Chu, John Langford, and Xuanhui Wang. Unbiased offline evaluation of contextualbandit-based news article recommendation algorithms. In Proceedings of the Fourth ACM International Conference on Web Search and Data Mining, pp. 297\u2013306. ACM, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Lihong%20Chu%2C%20Wei%20Langford%2C%20John%20Wang%2C%20Xuanhui%20Unbiased%20offline%20evaluation%20of%20contextualbandit-based%20news%20article%20recommendation%20algorithms%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Lihong%20Chu%2C%20Wei%20Langford%2C%20John%20Wang%2C%20Xuanhui%20Unbiased%20offline%20evaluation%20of%20contextualbandit-based%20news%20article%20recommendation%20algorithms%202011"
        },
        {
            "id": "Li_et+al_2014_a",
            "entry": "Lihong Li, Shunbao Chen, Jim Kleban, and Ankur Gupta. Counterfactual estimation and optimization of click metrics for search engines. arXiv preprint arXiv:1403.1891, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1403.1891"
        },
        {
            "id": "Li_et+al_2015_a",
            "entry": "Lihong Li, Remi Munos, and Csaba Szepesvari. Toward minimax off-policy value estimation. In Artificial Intelligence and Statistics, pp. 608\u2013616, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lihong%20Li%20Remi%20Munos%20and%20Csaba%20Szepesvari%20Toward%20minimax%20offpolicy%20value%20estimation%20In%20Artificial%20Intelligence%20and%20Statistics%20pp%20608616%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lihong%20Li%20Remi%20Munos%20and%20Csaba%20Szepesvari%20Toward%20minimax%20offpolicy%20value%20estimation%20In%20Artificial%20Intelligence%20and%20Statistics%20pp%20608616%202015"
        },
        {
            "id": "Liu_1989_a",
            "entry": "Dong C Liu and Jorge Nocedal. On the limited memory BFGS method for large scale optimization. Mathematical Programming, 45(1-3):503\u2013528, 1989.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Dong%20C.%20Nocedal%2C%20Jorge%20On%20the%20limited%20memory%20BFGS%20method%20for%20large%20scale%20optimization%201989",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Dong%20C.%20Nocedal%2C%20Jorge%20On%20the%20limited%20memory%20BFGS%20method%20for%20large%20scale%20optimization%201989"
        },
        {
            "id": "Schmidt-Hieber_2017_a",
            "entry": "Johannes Schmidt-Hieber. Nonparametric regression using deep neural networks with relu activation function. arXiv preprint arXiv:1708.06633, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1708.06633"
        },
        {
            "id": "Strehl_et+al_2010_a",
            "entry": "Alex Strehl, John Langford, Lihong Li, and Sham M Kakade. Learning from logged implicit exploration data. In Advances in Neural Information Processing Systems, pp. 2217\u20132225, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Strehl%2C%20Alex%20Langford%2C%20John%20Li%2C%20Lihong%20Kakade%2C%20Sham%20M.%20Learning%20from%20logged%20implicit%20exploration%20data%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Strehl%2C%20Alex%20Langford%2C%20John%20Li%2C%20Lihong%20Kakade%2C%20Sham%20M.%20Learning%20from%20logged%20implicit%20exploration%20data%202010"
        },
        {
            "id": "Sutton_2012_a",
            "entry": "Charles Sutton and Andrew McCallum. An Introduction to Conditional Random Fields. Nowpublishers, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sutton%2C%20Charles%20McCallum%2C%20Andrew%20An%20Introduction%20to%20Conditional%20Random%20Fields%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sutton%2C%20Charles%20McCallum%2C%20Andrew%20An%20Introduction%20to%20Conditional%20Random%20Fields%202012"
        },
        {
            "id": "Published_2015_a",
            "entry": "Published as a conference paper at ICLR 2019 Adith Swaminathan and Thorsten Joachims. Counterfactual risk minimization: Learning from logged bandit feedback. In International Conference on Machine Learning, pp. 814\u2013823, 2015a. Adith Swaminathan and Thorsten Joachims. The self-normalized estimator for counterfactual learning. In Advances in Neural Information Processing Systems, pp. 3231\u20133239, 2015b. Matus Telgarsky. Benefits of depth in neural networks. arXiv preprint arXiv:1602.04485, 2016. Joel A Tropp. User-friendly tail bounds for sums of random matrices. Foundations of computational mathematics, 12(4):389\u2013434, 2012. Roman Vershynin. Introduction to the non-asymptotic analysis of random matrices. arXiv preprint arXiv:1011.3027, 2010. Dmitry Yarotsky. Error bounds for approximations with deep relu networks. Neural Networks, 94: 103\u2013114, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1602.04485"
        }
    ]
}

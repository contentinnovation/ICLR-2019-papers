{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "MINIMAL IMAGES IN DEEP NEURAL NETWORKS: FRAGILE OBJECT RECOGNITION IN NATURAL IMAGES",
        "author": "Sanjana Srivastava, Guy Ben-Yosef,Xavier Boix,\u2217 1Center for Brains, Minds, and Machines (CBMM) 2Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, USA 3Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, USA 4Children\u2019s Hospital, Harvard Medical School, USA {sanjanas, gby, xboix}@mit.edu",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=S1xNb2A9YX"
        },
        "abstract": "The human ability to recognize objects is impaired when the object is not shown in full. \"Minimal images\" are the smallest regions of an image that remain recognizable for humans. Ullman et al. (2016) show that a slight modification of the location and size of the visible region of the minimal image produces a sharp drop in human recognition accuracy. In this paper, we demonstrate that such drops in accuracy due to changes of the visible region are a common phenomenon between humans and existing state-of-the-art deep neural networks (DNNs), and are much more prominent in DNNs. We found many cases where DNNs classified one region correctly and the other incorrectly, though they only differed by one row or column of pixels, and were often bigger than the average human minimal image size. We show that this phenomenon is independent from previous works that have reported lack of invariance to minor modifications in object location in DNNs. Our results thus reveal a new failure mode of DNNs that also affects humans to a much lesser degree. They expose how fragile DNN recognition ability is for natural images even without adversarial patterns being introduced. Bringing the robustness of DNNs in natural images to the human level remains an open challenge for the community."
    },
    "keywords": [
        {
            "term": "human vision",
            "url": "https://en.wikipedia.org/wiki/human_vision"
        },
        {
            "term": "object recognition",
            "url": "https://en.wikipedia.org/wiki/object_recognition"
        },
        {
            "term": "visible region",
            "url": "https://en.wikipedia.org/wiki/visible_region"
        },
        {
            "term": "Deep neural networks",
            "url": "https://en.wikipedia.org/wiki/Deep_neural_networks"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        }
    ],
    "abbreviations": {
        "DNNs": "Deep neural networks",
        "FRIs": "fragile recognition images",
        "FRI": "fragile recognition image"
    },
    "highlights": [
        "Deep neural networks (DNNs) have reached tremendous success in recognizing and localizing objects in images",
        "The adjustments of the visible area that affect Deep neural networks are almost indistinguishable to humans and can occur in larger regions than the \u201chuman minimal\u201d region. To describe this phenomenon we introduce fragile recognition images (FRIs) for Deep neural networks, which are more general than minimal images: Fragile Recognition Image (FRI): A fragile recognition image is a region of an image for which a slight change of the region\u2019s size or location in the image produces a large change in Deep neural networks recognition output",
        "We investigate whether fragile recognition is related to the lack of invariance to small changes in the object location, which has been recently reported in the literature to affect Deep neural networks (<a class=\"ref-link\" id=\"cEngstrom_et+al_2017_a\" href=\"#rEngstrom_et+al_2017_a\">Engstrom et al, 2017</a>; <a class=\"ref-link\" id=\"cAzulay_2018_a\" href=\"#rAzulay_2018_a\">Azulay & Weiss, 2018</a>)",
        "We evaluate how much a Deep neural networks is affected by fragile recognition by quantifying the proportion of possible image regions that are fragile recognition images, i.e. we quantify the amount of regions affected by a shift or shrink",
        "We have demonstrated that both humans and Deep neural networks are affected by slight changes of the visible region",
        "Our results have revealed that the fragile recognition level in humans is fundamentally different from the one in Deep neural networks in terms of size, position and frequency"
    ],
    "key_statements": [
        "Deep neural networks (DNNs) have reached tremendous success in recognizing and localizing objects in images",
        "The adjustments of the visible area that affect Deep neural networks are almost indistinguishable to humans and can occur in larger regions than the \u201chuman minimal\u201d region. To describe this phenomenon we introduce fragile recognition images (FRIs) for Deep neural networks, which are more general than minimal images: Fragile Recognition Image (FRI): A fragile recognition image is a region of an image for which a slight change of the region\u2019s size or location in the image produces a large change in Deep neural networks recognition output",
        "We evaluate fragile recognition images in ImageNet (<a class=\"ref-link\" id=\"cDeng_et+al_2009_a\" href=\"#rDeng_et+al_2009_a\">Deng et al, 2009</a>) for state-of-the-art Deep neural networks, VGG16 (<a class=\"ref-link\" id=\"cSimonyan_2015_a\" href=\"#rSimonyan_2015_a\">Simonyan & Zisserman, 2015</a>), Inception (<a class=\"ref-link\" id=\"cSzegedy_et+al_2014_a\" href=\"#rSzegedy_et+al_2014_a\">Szegedy et al, 2014</a>), and ResNet (<a class=\"ref-link\" id=\"cHe_et+al_2016_a\" href=\"#rHe_et+al_2016_a\">He et al, 2016</a>)",
        "We investigate whether fragile recognition is related to the lack of invariance to small changes in the object location, which has been recently reported in the literature to affect Deep neural networks (<a class=\"ref-link\" id=\"cEngstrom_et+al_2017_a\" href=\"#rEngstrom_et+al_2017_a\">Engstrom et al, 2017</a>; <a class=\"ref-link\" id=\"cAzulay_2018_a\" href=\"#rAzulay_2018_a\">Azulay & Weiss, 2018</a>)",
        "Our results demonstrate that fragile recognition is independent from this phenomenon: bigger pooling regions reduce most of the lack of invariance to changes in object location, while pooling only marginally reduces fragile recognition",
        "We evaluate how much a Deep neural networks is affected by fragile recognition by quantifying the proportion of possible image regions that are fragile recognition images, i.e. we quantify the amount of regions affected by a shift or shrink",
        "We focus on the relationship of fragile recognition with recent works that show that Deep neural networks are affected by small changes of the object location, scale and orientation (<a class=\"ref-link\" id=\"cEngstrom_et+al_2017_a\" href=\"#rEngstrom_et+al_2017_a\">Engstrom et al, 2017</a>; <a class=\"ref-link\" id=\"cAzulay_2018_a\" href=\"#rAzulay_2018_a\">Azulay & Weiss, 2018</a>)",
        "We evaluate the Deep neural networks by embedding the object in a black background at all possible locations, and we quantify for how many locations a one-pixel shift of the object location produces a change in the output of the Deep neural networks",
        "Note that for small region sizes the amount of fragile recognition images increases, which is different from what we observe in the data augmentation and regularization experiment in the previous section",
        "We show the converse, namely that when humans are tested on Deep neural networks fragile recognition images, they do not exhibit the same fragile response",
        "The results show a small gap in correct recognition: on average, success rates among humans for Deep neural networks fragile recognition images and incorrect counterparts differ by 14.5%",
        "Comparing Deep neural networks fragile recognition images and human minimal images of the same region size, P , we find two additional differences: first, Deep neural networks have more fragile recognition images (5.3 minimal images per image for humans on average, 13.4 for Deep neural networks)",
        "Deep neural networks fragile recognition images differ in location within the object region (Intersection Over Union between human minimal image maps and Deep neural networks fragile recognition images maps was small, < 6% for all tested images)",
        "While human minimal images are centered in meaningful object parts, Deep neural networks fragile recognition images contain mostly a background set of pixels",
        "We have demonstrated that both humans and Deep neural networks are affected by slight changes of the visible region",
        "Our results have revealed that the fragile recognition level in humans is fundamentally different from the one in Deep neural networks in terms of size, position and frequency",
        "Data augmentation, regularization and larger-size pooling regions alleviate fragile recongition in Deep neural networks, but are not sufficient to close the gap with humans",
        "Making Deep neural networks robust like humans remains a challenge for the community"
    ],
    "summary": [
        "Deep neural networks (DNNs) have reached tremendous success in recognizing and localizing objects in images.",
        "Minimal images are small regions of an image (e.g. 10x10 pixels) in which only a part of an object is observed, and a slight adjustment of the visible area produces a sharp drop in human recognition accuracy.",
        "We define different variations of FRIs, depending if they are based on changes on the location or size of the image region, and on how strict we are when evaluating the changes in the correctness of DNN:",
        "We evaluate how much a DNN is affected by fragile recognition by quantifying the proportion of possible image regions that are FRIs, i.e. we quantify the amount of regions affected by a shift or shrink.",
        "These results demonstrate the existence of many minimal images analogs in DNNs. Note that smaller FRIs are much more frequent than larger ones, as observed across the different network architectures and types of FRIs. This trend is expected: one-pixel shifts and two-pixel shrinks are proportionally larger changes for smaller regions, and larger regions generally allow for more high-level features to be included.",
        "We focus on the relationship of fragile recognition with recent works that show that DNNs are affected by small changes of the object location, scale and orientation (<a class=\"ref-link\" id=\"cEngstrom_et+al_2017_a\" href=\"#rEngstrom_et+al_2017_a\">Engstrom et al, 2017</a>; <a class=\"ref-link\" id=\"cAzulay_2018_a\" href=\"#rAzulay_2018_a\">Azulay & Weiss, 2018</a>).",
        "Note that for small region sizes the amount of FRIs increases, which is different from what we observe in the data augmentation and regularization experiment in the previous section.",
        "The results show a small gap in correct recognition: on average, success rates among humans for DNN fragile recognition images and incorrect counterparts differ by 14.5%.",
        "DNN FRIs differ in location within the object region (Intersection Over Union between human minimal image maps and DNN FRI maps was small, < 6% for all tested images).",
        "While human minimal images are centered in meaningful object parts, DNN FRIs contain mostly a background set of pixels.",
        "Our results have revealed that the fragile recognition level in humans is fundamentally different from the one in DNNs in terms of size, position and frequency.",
        "Data augmentation, regularization and larger-size pooling regions alleviate fragile recongition in DNNs, but are not sufficient to close the gap with humans.",
        "We have shown that fragile recognition is a more complex phenomenon than object location invariance, which exposes new concerns of the recognition ability of DNNs in natural images, even without adversarial patterns being introduced."
    ],
    "headline": "We demonstrate that such drops in accuracy due to changes of the visible region are a common phenomenon between humans and existing state-of-the-art deep neural networks, and are much more prominent in Deep neural networks",
    "reference_links": [
        {
            "id": "Anselmi_et+al_2015_a",
            "entry": "Fabio Anselmi, Lorenzo Rosasco, and Tomaso Poggio. On invariance and selectivity in representation learning. arXiv preprint arXiv:1503.05938v1, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1503.05938v1"
        },
        {
            "id": "Azulay_2018_a",
            "entry": "Aharon Azulay and Yair Weiss. Why do deep convolutional networks generalize so poorly to small image transformations? arXiv preprint arXiv:1805.12177, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1805.12177"
        },
        {
            "id": "Ben-Yosef_2018_a",
            "entry": "Guy Ben-Yosef and Shimon Ullman. Image interpretation above and below the object level. Journal of the Royal Society Interface Focus, 8(4):20180020, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ben-Yosef%2C%20Guy%20Ullman%2C%20Shimon%20Image%20interpretation%20above%20and%20below%20the%20object%20level%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ben-Yosef%2C%20Guy%20Ullman%2C%20Shimon%20Image%20interpretation%20above%20and%20below%20the%20object%20level%202018"
        },
        {
            "id": "Ben-Yosef_et+al_2018_b",
            "entry": "Guy Ben-Yosef, Liav Assif, and Shimon Ullman. Full interpretation of minimal images. Cognition, 171:65\u201384, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ben-Yosef%2C%20Guy%20Assif%2C%20Liav%20Ullman%2C%20Shimon%20Full%20interpretation%20of%20minimal%20images%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ben-Yosef%2C%20Guy%20Assif%2C%20Liav%20Ullman%2C%20Shimon%20Full%20interpretation%20of%20minimal%20images%202018"
        },
        {
            "id": "Buhrmester_et+al_2011_a",
            "entry": "Michael Buhrmester, Tracy Kwang, and Samuel D Gosling. Amazon\u2019s mechanical turk: A new source of inexpensive, yet high-quality, data? Perspectives on psychological science, 6(1):3\u20135, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Buhrmester%2C%20Michael%20Kwang%2C%20Tracy%20Gosling%2C%20Samuel%20D.%20Amazon%E2%80%99s%20mechanical%20turk%3A%20A%20new%20source%20of%20inexpensive%2C%20yet%20high-quality%2C%20data%3F%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Buhrmester%2C%20Michael%20Kwang%2C%20Tracy%20Gosling%2C%20Samuel%20D.%20Amazon%E2%80%99s%20mechanical%20turk%3A%20A%20new%20source%20of%20inexpensive%2C%20yet%20high-quality%2C%20data%3F%202011"
        },
        {
            "id": "Chen_et+al_2017_a",
            "entry": "Francis X Chen, Gemma Roig, Leyla Isik, Xavier Boix, and Tomaso Poggio. Eccentricity dependent deep neural networks: Modeling invariance in human vision. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Francis%20X.%20Roig%2C%20Gemma%20Isik%2C%20Leyla%20Boix%2C%20Xavier%20Eccentricity%20dependent%20deep%20neural%20networks%3A%20Modeling%20invariance%20in%20human%20vision%202017"
        },
        {
            "id": "Deng_et+al_2009_a",
            "entry": "Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Fei-Fei Li. Imagenet: a large-scale hierarchical image database. 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Deng%2C%20Jia%20Dong%2C%20Wei%20Socher%2C%20Richard%20Li%2C%20Li-Jia%20Imagenet%3A%20a%20large-scale%20hierarchical%20image%20database%202009"
        },
        {
            "id": "Elsayed_et+al_2018_a",
            "entry": "Gamaleldin F Elsayed, Shreya Shankar, Brian Cheung, Nicolas Papernot, Alex Kurakin, Ian Goodfellow, and Jascha Sohl-Dickstein. Adversarial examples that fool both human and computer vision. arXiv preprint arXiv:1802.08195, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.08195"
        },
        {
            "id": "Engstrom_et+al_2017_a",
            "entry": "Logan Engstrom, Dimitris Tsipras, Ludwig Schmidt, and Aleksander Madry. A rotation and a translation suffice: Fooling cnns with simple transformations. arXiv preprint arXiv:1712.02779, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.02779"
        },
        {
            "id": "Goodfellow_et+al_2014_a",
            "entry": "Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6572"
        },
        {
            "id": "Hassabis_et+al_2017_a",
            "entry": "Demis Hassabis, Dharshan Kumaran, Christopher Summerfield, and Matthew Botvinick. Neuroscience-inspired artificial intelligence. Neuron, 95(2):245\u2013258, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hassabis%2C%20Demis%20Kumaran%2C%20Dharshan%20Summerfield%2C%20Christopher%20Botvinick%2C%20Matthew%20Neuroscience-inspired%20artificial%20intelligence%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hassabis%2C%20Demis%20Kumaran%2C%20Dharshan%20Summerfield%2C%20Christopher%20Botvinick%2C%20Matthew%20Neuroscience-inspired%20artificial%20intelligence%202017"
        },
        {
            "id": "He_et+al_2016_a",
            "entry": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "Krizhevsky_2009_a",
            "entry": "Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Learning%20multiple%20layers%20of%20features%20from%20tiny%20images%202009"
        },
        {
            "id": "Liu_et+al_2016_a",
            "entry": "Yanpei Liu, Xinyun Chen, Chang Liu, and Dawn Song. Delving into transferable adversarial examples and black-box attacks. arXiv preprint arXiv:1611.02770, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.02770"
        },
        {
            "id": "Madry_et+al_2017_a",
            "entry": "Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.06083"
        },
        {
            "id": "Redmon_2017_a",
            "entry": "Joseph Redmon and Ali Farhadi. Yolo9000: Better, faster, stronger. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Joseph%20Redmon%20and%20Ali%20Farhadi%20Yolo9000%20Better%20faster%20stronger%20In%202017%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%20CVPR%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Joseph%20Redmon%20and%20Ali%20Farhadi%20Yolo9000%20Better%20faster%20stronger%20In%202017%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%20CVPR%202017"
        },
        {
            "id": "Simonyan_2015_a",
            "entry": "Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Simonyan%2C%20Karen%20Zisserman%2C%20Andrew%20Very%20deep%20convolutional%20networks%20for%20large-scale%20image%20recognition%202015"
        },
        {
            "id": "Szegedy_et+al_2013_a",
            "entry": "Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1312.6199"
        },
        {
            "id": "Szegedy_et+al_2014_a",
            "entry": "Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. arXiv preprint arXiv:1409.4842v1, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1409.4842v1"
        },
        {
            "id": "Tram_et+al_2017_a",
            "entry": "Florian Tram\u00e8r, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan Boneh, and Patrick McDaniel. Ensemble adversarial training: Attacks and defenses. arXiv preprint arXiv:1705.07204, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.07204"
        },
        {
            "id": "Ullman_et+al_2016_a",
            "entry": "Shimon Ullman, Liav Assif, Ethan Fetaya, and Daniel Harari. Atoms of recognition in human and computer vision. Proceedings of the National Academy of Sciences, 113(10):2744\u20132749, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ullman%2C%20Shimon%20Assif%2C%20Liav%20Fetaya%2C%20Ethan%20Harari%2C%20Daniel%20Atoms%20of%20recognition%20in%20human%20and%20computer%20vision%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ullman%2C%20Shimon%20Assif%2C%20Liav%20Fetaya%2C%20Ethan%20Harari%2C%20Daniel%20Atoms%20of%20recognition%20in%20human%20and%20computer%20vision%202016"
        },
        {
            "id": "Zhang_et+al_2016_a",
            "entry": "Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep learning requires rethinking generalization. arXiv preprint arXiv:1611.03530, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.03530"
        },
        {
            "id": "Zhu_et+al_2016_a",
            "entry": "Zhuotun Zhu, Lingxi Xie, and Alan L Yuille. Object recognition with and without objects. arXiv preprint arXiv:1611.06596, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.06596"
        }
    ]
}

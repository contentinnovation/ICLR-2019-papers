{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "AUGMENTED CYCLIC ADVERSARIAL LEARNING FOR LOW RESOURCE DOMAIN ADAPTATION",
        "author": "Ehsan Hosseini-Asl, Yingbo Zhou, Caiming Xiong, Richard Socher Salesforce Research {ehosseiniasl,yingbo.zhou,cxiong,rsocher}@salesforce.com",
        "date": 2018,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=B1G9doA9F7"
        },
        "abstract": "Training a model to perform a task typically requires a large amount of data from the domains in which the task will be applied. However, it is often the case that data are abundant in some domains but scarce in others. Domain adaptation deals with the challenge of adapting a model trained from a data-rich source domain to perform well in a data-poor target domain. In general, this requires learning plausible mappings between domains. CycleGAN is a powerful framework that efficiently learns to map inputs from one domain to another using adversarial training and a cycle-consistency constraint. However, the conventional approach of enforcing cycle-consistency via reconstruction may be overly restrictive in cases where one or more domains have limited training data. In this paper, we propose an augmented cyclic adversarial learning model that enforces the cycle-consistency constraint via an external task specific model, which encourages the preservation of task-relevant content as opposed to exact reconstruction. We explore digit classification in a low-resource setting in supervised, semi and unsupervised situation, as well as high resource unsupervised. In low-resource supervised setting, the results show that our approach improves absolute performance by 14% and 4% when adapting SVHN to MNIST and vice versa, respectively, which outperforms unsupervised domain adaptation methods that require high-resource unlabeled target domain. Moreover, using only few unsupervised target data, our approach can still outperforms many high-resource unsupervised models. Our model also outperforms on USPS to MNIST and synthetic digit to SVHN for high resource unsupervised adaptation. In speech domains, we similarly adopt a speech recognition model from each domain as the task specific model. Our approach improves absolute performance of speech recognition by 2% for female speakers in the TIMIT dataset, where the majority of training samples are from male voices."
    },
    "keywords": [
        {
            "term": "generative adversarial network",
            "url": "https://en.wikipedia.org/wiki/generative_adversarial_network"
        },
        {
            "term": "domain adaptation",
            "url": "https://en.wikipedia.org/wiki/domain_adaptation"
        },
        {
            "term": "TIMIT",
            "url": "https://en.wikipedia.org/wiki/TIMIT"
        },
        {
            "term": "speech recognition",
            "url": "https://en.wikipedia.org/wiki/speech_recognition"
        },
        {
            "term": "MNIST",
            "url": "https://en.wikipedia.org/wiki/MNIST"
        },
        {
            "term": "adversarial learning",
            "url": "https://en.wikipedia.org/wiki/adversarial_learning"
        }
    ],
    "abbreviations": {
        "ACAL": "Augmented Cyclic Adversarial Learning",
        "MMD": "Maximum Mean Discrepancy",
        "GAN": "generative adversarial network",
        "SVHN": "Street View House Numbers",
        "SD": "Synthetic Digits",
        "PER": "phoneme error rate"
    },
    "highlights": [
        "Domain adaptation (<a class=\"ref-link\" id=\"cHuang_et+al_2007_a\" href=\"#rHuang_et+al_2007_a\"><a class=\"ref-link\" id=\"cHuang_et+al_2007_a\" href=\"#rHuang_et+al_2007_a\">Huang et al, 2007</a></a>; <a class=\"ref-link\" id=\"cXue_et+al_2008_a\" href=\"#rXue_et+al_2008_a\"><a class=\"ref-link\" id=\"cXue_et+al_2008_a\" href=\"#rXue_et+al_2008_a\">Xue et al, 2008</a></a>; <a class=\"ref-link\" id=\"cBen-David_et+al_2010_a\" href=\"#rBen-David_et+al_2010_a\"><a class=\"ref-link\" id=\"cBen-David_et+al_2010_a\" href=\"#rBen-David_et+al_2010_a\">Ben-David et al, 2010</a></a>) aims to generalize a model from source domain to a target domain",
        "The source domain has a large amount of training data, whereas the data are scarce in the target domain",
        "This challenge is typically addressed by learning a mapping between domains, which allows data from the source domain to enrich the available data for training in the target domain",
        "One way of learning such mappings is through Generative Adversarial Networks (GANs Goodfellow et al, 2014) with cycle-consistency constraint (CycleGAN Zhu et al, 2017), which enforces that mapping of an example from the source to the target and back to the source domain would result in the same example",
        "We propose to use augmented cycle-consistency adversarial learning for domain adaptation and introduce a task specific model to facilitate learning domain related mappings",
        "We demonstrate the effectiveness of our proposed approach by evaluating on two domain adaptation tasks, and in both cases we achieve significant performance improvement as compared to the baseline"
    ],
    "key_statements": [
        "Domain adaptation (<a class=\"ref-link\" id=\"cHuang_et+al_2007_a\" href=\"#rHuang_et+al_2007_a\"><a class=\"ref-link\" id=\"cHuang_et+al_2007_a\" href=\"#rHuang_et+al_2007_a\">Huang et al, 2007</a></a>; <a class=\"ref-link\" id=\"cXue_et+al_2008_a\" href=\"#rXue_et+al_2008_a\"><a class=\"ref-link\" id=\"cXue_et+al_2008_a\" href=\"#rXue_et+al_2008_a\">Xue et al, 2008</a></a>; <a class=\"ref-link\" id=\"cBen-David_et+al_2010_a\" href=\"#rBen-David_et+al_2010_a\"><a class=\"ref-link\" id=\"cBen-David_et+al_2010_a\" href=\"#rBen-David_et+al_2010_a\">Ben-David et al, 2010</a></a>) aims to generalize a model from source domain to a target domain",
        "The source domain has a large amount of training data, whereas the data are scarce in the target domain",
        "This challenge is typically addressed by learning a mapping between domains, which allows data from the source domain to enrich the available data for training in the target domain",
        "One way of learning such mappings is through Generative Adversarial Networks (GANs Goodfellow et al, 2014) with cycle-consistency constraint (CycleGAN Zhu et al, 2017), which enforces that mapping of an example from the source to the target and back to the source domain would result in the same example",
        "We propose an augmented cyclic adversarial learning model (ACAL) for domain adaptation",
        "We show that our approach improves the performance by 40% as compared to the baseline on digit domain adaptation",
        "<a class=\"ref-link\" id=\"cSpringenberg_2015_a\" href=\"#rSpringenberg_2015_a\">Springenberg (2015</a>) proposed CatGAN, where the discriminator is converted to a multi-class classifier. We extend this idea to any task specific model, including speech recognition task, and use this model to preserve task specific information regarding the data.We propose that the definition of task model can be extended to unsupervised tasks,such as language or speech modeling in domains, meaning augmented unsupervised domain adaptation.\n2.1",
        "We propose to use augmented cycle-consistency adversarial learning for domain adaptation and introduce a task specific model to facilitate learning domain related mappings",
        "We demonstrate the effectiveness of our proposed approach by evaluating on two domain adaptation tasks, and in both cases we achieve significant performance improvement as compared to the baseline"
    ],
    "summary": [
        "Domain adaptation (<a class=\"ref-link\" id=\"cHuang_et+al_2007_a\" href=\"#rHuang_et+al_2007_a\"><a class=\"ref-link\" id=\"cHuang_et+al_2007_a\" href=\"#rHuang_et+al_2007_a\">Huang et al, 2007</a></a>; <a class=\"ref-link\" id=\"cXue_et+al_2008_a\" href=\"#rXue_et+al_2008_a\"><a class=\"ref-link\" id=\"cXue_et+al_2008_a\" href=\"#rXue_et+al_2008_a\">Xue et al, 2008</a></a>; <a class=\"ref-link\" id=\"cBen-David_et+al_2010_a\" href=\"#rBen-David_et+al_2010_a\"><a class=\"ref-link\" id=\"cBen-David_et+al_2010_a\" href=\"#rBen-David_et+al_2010_a\">Ben-David et al, 2010</a></a>) aims to generalize a model from source domain to a target domain.",
        "One way of learning such mappings is through Generative Adversarial Networks (GANs Goodfellow et al, 2014) with cycle-consistency constraint (CycleGAN Zhu et al, 2017), which enforces that mapping of an example from the source to the target and back to the source domain would result in the same example.",
        "We propose an augmented cyclic adversarial learning model (ACAL) for domain adaptation.",
        "The model learns to preserve the \u2018semantic\u2019 information from the data samples in a particular domain by minimizing the loss of the mapped samples for the task specific model.",
        "To address these two problems, we propose to 1) use a task specific model to enforce the cycle-consistency constraint, and 2) use the same task specific model in addition to the discriminator to train more meaningful cross domain mappings.",
        "In case of unsupervised domain adaptation, when there is no information of target conditional probability distribution PT (Y |X), we propose to use source model MS to estimate PT (Y |X) through adversarial learning, i.e. PT (Y |X) \u2248 Ex\u223cPT (X) [MS(GS\u2192T (x))].",
        "There are various ways that one may utilize cycle-consistency or adversarial Table 1: Ablation study results from SVHN (Source) to training to do domain adaptation from MNIST (Target).",
        "To further evaluate the effectiveness of using task-specific loss with two cycles for low-resource unsupervised domain adaptation scenario, we comapre our model with CyCADA (Hoffman et al, 2018), and when no reconstruction loss is used in CyCADA, referred as \"CyCADA (Relaxed)\".",
        "As shown in Figure 2, CyCADA model and its relaxed variation fail to learn a good adaptation, where target domain contains few unlabaled samples per class.",
        "Low-resource semi-supervised adaptation: We evaluate the performance of ACAL algorithm when there are limited labeled and unlabeled target samples in Table 6 (Appendix A).",
        "We propose to use augmented cycle-consistency adversarial learning for domain adaptation and introduce a task specific model to facilitate learning domain related mappings.",
        "We use the task specific model as an additional source of information for the discriminator in the corresponding domain.",
        "We demonstrate the effectiveness of our proposed approach by evaluating on two domain adaptation tasks, and in both cases we achieve significant performance improvement as compared to the baseline.",
        "By extending the definition of task-specific model to unsupervised learning, such as reconstruction loss using autoencoder, or self-supervision, our proposed method would work on all settings of domain adaptation."
    ],
    "headline": "We propose an augmented cyclic adversarial learning model that enforces the cycle-consistency constraint via an external task specific model, which encourages the preservation of task-relevant content as opposed to exact reconstruction",
    "reference_links": [
        {
            "id": "Almahairi_et+al_2018_a",
            "entry": "A. Almahairi, S. Rajeswar, A. Sordoni, P. Bachman, and A. C. Courville. Augmented cyclegan: Learning many-to-many mappings from unpaired data. In ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Almahairi%2C%20A.%20Rajeswar%2C%20S.%20Sordoni%2C%20A.%20Bachman%2C%20P.%20Augmented%20cyclegan%3A%20Learning%20many-to-many%20mappings%20from%20unpaired%20data%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Almahairi%2C%20A.%20Rajeswar%2C%20S.%20Sordoni%2C%20A.%20Bachman%2C%20P.%20Augmented%20cyclegan%3A%20Learning%20many-to-many%20mappings%20from%20unpaired%20data%202018"
        },
        {
            "id": "Ben-David_et+al_2010_a",
            "entry": "S. Ben-David, J. Blitzer, K. Crammer, A. Kulesza, F. Pereira, and J. W. Vaughan. A theory of learning from different domains. Machine Learning, 79(1):151\u2013175, May 2010. ISSN 1573-0565. doi: 10.1007/ s10994-009-5152-4. URL https://doi.org/10.1007/s10994-009-5152-4.",
            "crossref": "https://dx.doi.org/10.1007/s10994-009-5152-4",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1007/s10994-009-5152-4"
        },
        {
            "id": "Bousmalis_et+al_2017_a",
            "entry": "K. Bousmalis, N. Silberman, D. Dohan, D. Erhan, and D. Krishnan. Unsupervised pixel-level domain adaptation with generative adversarial networks. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), volume 1, page 7, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bousmalis%2C%20K.%20Silberman%2C%20N.%20Dohan%2C%20D.%20Erhan%2C%20D.%20Unsupervised%20pixel-level%20domain%20adaptation%20with%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bousmalis%2C%20K.%20Silberman%2C%20N.%20Dohan%2C%20D.%20Erhan%2C%20D.%20Unsupervised%20pixel-level%20domain%20adaptation%20with%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "French_et+al_2018_a",
            "entry": "G. French, M. Mackiewicz, and M. Fisher. Self-ensembling for visual domain adaptation. In International Conference on Learning Representations (ICLR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=French%2C%20G.%20Mackiewicz%2C%20M.%20Fisher%2C%20M.%20Self-ensembling%20for%20visual%20domain%20adaptation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=French%2C%20G.%20Mackiewicz%2C%20M.%20Fisher%2C%20M.%20Self-ensembling%20for%20visual%20domain%20adaptation%202018"
        },
        {
            "id": "Ganin_2014_a",
            "entry": "Y. Ganin and V. Lempitsky. Unsupervised domain adaptation by backpropagation. arXiv preprint arXiv:1409.7495, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1409.7495"
        },
        {
            "id": "Garofolo_1993_a",
            "entry": "J. S. Garofolo et al. TIMIT acoustic-phonetic continuous speech corpus LDC93S1. Philadelphia: Linguistic Data Consortium, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Garofolo%2C%20J.S.%20TIMIT%20acoustic-phonetic%20continuous%20speech%20corpus%20LDC93S1%201993"
        },
        {
            "id": "Ge_2017_a",
            "entry": "W. Ge and Y. Yu. Borrowing treasures from the wealthy: Deep transfer learning through selective joint finetuning. In Proc. IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, volume 6, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ge%2C%20W.%20Yu%2C%20Y.%20Borrowing%20treasures%20from%20the%20wealthy%3A%20Deep%20transfer%20learning%20through%20selective%20joint%20finetuning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ge%2C%20W.%20Yu%2C%20Y.%20Borrowing%20treasures%20from%20the%20wealthy%3A%20Deep%20transfer%20learning%20through%20selective%20joint%20finetuning%202017"
        },
        {
            "id": "Gebru_et+al_2017_a",
            "entry": "T. Gebru, J. Hoffman, and L. Fei-Fei. Fine-grained recognition in the wild: A multi-task domain adaptation approach. In 2017 IEEE International Conference on Computer Vision (ICCV), pages 1358\u20131367. IEEE, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gebru%2C%20T.%20Hoffman%2C%20J.%20Fei-Fei%2C%20L.%20Fine-grained%20recognition%20in%20the%20wild%3A%20A%20multi-task%20domain%20adaptation%20approach%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gebru%2C%20T.%20Hoffman%2C%20J.%20Fei-Fei%2C%20L.%20Fine-grained%20recognition%20in%20the%20wild%3A%20A%20multi-task%20domain%20adaptation%20approach%202017"
        },
        {
            "id": "Goodfellow_et+al_2014_a",
            "entry": "I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 27, pages 2672\u20132680. 2014. URL http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf.",
            "url": "http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20I.%20Pouget-Abadie%2C%20J.%20Mirza%2C%20M.%20Xu%2C%20B.%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "Gupta_et+al_2016_a",
            "entry": "S. Gupta, J. Hoffman, and J. Malik. Cross modal distillation for supervision transfer. In Computer Vision and Pattern Recognition (CVPR), 2016 IEEE Conference on, pages 2827\u20132836. IEEE, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gupta%2C%20S.%20Hoffman%2C%20J.%20Malik%2C%20J.%20Cross%20modal%20distillation%20for%20supervision%20transfer%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gupta%2C%20S.%20Hoffman%2C%20J.%20Malik%2C%20J.%20Cross%20modal%20distillation%20for%20supervision%20transfer%202016"
        },
        {
            "id": "Haeusser_et+al_2017_a",
            "entry": "P. H\u00e4usser, T. Frerix, A. Mordvintsev, and D. Cremers. Associative domain adaptation. 2017 IEEE International Conference on Computer Vision (ICCV), pages 2784\u20132792, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=H%C3%A4usser%2C%20P.%20Frerix%2C%20T.%20Mordvintsev%2C%20A.%20Cremers%2C%20D.%20Associative%20domain%20adaptation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=H%C3%A4usser%2C%20P.%20Frerix%2C%20T.%20Mordvintsev%2C%20A.%20Cremers%2C%20D.%20Associative%20domain%20adaptation%202017"
        },
        {
            "id": "Hoffman_et+al_2016_a",
            "entry": "J. Hoffman, S. Gupta, J. Leong, S. Guadarrama, and T. Darrell. Cross-modal adaptation for rgb-d detection. In Robotics and Automation (ICRA), 2016 IEEE International Conference on, pages 5032\u20135039. IEEE, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hoffman%2C%20J.%20Gupta%2C%20S.%20Leong%2C%20J.%20Guadarrama%2C%20S.%20Cross-modal%20adaptation%20for%20rgb-d%20detection%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hoffman%2C%20J.%20Gupta%2C%20S.%20Leong%2C%20J.%20Guadarrama%2C%20S.%20Cross-modal%20adaptation%20for%20rgb-d%20detection%202016"
        },
        {
            "id": "Hoffman_et+al_1994_a",
            "entry": "J. Hoffman, E. Tzeng, T. Park, J.-Y. Zhu, P. Isola, K. Saenko, A. Efros, and T. Darrell. CyCADA: Cycleconsistent adversarial domain adaptation. In Proceedings of the 35th International Conference on Machine Learning, volume 80, pages 1994\u20132003, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hoffman%2C%20J.%20Tzeng%2C%20E.%20Park%2C%20T.%20Zhu%2C%20J.-Y.%20CyCADA%3A%20Cycleconsistent%20adversarial%20domain%20adaptation%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hoffman%2C%20J.%20Tzeng%2C%20E.%20Park%2C%20T.%20Zhu%2C%20J.-Y.%20CyCADA%3A%20Cycleconsistent%20adversarial%20domain%20adaptation%201994"
        },
        {
            "id": "Hosseini-Asl_et+al_2018_a",
            "entry": "E. Hosseini-Asl, Y. Zhou, C. Xiong, and R. Socher. A multi-discriminator cyclegan for unsupervised non-parallel speech domain adaptation. In INTERSPEECH, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hosseini-Asl%2C%20E.%20Zhou%2C%20Y.%20Xiong%2C%20C.%20Socher%2C%20R.%20A%20multi-discriminator%20cyclegan%20for%20unsupervised%20non-parallel%20speech%20domain%20adaptation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hosseini-Asl%2C%20E.%20Zhou%2C%20Y.%20Xiong%2C%20C.%20Socher%2C%20R.%20A%20multi-discriminator%20cyclegan%20for%20unsupervised%20non-parallel%20speech%20domain%20adaptation%202018"
        },
        {
            "id": "Hsu_et+al_2017_a",
            "entry": "W.-N. Hsu, Y. Zhang, and J. R. Glass. Unsupervised learning of disentangled and interpretable representations from sequential data. In NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hsu%2C%20W.-N.%20Zhang%2C%20Y.%20Glass%2C%20J.R.%20Unsupervised%20learning%20of%20disentangled%20and%20interpretable%20representations%20from%20sequential%20data%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hsu%2C%20W.-N.%20Zhang%2C%20Y.%20Glass%2C%20J.R.%20Unsupervised%20learning%20of%20disentangled%20and%20interpretable%20representations%20from%20sequential%20data%202017"
        },
        {
            "id": "Hu_et+al_2015_a",
            "entry": "J. Hu, J. Lu, and Y.-P. Tan. Deep transfer metric learning. In Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on, pages 325\u2013333. IEEE, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hu%2C%20J.%20Lu%2C%20J.%20Tan%2C%20Y.-P.%20Deep%20transfer%20metric%20learning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hu%2C%20J.%20Lu%2C%20J.%20Tan%2C%20Y.-P.%20Deep%20transfer%20metric%20learning%202015"
        },
        {
            "id": "Hu_et+al_2018_a",
            "entry": "L. Hu, M. Kan, S. Shan, and X. Chen. Duplex generative adversarial network for unsupervised domain adaptation. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hu%2C%20L.%20Kan%2C%20M.%20Shan%2C%20S.%20Chen%2C%20X.%20Duplex%20generative%20adversarial%20network%20for%20unsupervised%20domain%20adaptation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hu%2C%20L.%20Kan%2C%20M.%20Shan%2C%20S.%20Chen%2C%20X.%20Duplex%20generative%20adversarial%20network%20for%20unsupervised%20domain%20adaptation%202018"
        },
        {
            "id": "Huang_et+al_2017_a",
            "entry": "G. Huang, Z. Liu, L. van der Maaten, and K. Q. Weinberger. Densely connected convolutional networks. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2261\u20132269, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20G.%20Liu%2C%20Z.%20van%20der%20Maaten%2C%20L.%20Weinberger%2C%20K.Q.%20Densely%20connected%20convolutional%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20G.%20Liu%2C%20Z.%20van%20der%20Maaten%2C%20L.%20Weinberger%2C%20K.Q.%20Densely%20connected%20convolutional%20networks%202017"
        },
        {
            "id": "Huang_et+al_2007_a",
            "entry": "J. Huang, A. Gretton, K. M. Borgwardt, B. Sch\u00f6lkopf, and A. J. Smola. Correcting sample selection bias by unlabeled data. In Advances in neural information processing systems, pages 601\u2013608, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20J.%20Gretton%2C%20A.%20Borgwardt%2C%20K.M.%20Sch%C3%B6lkopf%2C%20B.%20Correcting%20sample%20selection%20bias%20by%20unlabeled%20data%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20J.%20Gretton%2C%20A.%20Borgwardt%2C%20K.M.%20Sch%C3%B6lkopf%2C%20B.%20Correcting%20sample%20selection%20bias%20by%20unlabeled%20data%202007"
        },
        {
            "id": "Hull_1994_a",
            "entry": "J. J. Hull. A database for handwritten text recognition research. IEEE Trans. Pattern Anal. Mach. Intell., 16: 550\u2013554, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hull%2C%20J.J.%20A%20database%20for%20handwritten%20text%20recognition%20research%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hull%2C%20J.J.%20A%20database%20for%20handwritten%20text%20recognition%20research%201994"
        },
        {
            "id": "Kim_et+al_2017_a",
            "entry": "T. Kim, M. Cha, H. Kim, J. Lee, and J. Kim. Learning to discover cross-domain relations with generative adversarial networks. arXiv preprint arXiv:1703.05192, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.05192"
        },
        {
            "id": "Kumar_et+al_2017_a",
            "entry": "A. Kumar, P. Sattigeri, and T. Fletcher. Semi-supervised learning with gans: Manifold invariance with improved inference. In Advances in Neural Information Processing Systems, pages 5540\u20135550, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kumar%2C%20A.%20Sattigeri%2C%20P.%20Fletcher%2C%20T.%20Semi-supervised%20learning%20with%20gans%3A%20Manifold%20invariance%20with%20improved%20inference%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kumar%2C%20A.%20Sattigeri%2C%20P.%20Fletcher%2C%20T.%20Semi-supervised%20learning%20with%20gans%3A%20Manifold%20invariance%20with%20improved%20inference%202017"
        },
        {
            "id": "Lecun_et+al_1998_a",
            "entry": "Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278\u20132324, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lecun%2C%20Y.%20Bottou%2C%20L.%20Bengio%2C%20Y.%20Haffner%2C%20P.%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lecun%2C%20Y.%20Bottou%2C%20L.%20Bengio%2C%20Y.%20Haffner%2C%20P.%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998"
        },
        {
            "id": "Liu_2016_a",
            "entry": "M.-Y. Liu and O. Tuzel. Coupled generative adversarial networks. In Advances in neural information processing systems, pages 469\u2013477, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20M.-Y.%20Tuzel%2C%20O.%20Coupled%20generative%20adversarial%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20M.-Y.%20Tuzel%2C%20O.%20Coupled%20generative%20adversarial%20networks%202016"
        },
        {
            "id": "Liu_et+al_2017_a",
            "entry": "M.-Y. Liu, T. Breuel, and J. Kautz. Unsupervised image-to-image translation networks. In Advances in Neural Information Processing Systems, pages 700\u2013708, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20M.-Y.%20Breuel%2C%20T.%20Kautz%2C%20J.%20Unsupervised%20image-to-image%20translation%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20M.-Y.%20Breuel%2C%20T.%20Kautz%2C%20J.%20Unsupervised%20image-to-image%20translation%20networks%202017"
        },
        {
            "id": "Motiian_et+al_2017_a",
            "entry": "S. Motiian, Q. Jones, S. Iranmanesh, and G. Doretto. Few-shot adversarial domain adaptation. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems 30, pages 6670\u20136680. Curran Associates, Inc., 2017. URL http://papers.nips.cc/paper/7244-few-shot-adversarial-domain-adaptation.pdf.",
            "url": "http://papers.nips.cc/paper/7244-few-shot-adversarial-domain-adaptation.pdf",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Motiian%2C%20S.%20Jones%2C%20Q.%20Iranmanesh%2C%20S.%20Doretto%2C%20G.%20Few-shot%20adversarial%20domain%20adaptation%202017"
        },
        {
            "id": "Netzer_et+al_2011_a",
            "entry": "Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, and A. Y Ng. Reading digits in natural images with unsupervised feature learning. NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011, 2011. URL http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf.",
            "url": "http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Netzer%2C%20Y.%20Wang%2C%20T.%20Coates%2C%20A.%20Bissacco%2C%20A.%20Reading%20digits%20in%20natural%20images%20with%20unsupervised%20feature%20learning%202011"
        },
        {
            "id": "Radford_et+al_2018_a",
            "entry": "A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever. Improving language understanding by generative pre-training. 2018. URL https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf.",
            "url": "https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf"
        },
        {
            "id": "Ronneberger_et+al_2015_a",
            "entry": "O. Ronneberger, P. Fischer, and T. Brox. U-Net: Convolutional networks for biomedical image segmentation. In MICCAI, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ronneberger%2C%20O.%20Fischer%2C%20P.%20Brox%2C%20T.%20U-Net%3A%20Convolutional%20networks%20for%20biomedical%20image%20segmentation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ronneberger%2C%20O.%20Fischer%2C%20P.%20Brox%2C%20T.%20U-Net%3A%20Convolutional%20networks%20for%20biomedical%20image%20segmentation%202015"
        },
        {
            "id": "Russo_et+al_2018_a",
            "entry": "P. Russo, F. M. Carlucci, T. Tommasi, and B. Caputo. From source to target and back: symmetric bi-directional adaptive gan. CVPR, abs/1705.08824, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Russo%2C%20P.%20Carlucci%2C%20F.M.%20Tommasi%2C%20T.%20Caputo%2C%20B.%20From%20source%20to%20target%20and%20back%3A%20symmetric%20bi-directional%20adaptive%20gan%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Russo%2C%20P.%20Carlucci%2C%20F.M.%20Tommasi%2C%20T.%20Caputo%2C%20B.%20From%20source%20to%20target%20and%20back%3A%20symmetric%20bi-directional%20adaptive%20gan%202018"
        },
        {
            "id": "Shu_et+al_2018_a",
            "entry": "R. Shu, H. Bui, H. Narui, and S. Ermon. A DIRT-t approach to unsupervised domain adaptation. In International Conference on Learning Representations (ICLR), 2018. URL https://openreview.net/forum?id=H1q-TM-AW.",
            "url": "https://openreview.net/forum?id=H1q-TM-AW",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shu%2C%20R.%20Bui%2C%20H.%20Narui%2C%20H.%20Ermon%2C%20S.%20A%20DIRT-t%20approach%20to%20unsupervised%20domain%20adaptation%202018"
        },
        {
            "id": "Springenberg_2015_a",
            "entry": "J. T. Springenberg. Unsupervised and semi-supervised learning with categorical generative adversarial networks. arXiv preprint arXiv:1511.06390, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06390"
        },
        {
            "id": "Sricharan_et+al_2017_a",
            "entry": "K. Sricharan, R. Bala, M. Shreve, H. Ding, K. Saketh, and J. Sun. Semi-supervised conditional gans. arXiv preprint arXiv:1708.05789, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1708.05789"
        },
        {
            "id": "Tzeng_et+al_2015_a",
            "entry": "E. Tzeng, J. Hoffman, T. Darrell, and K. Saenko. Simultaneous deep transfer across domains and tasks. In Computer Vision (ICCV), 2015 IEEE International Conference on, pages 4068\u20134076. IEEE, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tzeng%2C%20E.%20Hoffman%2C%20J.%20Darrell%2C%20T.%20Saenko%2C%20K.%20Simultaneous%20deep%20transfer%20across%20domains%20and%20tasks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tzeng%2C%20E.%20Hoffman%2C%20J.%20Darrell%2C%20T.%20Saenko%2C%20K.%20Simultaneous%20deep%20transfer%20across%20domains%20and%20tasks%202015"
        },
        {
            "id": "Tzeng_et+al_2017_a",
            "entry": "E. Tzeng, J. Hoffman, K. Saenko, and T. Darrell. Adversarial discriminative domain adaptation. In Computer Vision and Pattern Recognition (CVPR), volume 1, page 4, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tzeng%2C%20E.%20Hoffman%2C%20J.%20Saenko%2C%20K.%20Darrell%2C%20T.%20Adversarial%20discriminative%20domain%20adaptation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tzeng%2C%20E.%20Hoffman%2C%20J.%20Saenko%2C%20K.%20Darrell%2C%20T.%20Adversarial%20discriminative%20domain%20adaptation%202017"
        },
        {
            "id": "Van_et+al_2016_a",
            "entry": "A. van den Oord, S. Dieleman, H. Zen, K. Simonyan, O. Vinyals, A. Graves, N. Kalchbrenner, A. W. Senior, and K. Kavukcuoglu. Wavenet: A generative model for raw audio. In SSW, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=van%20den%20Oord%2C%20A.%20Dieleman%2C%20S.%20Zen%2C%20H.%20Simonyan%2C%20K.%20Wavenet%3A%20A%20generative%20model%20for%20raw%20audio%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=van%20den%20Oord%2C%20A.%20Dieleman%2C%20S.%20Zen%2C%20H.%20Simonyan%2C%20K.%20Wavenet%3A%20A%20generative%20model%20for%20raw%20audio%202016"
        },
        {
            "id": "Xue_et+al_2008_a",
            "entry": "G.-R. Xue, W. Dai, Q. Yang, and Y. Yu. Topic-bridged plsa for cross-domain text classification. In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, pages 627\u2013634. ACM, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xue%2C%20G.-R.%20Dai%2C%20W.%20Yang%2C%20Q.%20Yu%2C%20Y.%20Topic-bridged%20plsa%20for%20cross-domain%20text%20classification%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xue%2C%20G.-R.%20Dai%2C%20W.%20Yang%2C%20Q.%20Yu%2C%20Y.%20Topic-bridged%20plsa%20for%20cross-domain%20text%20classification%202008"
        },
        {
            "id": "Yi_et+al_2017_a",
            "entry": "Z. Yi, H. Zhang, P. Tan, and M. Gong. Dualgan: Unsupervised dual learning for image-to-image translation. arXiv preprint, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yi%2C%20Z.%20Zhang%2C%20H.%20Tan%2C%20P.%20Gong%2C%20M.%20Dualgan%3A%20Unsupervised%20dual%20learning%20for%20image-to-image%20translation.%20arXiv%20p%202017"
        },
        {
            "id": "Zhou_et+al_2017_a",
            "entry": "Y. Zhou, C. Xiong, and R. Socher. Improving end-to-end speech recognition with policy learning. arXiv preprint arXiv:1712.07101, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.07101"
        },
        {
            "id": "Zhu_et+al_2017_a",
            "entry": "J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. In Computer Vision (ICCV), 2017 IEEE International Conference on, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20J.-Y.%20Park%2C%20T.%20Isola%2C%20P.%20Efros%2C%20A.A.%20Unpaired%20image-to-image%20translation%20using%20cycle-consistent%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20J.-Y.%20Park%2C%20T.%20Isola%2C%20P.%20Efros%2C%20A.A.%20Unpaired%20image-to-image%20translation%20using%20cycle-consistent%20adversarial%20networks%202017"
        }
    ]
}

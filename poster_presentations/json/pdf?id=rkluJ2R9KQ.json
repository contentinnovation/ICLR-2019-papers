{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "A NEW DOG LEARNS OLD TRICKS: RL FINDS CLASSIC OPTIMIZATION ALGORITHMS",
        "author": "Weiwei Kong",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=rkluJ2R9KQ"
        },
        "abstract": "We ask whether reinforcement learning can find theoretically optimal algorithms for online optimization problems, and introduce a novel learning framework in this setting. To answer this question, we introduce a number of key ideas from traditional algorithms and complexity theory. Specifically, we introduce the concept of adversarial distributions (universal and high-entropy training sets), which are distributions that encourage the learner to find algorithms that work well in the worst case. We test our new ideas on the AdWords problem, the online knapsack problem, and the secretary problem. Our results indicate that the models have learned behaviours that are consistent with the optimal algorithms for these problems derived using the online primal-dual framework."
    },
    "keywords": [
        {
            "term": "Theoretical computer science",
            "url": "https://en.wikipedia.org/wiki/Theoretical_computer_science"
        },
        {
            "term": "combinatorial optimization",
            "url": "https://en.wikipedia.org/wiki/combinatorial_optimization"
        },
        {
            "term": "machine learning",
            "url": "https://en.wikipedia.org/wiki/machine_learning"
        },
        {
            "term": "complexity theory",
            "url": "https://en.wikipedia.org/wiki/complexity_theory"
        },
        {
            "term": "optimization problem",
            "url": "https://en.wikipedia.org/wiki/optimization_problem"
        },
        {
            "term": "secretary problem",
            "url": "https://en.wikipedia.org/wiki/secretary_problem"
        },
        {
            "term": "reinforcement learning",
            "url": "https://en.wikipedia.org/wiki/reinforcement_learning"
        },
        {
            "term": "Markov Decision Process",
            "url": "https://en.wikipedia.org/wiki/Markov_Decision_Process"
        }
    ],
    "abbreviations": {
        "MDP": "Markov Decision Process",
        "TCS": "Theoretical computer science"
    },
    "highlights": [
        "Machine learning has led to dramatic improvements in our capabilities to solve problems previously considered intractable",
        "Our goal in this paper is to explore whether machine learning can be used to learn algorithms for classic combinatorial optimization problems",
        "A related previous work is that of <a class=\"ref-link\" id=\"cBello_et+al_2016_a\" href=\"#rBello_et+al_2016_a\">Bello et al (2016</a>) which studies combinatorial problems, the Traveling Salesman Problem and Knapsack, and uses policy gradient method for an RL framework to optimize the parameters of a pointer network. (This paper summarizes previous literature on combinatorial optimization using neural networks.) Our work differs in a few ways, but the goal is not only to solve the problem, but to interpret the learned RL policy network and compare to the known optimal algorithms, both in performance and in structure",
        "I.I.D. value setting with changing distributions In this case, our results show that by using a distribution which has very high entropy, max(a, b)]), the model is able to learn a behaviour which is characteristic of Wait--Pick, i.e. it waits until some time before accepting any value which is larger than the maximum value seen so far",
        "We introduced several ideas from traditional algorithmic thinking to train neural networks to solve online optimization problems",
        "In some instances, we saw that some state augmentation was needed in order for the learner to more adequately recover the optimal algorithms"
    ],
    "key_statements": [
        "Machine learning has led to dramatic improvements in our capabilities to solve problems previously considered intractable",
        "Our goal in this paper is to explore whether machine learning can be used to learn algorithms for classic combinatorial optimization problems",
        "We study three optimization problems in this work \u2013 the Adwords Problem, the Online (0-1) Knapsack Problem, and the so called Secretary Problem1",
        "A related previous work is that of <a class=\"ref-link\" id=\"cBello_et+al_2016_a\" href=\"#rBello_et+al_2016_a\">Bello et al (2016</a>) which studies combinatorial problems, the Traveling Salesman Problem and Knapsack, and uses policy gradient method for an RL framework to optimize the parameters of a pointer network. (This paper summarizes previous literature on combinatorial optimization using neural networks.) Our work differs in a few ways, but the goal is not only to solve the problem, but to interpret the learned RL policy network and compare to the known optimal algorithms, both in performance and in structure",
        "One of the goals in this work is to find a uniform algorithm, i.e., one which is independent of the input length, for which we use the RL approach and focus on online optimization problems",
        "I.I.D. value setting with changing distributions In this case, our results show that by using a distribution which has very high entropy, max(a, b)]), the model is able to learn a behaviour which is characteristic of Wait--Pick, i.e. it waits until some time before accepting any value which is larger than the maximum value seen so far",
        "We introduced several ideas from traditional algorithmic thinking to train neural networks to solve online optimization problems",
        "In some instances, we saw that some state augmentation was needed in order for the learner to more adequately recover the optimal algorithms"
    ],
    "summary": [
        "Machine learning has led to dramatic improvements in our capabilities to solve problems previously considered intractable.",
        "We will answer such questions by plotting the input-output characteristics of the network learned for the different problems we consider, and compare them to the expected behavior of the traditional algorithms.",
        "Online Knapsack problem: The model learns to find an optimal threshold on value per unit size to use to either accept or reject incoming items.",
        "Secretary Problem: The model learns the optimal \u201cWait--Pick\u201d algorithm which samples the first 1/e fraction of the input stream and picks the item which is higher than any seen before.",
        "(This paper summarizes previous literature on combinatorial optimization using neural networks.) Our work differs in a few ways, but the goal is not only to solve the problem, but to interpret the learned RL policy network and compare to the known optimal algorithms, both in performance and in structure.",
        "One of the goals in this work is to find a uniform algorithm, i.e., one which is independent of the input length, for which we use the RL approach and focus on online optimization problems.",
        "We do know that a universal algorithm would need to maintain a larger state, for example a histogram of value-by-size ratios of items seen so far, and be able to read the thresholds from the histogram.",
        "We train our RL agent on this distribution in two different settings: (A) The original state space defined above, and (B) The same state augmented by a histogram of the spend binned by the value-by-size ratio.",
        "We leave for future work the question of leveraging this simple mixed distribution defined above, to find a truly universal training set and show that an RL learner with the augmented state can find a universal bang-per-buck learner.",
        "In the value setting with changing distributions, it is impossible to recover the secretary problem with just these two inputs so we augment the state space by providing the maximum value in the past.",
        "I.I.D. value setting with changing distributions In this case, our results show that by using a distribution which has very high entropy, max(a, b)]), the model is able to learn a behaviour which is characteristic of Wait--Pick, i.e. it waits until some time before accepting any value which is larger than the maximum value seen so far.",
        "We introduced several ideas from traditional algorithmic thinking to train neural networks to solve online optimization problems.",
        "We plan to remove the state augmentation from the RL environment and force the agent to learn the state augmentation as part of the training process"
    ],
    "headline": "We introduce a number of key ideas from traditional algorithms and complexity theory",
    "reference_links": [
        {
            "id": "Aaronson_0000_a",
            "entry": "Scott Aaronson. Complexity zoo. URL https://complexityzoo.uwaterloo.ca/ Complexity_Zoo.",
            "url": "https://complexityzoo.uwaterloo.ca/Complexity_Zoo"
        },
        {
            "id": "Agrawal_et+al_2018_a",
            "entry": "Shipra Agrawal, Morteza Zadimoghaddam, and Vahab S. Mirrokni. Proportional allocation: Simple, distributed, and diverse matching with high entropy. In Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsmassan, Stockholm, Sweden, July 10-15, 2018, pages 99\u2013108, 2018. URL http://proceedings.mlr.press/v80/agrawal18b.html.",
            "url": "http://proceedings.mlr.press/v80/agrawal18b.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Agrawal%2C%20Shipra%20Zadimoghaddam%2C%20Morteza%20Mirrokni%2C%20Vahab%20S.%20Proportional%20allocation%3A%20Simple%2C%20distributed%2C%20and%20diverse%20matching%20with%20high%20entropy%202018-07-10"
        },
        {
            "id": "Alon_et+al_1999_a",
            "entry": "Noga Alon, Yossi Matias, and Mario Szegedy. The space complexity of approximating the frequency moments. J. Comput. Syst. Sci., 58(1):137\u2013147, 1999. doi: 10.1006/jcss.1997.1545. URL https://doi.org/10.1006/jcss.1997.1545.",
            "crossref": "https://dx.doi.org/10.1006/jcss.1997.1545",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1006/jcss.1997.1545"
        },
        {
            "id": "Ziv_et+al_2002_a",
            "entry": "Ziv Bar-Yossef, T. S. Jayram, Ravi Kumar, and D. Sivakumar. Information theory methods in communication complexity. In Proceedings of the 17th Annual IEEE Conference on Computational Complexity, Montreal, Quebec, Canada, May 21-24, 2002, pages 93\u2013102, 2002. doi: 10.1109/CCC.2002.1004344. URL https://doi.org/10.1109/CCC.2002.1004344.",
            "crossref": "https://dx.doi.org/10.1109/CCC.2002.1004344",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/CCC.2002.1004344"
        },
        {
            "id": "Bello_et+al_2016_a",
            "entry": "Irwan Bello, Hieu Pham, Quoc V Le, Mohammad Norouzi, and Samy Bengio. Neural combinatorial optimization with reinforcement learning. arXiv preprint arXiv:1611.09940, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.09940"
        },
        {
            "id": "Boutilier_2016_a",
            "entry": "Craig Boutilier and Tyler Lu. Budget allocation using weakly coupled, constrained markov decision processes. In UAI, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Boutilier%2C%20Craig%20Lu%2C%20Tyler%20Budget%20allocation%20using%20weakly%20coupled%2C%20constrained%20markov%20decision%20processes%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Boutilier%2C%20Craig%20Lu%2C%20Tyler%20Budget%20allocation%20using%20weakly%20coupled%2C%20constrained%20markov%20decision%20processes%202016"
        },
        {
            "id": "Buchbinder_2009_a",
            "entry": "Niv Buchbinder and Joseph Naor. The design of competitive online algorithms via a primal-dual approach. Foundations and Trends in Theoretical Computer Science, 3(2-3):93\u2013263, 2009. doi: 10.1561/0400000024. URL https://doi.org/10.1561/0400000024.",
            "crossref": "https://dx.doi.org/10.1561/0400000024",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1561/0400000024"
        },
        {
            "id": "Buchbinder_et+al_2007_a",
            "entry": "Niv Buchbinder, Kamal Jain, and Joseph Naor. Online primal-dual algorithms for maximizing adauctions revenue. In Algorithms - ESA 2007, 15th Annual European Symposium, Eilat, Israel, October 8-10, 2007, Proceedings, pages 253\u2013264, 2007. doi: 10.1007/978-3-540-75520-3\\ 24. URL https://doi.org/10.1007/978-3-540-75520-3_24.",
            "crossref": "https://dx.doi.org/10.1007/978-3-540-75520-3\\",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1007/978-3-540-75520-3%5C"
        },
        {
            "id": "Buchbinder_2009_b",
            "entry": "Niv Buchbinder, Joseph Seffi Naor, et al. The design of competitive online algorithms via a primal\u2013 dual approach. Foundations and Trends R in Theoretical Computer Science, 3(2\u20133):93\u2013263, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Buchbinder%2C%20Niv%20Naor%2C%20Joseph%20Seffi%20The%20design%20of%20competitive%20online%20algorithms%20via%20a%20primal%E2%80%93%20dual%20approach%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Buchbinder%2C%20Niv%20Naor%2C%20Joseph%20Seffi%20The%20design%20of%20competitive%20online%20algorithms%20via%20a%20primal%E2%80%93%20dual%20approach%202009"
        },
        {
            "id": "Buchbinder_et+al_2014_a",
            "entry": "Niv Buchbinder, Kamal Jain, and Mohit Singh. Secretary problems via linear programming. Math. Oper. Res., 39(1):190\u2013206, 2014. doi: 10.1287/moor.2013.0604. URL https://doi.org/10.1287/moor.2013.0604.",
            "crossref": "https://dx.doi.org/10.1287/moor.2013.0604",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1287/moor.2013.0604"
        },
        {
            "id": "Dai_et+al_2017_a",
            "entry": "Hanjun Dai, Elias Khalil, Yuyu Zhang, Bistra Dilkina, and Le Song. Learning combinatorial optimization algorithms over graphs. In Advances in Neural Information Processing Systems, pages 6348\u20136358, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dai%2C%20Hanjun%20Khalil%2C%20Elias%20Zhang%2C%20Yuyu%20Dilkina%2C%20Bistra%20Learning%20combinatorial%20optimization%20algorithms%20over%20graphs%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dai%2C%20Hanjun%20Khalil%2C%20Elias%20Zhang%2C%20Yuyu%20Dilkina%2C%20Bistra%20Learning%20combinatorial%20optimization%20algorithms%20over%20graphs%202017"
        },
        {
            "id": "Dantzig_1957_a",
            "entry": "G. Dantzig. Discrete variable extremum problems. Operations Research, 5:266\u2013277, 1957.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dantzig%2C%20G.%20Discrete%20variable%20extremum%20problems%201957",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dantzig%2C%20G.%20Discrete%20variable%20extremum%20problems%201957"
        },
        {
            "id": "Dean_2008_a",
            "entry": "Jeffrey Dean and Sanjay Ghemawat. Mapreduce: simplified data processing on large clusters. Commun. ACM, 51(1):107\u2013113, 2008. doi: 10.1145/1327452.1327492. URL http://doi.acm.org/10.1145/1327452.1327492.",
            "crossref": "https://dx.doi.org/10.1145/1327452.1327492",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/1327452.1327492"
        },
        {
            "id": "Dynkin_1963_a",
            "entry": "Eugene B Dynkin. The optimum choice of the instant for stopping a markov process. Sov. Math. Dokl., 4:627\u2013629, 1963.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dynkin%2C%20Eugene%20B.%20The%20optimum%20choice%20of%20the%20instant%20for%20stopping%20a%20markov%20process%201963",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dynkin%2C%20Eugene%20B.%20The%20optimum%20choice%20of%20the%20instant%20for%20stopping%20a%20markov%20process%201963"
        },
        {
            "id": "Jon_et+al_2010_a",
            "entry": "Jon Feldman, S. Muthukrishnan, Anastasios Sidiropoulos, Clifford Stein, and Zoya Svitkina. On distributing symmetric streaming computations. ACM Trans. Algorithms, 6(4):66:1\u2013 66:19, 2010. doi: 10.1145/1824777.1824786. URL http://doi.acm.org/10.1145/1824777.1824786.",
            "crossref": "https://dx.doi.org/10.1145/1824777.1824786",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/1824777.1824786"
        },
        {
            "id": "Gilbert_1966_a",
            "entry": "John P. Gilbert and Frederick Mosteller. Recognizing the maximum of a sequence. Journal of the American Statistical Association, 61(313):35\u201373, 1966. ISSN 01621459. URL http://www.jstor.org/stable/2283044.",
            "url": "http://www.jstor.org/stable/2283044",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gilbert%2C%20John%20P.%20Mosteller%2C%20Frederick%20Recognizing%20the%20maximum%20of%20a%20sequence%201966"
        },
        {
            "id": "Goodfellow_et+al_2014_a",
            "entry": "Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. CoRR, abs/1412.6572, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6572"
        },
        {
            "id": "Graves_et+al_2014_a",
            "entry": "Alex Graves, Greg Wayne, and Ivo Danihelka. Neural turing machines. arXiv preprint arXiv:1410.5401, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1410.5401"
        },
        {
            "id": "Henzinger_et+al_1998_a",
            "entry": "Monika Rauch Henzinger, Prabhakar Raghavan, and Sridhar Rajagopalan. Computing on data streams. In External Memory Algorithms, Proceedings of a DIMACS Workshop, New Brunswick, New Jersey, USA, May 20-22, 1998, pages 107\u2013118, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Henzinger%2C%20Monika%20Rauch%20Raghavan%2C%20Prabhakar%20Rajagopalan%2C%20Sridhar%20Computing%20on%20data%20streams.%20In%20External%20Memory%20Algorithms%2C%20Proceedings%20of%20a%20DIMACS%20Workshop%201998-05-20",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Henzinger%2C%20Monika%20Rauch%20Raghavan%2C%20Prabhakar%20Rajagopalan%2C%20Sridhar%20Computing%20on%20data%20streams.%20In%20External%20Memory%20Algorithms%2C%20Proceedings%20of%20a%20DIMACS%20Workshop%201998-05-20"
        },
        {
            "id": "Hochreiter_1997_a",
            "entry": "Sepp Hochreiter and Jurgen Schmidhuber. Long short-term memory. Neural computation, 9(8): 1735\u20131780, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hochreiter%2C%20Sepp%20Schmidhuber%2C%20Jurgen%20Long%20short-term%20memory%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hochreiter%2C%20Sepp%20Schmidhuber%2C%20Jurgen%20Long%20short-term%20memory%201997"
        },
        {
            "id": "Hopcroft_1979_a",
            "entry": "John E. Hopcroft and Jeffrey D. Ullman. Introduction to Automata Theory, Languages and Computation. Addison-Wesley, 1979. ISBN 0-201-02988-X.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hopcroft%2C%20John%20E.%20Ullman%2C%20Jeffrey%20D.%20Introduction%20to%20Automata%20Theory%2C%20Languages%20and%20Computation%201979"
        },
        {
            "id": "Kaiser_2015_a",
            "entry": "\u0141ukasz Kaiser and Ilya Sutskever. Neural gpus learn algorithms. arXiv preprint arXiv:1511.08228, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.08228"
        },
        {
            "id": "Kalyanasundaram_2000_a",
            "entry": "Bala Kalyanasundaram and Kirk R. Pruhs. An optimal deterministic algorithm for online bmatching. Theoretical Computer Science, 233(1):319 \u2013 325, 2000. ISSN 0304-3975. doi: https://doi.org/10.1016/S0304-3975(99)00140-1. URL http://www.sciencedirect.com/science/article/pii/S0304397599001401.",
            "crossref": "https://dx.doi.org/10.1016/S0304-3975(99)00140-1",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1016/S0304-3975%2899%2900140-1"
        },
        {
            "id": "Karp_et+al_1990_a",
            "entry": "Richard M Karp, Umesh V Vazirani, and Vijay V Vazirani. An optimal algorithm for on-line bipartite matching. In Proceedings of the twenty-second annual ACM symposium on Theory of computing, pages 352\u2013358. ACM, 1990.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Karp%2C%20Richard%20M.%20Vazirani%2C%20Umesh%20V.%20Vazirani%2C%20Vijay%20V.%20An%20optimal%20algorithm%20for%20on-line%20bipartite%20matching%201990",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Karp%2C%20Richard%20M.%20Vazirani%2C%20Umesh%20V.%20Vazirani%2C%20Vijay%20V.%20An%20optimal%20algorithm%20for%20on-line%20bipartite%20matching%201990"
        },
        {
            "id": "Kool_2018_a",
            "entry": "WWM Kool and M Welling. Attention solves your TSP. arXiv preprint arXiv:1803.08475, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.08475"
        },
        {
            "id": "Levine_et+al_2016_a",
            "entry": "Sergey Levine, Chelsea Finn, Trevor Darrell, and Pieter Abbeel. End-to-end training of deep visuomotor policies. The Journal of Machine Learning Research, 17(1):1334\u20131373, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Levine%2C%20Sergey%20Finn%2C%20Chelsea%20Darrell%2C%20Trevor%20Abbeel%2C%20Pieter%20End-to-end%20training%20of%20deep%20visuomotor%20policies%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Levine%2C%20Sergey%20Finn%2C%20Chelsea%20Darrell%2C%20Trevor%20Abbeel%2C%20Pieter%20End-to-end%20training%20of%20deep%20visuomotor%20policies%202016"
        },
        {
            "id": "Lillicrap_et+al_2015_a",
            "entry": "Timothy P Lillicrap, Jonathan J Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa, David Silver, and Daan Wierstra. Continuous control with deep reinforcement learning. arXiv preprint arXiv:1509.02971, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1509.02971"
        },
        {
            "id": "Mehta_et+al_2007_a",
            "entry": "Aranyak Mehta, Amin Saberi, Umesh Vazirani, and Vijay Vazirani. Adwords and generalized online matching. J. ACM, 54(5), October 2007. ISSN 0004-5411. doi: 10.1145/1284320.1284321. URL http://doi.acm.org/10.1145/1284320.1284321.",
            "crossref": "https://dx.doi.org/10.1145/1284320.1284321",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/1284320.1284321"
        },
        {
            "id": "Mehta_2013_a",
            "entry": "Aranyak Mehta et al. Online matching and ad allocation. Foundations and Trends R in Theoretical Computer Science, 8(4):265\u2013368, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mehta%2C%20Aranyak%20Online%20matching%20and%20ad%20allocation.%20Foundations%20and%20Trends%20R%20in%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mehta%2C%20Aranyak%20Online%20matching%20and%20ad%20allocation.%20Foundations%20and%20Trends%20R%20in%202013"
        },
        {
            "id": "Muthukrishnan_2005_a",
            "entry": "S. Muthukrishnan. Data streams: Algorithms and applications. Foundations and Trends in Theoretical Computer Science, 1(2), 2005. doi: 10.1561/0400000002. URL https://doi.org/10.1561/0400000002.",
            "crossref": "https://dx.doi.org/10.1561/0400000002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1561/0400000002"
        },
        {
            "id": "Andrew_1977_a",
            "entry": "Andrew Chi-Chih Yao. Probabilistic computations: Toward a unified measure of complexity. In Proceedings of the 18th Annual Symposium on Foundations of Computer Science, SFCS \u201977, pages 222\u2013227, Washington, DC, USA, 1977. IEEE Computer Society. doi: 10.1109/SFCS. 1977.24. URL https://doi.org/10.1109/SFCS.1977.24.",
            "crossref": "https://dx.doi.org/10.1109/SFCS.1977.24",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/SFCS.1977.24"
        },
        {
            "id": "Zaheer_et+al_2017_a",
            "entry": "Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan R. Salakhutdinov, and Alexander J. Smola. Deep sets. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, 4-9 December 2017, Long Beach, CA, USA, pages 3394\u20133404, 2017. URL http://papers.nips.cc/paper/6931-deep-sets.",
            "url": "http://papers.nips.cc/paper/6931-deep-sets",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zaheer%2C%20Manzil%20Kottur%2C%20Satwik%20Ravanbakhsh%2C%20Siamak%20Poczos%2C%20Barnabas%20Deep%20sets%202017-12"
        },
        {
            "id": "(i)_2007_a",
            "entry": "(i) The adversarial graph is defined as follows. Let B be an integer and set Bi = B for all i. Let m = Bn. To define the adversarial graph, we label the ad slots 1,..., m. For i \u2208 [n], we add an edges between all advertisers in {i, i + 1,..., n} and all ad slots in {(i \u2212 1)B + 1,..., iB}. Observe that this graph has a perfect b-matching by matching advertiser i to ad slots {(i \u2212 1)B + 1,..., iB}. Figure 4a shows an example of the this graph. It can be shown that for any deterministic algorithm, if one randomly permutes the advertisers then the expected competitive ratio is bounded above by 1 \u2212 1/e (Mehta et al., 2007, Theorem 9). Consequently, by an application of Yao\u2019s principle (Yao, 1977), for any randomized algorithm, there exists a permutation for which the competitive ratio is bounded above by 1 \u2212 1/e (see (Mehta et al., 2007, Theorem 9)).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=i%20The%20adversarial%20graph%20is%20defined%20as%20follows%20Let%20B%20be%20an%20integer%20and%20set%20Bi%20%20B%20for%20all%20i%20Let%20m%20%20Bn%20To%20define%20the%20adversarial%20graph%20we%20label%20the%20ad%20slots%201%20m%20For%20i%20%20n%20we%20add%20an%20edges%20between%20all%20advertisers%20in%20i%20i%20%201%20n%20and%20all%20ad%20slots%20in%20i%20%201B%20%201%20iB%20Observe%20that%20this%20graph%20has%20a%20perfect%20bmatching%20by%20matching%20advertiser%20i%20to%20ad%20slots%20i%20%201B%20%201%20iB%20Figure%204a%20shows%20an%20example%20of%20the%20this%20graph%20It%20can%20be%20shown%20that%20for%20any%20deterministic%20algorithm%20if%20one%20randomly%20permutes%20the%20advertisers%20then%20the%20expected%20competitive%20ratio%20is%20bounded%20above%20by%201%20%201e%20Mehta%20et%20al%202007%20Theorem%209%20Consequently%20by%20an%20application%20of%20Yaos%20principle%20Yao%201977%20for%20any%20randomized%20algorithm%20there%20exists%20a%20permutation%20for%20which%20the%20competitive%20ratio%20is%20bounded%20above%20by%201%20%201e%20see%20Mehta%20et%20al%202007%20Theorem%209",
            "oa_query": "https://api.scholarcy.com/oa_version?query=i%20The%20adversarial%20graph%20is%20defined%20as%20follows%20Let%20B%20be%20an%20integer%20and%20set%20Bi%20%20B%20for%20all%20i%20Let%20m%20%20Bn%20To%20define%20the%20adversarial%20graph%20we%20label%20the%20ad%20slots%201%20m%20For%20i%20%20n%20we%20add%20an%20edges%20between%20all%20advertisers%20in%20i%20i%20%201%20n%20and%20all%20ad%20slots%20in%20i%20%201B%20%201%20iB%20Observe%20that%20this%20graph%20has%20a%20perfect%20bmatching%20by%20matching%20advertiser%20i%20to%20ad%20slots%20i%20%201B%20%201%20iB%20Figure%204a%20shows%20an%20example%20of%20the%20this%20graph%20It%20can%20be%20shown%20that%20for%20any%20deterministic%20algorithm%20if%20one%20randomly%20permutes%20the%20advertisers%20then%20the%20expected%20competitive%20ratio%20is%20bounded%20above%20by%201%20%201e%20Mehta%20et%20al%202007%20Theorem%209%20Consequently%20by%20an%20application%20of%20Yaos%20principle%20Yao%201977%20for%20any%20randomized%20algorithm%20there%20exists%20a%20permutation%20for%20which%20the%20competitive%20ratio%20is%20bounded%20above%20by%201%20%201e%20see%20Mehta%20et%20al%202007%20Theorem%209"
        }
    ]
}

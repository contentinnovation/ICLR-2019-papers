{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "O PPORTUNISTIC L EARNING :",
        "author": "B UDGETED C OST-S ENSITIVE L EARNING",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=S1eOHo09KX"
        },
        "abstract": "In many real-world learning scenarios, features are only acquirable at a cost constrained under a budget. In this paper, we propose a novel approach for costsensitive feature acquisition at the prediction-time. The suggested method acquires features incrementally based on a context-aware feature-value function. We formulate the problem in the reinforcement learning paradigm, and introduce a reward function based on the utility of each feature. Specifically, MC dropout sampling is used to measure expected variations of the model uncertainty which is used as a feature-value function. Furthermore, we suggest sharing representations between the class predictor and value function estimator networks. The suggested approach is completely online and is readily applicable to stream learning setups. The solution is evaluated on three different datasets including the well-known MNIST"
    },
    "keywords": [
        {
            "term": "value function",
            "url": "https://en.wikipedia.org/wiki/value_function"
        },
        {
            "term": "real world",
            "url": "https://en.wikipedia.org/wiki/real_world"
        },
        {
            "term": "Transactions on Information Systems",
            "url": "https://en.wikipedia.org/wiki/Transactions_on_Information_Systems"
        },
        {
            "term": "normalized discounted cumulative gain",
            "url": "https://en.wikipedia.org/wiki/normalized_discounted_cumulative_gain"
        },
        {
            "term": "medical test",
            "url": "https://en.wikipedia.org/wiki/medical_test"
        },
        {
            "term": "mean squared error",
            "url": "https://en.wikipedia.org/wiki/mean_squared_error"
        }
    ],
    "abbreviations": {
        "Si": "samples as input",
        "OL": "Opportunistic Learning",
        "DQN": "deep Q-network",
        "MSE": "mean squared error",
        "NDCG": "normalized discounted cumulative gain",
        "AUACC": "accuracy-cost curve",
        "TOIS": "Transactions on Information Systems"
    },
    "highlights": [
        "In traditional machine learning settings, it is usually assumed that a training dataset is freely available and the objective is to train models that generalize well",
        "We propose a novel approach for costsensitive feature acquisition at the prediction-time",
        "The suggested method acquires features incrementally based on a context-aware feature-value function",
        "MC dropout sampling is used to measure expected variations of the model uncertainty which is used as a feature-value function",
        "The feature set is fixed, and we are dealing with complete feature vectors accompanied by class labels that are provided for training",
        "This paper presents a novel method based on deep Q-networks for cost-sensitive feature acquisition"
    ],
    "key_statements": [
        "In traditional machine learning settings, it is usually assumed that a training dataset is freely available and the objective is to train models that generalize well",
        "We propose a novel approach for costsensitive feature acquisition at the prediction-time",
        "The suggested method acquires features incrementally based on a context-aware feature-value function",
        "MC dropout sampling is used to measure expected variations of the model uncertainty which is used as a feature-value function",
        "The solution is evaluated on three different datasets including the well-known MNIST",
        "The feature set is fixed, and we are dealing with complete feature vectors accompanied by class labels that are provided for training",
        "The notation of cost is more general than financial cost and it refers to other concepts such as computational cost, privacy impacts, energy consumption, patient discomfort in medical tests, and so forth (Krishnapuram et al, 2011)",
        "Take the example of the disease diagnosis based on medical tests",
        "Creating a complete feature vector from all the relevant information is synonymous with conducting many tests such as MRI scan, blood test, etc. which would not be practical",
        "Various approaches were suggested in the literature for cost-sensitive feature acquisition",
        "This paper presents a novel method based on deep Q-networks for cost-sensitive feature acquisition",
        "This paper suggests a method for sharing the representations between the class predictor and action-value models that increases the training efficiency",
        "We evaluated our method using a real-world health dataset for diabetes classification where feature acquisition costs and budgets are natural and essential to be considered",
        "Proposed method is able to achieve higher normalized discounted cumulative gain values using a much lower acquisition budget compared to tree-based approaches in the literature including CSTC (Xu et al, 2014), Cronus (Chen et al, 2012), and Early Exit (Cambazoglu et al, 2010)",
        "Figure 8a and 8b demonstrate the validation accuracy and accuracy-cost curve values measured during the processing of the data stream at each episode for the MNIST and Diabetes datasets, respectively",
        "We demonstrated that certainty estimation in neural network classifiers can be used as a viable measure for the value of features",
        "The suggested method is able to learn from data streams, make accurate predictions, and effectively reduce the prediction-time feature acquisition cost"
    ],
    "summary": [
        "In traditional machine learning settings, it is usually assumed that a training dataset is freely available and the objective is to train models that generalize well.",
        "This paper presents a novel method based on deep Q-networks for cost-sensitive feature acquisition.",
        "In contrast to the recent feature acquisition methods that use reinforcement learning ideas (He et al, 2016; Shim et al, 2017; Janisch et al, 2017), the suggested reward function does not require any hyper-parameter tuning to balance cost versus performance trade-off.",
        "In contrast to many other work in the literature that assume an initial complete dataset (He et al, 2012; Kusner et al, 2014; Chen et al, 2015; Early et al, 2016b; Nan & Saligrama, 2017), the proposed solution is stream-based and online which learns and optimizes acquisition costs during the training and the prediction.",
        "Other reinforcement learning based feature acquisition methods in the literature usually use the final prediction accuracy and feature acquisition costs as components of reward function (He et al, 2016; Shim et al, 2017; Janisch et al, 2017).",
        "Figure 1 presents the network architecture of the proposed method for prediction and feature acquisition.",
        "We evaluated our method using a real-world health dataset for diabetes classification where feature acquisition costs and budgets are natural and essential to be considered.",
        "Proposed method is able to achieve higher NDCG values using a much lower acquisition budget compared to tree-based approaches in the literature including CSTC (Xu et al, 2014), Cronus (Chen et al, 2012), and Early Exit (Cambazoglu et al, 2010).",
        "We show the effectiveness of three ideas suggested by this paper i.e, using model uncertainty as a feature-value measure, representation sharing between the P and Q networks, and using MC-dropout as a measure of prediction uncertainty.",
        "We implemented the RL-Based method such that it is using a similar architecture and learning algorithm as the OL, while the reward function is the the negative of feature costs for acquiring each feature and a positive value for making correct predictions.",
        "Figure 5 shows the average prediction accuracy versus the certainty of samples reported using the MC-dropout method and directly using the softmax output values.",
        "Figure 8a and 8b demonstrate the validation accuracy and AUACC values measured during the processing of the data stream at each episode for the MNIST and Diabetes datasets, respectively.",
        "The suggested method is able to learn from data streams, make accurate predictions, and effectively reduce the prediction-time feature acquisition cost."
    ],
    "headline": "We propose a novel approach for costsensitive feature acquisition at the prediction-time",
    "reference_links": []
}

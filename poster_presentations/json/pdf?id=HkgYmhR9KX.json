{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "AD-VAT: AN ASYMMETRIC DUELING MECHANISM",
        "author": "FOR LEARNING VISUAL ACTIVE TRACKING",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=HkgYmhR9KX"
        },
        "abstract": "Visual Active Tracking (VAT) aims at following a target object by autonomously controlling the motion system of a tracker given visual observations. Previous work has shown that the tracker can be trained in a simulator via reinforcement learning and deployed in real-world scenarios. However, during training, such method requires manually specifying the moving path of the target object to be tracked, which cannot ensure the tracker\u2019s generalization on unseen object moving patterns. To learn a robust tracker for VAT, in this paper, we propose a novel adversarial RL method which adopts an Asymmetric Dueling mechanism, referred to as AD-VAT. In AD-VAT, both the tracker and the target are approximated by end-to-end neural networks, and are trained via RL in a dueling/competitive manner: i.e., the tracker intends to lockup the target, while the target tries to escape from the tracker. They are asymmetric in that the target is aware of the tracker, but not vice versa. Specifically, besides its own observation, the target is fed with the tracker\u2019s observation and action, and learns to predict the tracker\u2019s reward as an auxiliary task. We show that such an asymmetric dueling mechanism produces a stronger target, which in turn induces a more robust tracker. To stabilize the training, we also propose a novel partial zero-sum reward for the tracker/target. The experimental results, in both 2D and 3D environments, demonstrate that the proposed method leads to a faster convergence in training and yields more robust tracking behaviors in different testing scenarios. For supplementary videos, see: https://www.youtube. com/playlist?list=PL9rZj4Mea7wOZkdajK1TsprRg8iUf51BS"
    },
    "keywords": [
        {
            "term": "reinforcement learning",
            "url": "https://en.wikipedia.org/wiki/reinforcement_learning"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "motion system",
            "url": "https://en.wikipedia.org/wiki/motion_system"
        },
        {
            "term": "Field of View",
            "url": "https://en.wikipedia.org/wiki/Field_of_View"
        },
        {
            "term": "real world",
            "url": "https://en.wikipedia.org/wiki/real_world"
        },
        {
            "term": "visual tracking",
            "url": "https://en.wikipedia.org/wiki/visual_tracking"
        }
    ],
    "abbreviations": {
        "VAT": "Visual Active Tracking",
        "PZR": "partial zerosum reward",
        "TAM": "tracker-aware model",
        "FoV": "Field of View",
        "DR Room": "Domain Randomized Room",
        "AR": "Accumulated Reward",
        "EL": "Episode Length"
    },
    "highlights": [
        "Visual Active Tracking (VAT) aims at following a target object by autonomously controlling the motion system of a tracker given visual observations",
        "We propose a novel adversarial RL method for learning Visual Active Tracking, refereed to as AD-Visual Active Tracking (Asymmetric Dueling mechanism for learning Visual Active Tracking)",
        "We test the active tracker trained with different target agents in four testing settings, showing the effectiveness of AD-Visual Active Tracking",
        "In Section 3, we introduced two components to implement AD-Visual Active Tracking: partial zerosum reward (PZR) and tracker-aware model (TAM) for target",
        "We have proposed an asymmetric dueling mechanism for visual active tracking (ADVAT)",
        "Within AD-Visual Active Tracking, agents of tracker and target are learned in an adversarial manner"
    ],
    "key_statements": [
        "Visual Active Tracking (VAT) aims at following a target object by autonomously controlling the motion system of a tracker given visual observations",
        "We propose a novel adversarial RL method for learning Visual Active Tracking, refereed to as AD-Visual Active Tracking (Asymmetric Dueling mechanism for learning Visual Active Tracking)",
        "The environments of AD-Visual Active Tracking naturally compose a curriculum, because the tracker is more likely to compete with a target with the appropriate difficulty level when both agents are becoming stronger simultaneously",
        "To learn the optimal policy to escape, we model the target with a \u201ctracker-aware network\u201d, i.e., besides its own observation, the observation and actions of the tracker are fed to the escaping network",
        "We argue that such an \u201casymmetric dueling\u201d mechanism is able to learn a stronger target, which vice versa yields a more robust tracker",
        "In the 3D environments, we further demonstrate that the tracker trained in AD-Visual Active Tracking is capable of generalizing to high-fidelity environments even it is trained in a simple environment",
        "We propose a novel Adversarial Reinforcement Learning method for Visual Active Tracking task, i.e., the Asymmetric Dueling mechanism (AD-Visual Active Tracking)",
        "In AD-Visual Active Tracking, the target learns to generate diverse trajectories when competing with the tracker, which in turn helps train a more robust tracker",
        "We quantitatively evaluate the performance of our approach, comparing to the two baselines",
        "We test the active tracker trained with different target agents in four testing settings, showing the effectiveness of AD-Visual Active Tracking",
        "The max episode length is 500, so the upper bound of Episode Length is 500",
        "In Section 3, we introduced two components to implement AD-Visual Active Tracking: partial zerosum reward (PZR) and tracker-aware model (TAM) for target",
        "The naive method is an intuitive idea that target only uses its own observation with auxiliary task, guided by a zero-sum reward",
        "We have proposed an asymmetric dueling mechanism for visual active tracking (ADVAT)",
        "Within AD-Visual Active Tracking, agents of tracker and target are learned in an adversarial manner",
        "Experiments including ablation study in both 2D and 3D environments verify the effectiveness of the proposed mechanism"
    ],
    "summary": [
        "Visual Active Tracking (VAT) aims at following a target object by autonomously controlling the motion system of a tracker given visual observations.",
        "The environments of AD-VAT naturally compose a curriculum, because the tracker is more likely to compete with a target with the appropriate difficulty level when both agents are becoming stronger simultaneously.",
        "We derive two components in AD-VAT: partial zero-sum reward(PZR) and tracker-aware model(TAM) for target.",
        "To learn the optimal policy to escape, we model the target with a \u201ctracker-aware network\u201d, i.e., besides its own observation, the observation and actions of the tracker are fed to the escaping network.",
        "In AD-VAT, the target learns to generate diverse trajectories when competing with the tracker, which in turn helps train a more robust tracker.",
        "We introduce our proposed method: Asymmetric Dueling mechanism for learning Visual Active Tracking (AD-VAT).",
        "We illustrate the two key components in AD-VAT: partial zero-sum reward structure and a tracker-aware model for the target.",
        "The reward function is simplified to r2 = \u2212r1, which means that the target and tracker play a zero-sum game.",
        "By applying this reward function, the optimal policy for the target we expect should be escaping and disappearing from the observable range of the tracker but keeping close to the edge of the range.",
        "Note that the validation environment is of the same settings as training, except that the target is controlled by a Nav agent.",
        "We conduct an ablation study to show the effectiveness of the partial zero-sum reward and tracker-aware model.",
        "We test the active tracker trained with different target agents in four testing settings, showing the effectiveness of AD-VAT.",
        "At the beginning of the learning, the adversarial target usually walks randomly around the start point, performing similar policy as Ram. Such target is easier to be found and observed, even though the tracker is in exploration.",
        "In Section 3, we introduced two components to implement AD-VAT: partial zerosum reward (PZR) and tracker-aware model (TAM) for target.",
        "The naive method is an intuitive idea that target only uses its own observation with auxiliary task, guided by a zero-sum reward.",
        "Within AD-VAT, agents of tracker and target are learned in an adversarial manner.",
        "With the design of the partial zero-sum reward structure and tracker-aware model, the reinforced active tracker outperforms baseline methods.",
        "We would like to: 1) investigate the theoretical justification of applying modern Multi-Agent RL methods (<a class=\"ref-link\" id=\"cLanctot_et+al_2017_a\" href=\"#rLanctot_et+al_2017_a\"><a class=\"ref-link\" id=\"cLanctot_et+al_2017_a\" href=\"#rLanctot_et+al_2017_a\">Lanctot et al, 2017</a></a>; <a class=\"ref-link\" id=\"cSrinivasan_et+al_2018_a\" href=\"#rSrinivasan_et+al_2018_a\"><a class=\"ref-link\" id=\"cSrinivasan_et+al_2018_a\" href=\"#rSrinivasan_et+al_2018_a\">Srinivasan et al, 2018</a></a>) to solving Partially Observable Markov Game and finding Nash Equilibrium. 2) further develop the mechanism/model for active tracking in more complex environment; 3) adapt the mechanism to other tasks"
    ],
    "headline": "To learn a robust tracker for Visual Active Tracking, in this paper, we propose a novel adversarial RL method which adopts an Asymmetric Dueling mechanism, referred to as AD-Visual Active Tracking",
    "reference_links": [
        {
            "id": "Babenko_et+al_2009_a",
            "entry": "Boris Babenko, Ming-Hsuan Yang, and Serge Belongie. Visual tracking with online multiple instance learning. In The IEEE Conference on Computer Vision and Pattern Recognition, pp. 983\u2013990, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Babenko%2C%20Boris%20Yang%2C%20Ming-Hsuan%20Belongie%2C%20Serge%20Visual%20tracking%20with%20online%20multiple%20instance%20learning%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Babenko%2C%20Boris%20Yang%2C%20Ming-Hsuan%20Belongie%2C%20Serge%20Visual%20tracking%20with%20online%20multiple%20instance%20learning%202009"
        },
        {
            "id": "Bansal_et+al_2017_a",
            "entry": "Trapit Bansal, Jakub Pachocki, Szymon Sidor, Ilya Sutskever, and Igor Mordatch. Emergent complexity via multi-agent competition. arXiv preprint arXiv:1710.03748, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.03748"
        },
        {
            "id": "Bengio_et+al_2009_a",
            "entry": "Yoshua Bengio, J\u00e9r\u00f4me Louradour, Ronan Collobert, and Jason Weston. Curriculum learning. In Proceedings of the 26th Annual International Conference on Machine Learning, pp. 41\u201348. ACM, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bengio%2C%20Yoshua%20Louradour%2C%20J%C3%A9r%C3%B4me%20Collobert%2C%20Ronan%20Weston%2C%20Jason%20Curriculum%20learning%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bengio%2C%20Yoshua%20Louradour%2C%20J%C3%A9r%C3%B4me%20Collobert%2C%20Ronan%20Weston%2C%20Jason%20Curriculum%20learning%202009"
        },
        {
            "id": "Bolme_et+al_2010_a",
            "entry": "David S Bolme, J Ross Beveridge, Bruce A Draper, and Yui Man Lui. Visual object tracking using adaptive correlation filters. In The IEEE Conference on Computer Vision and Pattern Recognition, pp. 2544\u20132550, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bolme%2C%20David%20S.%20Beveridge%2C%20J.Ross%20Draper%2C%20Bruce%20A.%20Lui%2C%20Yui%20Man%20Visual%20object%20tracking%20using%20adaptive%20correlation%20filters%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bolme%2C%20David%20S.%20Beveridge%2C%20J.Ross%20Draper%2C%20Bruce%20A.%20Lui%2C%20Yui%20Man%20Visual%20object%20tracking%20using%20adaptive%20correlation%20filters%202010"
        },
        {
            "id": "Brockman_et+al_2016_a",
            "entry": "Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba. Openai gym. arXiv preprint arXiv:1606.01540, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1606.01540"
        },
        {
            "id": "Choi_2017_a",
            "entry": "Janghoon Choi, Junseok Kwon, and Kyoung Mu Lee. Visual tracking by reinforced decision making. arXiv preprint arXiv:1702.06291, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.06291"
        },
        {
            "id": "Denzler_1994_a",
            "entry": "Joachim Denzler and Dietrich WR Paulus. Active motion detection and object tracking. In International Conference on Image Processing, volume 3, pp. 635\u2013639, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Denzler%2C%20Joachim%20Paulus%2C%20Dietrich%20W.R.%20Active%20motion%20detection%20and%20object%20tracking%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Denzler%2C%20Joachim%20Paulus%2C%20Dietrich%20W.R.%20Active%20motion%20detection%20and%20object%20tracking%201994"
        },
        {
            "id": "Griffis_0000_a",
            "entry": "David Griffis. A3c lstm atari with pytorch plus a3g design. Web Page. URL https://github.com/dgriff777/rl_a3c_pytorch.",
            "url": "https://github.com/dgriff777/rl_a3c_pytorch"
        },
        {
            "id": "Held_et+al_2017_a",
            "entry": "David Held, Xinyang Geng, Carlos Florensa, and Pieter Abbeel. Automatic goal generation for reinforcement learning agents. arXiv preprint arXiv:1705.06366, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.06366"
        },
        {
            "id": "Henriques_et+al_0000_a",
            "entry": "Jo\u00e3o F Henriques, Rui Caseiro, Pedro Martins, and Jorge Batista. High-speed tracking with kernelized correlation filters. IEEE Transactions on Pattern Analysis and Machine Intelligence, 37(3):583\u2013 596, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Henriques%2C%20Jo%C3%A3o%20F.%20Caseiro%2C%20Rui%20Martins%2C%20Pedro%20Batista%2C%20Jorge%20High-speed%20tracking%20with%20kernelized%20correlation%20filters",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Henriques%2C%20Jo%C3%A3o%20F.%20Caseiro%2C%20Rui%20Martins%2C%20Pedro%20Batista%2C%20Jorge%20High-speed%20tracking%20with%20kernelized%20correlation%20filters"
        },
        {
            "id": "Hong_2018_a",
            "entry": "Zhang-Wei Hong, Chen Yu-Ming, Shih-Yang Su, Tzu-Yun Shann, Yi-Hsiang Chang, Hsuan-Kung Yang, Brian Hsi-Lin Ho, Chih-Chieh Tu, Yueh-Chuan Chang, Tsu-Ching Hsiao, et al. Virtualto-real: Learning to control in visual semantic segmentation. arXiv preprint arXiv:1802.00285, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.00285"
        },
        {
            "id": "Hu_et+al_2012_a",
            "entry": "Weiming Hu, Xi Li, Wenhan Luo, Xiaoqin Zhang, Stephen Maybank, and Zhongfei Zhang. Single and multiple object tracking using log-euclidean riemannian subspace and block-division appearance model. IEEE Transactions on Pattern Analysis and Machine Intelligence, 34(12):2420\u20132440, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hu%2C%20Weiming%20Li%2C%20Xi%20Luo%2C%20Wenhan%20Zhang%2C%20Xiaoqin%20Single%20and%20multiple%20object%20tracking%20using%20log-euclidean%20riemannian%20subspace%20and%20block-division%20appearance%20model%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hu%2C%20Weiming%20Li%2C%20Xi%20Luo%2C%20Wenhan%20Zhang%2C%20Xiaoqin%20Single%20and%20multiple%20object%20tracking%20using%20log-euclidean%20riemannian%20subspace%20and%20block-division%20appearance%20model%202012"
        },
        {
            "id": "Huang_et+al_2017_a",
            "entry": "Sandy Huang, Nicolas Papernot, Ian Goodfellow, Yan Duan, and Pieter Abbeel. Adversarial attacks on neural network policies. arXiv preprint arXiv:1702.02284, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.02284"
        },
        {
            "id": "Kalal_et+al_2012_a",
            "entry": "Zdenek Kalal, Krystian Mikolajczyk, and Jiri Matas. Tracking-learning-detection. IEEE Transactions on Pattern Analysis and Machine Intelligence, 34(7):1409\u20131422, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zdenek%20Kalal%20Krystian%20Mikolajczyk%20and%20Jiri%20Matas%20Trackinglearningdetection%20IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence%2034714091422%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zdenek%20Kalal%20Krystian%20Mikolajczyk%20and%20Jiri%20Matas%20Trackinglearningdetection%20IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence%2034714091422%202012"
        },
        {
            "id": "Kim_et+al_2005_a",
            "entry": "Kye Kyung Kim, Soo Hyun Cho, Hae Jin Kim, and Jae Yeon Lee. Detecting and tracking moving object using an active camera. In International Conference on Advanced Communication Technology, volume 2, pp. 817\u2013820, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kim%2C%20Kye%20Kyung%20Cho%2C%20Soo%20Hyun%20Kim%2C%20Hae%20Jin%20Lee%2C%20Jae%20Yeon%20Detecting%20and%20tracking%20moving%20object%20using%20an%20active%20camera%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kim%2C%20Kye%20Kyung%20Cho%2C%20Soo%20Hyun%20Kim%2C%20Hae%20Jin%20Lee%2C%20Jae%20Yeon%20Detecting%20and%20tracking%20moving%20object%20using%20an%20active%20camera%202005"
        },
        {
            "id": "Kristan_et+al_2016_a",
            "entry": "Matej Kristan, Jiri Matas, Ale\u0161 Leonardis, Tomas Vojir, Roman Pflugfelder, Gustavo Fernandez, Georg Nebehay, Fatih Porikli, and Luka Cehovin. A novel performance evaluation methodology for single-target trackers. IEEE Transactions on Pattern Analysis and Machine Intelligence, 38 (11):2137\u20132155, Nov 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kristan%2C%20Matej%20Matas%2C%20Jiri%20Leonardis%2C%20Ale%C5%A1%20Vojir%2C%20Tomas%20A%20novel%20performance%20evaluation%20methodology%20for%20single-target%20trackers%202016-11-11",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kristan%2C%20Matej%20Matas%2C%20Jiri%20Leonardis%2C%20Ale%C5%A1%20Vojir%2C%20Tomas%20A%20novel%20performance%20evaluation%20methodology%20for%20single-target%20trackers%202016-11-11"
        },
        {
            "id": "Kumar_et+al_2010_a",
            "entry": "M Pawan Kumar, Benjamin Packer, and Daphne Koller. Self-paced learning for latent variable models. In Advances in Neural Information Processing Systems, pp. 1189\u20131197, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kumar%2C%20M.Pawan%20Packer%2C%20Benjamin%20Koller%2C%20Daphne%20Self-paced%20learning%20for%20latent%20variable%20models%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kumar%2C%20M.Pawan%20Packer%2C%20Benjamin%20Koller%2C%20Daphne%20Self-paced%20learning%20for%20latent%20variable%20models%202010"
        },
        {
            "id": "Kylberg_2011_a",
            "entry": "Gustaf Kylberg. The kylberg texture dataset v. 1.0. External report (Blue series) 35, Centre for Image Analysis, Swedish University of Agricultural Sciences and Uppsala University, Uppsala, Sweden, September 2011. URL http://www.cb.uu.se/~gustaf/texture/.",
            "url": "http://www.cb.uu.se/~gustaf/texture/"
        },
        {
            "id": "Lanctot_et+al_2017_a",
            "entry": "Marc Lanctot, Vinicius Zambaldi, Audrunas Gruslys, Angeliki Lazaridou, Julien Perolat, David Silver, Thore Graepel, et al. A unified game-theoretic approach to multiagent reinforcement learning. In Advances in Neural Information Processing Systems, pp. 4190\u20134203, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lanctot%2C%20Marc%20Zambaldi%2C%20Vinicius%20Gruslys%2C%20Audrunas%20Lazaridou%2C%20Angeliki%20A%20unified%20game-theoretic%20approach%20to%20multiagent%20reinforcement%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lanctot%2C%20Marc%20Zambaldi%2C%20Vinicius%20Gruslys%2C%20Audrunas%20Lazaridou%2C%20Angeliki%20A%20unified%20game-theoretic%20approach%20to%20multiagent%20reinforcement%20learning%202017"
        },
        {
            "id": "Littman_1994_a",
            "entry": "Michael L Littman. Markov games as a framework for multi-agent reinforcement learning. In Machine Learning Proceedings 1994, pp. 157\u2013163.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Littman%2C%20Michael%20L.%20Markov%20games%20as%20a%20framework%20for%20multi-agent%20reinforcement%20learning%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Littman%2C%20Michael%20L.%20Markov%20games%20as%20a%20framework%20for%20multi-agent%20reinforcement%20learning%201994"
        },
        {
            "id": "Luo_et+al_2019_a",
            "entry": "W. Luo, P. Sun, F. Zhong, W. Liu, T. Zhang, and Y. Wang. End-to-end active object tracking and its real-world deployment via reinforcement learning. IEEE Transactions on Pattern Analysis and Machine Intelligence, pp. 1\u20131, 2019. ISSN 0162-8828. doi: 10.1109/TPAMI.2019.2899570.",
            "crossref": "https://dx.doi.org/10.1109/TPAMI.2019.2899570",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/TPAMI.2019.2899570"
        },
        {
            "id": "Luo_et+al_2018_a",
            "entry": "Wenhan Luo, Peng Sun, Fangwei Zhong, Wei Liu, Tong Zhang, and Yizhou Wang. End-to-end active object tracking via reinforcement learning. In International Conference on Machine Learning, pp. 3286\u20133295, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Luo%2C%20Wenhan%20Sun%2C%20Peng%20Zhong%2C%20Fangwei%20Liu%2C%20Wei%20End-to-end%20active%20object%20tracking%20via%20reinforcement%20learning%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Luo%2C%20Wenhan%20Sun%2C%20Peng%20Zhong%2C%20Fangwei%20Liu%2C%20Wei%20End-to-end%20active%20object%20tracking%20via%20reinforcement%20learning%202018"
        },
        {
            "id": "Ma_et+al_2015_a",
            "entry": "Chao Ma, Jia-Bin Huang, Xiaokang Yang, and Ming-Hsuan Yang. Hierarchical convolutional features for visual tracking. In International Conference on Computer Vision, pp. 3074\u20133082, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ma%2C%20Chao%20Huang%2C%20Jia-Bin%20Yang%2C%20Xiaokang%20Yang%2C%20Ming-Hsuan%20Hierarchical%20convolutional%20features%20for%20visual%20tracking%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ma%2C%20Chao%20Huang%2C%20Jia-Bin%20Yang%2C%20Xiaokang%20Yang%2C%20Ming-Hsuan%20Hierarchical%20convolutional%20features%20for%20visual%20tracking%202015"
        },
        {
            "id": "Mandlekar_et+al_2017_a",
            "entry": "Ajay Mandlekar, Yuke Zhu, Animesh Garg, Li Fei-Fei, and Silvio Savarese. Adversarially robust policy learning: Active construction of physically-plausible perturbations. In 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 3932\u20133939. IEEE, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mandlekar%2C%20Ajay%20Zhu%2C%20Yuke%20Garg%2C%20Animesh%20Fei-Fei%2C%20Li%20Adversarially%20robust%20policy%20learning%3A%20Active%20construction%20of%20physically-plausible%20perturbations%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mandlekar%2C%20Ajay%20Zhu%2C%20Yuke%20Garg%2C%20Animesh%20Fei-Fei%2C%20Li%20Adversarially%20robust%20policy%20learning%3A%20Active%20construction%20of%20physically-plausible%20perturbations%202017"
        },
        {
            "id": "Mei_2009_a",
            "entry": "Xue Mei and Haibin Ling. Robust visual tracking using l1 minimization. In International Conference on Computer Vision, pp. 1436\u20131443, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mei%2C%20Xue%20Ling%2C%20Haibin%20Robust%20visual%20tracking%20using%20l1%20minimization%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mei%2C%20Xue%20Ling%2C%20Haibin%20Robust%20visual%20tracking%20using%20l1%20minimization%202009"
        },
        {
            "id": "Mnih_et+al_2015_a",
            "entry": "Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, et al. Human-level control through deep reinforcement learning. Nature, 518(7540):529\u2013533, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mnih%2C%20Volodymyr%20Kavukcuoglu%2C%20Koray%20Silver%2C%20David%20Rusu%2C%20Andrei%20A.%20Human-level%20control%20through%20deep%20reinforcement%20learning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mnih%2C%20Volodymyr%20Kavukcuoglu%2C%20Koray%20Silver%2C%20David%20Rusu%2C%20Andrei%20A.%20Human-level%20control%20through%20deep%20reinforcement%20learning%202015"
        },
        {
            "id": "Mnih_et+al_2016_a",
            "entry": "Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. Asynchronous methods for deep reinforcement learning. In International Conference on Machine Learning, pp. 1928\u20131937, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mnih%2C%20Volodymyr%20Badia%2C%20Adria%20Puigdomenech%20Mirza%2C%20Mehdi%20Graves%2C%20Alex%20Asynchronous%20methods%20for%20deep%20reinforcement%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mnih%2C%20Volodymyr%20Badia%2C%20Adria%20Puigdomenech%20Mirza%2C%20Mehdi%20Graves%2C%20Alex%20Asynchronous%20methods%20for%20deep%20reinforcement%20learning%202016"
        },
        {
            "id": "Pinto_et+al_2017_a",
            "entry": "Lerrel Pinto, James Davidson, Rahul Sukthankar, and Abhinav Gupta. Robust adversarial reinforcement learning. arXiv preprint arXiv:1703.02702, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.02702"
        },
        {
            "id": "Qiu_et+al_2017_a",
            "entry": "Weichao Qiu, Fangwei Zhong, Yi Zhang, Siyuan Qiao, Zihao Xiao, Tae Soo Kim, Yizhou Wang, and Alan Yuille. Unrealcv: Virtual worlds for computer vision. In Proceedings of the 2017 ACM on Multimedia Conference, pp. 1221\u20131224. ACM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Qiu%2C%20Weichao%20Zhong%2C%20Fangwei%20Zhang%2C%20Yi%20Qiao%2C%20Siyuan%20Unrealcv%3A%20Virtual%20worlds%20for%20computer%20vision%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Qiu%2C%20Weichao%20Zhong%2C%20Fangwei%20Zhang%2C%20Yi%20Qiao%2C%20Siyuan%20Unrealcv%3A%20Virtual%20worlds%20for%20computer%20vision%202017"
        },
        {
            "id": "Ross_et+al_2008_a",
            "entry": "David A Ross, Jongwoo Lim, Ruei-Sung Lin, and Ming-Hsuan Yang. Incremental learning for robust visual tracking. International Journal of Computer Vision, 77(1-3):125\u2013141, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ross%2C%20David%20A.%20Lim%2C%20Jongwoo%20Lin%2C%20Ruei-Sung%20Yang%2C%20Ming-Hsuan%20Incremental%20learning%20for%20robust%20visual%20tracking%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ross%2C%20David%20A.%20Lim%2C%20Jongwoo%20Lin%2C%20Ruei-Sung%20Yang%2C%20Ming-Hsuan%20Incremental%20learning%20for%20robust%20visual%20tracking%202008"
        },
        {
            "id": "Silver_et+al_2016_a",
            "entry": "David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van Den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, et al. Mastering the game of go with deep neural networks and tree search. Nature, 529(7587):484\u2013489, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Silver%2C%20David%20Huang%2C%20Aja%20Maddison%2C%20Chris%20J.%20Guez%2C%20Arthur%20Mastering%20the%20game%20of%20go%20with%20deep%20neural%20networks%20and%20tree%20search%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Silver%2C%20David%20Huang%2C%20Aja%20Maddison%2C%20Chris%20J.%20Guez%2C%20Arthur%20Mastering%20the%20game%20of%20go%20with%20deep%20neural%20networks%20and%20tree%20search%202016"
        },
        {
            "id": "Silver_et+al_2017_a",
            "entry": "David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, et al. Mastering the game of go without human knowledge. Nature, 550(7676):354, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Silver%2C%20David%20Schrittwieser%2C%20Julian%20Simonyan%2C%20Karen%20Antonoglou%2C%20Ioannis%20Mastering%20the%20game%20of%20go%20without%20human%20knowledge%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Silver%2C%20David%20Schrittwieser%2C%20Julian%20Simonyan%2C%20Karen%20Antonoglou%2C%20Ioannis%20Mastering%20the%20game%20of%20go%20without%20human%20knowledge%202017"
        },
        {
            "id": "Srinivasan_et+al_2018_a",
            "entry": "Sriram Srinivasan, Marc Lanctot, Vinicius Zambaldi, Julien P\u00e9rolat, Karl Tuyls, R\u00e9mi Munos, and Michael Bowling. Actor-critic policy optimization in partially observable multiagent environments. In Advances in Neural Information Processing Systems, pp. 3426\u20133439, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Srinivasan%2C%20Sriram%20Lanctot%2C%20Marc%20Zambaldi%2C%20Vinicius%20P%C3%A9rolat%2C%20Julien%20Actor-critic%20policy%20optimization%20in%20partially%20observable%20multiagent%20environments%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Srinivasan%2C%20Sriram%20Lanctot%2C%20Marc%20Zambaldi%2C%20Vinicius%20P%C3%A9rolat%2C%20Julien%20Actor-critic%20policy%20optimization%20in%20partially%20observable%20multiagent%20environments%202018"
        },
        {
            "id": "Sukhbaatar_et+al_2017_a",
            "entry": "Sainbayar Sukhbaatar, Zeming Lin, Ilya Kostrikov, Gabriel Synnaeve, Arthur Szlam, and Rob Fergus. Intrinsic motivation and automatic curricula via asymmetric self-play. arXiv preprint arXiv:1703.05407, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.05407"
        },
        {
            "id": "Routledge_2008_a",
            "entry": "Routledge, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Routledge%202008"
        },
        {
            "id": "Sutton_1998_a",
            "entry": "Published as a conference paper at ICLR 2019 Richard S. Sutton and Andrew G. Barto. Introduction to Reinforcement Learning. MIT Press, Cambridge, MA, USA, 1st edition, 1998. ISBN 0262193981. Yi Wu, Jongwoo Lim, and Ming-Hsuan Yang. Online object tracking: A benchmark. In The IEEE",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Published%20as%20a%20conference%20paper%20at%20ICLR%202019%20Richard%20S%20Sutton%20and%20Andrew%20G%20Barto%20Introduction%20to%20Reinforcement%20Learning%20MIT%20Press%20Cambridge%20MA%20USA%201st%20edition%201998%20ISBN%200262193981%20Yi%20Wu%20Jongwoo%20Lim%20and%20MingHsuan%20Yang%20Online%20object%20tracking%20A%20benchmark%20In%20The%20IEEE",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Published%20as%20a%20conference%20paper%20at%20ICLR%202019%20Richard%20S%20Sutton%20and%20Andrew%20G%20Barto%20Introduction%20to%20Reinforcement%20Learning%20MIT%20Press%20Cambridge%20MA%20USA%201st%20edition%201998%20ISBN%200262193981%20Yi%20Wu%20Jongwoo%20Lim%20and%20MingHsuan%20Yang%20Online%20object%20tracking%20A%20benchmark%20In%20The%20IEEE"
        },
        {
            "id": "Zhong_et+al_2013_a",
            "entry": "Conference on Computer Vision and Pattern Recognition, pp. 2411\u20132418, 2013. Fangwei Zhong, Weichao Qiu, Tingyun Yan, Alan Yuille, and Yizhou Wang. Gym-unrealcv: Realistic virtual worlds for visual reinforcement learning. Web Page, 2017. URL https://github.com/unrealcv/gym-unrealcv. Yuke Zhu, Roozbeh Mottaghi, Eric Kolve, Joseph J Lim, Abhinav Gupta, Li Fei-Fei, and Ali Farhadi. Target-driven visual navigation in indoor scenes using deep reinforcement learning. In International Conference on Robotics and Automation, 2017.",
            "url": "https://github.com/unrealcv/gym-unrealcv",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhong%2C%20Weichao%20Qiu%20Yan%2C%20Tingyun%20Yuille%2C%20Alan%20Wang%2C%20Yizhou%20Pattern%20Recognition%202013"
        }
    ]
}

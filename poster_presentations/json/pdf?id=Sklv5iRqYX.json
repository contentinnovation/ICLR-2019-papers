{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "Improving Phenotypic Measurements in High-Content Imaging Screens",
        "author": "D. Michael Ando, Cory McLean, Marc Berndl",
        "date": 2017,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=Sklv5iRqYX",
            "doi": "10.1101/161422"
        },
        "abstract": "Image-based screening is a powerful technique to reveal how chemical, genetic, and environmental perturbations affect cellular state. Its potential is restricted by the current analysis algorithms that target a small number of cellular phenotypes and rely on expert-engineered image features. Newer algorithms that learn how to represent an image are limited by the small amount of labeled data for ground-truth, a common problem for scientific projects. We demonstrate a sensitive and robust method for distinguishing cellular phenotypes that requires no additional ground-truth data or training. It achieves state-of-the-art performance classifying drugs by similar molecular mechanism, using a Deep Metric Network that has been pre-trained on consumer images and a transformation that improves sensitivity to biological variation. However, our method is not limited to classification into predefined categories. It provides a continuous measure of the similarity between cellular phenotypes that can also detect subtle differences such as from increasing dose. The rich, biologically-meaningful image representation that our method provides can help therapy development by supporting high-throughput investigations, even exploratory ones, with more sophisticated and disease-relevant models."
    },
    "keywords": [
        {
            "term": "XRCC5",
            "url": "https://en.wikipedia.org/wiki/XRCC5"
        },
        {
            "term": "asymmetry",
            "url": "https://en.wikipedia.org/wiki/asymmetry"
        },
        {
            "term": "domain adaptation",
            "url": "https://en.wikipedia.org/wiki/domain_adaptation"
        }
    ],
    "abbreviations": {
        "MDL": "Multi-domain learning",
        "DA": "domain adaptation",
        "MULANN": "Multi-domain Learning Adversarial Neural Network",
        "DANNs": "Domain Adversarial Neural Networks",
        "KUD": "Known Unknown Discrimination"
    },
    "highlights": [
        "Advances in technology have enabled large scale dataset generation by life sciences laboratories",
        "This section reports on the experimental validation of Multi-domain Learning Adversarial Neural Network in domain adaptation and Multi-domain learning settings on three image datasets (Sec. 4.2), prior to analyzing Multi-domain Learning Adversarial Neural Network and investigating the impact of class asymmetry on model performances (Sec. 4.3).\n4.1",
        "The impact of the class asymmetry is displayed on Fig. 3, reporting the average classification accuracy of \u03b1, \u03b2 classes on domain 1 on the x-axis, and classification accuracy of unlabeled \u03b2 classes on domain 2 on the y-axis, for Multi-domain Learning Adversarial Neural Network, Domain Adversarial Neural Networks and MADA on OFFICE",
        "This paper extends the use of domain adversarial learning to multi-domain learning, establishing how the H-divergence can be used to bound both the risk across all domains and the worst-domain risk",
        "Showing the significant impact of class asymmetry on the state of the art, this paper introduces Multi-domain Learning Adversarial Neural Network, where a new loss is meant to resist the contractive effects of the adversarial domain discriminator and to repulse unlabeled examples from labeled ones in each domain",
        "The merits of the approach are satisfactorily demonstrated by comparison to Domain Adversarial Neural Networks and MADA on DIGITS, RoadSigns and OFFICE, and results obtained on the real-world CELL problem establish a new baseline for the microscopy image community"
    ],
    "key_statements": [
        "Advances in technology have enabled large scale dataset generation by life sciences laboratories",
        "There is no standardized set of labeled perturbations, and datasets often contain labeled examples for a subset of possible classes only. This has limited microscopy image classification to single datasets and does not leverage the growing number of datasets collected by the life sciences community",
        "We extend the domain adaptation guarantees to Multi-domain learning (Sec. 3.1), showing that the risk of the learned model over all considered domains is upper bounded by the oracle risk and the sum of the H-divergences between any two domains",
        "This section reports on the experimental validation of Multi-domain Learning Adversarial Neural Network in domain adaptation and Multi-domain learning settings on three image datasets (Sec. 4.2), prior to analyzing Multi-domain Learning Adversarial Neural Network and investigating the impact of class asymmetry on model performances (Sec. 4.3).\n4.1",
        "Other baselines include: Learning from source and target examples with no transfer loss; Published results from (<a class=\"ref-link\" id=\"cMotiian_et+al_2017_a\" href=\"#rMotiian_et+al_2017_a\">Motiian et al, 2017</a>), that uses a contrastive loss to penalizes large distances between same classes and different domains in the feature space; Published results from (<a class=\"ref-link\" id=\"cTzeng_et+al_2015_a\" href=\"#rTzeng_et+al_2015_a\">Tzeng et al, 2015</a>), an extension of Domain Adversarial Neural Networks that adds a loss on target softmax values (\"soft label loss\"; legend Tseng15)",
        "The impact of the class asymmetry is displayed on Fig. 3, reporting the average classification accuracy of \u03b1, \u03b2 classes on domain 1 on the x-axis, and classification accuracy of unlabeled \u03b2 classes on domain 2 on the y-axis, for Multi-domain Learning Adversarial Neural Network, Domain Adversarial Neural Networks and MADA on OFFICE",
        "This paper extends the use of domain adversarial learning to multi-domain learning, establishing how the H-divergence can be used to bound both the risk across all domains and the worst-domain risk",
        "The stress is put on the notion of class asymmetry, that is, when some domains contain labeled or unlabeled examples of classes not present in other domains",
        "Showing the significant impact of class asymmetry on the state of the art, this paper introduces Multi-domain Learning Adversarial Neural Network, where a new loss is meant to resist the contractive effects of the adversarial domain discriminator and to repulse unlabeled examples from labeled ones in each domain",
        "The merits of the approach are satisfactorily demonstrated by comparison to Domain Adversarial Neural Networks and MADA on DIGITS, RoadSigns and OFFICE, and results obtained on the real-world CELL problem establish a new baseline for the microscopy image community"
    ],
    "summary": [
        "Advances in technology have enabled large scale dataset generation by life sciences laboratories.",
        "Restricting ourselves to addressing a single task on a common input space, we distinguish two objectives: minimizing the learning risk over all considered distributions (MDL), or over a single target distribution while exploiting samples from richer source(s) (DA).",
        "In the case of class asymmetry, domain alignment will tend to shuffle unlabeled samples more than labeled ones.",
        "KUD aims at discriminating, within each domain, labeled samples from unlabeled ones that most likely belong to such extra classes.",
        "This section reports on the experimental validation of MULANN in DA and MDL settings on three image datasets (Sec. 4.2), prior to analyzing MULANN and investigating the impact of class asymmetry on model performances (Sec. 4.3).",
        "Other baselines include: Learning from source and target examples with no transfer loss; Published results from (<a class=\"ref-link\" id=\"cMotiian_et+al_2017_a\" href=\"#rMotiian_et+al_2017_a\">Motiian et al, 2017</a>), that uses a contrastive loss to penalizes large distances between same classes and different domains in the feature space; Published results from (<a class=\"ref-link\" id=\"cTzeng_et+al_2015_a\" href=\"#rTzeng_et+al_2015_a\">Tzeng et al, 2015</a>), an extension of DANN that adds a loss on target softmax values (\"soft label loss\"; legend Tseng15).",
        "Table 2 compares DANN, MADA and MULANN to the baselines, where columns 4-7 consider raw images.4 The fact that a profile-based baseline generally outperforms an image-based baseline was expected, as profiles are designed to reduce the impact of experimental settings.",
        "In the general case the classes represented by the unlabeled examples are unknown, there might exist \"orphan\" classes, with labeled or unlabeled samples, unique to a single domain.",
        "The impact of the class asymmetry is displayed on Fig. 3, reporting the average classification accuracy of \u03b1, \u03b2 classes on domain 1 on the x-axis, and classification accuracy of unlabeled \u03b2 classes on domain 2 on the y-axis, for MULANN, DANN and MADA on OFFICE.",
        "The results in case \"3\" are consistent with the above explanation: since the unlabeled \u03b4 samples are only seen by the discriminator(s), their addition has little impact on either the labeled or unlabeled data classification accuracy (Figs.",
        "Showing the significant impact of class asymmetry on the state of the art, this paper introduces MULANN, where a new loss is meant to resist the contractive effects of the adversarial domain discriminator and to repulse unlabeled examples from labeled ones in each domain.",
        "The merits of the approach are satisfactorily demonstrated by comparison to DANN and MADA on DIGITS, RoadSigns and OFFICE, and results obtained on the real-world CELL problem establish a new baseline for the microscopy image community."
    ],
    "headline": "We demonstrate a sensitive and robust method for distinguishing cellular phenotypes that requires no additional ground-truth data or training",
    "reference_links": [
        {
            "id": "Ando_et+al_2017_a",
            "entry": "D. Michael Ando, Cory McLean, and Marc Berndl. Improving phenotypic measurements in high-content imaging screens. bioRxiv, 2017. doi: 10.1101/161422. URL https://www.biorxiv.org/content/early/2017/07/10/161422.",
            "crossref": "https://dx.doi.org/10.1101/161422"
        },
        {
            "id": "Anoosheh_et+al_2017_a",
            "entry": "Asha Anoosheh, Eirikur Agustsson, Radu Timofte, and Luc Van Gool. Combogan: Unrestrained scalability for image domain translation. CoRR, abs/1712.06909, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.06909"
        },
        {
            "id": "Batu_et+al_2000_a",
            "entry": "Tugkan Batu, Lance Fortnow, Ronitt Rubinfeld, Warren D. Smith, and Patrick White. Testing that distributions are close. In 41st Annual Symposium on Foundations of Computer Science, FOCS 2000, 12-14 November 2000, Redondo Beach, California, USA, pp. 259\u2013269, 2000. doi: 10.1109/SFCS.2000.892113. URL https://doi.org/10.1109/SFCS.2000.892113.",
            "crossref": "https://dx.doi.org/10.1109/SFCS.2000.892113",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/SFCS.2000.892113"
        },
        {
            "id": "Becker_et+al_2015_a",
            "entry": "C. Becker, C. M. Christoudias, and P. Fua. Domain adaptation for microscopy imaging. IEEE Trans Med Imaging, 34(5):1125\u20131139, May 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Becker%2C%20C.%20Christoudias%2C%20C.M.%20Fua%2C%20P.%20Domain%20adaptation%20for%20microscopy%20imaging%202015-05",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Becker%2C%20C.%20Christoudias%2C%20C.M.%20Fua%2C%20P.%20Domain%20adaptation%20for%20microscopy%20imaging%202015-05"
        },
        {
            "id": "Ben-David_et+al_2006_a",
            "entry": "Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira. Analysis of representations for domain adaptation. In Proceedings of the 19th International Conference on Neural Information Processing Systems, NIPS\u201906, pp. 137\u2013144, Cambridge, MA, USA, 2006. MIT Press. URL http://dl.acm.org/citation.cfm?id=2976456.2976474.",
            "url": "http://dl.acm.org/citation.cfm?id=2976456.2976474",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ben-David%2C%20Shai%20Blitzer%2C%20John%20Crammer%2C%20Koby%20Pereira%2C%20Fernando%20Analysis%20of%20representations%20for%20domain%20adaptation%202006"
        },
        {
            "id": "Ben-David_et+al_2010_a",
            "entry": "Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan. A theory of learning from different domains. Machine Learning, 79(1):151\u2013175, May 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ben-David%2C%20Shai%20Blitzer%2C%20John%20Crammer%2C%20Koby%20Kulesza%2C%20Alex%20A%20theory%20of%20learning%20from%20different%20domains%202010-05",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ben-David%2C%20Shai%20Blitzer%2C%20John%20Crammer%2C%20Koby%20Kulesza%2C%20Alex%20A%20theory%20of%20learning%20from%20different%20domains%202010-05"
        },
        {
            "id": "Berm_et+al_2016_a",
            "entry": "R\u00f3ger Berm\u00fadez-Chac\u00f3n, Carlos Becker, Mathieu Salzmann, and Pascal Fua. Scalable unsupervised domain adaptation for electron microscopy. In Sebastien Ourselin, Leo Joskowicz, Mert R. Sabuncu, Gozde Unal, and William Wells (eds.), Medical Image Computing and Computer-Assisted Intervention \u2013 MICCAI 2016, pp. 326\u2013334, Cham, 2016. Springer International Publishing. ISBN 978-3-319-46723-8.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Berm%C3%BAdez-Chac%C3%B3n%2C%20R%C3%B3ger%20Becker%2C%20Carlos%20Salzmann%2C%20Mathieu%20Fua%2C%20Pascal%20Scalable%20unsupervised%20domain%20adaptation%20for%20electron%20microscopy%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Berm%C3%BAdez-Chac%C3%B3n%2C%20R%C3%B3ger%20Becker%2C%20Carlos%20Salzmann%2C%20Mathieu%20Fua%2C%20Pascal%20Scalable%20unsupervised%20domain%20adaptation%20for%20electron%20microscopy%202016"
        },
        {
            "id": "Bickel_et+al_2007_a",
            "entry": "Steffen Bickel, Michael Br\u00fcckner, and Tobias Scheffer. Discriminative learning for differing training and test distributions. In Proceedings of the 24th International Conference on Machine Learning, ICML \u201907, pp. 81\u201388, New York, NY, USA, 2007. ACM. ISBN 978-1-59593-793-3. doi: 10.1145/1273496.1273507. URL http://doi.acm.org/10.1145/1273496.1273507.",
            "crossref": "https://dx.doi.org/10.1145/1273496.1273507",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/1273496.1273507"
        },
        {
            "id": "Birmingham_et+al_2009_a",
            "entry": "A. Birmingham, L. M. Selfors, T. Forster, D. Wrobel, C. J. Kennedy, E. Shanks, J. Santoyo-Lopez, D. J. Dunican, A. Long, D. Kelleher, Q. Smith, R. L. Beijersbergen, P. Ghazal, and C. E. Shamu. Statistical methods for analysis of high-throughput RNA interference screens. Nat. Methods, 6(8):569\u2013575, Aug 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Birmingham%2C%20A.%20Selfors%2C%20L.M.%20Forster%2C%20T.%20Wrobel%2C%20D.%20Statistical%20methods%20for%20analysis%20of%20high-throughput%20RNA%20interference%20screens%202009-08",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Birmingham%2C%20A.%20Selfors%2C%20L.M.%20Forster%2C%20T.%20Wrobel%2C%20D.%20Statistical%20methods%20for%20analysis%20of%20high-throughput%20RNA%20interference%20screens%202009-08"
        },
        {
            "id": "Borgwardt_et+al_2006_a",
            "entry": "K. M. Borgwardt, A. Gretton, M. J. Rasch, H. P. Kriegel, B. Scholkopf, and A. J. Smola. Integrating structured biological data by Kernel Maximum Mean Discrepancy. Bioinformatics, 22(14):49\u201357, Jul 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Borgwardt%2C%20K.M.%20Gretton%2C%20A.%20Rasch%2C%20M.J.%20Kriegel%2C%20H.P.%20Integrating%20structured%20biological%20data%20by%20Kernel%20Maximum%20Mean%20Discrepancy%202006-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Borgwardt%2C%20K.M.%20Gretton%2C%20A.%20Rasch%2C%20M.J.%20Kriegel%2C%20H.P.%20Integrating%20structured%20biological%20data%20by%20Kernel%20Maximum%20Mean%20Discrepancy%202006-07"
        },
        {
            "id": "Bousmalis_et+al_2016_a",
            "entry": "Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman, Dilip Krishnan, and Dumitru Erhan. Domain separation networks. CoRR, abs/1608.06019, 2016. URL http://arxiv.org/abs/1608.06019.",
            "url": "http://arxiv.org/abs/1608.06019",
            "arxiv_url": "https://arxiv.org/pdf/1608.06019"
        },
        {
            "id": "Bousquet_2002_a",
            "entry": "Olivier Bousquet and Andr\u00e9 Elisseeff. Stability and generalization. Journal of Machine Learning Research, 2: 499\u2013526, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bousquet%2C%20Olivier%20Elisseeff%2C%20Andr%C3%A9%20Stability%20and%20generalization%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bousquet%2C%20Olivier%20Elisseeff%2C%20Andr%C3%A9%20Stability%20and%20generalization%202002"
        },
        {
            "id": "Caie_et+al_2010_a",
            "entry": "P. D. Caie, R. E. Walls, A. Ingleston-Orme, S. Daya, T. Houslay, R. Eagle, M. E. Roberts, and N. O. Carragher. High-content phenotypic profiling of drug response signatures across distinct cancer cells. Mol. Cancer Ther., 9(6):1913\u20131926, Jun 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Caie%2C%20P.D.%20Walls%2C%20R.E.%20Ingleston-Orme%2C%20A.%20Daya%2C%20S.%20High-content%20phenotypic%20profiling%20of%20drug%20response%20signatures%20across%20distinct%20cancer%20cells%202010-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Caie%2C%20P.D.%20Walls%2C%20R.E.%20Ingleston-Orme%2C%20A.%20Daya%2C%20S.%20High-content%20phenotypic%20profiling%20of%20drug%20response%20signatures%20across%20distinct%20cancer%20cells%202010-06"
        },
        {
            "id": "Cao_et+al_2018_a",
            "entry": "Zhangjie Cao, Mingsheng Long, Jianmin Wang, and Michael I. Jordan. Partial transfer learning with selective adversarial networks. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cao%2C%20Zhangjie%20Long%2C%20Mingsheng%20Wang%2C%20Jianmin%20Jordan%2C%20Michael%20I.%20Partial%20transfer%20learning%20with%20selective%20adversarial%20networks%202018-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cao%2C%20Zhangjie%20Long%2C%20Mingsheng%20Wang%2C%20Jianmin%20Jordan%2C%20Michael%20I.%20Partial%20transfer%20learning%20with%20selective%20adversarial%20networks%202018-06"
        },
        {
            "id": "Chigorin_et+al_2012_a",
            "entry": "Alexander Chigorin, Gleb Krivovyaz, Alexander Velizhev, and Anton Konushin. A method for traffic sign detection in an image with learning from synthetic data. In 14th International Conference Digital Signal Processing and its Applications, volume 2, pp. 316\u2013319, 2012. URL http://graphics.cs.msu.ru/files/papers/dspa2012_chigorin_ts_recognition.pdf.",
            "url": "http://graphics.cs.msu.ru/files/papers/dspa2012_chigorin_ts_recognition.pdf",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chigorin%2C%20Alexander%20Krivovyaz%2C%20Gleb%20Velizhev%2C%20Alexander%20Konushin%2C%20Anton%20A%20method%20for%20traffic%20sign%20detection%20in%20an%20image%20with%20learning%20from%20synthetic%20data%202012"
        },
        {
            "id": "Choi_et+al_2018_a",
            "entry": "Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, and Jaegul Choo. Stargan: Unified generative adversarial networks for multi-domain image-to-image translation. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Choi%2C%20Yunjey%20Choi%2C%20Minje%20Kim%2C%20Munyoung%20Ha%2C%20Jung-Woo%20Stargan%3A%20Unified%20generative%20adversarial%20networks%20for%20multi-domain%20image-to-image%20translation%202018-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Choi%2C%20Yunjey%20Choi%2C%20Minje%20Kim%2C%20Munyoung%20Ha%2C%20Jung-Woo%20Stargan%3A%20Unified%20generative%20adversarial%20networks%20for%20multi-domain%20image-to-image%20translation%202018-06"
        },
        {
            "id": "Collobert_et+al_2011_a",
            "entry": "R. Collobert, K. Kavukcuoglu, and C. Farabet. Torch7: A matlab-like environment for machine learning. In BigLearn, NIPS Workshop, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Collobert%2C%20R.%20Kavukcuoglu%2C%20K.%20Farabet%2C%20C.%20Torch7%3A%20A%20matlab-like%20environment%20for%20machine%20learning%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Collobert%2C%20R.%20Kavukcuoglu%2C%20K.%20Farabet%2C%20C.%20Torch7%3A%20A%20matlab-like%20environment%20for%20machine%20learning%202011"
        },
        {
            "id": "Courty_et+al_2017_a",
            "entry": "N. Courty, R. Flamary, D. Tuia, and A. Rakotomamonjy. Optimal transport for domain adaptation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 39(9):1853\u20131865, Sept 2017. ISSN 0162-8828. doi: 10.1109/TPAMI.2016.2615921.",
            "crossref": "https://dx.doi.org/10.1109/TPAMI.2016.2615921",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/TPAMI.2016.2615921"
        },
        {
            "id": "Damodaran_et+al_2018_a",
            "entry": "Bharath Bhushan Damodaran, Benjamin Kellenberger, R\u00e9mi Flamary, Devis Tuia, and Nicolas Courty. Deepjdot: Deep joint distribution optimal transport for unsupervised domain adaptation. CoRR, abs/1803.10081, 2018. URL http://arxiv.org/abs/1803.10081.",
            "url": "http://arxiv.org/abs/1803.10081",
            "arxiv_url": "https://arxiv.org/pdf/1803.10081"
        },
        {
            "id": "Daum_2006_a",
            "entry": "Hal Daum\u00e9 III and Daniel Marcu. Domain adaptation for statistical classifiers. J. Artif. Intell. Res., 26:101\u2013126, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Daum%C3%A9%2C%20III%2C%20Hal%20Marcu%2C%20Daniel%20Domain%20adaptation%20for%20statistical%20classifiers%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Daum%C3%A9%2C%20III%2C%20Hal%20Marcu%2C%20Daniel%20Domain%20adaptation%20for%20statistical%20classifiers%202006"
        },
        {
            "id": "Dredze_et+al_2010_a",
            "entry": "Mark Dredze, Alex Kulesza, and Koby Crammer. Multi-domain learning by confidence-weighted parameter combination. Machine Learning, 79(1):123\u2013149, May 2010. ISSN 1573-0565. doi: 10.1007/s10994-009-5148-0. URL https://doi.org/10.1007/s10994-009-5148-0.",
            "crossref": "https://dx.doi.org/10.1007/s10994-009-5148-0",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1007/s10994-009-5148-0"
        },
        {
            "id": "Fernando_et+al_2015_a",
            "entry": "Basura Fernando, Tatiana Tommasi, and Tinne Tuytelaars. Joint cross-domain classification and subspace learning for unsupervised adaptation. Pattern Recognition Letters, 65:60\u201366, 2015. doi: 10.1016/j.patrec. 2015.07.009. URL https://doi.org/10.1016/j.patrec.2015.07.009.",
            "crossref": "https://dx.doi.org/10.1016/j.patrec.2015.07.009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1016/j.patrec.2015.07.009"
        },
        {
            "id": "Ganin_et+al_2016_a",
            "entry": "Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Fran\u00e7ois Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks. Journal of Machine Learning Research, 17(59):1\u201335, 2016. URL http://jmlr.org/papers/v17/15-239.html.",
            "url": "http://jmlr.org/papers/v17/15-239.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ganin%2C%20Yaroslav%20Ustinova%2C%20Evgeniya%20Ajakan%2C%20Hana%20Germain%2C%20Pascal%20Domain-adversarial%20training%20of%20neural%20networks%202016"
        },
        {
            "id": "Muhammad_et+al_2016_a",
            "entry": "Muhammad Ghifary, W. Bastiaan Kleijn, Mengjie Zhang, David Balduzzi, and Wen Li. Deep reconstructionclassification networks for unsupervised domain adaptation. In Computer Vision - ECCV, pp. 597\u2013613, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Muhammad%20Ghifary%2C%20W.Bastiaan%20Kleijn%20Zhang%2C%20Mengjie%20Balduzzi%2C%20David%20Li%2C%20Wen%20Deep%20reconstructionclassification%20networks%20for%20unsupervised%20domain%20adaptation%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Muhammad%20Ghifary%2C%20W.Bastiaan%20Kleijn%20Zhang%2C%20Mengjie%20Balduzzi%2C%20David%20Li%2C%20Wen%20Deep%20reconstructionclassification%20networks%20for%20unsupervised%20domain%20adaptation%202016"
        },
        {
            "id": "Gong_et+al_2013_a",
            "entry": "Boqing Gong, Kristen Grauman, and Fei Sha. Connecting the dots with landmarks: Discriminatively learning domain-invariant features for unsupervised domain adaptation. In Proceedings of the 30th International Conference on International Conference on Machine Learning - Volume 28, ICML\u201913, pp. I\u2013222\u2013I\u2013230. JMLR.org, 2013. URL http://dl.acm.org/citation.cfm?id=3042817.3042844.",
            "url": "http://dl.acm.org/citation.cfm?id=3042817.3042844",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gong%2C%20Boqing%20Grauman%2C%20Kristen%20Sha%2C%20Fei%20Connecting%20the%20dots%20with%20landmarks%3A%20Discriminatively%20learning%20domain-invariant%20features%20for%20unsupervised%20domain%20adaptation%202013"
        },
        {
            "id": "Gretton_et+al_2007_a",
            "entry": "Arthur Gretton, Karsten M. Borgwardt, Malte J. Rasch, Bernhard Sch\u00f6lkopf, and Alexander J. Smola. A kernel method for the two-sample-problem. In NIPS, pp. 513\u2013520. MIT Press, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gretton%2C%20Arthur%20Borgwardt%2C%20Karsten%20M.%20Rasch%2C%20Malte%20J.%20Sch%C3%B6lkopf%2C%20Bernhard%20A%20kernel%20method%20for%20the%20two-sample-problem%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gretton%2C%20Arthur%20Borgwardt%2C%20Karsten%20M.%20Rasch%2C%20Malte%20J.%20Sch%C3%B6lkopf%2C%20Bernhard%20A%20kernel%20method%20for%20the%20two-sample-problem%202007"
        },
        {
            "id": "Huang_et+al_2006_a",
            "entry": "Jiayuan Huang, Alexander J. Smola, Arthur Gretton, Karsten M. Borgwardt, and Bernhard Scholkopf. Correcting sample selection bias by unlabeled data. In Proceedings of the 19th International Conference on Neural Information Processing Systems, NIPS\u201906, pp. 601\u2013608, Cambridge, MA, USA, 2006. MIT Press. URL http://dl.acm.org/citation.cfm?id=2976456.2976532.",
            "url": "http://dl.acm.org/citation.cfm?id=2976456.2976532",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20Jiayuan%20Smola%2C%20Alexander%20J.%20Gretton%2C%20Arthur%20Borgwardt%2C%20Karsten%20M.%20Correcting%20sample%20selection%20bias%20by%20unlabeled%20data%202006"
        },
        {
            "id": "Isola_et+al_2017_a",
            "entry": "Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A. Efros. Image-to-image translation with conditional adversarial networks. In CVPR, pp. 5967\u20135976. IEEE Computer Society, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Isola%2C%20Phillip%20Zhu%2C%20Jun-Yan%20Zhou%2C%20Tinghui%20Efros%2C%20Alexei%20A.%20Image-to-image%20translation%20with%20conditional%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Isola%2C%20Phillip%20Zhu%2C%20Jun-Yan%20Zhou%2C%20Tinghui%20Efros%2C%20Alexei%20A.%20Image-to-image%20translation%20with%20conditional%20adversarial%20networks%202017"
        },
        {
            "id": "Jia_et+al_2014_a",
            "entry": "Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross Girshick, Sergio Guadarrama, and Trevor Darrell. Caffe: Convolutional architecture for fast feature embedding. arXiv preprint arXiv:1408.5093, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1408.5093"
        },
        {
            "id": "Jones_et+al_2001_a",
            "entry": "Eric Jones, Travis Oliphant, Pearu Peterson, et al. SciPy: Open source scientific tools for Python, 2001\u2013. URL http://www.scipy.org/.[Online; accessed <today>].",
            "url": "http://www.scipy.org/.[Online",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Eric%20Jones%20Travis%20Oliphant%20Pearu%20Peterson%20et%20al%20SciPy%20Open%20source%20scientific%20tools%20for%20Python%202001%20URL%20httpwwwscipyorgOnline%20accessed%20today"
        },
        {
            "id": "Kamnitsas_et+al_2017_a",
            "entry": "Konstantinos Kamnitsas, Christian Baumgartner, Christian Ledig, Virginia Newcombe, Joanna Simpson, Andrew Kane, David Menon, Aditya Nori, Antonio Criminisi, Daniel Rueckert, and Ben Glocker. Unsupervised domain adaptation in brain lesion segmentation with adversarial networks. In Marc Niethammer, Martin Styner, Stephen Aylward, Hongtu Zhu, Ipek Oguz, Pew-Thian Yap, and Dinggang Shen (eds.), Information Processing in Medical Imaging, pp. 597\u2013609, Cham, 2017. Springer International Publishing. ISBN 978-3319-59050-9.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kamnitsas%2C%20Konstantinos%20Baumgartner%2C%20Christian%20Ledig%2C%20Christian%20Newcombe%2C%20Virginia%20Unsupervised%20domain%20adaptation%20in%20brain%20lesion%20segmentation%20with%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kamnitsas%2C%20Konstantinos%20Baumgartner%2C%20Christian%20Ledig%2C%20Christian%20Newcombe%2C%20Virginia%20Unsupervised%20domain%20adaptation%20in%20brain%20lesion%20segmentation%20with%20adversarial%20networks%202017"
        },
        {
            "id": "Kang_et+al_2016_a",
            "entry": "J. Kang, C. H. Hsu, Q. Wu, S. Liu, A. D. Coster, B. A. Posner, S. J. Altschuler, and L. F. Wu. Improving drug discovery with high-content phenotypic screens by systematic selection of reporter cell lines. Nat. Biotechnol., 34(1):70\u201377, Jan 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kang%2C%20J.%20Hsu%2C%20C.H.%20Wu%2C%20Q.%20Liu%2C%20S.%20Improving%20drug%20discovery%20with%20high-content%20phenotypic%20screens%20by%20systematic%20selection%20of%20reporter%20cell%20lines%202016-01",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kang%2C%20J.%20Hsu%2C%20C.H.%20Wu%2C%20Q.%20Liu%2C%20S.%20Improving%20drug%20discovery%20with%20high-content%20phenotypic%20screens%20by%20systematic%20selection%20of%20reporter%20cell%20lines%202016-01"
        },
        {
            "id": "Kifer_et+al_2004_a",
            "entry": "Daniel Kifer, Shai Ben-David, and Johannes Gehrke. Detecting change in data streams. In Proceedings of the Thirtieth International Conference on Very Large Data Bases - Volume 30, VLDB \u201904, pp. 180\u2013191. VLDB Endowment, 2004. ISBN 0-12-088469-0. URL http://dl.acm.org/citation.cfm?id=1316689.1316707.",
            "url": "http://dl.acm.org/citation.cfm?id=1316689.1316707",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kifer%2C%20Daniel%20Ben-David%2C%20Shai%20Gehrke%2C%20Johannes%20Detecting%20change%20in%20data%20streams%202004"
        },
        {
            "id": "Koniusz_et+al_2016_a",
            "entry": "Piotr Koniusz, Yusuf Tas, and Fatih Porikli. Domain adaptation by mixture of alignments of second- or higherorder scatter tensors. CoRR, abs/1611.08195, 2016. URL http://arxiv.org/abs/1611.08195.",
            "url": "http://arxiv.org/abs/1611.08195",
            "arxiv_url": "https://arxiv.org/pdf/1611.08195"
        },
        {
            "id": "K_0000_a",
            "entry": "K. Q. Weinberger (eds.), Advances in Neural Information Processing Systems 25, pp.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=K%20Q%20Weinberger%20eds%20Advances%20in%20Neural%20Information%20Processing%20Systems%2025%20pp",
            "oa_query": "https://api.scholarcy.com/oa_version?query=K%20Q%20Weinberger%20eds%20Advances%20in%20Neural%20Information%20Processing%20Systems%2025%20pp"
        },
        {
            "id": "1097\u20131105._2012_a",
            "entry": "1097\u20131105. Curran Associates, Inc., 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Curran%20Associates%20Inc%202012"
        },
        {
            "id": "URL_0000_a",
            "entry": "URL http://papers.nips.cc/paper/",
            "url": "http://papers.nips.cc/paper/"
        },
        {
            "id": "Cun_et+al_1998_a",
            "entry": "Y. Le Cun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278\u20132324, Nov 1998. ISSN 0018-9219. doi: 10.1109/5.726791.",
            "crossref": "https://dx.doi.org/10.1109/5.726791",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/5.726791"
        },
        {
            "id": "Liu_et+al_2017_a",
            "entry": "Ming-Yu Liu, Thomas Breuel, and Jan Kautz. Unsupervised image-to-image translation networks. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems 30, pp. 700\u2013708. Curran Associates, Inc., 2017. URL http://papers.nips.cc/paper/6672-unsupervised-image-to-image-translation-networks.pdf.",
            "url": "http://papers.nips.cc/paper/6672-unsupervised-image-to-image-translation-networks.pdf",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Ming-Yu%20Breuel%2C%20Thomas%20Kautz%2C%20Jan%20Unsupervised%20image-to-image%20translation%20networks%202017"
        },
        {
            "id": "Ljosa_et+al_2012_a",
            "entry": "V. Ljosa, K. L. Sokolnicki, and A. E. Carpenter. Annotated high-throughput microscopy image sets for validation. Nat. Methods, 9(7):637, Jun 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ljosa%2C%20V.%20Sokolnicki%2C%20K.L.%20Carpenter%2C%20A.E.%20Annotated%20high-throughput%20microscopy%20image%20sets%20for%20validation%202012-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ljosa%2C%20V.%20Sokolnicki%2C%20K.L.%20Carpenter%2C%20A.E.%20Annotated%20high-throughput%20microscopy%20image%20sets%20for%20validation%202012-06"
        },
        {
            "id": "Long_et+al_2015_a",
            "entry": "Mingsheng Long, Yue Cao, Jianmin Wang, and Michael I. Jordan. Learning transferable features with deep adaptation networks. In Proceedings of the 32Nd International Conference on International Conference on Machine Learning - Volume 37, ICML\u201915, pp. 97\u2013105. JMLR.org, 2015. URL http://dl.acm.org/citation.cfm?id=3045118.3045130.",
            "url": "http://dl.acm.org/citation.cfm?id=3045118.3045130",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Long%2C%20Mingsheng%20Cao%2C%20Yue%20Wang%2C%20Jianmin%20Jordan%2C%20Michael%20I.%20Learning%20transferable%20features%20with%20deep%20adaptation%20networks%202015"
        },
        {
            "id": "Long_et+al_2016_a",
            "entry": "Mingsheng Long, Jianmin Wang, and Michael I. Jordan. Deep transfer learning with joint adaptation networks. CoRR, abs/1605.06636, 2016. URL http://arxiv.org/abs/1605.06636.",
            "url": "http://arxiv.org/abs/1605.06636",
            "arxiv_url": "https://arxiv.org/pdf/1605.06636"
        },
        {
            "id": "Long_et+al_2017_a",
            "entry": "Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael I. Jordan. Domain adaptation with randomized multilinear adversarial networks. CoRR, abs/1705.10667, 2017. URL http://arxiv.org/abs/1705.10667.",
            "url": "http://arxiv.org/abs/1705.10667",
            "arxiv_url": "https://arxiv.org/pdf/1705.10667"
        },
        {
            "id": "Mansour_2009_a",
            "entry": "Yishay Mansour. Learning and domain adaptation. In Algorithmic Learning Theory, 20th International Conference, ALT, pp. 4\u20136, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mansour%2C%20Yishay%20Learning%20and%20domain%20adaptation%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mansour%2C%20Yishay%20Learning%20and%20domain%20adaptation%202009"
        },
        {
            "id": "Mansour_et+al_2008_a",
            "entry": "Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Domain adaptation with multiple sources. In Proceedings of the 21st International Conference on Neural Information Processing Systems, NIPS\u201908, pp. 1041\u20131048, USA, 2008. Curran Associates Inc. ISBN 978-1-6056-0-949-2. URL http://dl.acm.org/citation.cfm?id=2981780.2981910.",
            "url": "http://dl.acm.org/citation.cfm?id=2981780.2981910",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mansour%2C%20Yishay%20Mohri%2C%20Mehryar%20Rostamizadeh%2C%20Afshin%20Domain%20adaptation%20with%20multiple%20sources%202008"
        },
        {
            "id": "Motiian_et+al_2017_a",
            "entry": "Saeid Motiian, Marco Piccirilli, Donald A. Adjeroh, and Gianfranco Doretto. Unified deep supervised domain adaptation and generalization. In The IEEE International Conference on Computer Vision (ICCV), Oct 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Motiian%2C%20Saeid%20Piccirilli%2C%20Marco%20Adjeroh%2C%20Donald%20A.%20Doretto%2C%20Gianfranco%20Unified%20deep%20supervised%20domain%20adaptation%20and%20generalization%202017-10",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Motiian%2C%20Saeid%20Piccirilli%2C%20Marco%20Adjeroh%2C%20Donald%20A.%20Doretto%2C%20Gianfranco%20Unified%20deep%20supervised%20domain%20adaptation%20and%20generalization%202017-10"
        },
        {
            "id": "Muandet_et+al_2013_a",
            "entry": "Krikamol Muandet, David Balduzzi, and Bernhard Sch\u00f6lkopf. Domain generalization via invariant feature representation. In Proceedings of the 30th International Conference on International Conference on Machine Learning - Volume 28, ICML\u201913, pp. I\u201310\u2013I\u201318. JMLR.org, 2013. URL http://dl.acm.org/citation.cfm?id=3042817.3042820.",
            "url": "http://dl.acm.org/citation.cfm?id=3042817.3042820",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Muandet%2C%20Krikamol%20Balduzzi%2C%20David%20Sch%C3%B6lkopf%2C%20Bernhard%20Domain%20generalization%20via%20invariant%20feature%20representation%202013"
        },
        {
            "id": "Otsu_1979_a",
            "entry": "Nobuyuki Otsu. A Threshold Selection Method from Gray-level Histograms. IEEE Transactions on Systems, Man and Cybernetics, 9(1):62\u201366, 1979. doi: 10.1109/TSMC.1979.4310076. URL http://dx.doi.org/10.1109/TSMC.1979.4310076.",
            "crossref": "https://dx.doi.org/10.1109/TSMC.1979.4310076",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/TSMC.1979.4310076"
        },
        {
            "id": "Pan_2010_a",
            "entry": "S. J. Pan and Q. Yang. A survey on transfer learning. IEEE Transactions on Knowledge and Data Engineering, 22(10):1345\u20131359, Oct 2010. ISSN 1041-4347.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pan%2C%20S.J.%20Yang%2C%20Q.%20A%20survey%20on%20transfer%20learning%202010-10",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pan%2C%20S.J.%20Yang%2C%20Q.%20A%20survey%20on%20transfer%20learning%202010-10"
        },
        {
            "id": "Pei_et+al_2018_a",
            "entry": "Zhongyi Pei, Zhangjie Cao, Mingsheng Long, and Jianmin Wang. Multi-adversarial domain adaptation. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence, 2018. URL https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17067.",
            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17067",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pei%2C%20Zhongyi%20Cao%2C%20Zhangjie%20Long%2C%20Mingsheng%20Wang%2C%20Jianmin%20Multi-adversarial%20domain%20adaptation%202018"
        },
        {
            "id": "Pratt_et+al_0000_a",
            "entry": "L. Y. Pratt, J. Mostow, and C. A. Kamm. Direct transfer of learned information among neural networks. In Proceedings of the Ninth National Conference on Artificial Intelligence (AAAI-91), AAAI\u201991, pp. 584\u2013589.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pratt%2C%20L.Y.%20Mostow%2C%20J.%20Kamm%2C%20C.A.%20Direct%20transfer%20of%20learned%20information%20among%20neural%20networks",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pratt%2C%20L.Y.%20Mostow%2C%20J.%20Kamm%2C%20C.A.%20Direct%20transfer%20of%20learned%20information%20among%20neural%20networks"
        },
        {
            "id": "Anaheim_1991_a",
            "entry": "Anaheim, CA, 1991. URL https://www.aaai.org/Papers/AAAI/1991/AAAI91-091.pdf.",
            "url": "https://www.aaai.org/Papers/AAAI/1991/AAAI91-091.pdf"
        },
        {
            "id": "Preibisch_et+al_2009_a",
            "entry": "S. Preibisch, S. Saalfeld, and P. Tomancak. Globally optimal stitching of tiled 3D microscopic image acquisitions. Bioinformatics, 25(11):1463\u20131465, Jun 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Preibisch%2C%20S.%20Saalfeld%2C%20S.%20Tomancak%2C%20P.%20Globally%20optimal%20stitching%20of%20tiled%203D%20microscopic%20image%20acquisitions%202009-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Preibisch%2C%20S.%20Saalfeld%2C%20S.%20Tomancak%2C%20P.%20Globally%20optimal%20stitching%20of%20tiled%203D%20microscopic%20image%20acquisitions%202009-06"
        },
        {
            "id": "Russakovsky_et+al_2015_a",
            "entry": "Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV), 115(3):211\u2013252, 2015. doi: 10.1007/s11263-015-0816-y.",
            "crossref": "https://dx.doi.org/10.1007/s11263-015-0816-y",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1007/s11263-015-0816-y"
        },
        {
            "id": "Saenko_et+al_2010_a",
            "entry": "Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Darrell. Adapting visual category models to new domains. In Kostas Daniilidis, Petros Maragos, and Nikos Paragios (eds.), Computer Vision \u2013 ECCV 2010, pp. 213\u2013226, Berlin, Heidelberg, 2010. Springer Berlin Heidelberg. ISBN 978-3-642-15561-1.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Saenko%2C%20Kate%20Kulis%2C%20Brian%20Fritz%2C%20Mario%20Darrell%2C%20Trevor%20Adapting%20visual%20category%20models%20to%20new%20domains%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Saenko%2C%20Kate%20Kulis%2C%20Brian%20Fritz%2C%20Mario%20Darrell%2C%20Trevor%20Adapting%20visual%20category%20models%20to%20new%20domains%202010"
        },
        {
            "id": "Sankaranarayanan_et+al_2017_a",
            "entry": "Swami Sankaranarayanan, Yogesh Balaji, Carlos D. Castillo, and Rama Chellappa. Generate to adapt: Aligning domains using generative adversarial networks. CoRR, abs/1704.01705, 2017. URL http://arxiv.org/abs/1704.01705.",
            "url": "http://arxiv.org/abs/1704.01705",
            "arxiv_url": "https://arxiv.org/pdf/1704.01705"
        },
        {
            "id": "Schneider_et+al_2012_a",
            "entry": "C. A. Schneider, W. S. Rasband, and K. W. Eliceiri. NIH Image to ImageJ: 25 years of image analysis. Nat. Methods, 9(7):671\u2013675, Jul 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schneider%2C%20C.A.%20Rasband%2C%20W.S.%20Eliceiri%2C%20K.W.%20NIH%20Image%20to%20ImageJ%3A%2025%20years%20of%20image%20analysis%202012-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schneider%2C%20C.A.%20Rasband%2C%20W.S.%20Eliceiri%2C%20K.W.%20NIH%20Image%20to%20ImageJ%3A%2025%20years%20of%20image%20analysis%202012-07"
        },
        {
            "id": "Schweikert_et+al_2008_a",
            "entry": "Gabriele Schweikert, Christian Widmer, Bernhard Sch\u00f6lkopf, and Gunnar R\u00e4tsch. An empirical analysis of domain adaptation algorithms for genomic sequence analysis. In Proceedings of the 21st International Conference on Neural Information Processing Systems, NIPS\u201908, pp. 1433\u20131440, USA, 2008. Curran Associates Inc. ISBN 978-1-6056-0-949-2. URL http://dl.acm.org/citation.cfm?id=2981780.2981959.",
            "url": "http://dl.acm.org/citation.cfm?id=2981780.2981959",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schweikert%2C%20Gabriele%20Widmer%2C%20Christian%20Sch%C3%B6lkopf%2C%20Bernhard%20R%C3%A4tsch%2C%20Gunnar%20An%20empirical%20analysis%20of%20domain%20adaptation%20algorithms%20for%20genomic%20sequence%20analysis%202008"
        },
        {
            "id": "Shimodaira_2000_a",
            "entry": "Hidetoshi Shimodaira. Improving predictive inference under covariate shift by weighting the log-likelihood function. Journal of Statistical Planning and Inference, 90(2):227\u2013244, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shimodaira%2C%20Hidetoshi%20Improving%20predictive%20inference%20under%20covariate%20shift%20by%20weighting%20the%20log-likelihood%20function%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shimodaira%2C%20Hidetoshi%20Improving%20predictive%20inference%20under%20covariate%20shift%20by%20weighting%20the%20log-likelihood%20function%202000"
        },
        {
            "id": "Shu_et+al_2018_a",
            "entry": "Rui Shu, Hung H. Bui, Hirokazu Narui, and Stefano Ermon. A DIRT-T approach to unsupervised domain adaptation. In Proceedings of the 6th International Conference on Learning Representations (ICLR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shu%2C%20Rui%20Bui%2C%20Hung%20H.%20Narui%2C%20Hirokazu%20Ermon%2C%20Stefano%20A%20DIRT-T%20approach%20to%20unsupervised%20domain%20adaptation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shu%2C%20Rui%20Bui%2C%20Hung%20H.%20Narui%2C%20Hirokazu%20Ermon%2C%20Stefano%20A%20DIRT-T%20approach%20to%20unsupervised%20domain%20adaptation%202018"
        },
        {
            "id": "Sigal_et+al_2006_a",
            "entry": "A. Sigal, R. Milo, A. Cohen, N. Geva-Zatorsky, Y. Klein, I. Alaluf, N. Swerdlin, N. Perzov, T. Danon, Y. Liron, T. Raveh, A. E. Carpenter, G. Lahav, and U. Alon. Dynamic proteomics in individual human cells uncovers widespread cell-cycle dependence of nuclear proteins. Nat. Methods, 3(7):525\u2013531, Jul 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sigal%2C%20A.%20Milo%2C%20R.%20Cohen%2C%20A.%20Geva-Zatorsky%2C%20N.%20Dynamic%20proteomics%20in%20individual%20human%20cells%20uncovers%20widespread%20cell-cycle%20dependence%20of%20nuclear%20proteins%202006-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sigal%2C%20A.%20Milo%2C%20R.%20Cohen%2C%20A.%20Geva-Zatorsky%2C%20N.%20Dynamic%20proteomics%20in%20individual%20human%20cells%20uncovers%20widespread%20cell-cycle%20dependence%20of%20nuclear%20proteins%202006-07"
        },
        {
            "id": "Simonyan_2014_a",
            "entry": "Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. CoRR, abs/1409.1556, 2014. URL http://arxiv.org/abs/1409.1556.",
            "url": "http://arxiv.org/abs/1409.1556",
            "arxiv_url": "https://arxiv.org/pdf/1409.1556"
        },
        {
            "id": "Stallkamp_et+al_2012_a",
            "entry": "J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition. Neural Networks, pp. \u2013, 2012. ISSN 0893-6080. doi: 10.1016/j.neunet.2012.02.016. URL http://www.sciencedirect.com/science/article/pii/S0893608012000457.",
            "crossref": "https://dx.doi.org/10.1016/j.neunet.2012.02.016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1016/j.neunet.2012.02.016"
        },
        {
            "id": "Stoeger_et+al_2015_a",
            "entry": "T. Stoeger, N. Battich, M. D. Herrmann, Y. Yakimovich, and L. Pelkmans. Computer vision for image-based transcriptomics. Methods, 85:44\u201353, Sep 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stoeger%2C%20T.%20Battich%2C%20N.%20Herrmann%2C%20M.D.%20Yakimovich%2C%20Y.%20Computer%20vision%20for%20image-based%20transcriptomics%202015-09",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Stoeger%2C%20T.%20Battich%2C%20N.%20Herrmann%2C%20M.D.%20Yakimovich%2C%20Y.%20Computer%20vision%20for%20image-based%20transcriptomics%202015-09"
        },
        {
            "id": "Sun_2016_a",
            "entry": "Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In Gang Hua and Herv\u00e9 J\u00e9gou (eds.), Computer Vision \u2013 ECCV 2016 Workshops, pp. 443\u2013450, Cham, 2016. Springer International Publishing. ISBN 978-3-319-49409-8.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sun%2C%20Baochen%20Saenko%2C%20Kate%20Deep%20coral%3A%20Correlation%20alignment%20for%20deep%20domain%20adaptation%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sun%2C%20Baochen%20Saenko%2C%20Kate%20Deep%20coral%3A%20Correlation%20alignment%20for%20deep%20domain%20adaptation%202016"
        },
        {
            "id": "Sun_et+al_2016_b",
            "entry": "Baochen Sun, Jiashi Feng, and Kate Saenko. Return of frustratingly easy domain adaptation. In Proceedings of the 29th AAAI Conference on Artificial Intelligence, AAAI, 2016. URL http://arxiv.org/abs/1511.05547.",
            "url": "http://arxiv.org/abs/1511.05547",
            "arxiv_url": "https://arxiv.org/pdf/1511.05547"
        },
        {
            "id": "Taigman_et+al_2016_a",
            "entry": "Yaniv Taigman, Adam Polyak, and Lior Wolf. Unsupervised cross-domain image generation. CoRR, abs/1611.02200, 2016. URL http://arxiv.org/abs/1611.02200.",
            "url": "http://arxiv.org/abs/1611.02200",
            "arxiv_url": "https://arxiv.org/pdf/1611.02200"
        },
        {
            "id": "Tzeng_et+al_2015_a",
            "entry": "E. Tzeng, J. Hoffman, T. Darrell, and K. Saenko. Simultaneous deep transfer across domains and tasks. In 2015 IEEE International Conference on Computer Vision (ICCV), pp. 4068\u20134076, Dec 2015. doi: 10.1109/ICCV.2015.463.",
            "crossref": "https://dx.doi.org/10.1109/ICCV.2015.463",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/ICCV.2015.463"
        },
        {
            "id": "Tzeng_et+al_2014_a",
            "entry": "Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and Trevor Darrell. Deep domain confusion: Maximizing for domain invariance. CoRR, abs/1412.3474, 2014. URL http://arxiv.org/abs/1412.3474.",
            "url": "http://arxiv.org/abs/1412.3474",
            "arxiv_url": "https://arxiv.org/pdf/1412.3474"
        },
        {
            "id": "Tzeng_et+al_2017_a",
            "entry": "Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell. Adversarial discriminative domain adaptation. CoRR, abs/1702.05464, 2017. URL http://arxiv.org/abs/1702.05464.",
            "url": "http://arxiv.org/abs/1702.05464",
            "arxiv_url": "https://arxiv.org/pdf/1702.05464"
        },
        {
            "id": "Vallania_et+al_2017_a",
            "entry": "Francesco Vallania, Andrew Tam, Shane Lofgren, Steven Schaffert, Tej D. Azad, Erika Bongen, Meia Alsup, Michael Alonso, Mark Davis, Edgar Engleman, and Purvesh Khatri. Leveraging heterogeneity across multiple data sets increases accuracy of cell-mixture deconvolution and reduces biological and technical biases. bioRxiv, 2017. doi: 10.1101/206466. URL https://www.biorxiv.org/content/early/2017/10/20/206466.",
            "crossref": "https://dx.doi.org/10.1101/206466"
        },
        {
            "id": "Van_2008_a",
            "entry": "Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-SNE. Journal of Machine Learning Research, 9:2579\u20132605, 2008. URL http://www.jmlr.org/papers/v9/vandermaaten08a.html.",
            "url": "http://www.jmlr.org/papers/v9/vandermaaten08a.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=van%20der%20Maaten%2C%20Laurens%20Hinton%2C%20Geoffrey%20Visualizing%20data%20using%20t-SNE%202008"
        },
        {
            "id": "Annegreet_et+al_2015_a",
            "entry": "Annegreet van Opbroek, M. Arfan Ikram, Meike W. Vernooij, and Marleen de Bruijne. Transfer learning improves supervised image segmentation across imaging protocols. I E E E Transactions on Medical Imaging, 34(5):1018\u20131030, 2015. ISSN 0278-0062. doi: 10.1109/TMI.2014.2366792.",
            "crossref": "https://dx.doi.org/10.1109/TMI.2014.2366792",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/TMI.2014.2366792"
        },
        {
            "id": "In_2017_a",
            "entry": "In the field of computer vision, another way of mapping examples in one domain onto the other domain is image-to-image translation. In the supervised case (the true pairs made of an image and its translation are given), Pic2Pix (Isola et al., 2017) trains a conditional GAN to discriminate true pairs from fake ones. In the unsupervised case, another loss is designed to enforce cycle consistency (simultaneously learning the mapping \u03c6 from domain A to B, \u03c8 from B to A, and requiring \u03c6o\u03c8 =Id) (Zhu et al., 2017; Yi et al., 2017). Note that translation approaches do not per se address domain adaptation as they are agnostic w.r.t. the classes. Additional losses are used to overcome this limitation: Domain transfer network (DTN) (Taigman et al., 2016) uses an auto-encoder-like loss in the latent space; GenToAdapt (Sankaranarayanan et al., 2017) uses a classifier loss in the latent space; UNIT (Liu et al., 2017) uses a VAE loss.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=In%20the%20field%20of%20computer%20vision%20another%20way%20of%20mapping%20examples%20in%20one%20domain%20onto%20the%20other%20domain%20is%20imagetoimage%20translation%20In%20the%20supervised%20case%20the%20true%20pairs%20made%20of%20an%20image%20and%20its%20translation%20are%20given%20Pic2Pix%20Isola%20et%20al%202017%20trains%20a%20conditional%20GAN%20to%20discriminate%20true%20pairs%20from%20fake%20ones%20In%20the%20unsupervised%20case%20another%20loss%20is%20designed%20to%20enforce%20cycle%20consistency%20simultaneously%20learning%20the%20mapping%20%CF%86%20from%20domain%20A%20to%20B%20%CF%88%20from%20B%20to%20A%20and%20requiring%20%CF%86o%CF%88%20Id%20Zhu%20et%20al%202017%20Yi%20et%20al%202017%20Note%20that%20translation%20approaches%20do%20not%20per%20se%20address%20domain%20adaptation%20as%20they%20are%20agnostic%20wrt%20the%20classes%20Additional%20losses%20are%20used%20to%20overcome%20this%20limitation%20Domain%20transfer%20network%20DTN%20Taigman%20et%20al%202016%20uses%20an%20autoencoderlike%20loss%20in%20the%20latent%20space%20GenToAdapt%20Sankaranarayanan%20et%20al%202017%20uses%20a%20classifier%20loss%20in%20the%20latent%20space%20UNIT%20Liu%20et%20al%202017%20uses%20a%20VAE%20loss",
            "oa_query": "https://api.scholarcy.com/oa_version?query=In%20the%20field%20of%20computer%20vision%20another%20way%20of%20mapping%20examples%20in%20one%20domain%20onto%20the%20other%20domain%20is%20imagetoimage%20translation%20In%20the%20supervised%20case%20the%20true%20pairs%20made%20of%20an%20image%20and%20its%20translation%20are%20given%20Pic2Pix%20Isola%20et%20al%202017%20trains%20a%20conditional%20GAN%20to%20discriminate%20true%20pairs%20from%20fake%20ones%20In%20the%20unsupervised%20case%20another%20loss%20is%20designed%20to%20enforce%20cycle%20consistency%20simultaneously%20learning%20the%20mapping%20%CF%86%20from%20domain%20A%20to%20B%20%CF%88%20from%20B%20to%20A%20and%20requiring%20%CF%86o%CF%88%20Id%20Zhu%20et%20al%202017%20Yi%20et%20al%202017%20Note%20that%20translation%20approaches%20do%20not%20per%20se%20address%20domain%20adaptation%20as%20they%20are%20agnostic%20wrt%20the%20classes%20Additional%20losses%20are%20used%20to%20overcome%20this%20limitation%20Domain%20transfer%20network%20DTN%20Taigman%20et%20al%202016%20uses%20an%20autoencoderlike%20loss%20in%20the%20latent%20space%20GenToAdapt%20Sankaranarayanan%20et%20al%202017%20uses%20a%20classifier%20loss%20in%20the%20latent%20space%20UNIT%20Liu%20et%20al%202017%20uses%20a%20VAE%20loss"
        },
        {
            "id": "Stargan_2018_a",
            "entry": "StarGAN (Choi et al., 2018) combines image-to-image translation with a GAN, where the discriminator is trained to discriminate true from fake pairs on the one hand, and the domain on the other hand. ComboGAN (Anoosheh et al., 2017) learns two networks per domain, an encoder and a decoder. DIRT-T (Shu et al., 2018) uses a conditional GAN and a classifier in the latent space, with two additional losses, respectively enforcing the cluster assumption (the classifier boundary should not cross high density region) and a virtual adversarial training (the hypothesis should be invariant under slight perturbations of the input). Interestingly, DA and MDL (like deep learning in general) tend to combine quite some losses; two benefits are expected from using a mixture of losses, a smoother optimization landscape and a good stability of the representation (Bousquet & Elisseeff, 2002).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=%28Choi%2C%20StarGAN%20combines%20image-to-image%20translation%20with%20a%20GAN%2C%20where%20the%20discriminator%20is%20trained%20to%20discriminate%20true%20from%20fake%20pairs%20on%20the%20one%20hand%2C%20and%20the%20domain%20on%20the%20other%20hand%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=%28Choi%2C%20StarGAN%20combines%20image-to-image%20translation%20with%20a%20GAN%2C%20where%20the%20discriminator%20is%20trained%20to%20discriminate%20true%20from%20fake%20pairs%20on%20the%20one%20hand%2C%20and%20the%20domain%20on%20the%20other%20hand%202018"
        },
        {
            "id": "Definition_2004_a",
            "entry": "Definition. (Kifer et al., 2004; Ben-David et al., 2006; 2010) Given a domain X, two distributions D and D over that domain and a binary hypothesis class H on X, the H-divergence between D and D is defined as: dH(D, D ) = 2 sup |PD(h(x) = 1) \u2212 PD (h(x) = 1)|",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=%28Kifer%2C%20Definition.%20Given%20a%20domain%20X%2C%20two%20distributions%20D%20and%20D%20over%20that%20domain%20and%20a%20binary%20hypothesis%20class%20H%20on%20X%2C%20the%20H-divergence%20between%20D%20and%20D%20is%20defined%20as%3A%20dH%28D%2C%20D%20%29%20%3D%202%20sup%20%7CPD%28h%28x%29%20%3D%201%29%20%E2%88%92%20PD%20%28h%28x%29%20%3D%201%29%7C%202004"
        },
        {
            "id": "Divergence_2010_a",
            "entry": "divergence (Ben-David et al., 2010) operates on the symmetric difference hypothesis space H\u2206H.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=divergence%20%28Ben-David%20operates%20on%20the%20symmetric%20difference%20hypothesis%20space%20H%E2%88%86H%202010"
        },
        {
            "id": "However_2010_a",
            "entry": "However, divergence H\u2206H does not lend itself to empirical estimation: even Ben-David et al. (2010)",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=However%2C%20divergence%20H%E2%88%86H%20does%20not%20lend%20itself%20to%20empirical%20estimation%3A%20even%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=However%2C%20divergence%20H%E2%88%86H%20does%20not%20lend%20itself%20to%20empirical%20estimation%3A%20even%202010"
        },
        {
            "id": "N_2010_a",
            "entry": "We have for \u03b1 in the simplex of dimension n, h \u2208 H and j \u2208 {1,..., m}, using the triangle inequality (similarly to the proof of Theorem 4 in (Ben-David et al., 2010))",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=We%20have%20for%20%CE%B1%20in%20the%20simplex%20of%20dimension%20n%20h%20%20H%20and%20j%20%201%20m%20using%20the%20triangle%20inequality%20similarly%20to%20the%20proof%20of%20Theorem%204%20in%20BenDavid%20et%20al%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=We%20have%20for%20%CE%B1%20in%20the%20simplex%20of%20dimension%20n%20h%20%20H%20and%20j%20%201%20m%20using%20the%20triangle%20inequality%20similarly%20to%20the%20proof%20of%20Theorem%204%20in%20BenDavid%20et%20al%202010"
        },
        {
            "id": "The_2010_a",
            "entry": "The last line follows from the definitions of \u03b2i,j and H-divergence. Thus using lemma 6 in (Ben-David et al., 2010)",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=The%20last%20line%20follows%20from%20the%20definitions%20of%20%CE%B2ij%20and%20Hdivergence%20Thus%20using%20lemma%206%20in%20BenDavid%20et%20al%202010"
        },
        {
            "id": "Proof_2006_a",
            "entry": "Proof of proposition 1 We have for h \u2208 H and j \u2208 [1,..., m], using the triangle inequality and the definition of i (similarly to the proof of Theorem 1 in (Ben-David et al., 2006))",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Proof%20of%20proposition%201%20We%20have%20for%20h%20%20H%20and%20j%20%201%20m%20using%20the%20triangle%20inequality%20and%20the%20definition%20of%20i%20similarly%20to%20the%20proof%20of%20Theorem%201%20in%20BenDavid%20et%20al%202006"
        },
        {
            "id": "The_2010_b",
            "entry": "The second line follows from Lemma 3 from (Ben-David et al., 2010), and the third from the triangle inequality. From this and proposition 1 we obtain the result.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=The%20second%20line%20follows%20from%20Lemma%203%20from%20BenDavid%20et%20al%202010%20and%20the%20third%20from%20the%20triangle%20inequality%20From%20this%20and%20proposition%201%20we%20obtain%20the%20result"
        },
        {
            "id": "This_2016_a",
            "entry": "This dataset is extracted from that published in (Kang et al., 2016). It contains 455 biologically active images, in 11 classes, on four 384-well plates, in three channels: H2B-CFP, XRCC5-YFP and cytoplasmic-mCherry. Our analysis used 10 classes: \u2019Actin\u2019, \u2019Aurora\u2019, \u2019DNA\u2019, \u2019ER\u2019, \u2019HDAC\u2019, \u2019Hsp90\u2019, \u2019MT\u2019, \u2019PLK\u2019, \u2019Proteasome\u2019, \u2019mTOR\u2019.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=This%20dataset%20is%20extracted%20from%20that%20published%20in%20Kang%20et%20al%202016%20It%20contains%20455%20biologically%20active%20images%20in%2011%20classes%20on%20four%20384well%20plates%20in%20three%20channels%20H2BCFP%20XRCC5YFP%20and%20cytoplasmicmCherry%20Our%20analysis%20used%2010%20classes%20Actin%20Aurora%20DNA%20ER%20HDAC%20Hsp90%20MT%20PLK%20Proteasome%20mTOR"
        },
        {
            "id": "On_2001_a",
            "entry": "On top of the quality control from the original paper, a visual quality control was implemented to remove images with only apoptotic cells, and XRCC5-YFP channel images were smoothed using a median filter of size 2 using SciPy (Jones et al., 2001\u2013).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=On%20top%20of%20the%20quality%20control%20from%20the%20original%20paper%20a%20visual%20quality%20control%20was%20implemented%20to%20remove%20images%20with%20only%20apoptotic%20cells%20and%20XRCC5YFP%20channel%20images%20were%20smoothed%20using%20a%20median%20filter%20of%20size%202%20using%20SciPy%20Jones%20et%20al%202001"
        }
    ]
}

{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "STRUCTURED NEURAL SUMMARIZATION",
        "author": "Patrick Fernandes, Miltiadis Allamanis & Marc Brockschmidt Microsoft Research Cambridge, United Kingdom {t-pafern,miallama,mabrocks}@microsoft.com",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=H1ersoRqtm"
        },
        "abstract": "Summarization of long sequences into a concise statement is a core problem in natural language processing, requiring non-trivial understanding of the input. Based on the promising results of graph neural networks on highly structured data, we develop a framework to extend existing sequence encoders with a graph component that can reason about long-distance relationships in weakly structured data such as text. In an extensive evaluation, we show that the resulting hybrid sequence-graph models outperform both pure sequence models as well as pure graph models on a range of summarization tasks."
    },
    "keywords": [
        {
            "term": "abstract meaning representation",
            "url": "https://en.wikipedia.org/wiki/Abstract_Meaning_Representation"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "long distance relationship",
            "url": "https://en.wikipedia.org/wiki/long_distance_relationship"
        },
        {
            "term": "natural language processing",
            "url": "https://en.wikipedia.org/wiki/natural_language_processing"
        },
        {
            "term": "sequence graph",
            "url": "https://en.wikipedia.org/wiki/sequence_graph"
        }
    ],
    "abbreviations": {
        "AMR": "abstract meaning representation"
    },
    "highlights": [
        "Summarization, the task of condensing a large and complex input into a smaller representation that retains the core semantics of the input, is a classical task for natural language processing systems",
        "Current approaches to summarization are based on the sequence-to-sequence paradigm over the words of some text, with a sequence encoder \u2014 typically a recurrent neural network, but sometimes a 1D-CNN (<a class=\"ref-link\" id=\"cNarayan_et+al_2018_a\" href=\"#rNarayan_et+al_2018_a\">Narayan et al, 2018</a>) or using self-attention (<a class=\"ref-link\" id=\"cMccann_et+al_2018_a\" href=\"#rMccann_et+al_2018_a\">McCann et al, 2018</a>) \u2014 processing the input and a sequence decoder generating the output",
        "The sequential aspect of the input data is still rich in meaning, and we propose a hybrid model in which a standard sequence encoder generates rich input for a graph neural network",
        "The results show the advantage of our hybrid sequence GNN encoders over pure sequence encoders",
        "We presented a framework for extending sequence encoders with a graph component that can leverage rich additional structure",
        "In an evaluation on three different summarization tasks, we have shown that this augmentation improves the performance of a range of different sequence models across all tasks"
    ],
    "key_statements": [
        "Summarization, the task of condensing a large and complex input into a smaller representation that retains the core semantics of the input, is a classical task for natural language processing systems",
        "Current approaches to summarization are based on the sequence-to-sequence paradigm over the words of some text, with a sequence encoder \u2014 typically a recurrent neural network, but sometimes a 1D-CNN (<a class=\"ref-link\" id=\"cNarayan_et+al_2018_a\" href=\"#rNarayan_et+al_2018_a\">Narayan et al, 2018</a>) or using self-attention (<a class=\"ref-link\" id=\"cMccann_et+al_2018_a\" href=\"#rMccann_et+al_2018_a\">McCann et al, 2018</a>) \u2014 processing the input and a sequence decoder generating the output",
        "The sequential aspect of the input data is still rich in meaning, and we propose a hybrid model in which a standard sequence encoder generates rich input for a graph neural network",
        "The results show the advantage of our hybrid sequence GNN encoders over pure sequence encoders",
        "We presented a framework for extending sequence encoders with a graph component that can leverage rich additional structure",
        "In an evaluation on three different summarization tasks, we have shown that this augmentation improves the performance of a range of different sequence models across all tasks"
    ],
    "summary": [
        "Summarization, the task of condensing a large and complex input into a smaller representation that retains the core semantics of the input, is a classical task for natural language processing systems.",
        "The resulting combination outperforms baselines that use pure sequence or pure graph-based representations.",
        "A framework that extends standard sequence encoder models with a graph component that leverages additional structure in sequence data.",
        "The first two tasks are related to the summarization of source code (Figure 1), which is highly structured and can profit most from models that can take advantage of this structure; the final task is a classical natural language task illustrating that hybrid sequence-graph models are applicable for less structured inputs as well.",
        "We evaluate Sequence GNNs on our three tasks by comparing them to models that use only sequence or graph information, as well as by comparing them to task-specific baselines.",
        "We use an LSTM with 1 layer and 256 hidden units with attention over the input sequence, and an extension using a pointer network-style copying mechanism.",
        "On METHODNAMING, we can see that all GNN-augmented models are able to outperform the current specialized state of the art, requiring only simple graph structure that can be obtained using existing parsers for a programming language.",
        "On METHODDOC, the unmodified SELFATT \u2192 SELFATT model already performs quite well, and the augmentation with graph data only improves the BLEU score and worsens the results on ROUGE.",
        "We add long-range dependency edges by connecting tokens with equivalent string representations of their stems and observe further minor improvements, indicating that even using only purely syntactical information, without a semantic parse, can already provide gains.",
        "BILSTM+GNN \u2192 LSTM+POINTER n\u2019golo kante is attracting interest from a host of premier league clubs .",
        "Recent work in summarization has proposed improved training objectives for summarization, such as tracking coverage of the input document (<a class=\"ref-link\" id=\"cSee_et+al_2017_a\" href=\"#rSee_et+al_2017_a\">See et al, 2017</a>) or using reinforcement learning to directly identify actions in the decoder that improve target measures such as ROUGE-L (<a class=\"ref-link\" id=\"cChen_2018_a\" href=\"#rChen_2018_a\">Chen & Bansal, 2018</a>; <a class=\"ref-link\" id=\"cNarayan_et+al_2018_a\" href=\"#rNarayan_et+al_2018_a\">Narayan et al, 2018</a>).",
        "In contrast to that work we do not use AMRs but directly encode relatively simple relationships directly on the tokenized text, and do not treat summarization as a graph rewrite problem.",
        "The use of additional structure on related tasks on source code has been studied recently, for example in models that are conditioned on learned traversals of the syntax tree (<a class=\"ref-link\" id=\"cBielik_et+al_2016_a\" href=\"#rBielik_et+al_2016_a\">Bielik et al, 2016</a>) and in graph-based approaches (Allamanis et al, 2018; <a class=\"ref-link\" id=\"cCvitkovic_et+al_2018_a\" href=\"#rCvitkovic_et+al_2018_a\">Cvitkovic et al, 2018</a>)."
    ],
    "headline": "Based on the promising results of graph neural networks on highly structured data, we develop a framework to extend existing sequence encoders with a graph component that can reason about long-distance relationships in weakly structured data such as text",
    "reference_links": [
        {
            "id": "Allamanis_2018_a",
            "entry": "Miltiadis Allamanis. The adverse effects of code duplication in machine learning models of code. arXiv preprint arXiv:1812.06469, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1812.06469"
        },
        {
            "id": "Allamanis_et+al_2015_a",
            "entry": "Miltiadis Allamanis, Earl T Barr, Christian Bird, and Charles Sutton. Suggesting accurate method and class names. In Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering, pp. 38\u201349. ACM, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Allamanis%2C%20Miltiadis%20Barr%2C%20Earl%20T.%20Bird%2C%20Christian%20Sutton%2C%20Charles%20Suggesting%20accurate%20method%20and%20class%20names%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Allamanis%2C%20Miltiadis%20Barr%2C%20Earl%20T.%20Bird%2C%20Christian%20Sutton%2C%20Charles%20Suggesting%20accurate%20method%20and%20class%20names%202015"
        },
        {
            "id": "Allamanis_et+al_2016_a",
            "entry": "Miltiadis Allamanis, Hao Peng, and Charles Sutton. A convolutional attention network for extreme summarization of source code. In International Conference on Machine Learning, pp. 2091\u20132100, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Allamanis%2C%20Miltiadis%20Peng%2C%20Hao%20Sutton%2C%20Charles%20A%20convolutional%20attention%20network%20for%20extreme%20summarization%20of%20source%20code%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Allamanis%2C%20Miltiadis%20Peng%2C%20Hao%20Sutton%2C%20Charles%20A%20convolutional%20attention%20network%20for%20extreme%20summarization%20of%20source%20code%202016"
        },
        {
            "id": "Allamanis_et+al_2018_b",
            "entry": "Miltiadis Allamanis, Marc Brockschmidt, and Mahmoud Khademi. Learning to represent programs with graphs. In International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Allamanis%2C%20Miltiadis%20Brockschmidt%2C%20Marc%20Khademi%2C%20Mahmoud%20Learning%20to%20represent%20programs%20with%20graphs%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Allamanis%2C%20Miltiadis%20Brockschmidt%2C%20Marc%20Khademi%2C%20Mahmoud%20Learning%20to%20represent%20programs%20with%20graphs%202018"
        },
        {
            "id": "Alon_et+al_0000_a",
            "entry": "Uri Alon, Omer Levy, and Eran Yahav. code2seq: Generating sequences from structured representations of code. arXiv preprint arXiv:1808.01400, 2018a.",
            "arxiv_url": "https://arxiv.org/pdf/1808.01400"
        },
        {
            "id": "Alon_et+al_2018_a",
            "entry": "Uri Alon, Meital Zilberstein, Omer Levy, and Eran Yahav. A general path-based representation for predicting program properties. In Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation, pp. 404\u2013419. ACM, 2018b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Alon%2C%20Uri%20Zilberstein%2C%20Meital%20Levy%2C%20Omer%20Yahav%2C%20Eran%20A%20general%20path-based%20representation%20for%20predicting%20program%20properties%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Alon%2C%20Uri%20Zilberstein%2C%20Meital%20Levy%2C%20Omer%20Yahav%2C%20Eran%20A%20general%20path-based%20representation%20for%20predicting%20program%20properties%202018"
        },
        {
            "id": "Bahdanau_et+al_2014_a",
            "entry": "Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1409.0473"
        },
        {
            "id": "Antonio_2017_a",
            "entry": "Antonio Valerio Miceli Barone and Rico Sennrich. A parallel corpus of Python functions and documentation strings for automated code documentation and code generation. In Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers), volume 2, pp. 314\u2013319, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Antonio%20Valerio%20Miceli%20Barone%20and%20Rico%20Sennrich%20A%20parallel%20corpus%20of%20Python%20functions%20and%20documentation%20strings%20for%20automated%20code%20documentation%20and%20code%20generation%20In%20Proceedings%20of%20the%20Eighth%20International%20Joint%20Conference%20on%20Natural%20Language%20Processing%20Volume%202%20Short%20Papers%20volume%202%20pp%20314319%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Antonio%20Valerio%20Miceli%20Barone%20and%20Rico%20Sennrich%20A%20parallel%20corpus%20of%20Python%20functions%20and%20documentation%20strings%20for%20automated%20code%20documentation%20and%20code%20generation%20In%20Proceedings%20of%20the%20Eighth%20International%20Joint%20Conference%20on%20Natural%20Language%20Processing%20Volume%202%20Short%20Papers%20volume%202%20pp%20314319%202017"
        },
        {
            "id": "Bichsel_et+al_2016_a",
            "entry": "Benjamin Bichsel, Veselin Raychev, Petar Tsankov, and Martin Vechev. Statistical deobfuscation of android applications. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 343\u2013355. ACM, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bichsel%2C%20Benjamin%20Raychev%2C%20Veselin%20Tsankov%2C%20Petar%20Vechev%2C%20Martin%20Statistical%20deobfuscation%20of%20android%20applications%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bichsel%2C%20Benjamin%20Raychev%2C%20Veselin%20Tsankov%2C%20Petar%20Vechev%2C%20Martin%20Statistical%20deobfuscation%20of%20android%20applications%202016"
        },
        {
            "id": "Bielik_et+al_2016_a",
            "entry": "Pavol Bielik, Veselin Raychev, and Martin Vechev. PHOG: probabilistic model for code. In International Conference on Machine Learning (ICML), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bielik%2C%20Pavol%20Raychev%2C%20Veselin%20Vechev%2C%20Martin%20PHOG%3A%20probabilistic%20model%20for%20code%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bielik%2C%20Pavol%20Raychev%2C%20Veselin%20Vechev%2C%20Martin%20PHOG%3A%20probabilistic%20model%20for%20code%202016"
        },
        {
            "id": "Chen_2018_a",
            "entry": "Yen-Chun Chen and Mohit Bansal. Fast abstractive summarization with reinforce-selected sentence rewriting. arXiv preprint arXiv:1805.11080, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1805.11080"
        },
        {
            "id": "Chopra_et+al_2016_a",
            "entry": "Sumit Chopra, Michael Auli, and Alexander M Rush. Abstractive sentence summarization with attentive recurrent neural networks. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 93\u201398, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chopra%2C%20Sumit%20Auli%2C%20Michael%20Rush%2C%20Alexander%20M.%20Abstractive%20sentence%20summarization%20with%20attentive%20recurrent%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chopra%2C%20Sumit%20Auli%2C%20Michael%20Rush%2C%20Alexander%20M.%20Abstractive%20sentence%20summarization%20with%20attentive%20recurrent%20neural%20networks%202016"
        },
        {
            "id": "Cvitkovic_et+al_2018_a",
            "entry": "Milan Cvitkovic, Badal Singh, and Anima Anandkumar. Deep learning on code with an unbounded vocabulary. In Machine Learning 4 Programming, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cvitkovic%2C%20Milan%20Singh%2C%20Badal%20Anandkumar%2C%20Anima%20Deep%20learning%20on%20code%20with%20an%20unbounded%20vocabulary%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cvitkovic%2C%20Milan%20Singh%2C%20Badal%20Anandkumar%2C%20Anima%20Deep%20learning%20on%20code%20with%20an%20unbounded%20vocabulary%202018"
        },
        {
            "id": "Cao_et+al_2018_a",
            "entry": "Nicola De Cao, Wilker Aziz, and Ivan Titov. Question answering by reasoning across documents with graph convolutional networks. arXiv preprint arXiv:1808.09920, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1808.09920"
        },
        {
            "id": "Gilmer_et+al_2017_a",
            "entry": "Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural message passing for quantum chemistry. In International Conference on Machine Learning, pp. 1263\u20131272, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gilmer%2C%20Justin%20Schoenholz%2C%20Samuel%20S.%20Riley%2C%20Patrick%20F.%20Vinyals%2C%20Oriol%20Neural%20message%20passing%20for%20quantum%20chemistry%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gilmer%2C%20Justin%20Schoenholz%2C%20Samuel%20S.%20Riley%2C%20Patrick%20F.%20Vinyals%2C%20Oriol%20Neural%20message%20passing%20for%20quantum%20chemistry%202017"
        },
        {
            "id": "Gu_et+al_2018_a",
            "entry": "Xiaodong Gu, Hongyu Zhang, and Sunghun Kim. Deep code search. In Proceedings of the 40th International Conference on Software Engineering, pp. 933\u2013944. ACM, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gu%2C%20Xiaodong%20Zhang%2C%20Hongyu%20Kim%2C%20Sunghun%20Deep%20code%20search%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gu%2C%20Xiaodong%20Zhang%2C%20Hongyu%20Kim%2C%20Sunghun%20Deep%20code%20search%202018"
        },
        {
            "id": "Guo_et+al_2017_a",
            "entry": "Jin Guo, Jinghui Cheng, and Jane Cleland-Huang. Semantically enhanced software traceability using deep learning techniques. In Software Engineering (ICSE), 2017 IEEE/ACM 39th International Conference on, pp. 3\u201314. IEEE, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Guo%2C%20Jin%20Cheng%2C%20Jinghui%20Cleland-Huang%2C%20Jane%20Semantically%20enhanced%20software%20traceability%20using%20deep%20learning%20techniques%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Guo%2C%20Jin%20Cheng%2C%20Jinghui%20Cleland-Huang%2C%20Jane%20Semantically%20enhanced%20software%20traceability%20using%20deep%20learning%20techniques%202017"
        },
        {
            "id": "Hermann_et+al_2015_a",
            "entry": "Karl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, and Phil Blunsom. Teaching machines to read and comprehend. In Advances in Neural Information Processing Systems, pp. 1693\u20131701, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hermann%2C%20Karl%20Moritz%20Kocisky%2C%20Tomas%20Grefenstette%2C%20Edward%20Espeholt%2C%20Lasse%20Teaching%20machines%20to%20read%20and%20comprehend%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hermann%2C%20Karl%20Moritz%20Kocisky%2C%20Tomas%20Grefenstette%2C%20Edward%20Espeholt%2C%20Lasse%20Teaching%20machines%20to%20read%20and%20comprehend%202015"
        },
        {
            "id": "Hu_et+al_2017_a",
            "entry": "Xing Hu, Yuhan Wei, Ge Li, and Zhi Jin. Codesum: Translate program language to natural language. arXiv preprint arXiv:1708.01837, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1708.01837"
        },
        {
            "id": "Jia_2017_a",
            "entry": "Robin Jia and Percy Liang. Adversarial examples for evaluating reading comprehension systems. In Empirical Methods in Natural Language Processing (EMNLP), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jia%2C%20Robin%20Liang%2C%20Percy%20Adversarial%20examples%20for%20evaluating%20reading%20comprehension%20systems%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jia%2C%20Robin%20Liang%2C%20Percy%20Adversarial%20examples%20for%20evaluating%20reading%20comprehension%20systems%202017"
        },
        {
            "id": "Kipf_2017_a",
            "entry": "Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In International Conference on Learning Representations, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kipf%2C%20Thomas%20N.%20Welling%2C%20Max%20Semi-supervised%20classification%20with%20graph%20convolutional%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kipf%2C%20Thomas%20N.%20Welling%2C%20Max%20Semi-supervised%20classification%20with%20graph%20convolutional%20networks%202017"
        },
        {
            "id": "Lample_et+al_2016_a",
            "entry": "Guillaume Lample, Miguel Ballesteros, Sandeep Subramanian, Kazuya Kawakami, and Chris Dyer. Neural architectures for named entity recognition. In Proceedings the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lample%2C%20Guillaume%20Ballesteros%2C%20Miguel%20Subramanian%2C%20Sandeep%20Kawakami%2C%20Kazuya%20Neural%20architectures%20for%20named%20entity%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lample%2C%20Guillaume%20Ballesteros%2C%20Miguel%20Subramanian%2C%20Sandeep%20Kawakami%2C%20Kazuya%20Neural%20architectures%20for%20named%20entity%20recognition%202016"
        },
        {
            "id": "Li_et+al_2015_a",
            "entry": "Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. Gated graph sequence neural networks. arXiv preprint arXiv:1511.05493, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.05493"
        },
        {
            "id": "Liao_et+al_2018_a",
            "entry": "Renjie Liao, Marc Brockschmidt, Daniel Tarlow, Alexander Gaunt, Raquel Urtasun, and Richard S. Zemel. Graph partition neural networks for semi-supervised classification. In International Conference on Learning Representations (ICLR) [Workshop Track], 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liao%2C%20Renjie%20Brockschmidt%2C%20Marc%20Tarlow%2C%20Daniel%20Gaunt%2C%20Alexander%20Graph%20partition%20neural%20networks%20for%20semi-supervised%20classification%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liao%2C%20Renjie%20Brockschmidt%2C%20Marc%20Tarlow%2C%20Daniel%20Gaunt%2C%20Alexander%20Graph%20partition%20neural%20networks%20for%20semi-supervised%20classification%202018"
        },
        {
            "id": "Chin-Yew_2004_a",
            "entry": "Chin-Yew Lin. ROUGE: A package for automatic evaluation of summaries. Text Summarization Branches Out, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=ChinYew%20Lin%20ROUGE%20A%20package%20for%20automatic%20evaluation%20of%20summaries%20Text%20Summarization%20Branches%20Out%202004"
        },
        {
            "id": "Liu_et+al_2018_a",
            "entry": "Fei Liu, Jeffrey Flanigan, Sam Thomson, Norman Sadeh, and Noah A Smith. Toward abstractive summarization using semantic representations. arXiv preprint arXiv:1805.10399, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1805.10399"
        },
        {
            "id": "Lopes_et+al_2017_a",
            "entry": "Cristina V Lopes, Petr Maj, Pedro Martins, Vaibhav Saini, Di Yang, Jakub Zitny, Hitesh Sajnani, and Jan Vitek. Dejavu: a map of code duplicates on github. Proceedings of the ACM on Programming Languages, 1(OOPSLA):84, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lopes%2C%20Cristina%20V.%20Maj%2C%20Petr%20Martins%2C%20Pedro%20Saini%2C%20Vaibhav%20Dejavu%3A%20a%20map%20of%20code%20duplicates%20on%20github%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lopes%2C%20Cristina%20V.%20Maj%2C%20Petr%20Martins%2C%20Pedro%20Saini%2C%20Vaibhav%20Dejavu%3A%20a%20map%20of%20code%20duplicates%20on%20github%202017"
        },
        {
            "id": "Louis_et+al_2018_a",
            "entry": "Annie Louis, Santanu Kumar Dash, Earl T Barr, and Charles Sutton. Deep learning to detect redundant method comments. arXiv preprint arXiv:1806.04616, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1806.04616"
        },
        {
            "id": "Luong_et+al_2015_a",
            "entry": "Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attentionbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1508.04025"
        },
        {
            "id": "Manning_et+al_2014_a",
            "entry": "Christopher Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven Bethard, and David McClosky. The stanford corenlp natural language processing toolkit. In Proceedings of 52nd annual meeting of the association for computational linguistics: system demonstrations, pp. 55\u201360, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Manning%2C%20Christopher%20Surdeanu%2C%20Mihai%20Bauer%2C%20John%20Finkel%2C%20Jenny%20The%20stanford%20corenlp%20natural%20language%20processing%20toolkit%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Manning%2C%20Christopher%20Surdeanu%2C%20Mihai%20Bauer%2C%20John%20Finkel%2C%20Jenny%20The%20stanford%20corenlp%20natural%20language%20processing%20toolkit%202014"
        },
        {
            "id": "Marcheggiani_2017_a",
            "entry": "Diego Marcheggiani and Ivan Titov. Encoding sentences with graph convolutional networks for semantic role labeling. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 1506\u20131515, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Marcheggiani%2C%20Diego%20Titov%2C%20Ivan%20Encoding%20sentences%20with%20graph%20convolutional%20networks%20for%20semantic%20role%20labeling%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Marcheggiani%2C%20Diego%20Titov%2C%20Ivan%20Encoding%20sentences%20with%20graph%20convolutional%20networks%20for%20semantic%20role%20labeling%202017"
        },
        {
            "id": "Mccann_et+al_2018_a",
            "entry": "Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, and Richard Socher. The natural language decathlon: Multitask learning as question answering. arXiv preprint arXiv:1806.08730, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1806.08730"
        },
        {
            "id": "Nallapati_et+al_2016_a",
            "entry": "Ramesh Nallapati, Bowen Zhou, Cicero dos Santos, Caglar Gulcehre, and Bing Xiang. Abstractive text summarization using sequence-to-sequence rnns and beyond. In Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning, pp. 280\u2013290, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nallapati%2C%20Ramesh%20Zhou%2C%20Bowen%20dos%20Santos%2C%20Cicero%20Gulcehre%2C%20Caglar%20Abstractive%20text%20summarization%20using%20sequence-to-sequence%20rnns%20and%20beyond%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nallapati%2C%20Ramesh%20Zhou%2C%20Bowen%20dos%20Santos%2C%20Cicero%20Gulcehre%2C%20Caglar%20Abstractive%20text%20summarization%20using%20sequence-to-sequence%20rnns%20and%20beyond%202016"
        },
        {
            "id": "Narayan_et+al_2018_a",
            "entry": "Shashi Narayan, Shay B Cohen, and Mirella Lapata. Ranking sentences for extractive summarization with reinforcement learning. arXiv preprint arXiv:1802.08636, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.08636"
        },
        {
            "id": "Raychev_et+al_2015_a",
            "entry": "Veselin Raychev, Martin Vechev, and Andreas Krause. Predicting program properties from Big Code. In Principles of Programming Languages (POPL), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Raychev%2C%20Veselin%20Vechev%2C%20Martin%20Krause%2C%20Andreas%20Predicting%20program%20properties%20from%20Big%20Code%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Raychev%2C%20Veselin%20Vechev%2C%20Martin%20Krause%2C%20Andreas%20Predicting%20program%20properties%20from%20Big%20Code%202015"
        },
        {
            "id": "See_et+al_2017_a",
            "entry": "Abigail See, Peter J Liu, and Christopher D Manning. Get to the point: Summarization with pointergenerator networks. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), volume 1, pp. 1073\u20131083, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=See%2C%20Abigail%20Liu%2C%20Peter%20J.%20Manning%2C%20Christopher%20D.%20Get%20to%20the%20point%3A%20Summarization%20with%20pointergenerator%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=See%2C%20Abigail%20Liu%2C%20Peter%20J.%20Manning%2C%20Christopher%20D.%20Get%20to%20the%20point%3A%20Summarization%20with%20pointergenerator%20networks%202017"
        },
        {
            "id": "Tai_et+al_2015_a",
            "entry": "Kai Sheng Tai, Richard Socher, and Christopher D Manning. Improved semantic representations from tree-structured long short-term memory networks. 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tai%2C%20Kai%20Sheng%20Socher%2C%20Richard%20Manning%2C%20Christopher%20D.%20Improved%20semantic%20representations%20from%20tree-structured%20long%20short-term%20memory%20networks%202015"
        },
        {
            "id": "Vaswani_et+al_2017_a",
            "entry": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in Neural Information Processing Systems, pp. 5998\u20136008, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ashish%20Vaswani%20Noam%20Shazeer%20Niki%20Parmar%20Jakob%20Uszkoreit%20Llion%20Jones%20Aidan%20N%20Gomez%20%C5%81ukasz%20Kaiser%20and%20Illia%20Polosukhin%20Attention%20is%20all%20you%20need%20In%20Advances%20in%20Neural%20Information%20Processing%20Systems%20pp%2059986008%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ashish%20Vaswani%20Noam%20Shazeer%20Niki%20Parmar%20Jakob%20Uszkoreit%20Llion%20Jones%20Aidan%20N%20Gomez%20%C5%81ukasz%20Kaiser%20and%20Illia%20Polosukhin%20Attention%20is%20all%20you%20need%20In%20Advances%20in%20Neural%20Information%20Processing%20Systems%20pp%2059986008%202017"
        },
        {
            "id": "Vinyals_et+al_2015_a",
            "entry": "Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. Pointer networks. In Advances in Neural Information Processing Systems, pp. 2692\u20132700, 2015a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vinyals%2C%20Oriol%20Fortunato%2C%20Meire%20Jaitly%2C%20Navdeep%20Pointer%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vinyals%2C%20Oriol%20Fortunato%2C%20Meire%20Jaitly%2C%20Navdeep%20Pointer%20networks%202015"
        },
        {
            "id": "Vinyals_et+al_2015_b",
            "entry": "Oriol Vinyals, Lukasz Kaiser, Terry Koo, Slav Petrov, Ilya Sutskever, and Geoffrey Hinton. Grammar as a foreign language. In Advances in Neural Information Processing Systems, 2015b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vinyals%2C%20Oriol%20Kaiser%2C%20Lukasz%20Koo%2C%20Terry%20Petrov%2C%20Slav%20Grammar%20as%20a%20foreign%20language%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vinyals%2C%20Oriol%20Kaiser%2C%20Lukasz%20Koo%2C%20Terry%20Petrov%2C%20Slav%20Grammar%20as%20a%20foreign%20language%202015"
        },
        {
            "id": "Wan_et+al_2018_a",
            "entry": "Yao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, and Philip S Yu. Improving automatic source code summarization via deep reinforcement learning. In Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 397\u2013407. ACM, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wan%2C%20Yao%20Zhao%2C%20Zhou%20Yang%2C%20Min%20Xu%2C%20Guandong%20Improving%20automatic%20source%20code%20summarization%20via%20deep%20reinforcement%20learning%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wan%2C%20Yao%20Zhao%2C%20Zhou%20Yang%2C%20Min%20Xu%2C%20Guandong%20Improving%20automatic%20source%20code%20summarization%20via%20deep%20reinforcement%20learning%202018"
        }
    ]
}

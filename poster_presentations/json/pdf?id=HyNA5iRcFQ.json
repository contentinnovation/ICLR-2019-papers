{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "DETECTING EGREGIOUS RESPONSES IN NEURAL SEQUENCE-TO-SEQUENCE MODELS",
        "author": "Tianxing He & James Glass Computer Science and Artificial Intelligence Laboratory Massachusetts Institute of Technology Cambridge, MA, USA {tianxing,glass}@mit.edu",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=HyNA5iRcFQ"
        },
        "abstract": "In this work, we attempt to answer a critical question: whether there exists some input sequence that will cause a well-trained discrete-space neural network sequence-to-sequence (seq2seq) model to generate egregious outputs (aggressive, malicious, attacking, etc.). And if such inputs exist, how to find them efficiently. We adopt an empirical methodology, in which we first create lists of egregious output sequences, and then design a discrete optimization algorithm to find input sequences that will cause the model to generate them. Moreover, the optimization algorithm is enhanced for large vocabulary search and constrained to search for input sequences that are likely to be input by real-world users. In our experiments, we apply this approach to dialogue response generation models trained on three real-world dialogue data-sets: Ubuntu, Switchboard and OpenSubtitles, testing whether the model can generate malicious responses. We demonstrate that given the trigger inputs our algorithm finds, a significant number of malicious sentences are assigned large probability by the model, which reveals an undesirable consequence of standard seq2seq training."
    },
    "keywords": [
        {
            "term": "learning rate",
            "url": "https://en.wikipedia.org/wiki/learning_rate"
        },
        {
            "term": "data set",
            "url": "https://en.wikipedia.org/wiki/data_set"
        },
        {
            "term": "neural machine translation",
            "url": "https://en.wikipedia.org/wiki/neural_machine_translation"
        },
        {
            "term": "recurrent neural network",
            "url": "https://en.wikipedia.org/wiki/recurrent_neural_network"
        },
        {
            "term": "deep neural networks",
            "url": "https://en.wikipedia.org/wiki/deep_neural_networks"
        },
        {
            "term": "optimization algorithm",
            "url": "https://en.wikipedia.org/wiki/optimization_algorithm"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "stochastic gradient descent",
            "url": "https://en.wikipedia.org/wiki/stochastic_gradient_descent"
        },
        {
            "term": "language model",
            "url": "https://en.wikipedia.org/wiki/language_model"
        }
    ],
    "abbreviations": {
        "DNNs": "deep neural networks",
        "RNN": "recurrent neural network",
        "LSTM": "long-short term memory",
        "LM": "language model",
        "SGD": "stochastic gradient descent",
        "NLL": "negative log-likelihood",
        "PGD": "Projected Gradient Descent",
        "LR": "learning rate"
    },
    "highlights": [
        "Research on adversarial attacks (<a class=\"ref-link\" id=\"cGoodfellow_et+al_2014_a\" href=\"#rGoodfellow_et+al_2014_a\">Goodfellow et al, 2014</a>; <a class=\"ref-link\" id=\"cSzegedy_et+al_2013_a\" href=\"#rSzegedy_et+al_2013_a\">Szegedy et al, 2013</a>) has been gaining increasing attention: it has been found that for trained deep neural networks (DNNs), when an imperceptible perturbation is applied to the input, the output of the model can change significantly",
        "Given a target sentence y of length m, and a trained seq2seq model, we aim to find a trigger input sequence x, which is a sequence of one-hot vectors {xt} of length n, which minimizes the negative log-likelihood (NLL) that the model will generate y, we formulate our objective function L(x; y)",
        "We propose a simple and effective algorithm gibbs-enum, which utilizes gradient information to speed up the search, due to the similarity of our algorithm with algorithms used in previous works, we don\u2019t provide an empirical comparison on different discrete optimization algorithms",
        "We provide an empirical answer to the important question of whether well-trained seq2seq models can generate egregious outputs, we hand-craft a list of malicious sentences that should never be generated by a well-behaved dialogue response model, and design an efficient discrete optimization algorithm to find trigger inputs for those outputs",
        "For models trained by popular real-world conversational data-sets, a large number of egregious outputs will be assigned a probability mass larger than \u201cproper\u201d outputs when some trigger input is fed into the model"
    ],
    "key_statements": [
        "Research on adversarial attacks (<a class=\"ref-link\" id=\"cGoodfellow_et+al_2014_a\" href=\"#rGoodfellow_et+al_2014_a\">Goodfellow et al, 2014</a>; <a class=\"ref-link\" id=\"cSzegedy_et+al_2013_a\" href=\"#rSzegedy_et+al_2013_a\">Szegedy et al, 2013</a>) has been gaining increasing attention: it has been found that for trained deep neural networks (DNNs), when an imperceptible perturbation is applied to the input, the output of the model can change significantly",
        "Like images, adversarial examples can be created by directly applying gradient information to the input",
        "Researchers have demonstrated that both text classification models (<a class=\"ref-link\" id=\"cEbrahimi_et+al_2017_a\" href=\"#rEbrahimi_et+al_2017_a\">Ebrahimi et al, 2017</a>) or seq2seq models (<a class=\"ref-link\" id=\"cCheng_et+al_2018_a\" href=\"#rCheng_et+al_2018_a\">Cheng et al, 2018</a>; <a class=\"ref-link\" id=\"cBelinkov_2017_a\" href=\"#rBelinkov_2017_a\">Belinkov & Bisk, 2017</a>) are vulnerable to adversarial attacks. All these efforts focus on crafting adversarial examples that carry the same semantic meaning of the original input, but cause the model to generate wrong outputs",
        "In this work we consider two popular ways of decoding a sentence given an input: 1Here \u201cwell-trained\u201d means that we focus on popular model settings and data-sets, and follow standard training protocols. 2The last word ym is a <EOS> token which indicates the end of a sentence. 3Here h refers to the output layer of long-short term memory, not the cell memory layer.\n1",
        "From row 1 and row 2 in Table 1, we observe first that a non-negligible portion of mal target sentences can be generated when optimizing on the continuous relaxation of the input space, this result motivates the rest of this work: we further investigate whether such input sequences exist for the original discrete input space",
        "In Appendix B, we showed that in the synthetic seq2seq task, there exists no input sequence that will cause the model to generate egregious outputs in the mal list via greedy decoding",
        "Assuming the model is robust during greedy decoding, we explore the question: \u201cWill egregious outputs be generated during sampling?\u201d we ask: \u201cWill the model assign an average word-level log-likelihood for egregious outputs larger than the average log-likelihood assigned to appropriate outputs?\u201d, and formulate this query as o-sample-avg-hit below",
        "O-greedy-hit: A trigger input sequence is found that the model generates the target sentence from greedy decoding",
        "O-sample-avg-k(1)-hit: A trigger input sequence is found that the model generates the target sentence with an average word log-probability larger than a given threshold Tout minus log(k)",
        "O-sample-min-k(1)-hit: A trigger input sequence is found that the model generates the target sentence with a minimum word log-probability larger than a given threshold Tout minus log(k)",
        "The inputs found by our algorithm are usually ungrammatical, are unlikely to be input by real-world users. We address this problem by requiring the language model score of the trigger input to be high enough, and term it io-sample-min/avg-k-hit:",
        "Given a target sentence y of length m, and a trained seq2seq model, we aim to find a trigger input sequence x, which is a sequence of one-hot vectors {xt} of length n, which minimizes the negative log-likelihood (NLL) that the model will generate y, we formulate our objective function L(x; y)",
        "We address different kinds of hit types by adding minor modifications to L(\u00b7) to ignore terms that have already met the requirements",
        "We propose a simple yet effective local updating algorithm to find a trigger input sequence for a target sequence y: every time we focus on a single time slot xt, and find the best one-hot xt while keeping the other parts of x fixed: arg min L(x<t, xt, x>t; y)",
        "We describe experiment setup and results in which the gibbs-enum algorithm is used to check whether egregious outputs exist in seq2seq models for dialogue generation tasks.\n5.1",
        "The task we study is dialogue response generation, in which the seq2seq model is asked to generate a response given a dialogue history",
        "Continuous optimization algorithm used in Section 3.1, which gets a zero hit rate, and shows that we can rely on gibbs-enum to check whether the model will generate target outputs in the other lists",
        "What is the reason for this \u201cegregious outputs\u201d phenomenon8? Here we provide a brief analysis of the target \u201ci will kill you\u201d for Ubuntu data: firstly, \u201ckill\u201d is frequent word because people a talk about killing processes, \u201ckill you\u201d appears in sentences like \u201cyour mom might kill you if you wipe out her win7\u201d or \u201csudo = work or i kill you\u201d, so it\u2019s not surprising that the model would assign high probability to \u201ci will kill you\u201d",
        "We propose a simple and effective algorithm gibbs-enum, which utilizes gradient information to speed up the search, due to the similarity of our algorithm with algorithms used in previous works, we don\u2019t provide an empirical comparison on different discrete optimization algorithms",
        "We propose to use a language model to constrain the trigger inputs, which is a principled and convenient way, and is shown to be very effective",
        "We provide an empirical answer to the important question of whether well-trained seq2seq models can generate egregious outputs, we hand-craft a list of malicious sentences that should never be generated by a well-behaved dialogue response model, and design an efficient discrete optimization algorithm to find trigger inputs for those outputs",
        "For models trained by popular real-world conversational data-sets, a large number of egregious outputs will be assigned a probability mass larger than \u201cproper\u201d outputs when some trigger input is fed into the model"
    ],
    "summary": [
        "Research on adversarial attacks (<a class=\"ref-link\" id=\"cGoodfellow_et+al_2014_a\" href=\"#rGoodfellow_et+al_2014_a\"><a class=\"ref-link\" id=\"cGoodfellow_et+al_2014_a\" href=\"#rGoodfellow_et+al_2014_a\">Goodfellow et al, 2014</a></a>; <a class=\"ref-link\" id=\"cSzegedy_et+al_2013_a\" href=\"#rSzegedy_et+al_2013_a\"><a class=\"ref-link\" id=\"cSzegedy_et+al_2013_a\" href=\"#rSzegedy_et+al_2013_a\">Szegedy et al, 2013</a></a>) has been gaining increasing attention: it has been found that for trained deep neural networks (DNNs), when an imperceptible perturbation is applied to the input, the output of the model can change significantly.",
        "We design algorithms and experiments attempting to answer the question: \u201cGiven a well-trained1 discrete-space neural seq2seq model, do there exist input sequence that will cause it to generate egregious outputs?\u201d We apply them to the dialogue response generation task.",
        "In Appendix B, we showed that in the synthetic seq2seq task, there exists no input sequence that will cause the model to generate egregious outputs in the mal list via greedy decoding.",
        "O-sample-avg-k(1)-hit: A trigger input sequence is found that the model generates the target sentence with an average word log-probability larger than a given threshold Tout minus log(k).",
        "O-sample-min-k(1)-hit: A trigger input sequence is found that the model generates the target sentence with a minimum word log-probability larger than a given threshold Tout minus log(k).",
        "Given a target sentence y of length m, and a trained seq2seq model, we aim to find a trigger input sequence x, which is a sequence of one-hot vectors {xt} of length n, which minimizes the negative log-likelihood (NLL) that the model will generate y, we formulate our objective function L(x; y)",
        "With the trained seq2seq models, the gibbs-enum algorithm is applied to find trigger inputs for targets in the normal, mal, and random lists with respect to different hit types.",
        "Continuous optimization algorithm used in Section 3.1, which gets a zero hit rate, and shows that we can rely on gibbs-enum to check whether the model will generate target outputs in the other lists.",
        "For the mal list, which is the major concern of this work, we observe that for both models on the Ubuntu and Switchboard data-sets, no o-greedy-hit has been achieved.",
        "The most striking result in this experiment is that trigger inputs for a significant percentage of targets in the mal list have been found w.r.t to io-sample-avg-k1-hit for all data-sets.",
        "Trigger inputs for larger than 10% of mal targets w.r.t io-sample-min-k1-hit have been found for the Ubuntu and OpenSubtitles data-sets.",
        "We provide an empirical answer to the important question of whether well-trained seq2seq models can generate egregious outputs, we hand-craft a list of malicious sentences that should never be generated by a well-behaved dialogue response model, and design an efficient discrete optimization algorithm to find trigger inputs for those outputs.",
        "We believe this work is a significant step towards understanding neural seq2seq model\u2019s behavior, and has important implications as for applying seq2seq models into real-world applications"
    ],
    "headline": "We demonstrate that given the trigger inputs our algorithm finds, a significant number of malicious sentences are assigned large probability by the model, which reveals an undesirable consequence of standard seq2seq training",
    "reference_links": [
        {
            "id": "Belinkov_2017_a",
            "entry": "Yonatan Belinkov and Yonatan Bisk. Synthetic and natural noise both break neural machine translation. CoRR, abs/1711.02173, 2017. URL http://arxiv.org/abs/1711.02173.",
            "url": "http://arxiv.org/abs/1711.02173",
            "arxiv_url": "https://arxiv.org/pdf/1711.02173"
        },
        {
            "id": "Chen_et+al_2017_a",
            "entry": "Hongge Chen, Huan Zhang, Pin-Yu Chen, Jinfeng Yi, and Cho-Jui Hsieh. Show-and-fool: Crafting adversarial examples for neural image captioning. CoRR, abs/1712.02051, 2017. URL http://arxiv.org/abs/1712.02051.",
            "url": "http://arxiv.org/abs/1712.02051",
            "arxiv_url": "https://arxiv.org/pdf/1712.02051"
        },
        {
            "id": "Cheng_et+al_2018_a",
            "entry": "Minhao Cheng, Jinfeng Yi, Huan Zhang, Pin-Yu Chen, and Cho-Jui Hsieh. Seq2sick: Evaluating the robustness of sequence-to-sequence models with adversarial examples. CoRR, abs/1803.01128, 2018. URL http://arxiv.org/abs/1803.01128.",
            "url": "http://arxiv.org/abs/1803.01128",
            "arxiv_url": "https://arxiv.org/pdf/1803.01128"
        },
        {
            "id": "Cho_et+al_2014_a",
            "entry": "Kyunghyun Cho, Bart van Merrienboer, Calar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder\u2013decoder for statistical machine translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1724\u20131734, Doha, Qatar, October 2014. Association for Computational Linguistics. URL http://www.aclweb.org/anthology/ D14-1179.",
            "url": "http://www.aclweb.org/anthology/D14-1179",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cho%2C%20Kyunghyun%20van%20Merrienboer%2C%20Bart%20Gulcehre%2C%20Calar%20Bahdanau%2C%20Dzmitry%20Learning%20phrase%20representations%20using%20rnn%20encoder%E2%80%93decoder%20for%20statistical%20machine%20translation%202014-10"
        },
        {
            "id": "Ebrahimi_et+al_2017_a",
            "entry": "Javid Ebrahimi, Anyi Rao, Daniel Lowd, and Dejing Dou. Hotflip: White-box adversarial examples for NLP. CoRR, abs/1712.06751, 2017. URL http://arxiv.org/abs/1712.06751.",
            "url": "http://arxiv.org/abs/1712.06751",
            "arxiv_url": "https://arxiv.org/pdf/1712.06751"
        },
        {
            "id": "Goodfellow_et+al_2014_a",
            "entry": "Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. CoRR, abs/1412.6572, 2014. URL http://arxiv.org/abs/1412.6572.",
            "url": "http://arxiv.org/abs/1412.6572",
            "arxiv_url": "https://arxiv.org/pdf/1412.6572"
        },
        {
            "id": "Hochreiter_1997_a",
            "entry": "Sepp Hochreiter and Jurgen Schmidhuber. Long short-term memory. Neural computation, 9(8): 1735\u20131780, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hochreiter%2C%20Sepp%20Schmidhuber%2C%20Jurgen%20Long%20short-term%20memory%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hochreiter%2C%20Sepp%20Schmidhuber%2C%20Jurgen%20Long%20short-term%20memory%201997"
        },
        {
            "id": "Jia_2017_a",
            "entry": "Robin Jia and Percy Liang. Adversarial examples for evaluating reading comprehension systems. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, EMNLP 2017, Copenhagen, Denmark, September 9-11, 2017, pp. 2021\u20132031, 2017. URL https://aclanthology.info/papers/D17-1215/d17-1215.",
            "url": "https://aclanthology.info/papers/D17-1215/d17-1215",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jia%2C%20Robin%20Liang%2C%20Percy%20Adversarial%20examples%20for%20evaluating%20reading%20comprehension%20systems%202017-09-09"
        },
        {
            "id": "Li_et+al_2016_a",
            "entry": "Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. A diversity-promoting objective function for neural conversation models. In NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, San Diego California, USA, June 12-17, 2016, pp. 110\u2013119, 2016. URL http://aclweb.org/anthology/N/N16/N16-1014.pdf.",
            "url": "http://aclweb.org/anthology/N/N16/N16-1014.pdf"
        },
        {
            "id": "Liang_et+al_2018_a",
            "entry": "Bin Liang, Hongcheng Li, Miaoqiang Su, Pan Bian, Xirong Li, and Wenchang Shi. Deep text classification can be fooled. In Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018, July 13-19, 2018, Stockholm, Sweden., pp. 4208\u20134215, 2018. doi: 10.24963/ijcai.2018/585. URL https://doi.org/10.24963/ijcai.2018/585.",
            "crossref": "https://dx.doi.org/10.24963/ijcai.2018/585",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.24963/ijcai.2018/585"
        },
        {
            "id": "Lowe_et+al_2015_a",
            "entry": "Ryan Lowe, Nissan Pow, Iulian Serban, and Joelle Pineau. The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems. CoRR, abs/1506.08909, 2015. URL http://arxiv.org/abs/1506.08909.",
            "url": "http://arxiv.org/abs/1506.08909",
            "arxiv_url": "https://arxiv.org/pdf/1506.08909"
        },
        {
            "id": "Luong_et+al_2015_a",
            "entry": "Thang Luong, Hieu Pham, and Christopher D. Manning. Effective approaches to attention-based neural machine translation. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 1412\u20131421. Association for Computational Linguistics, 2015. doi: 10.18653/v1/D15-1166. URL http://www.aclweb.org/anthology/D15-1166.",
            "crossref": "https://dx.doi.org/10.18653/v1/D15-1166",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.18653/v1/D15-1166"
        },
        {
            "id": "Madry_et+al_2017_a",
            "entry": "Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. CoRR, abs/1706.06083, 2017. URL http://arxiv.org/abs/1706.06083.",
            "url": "http://arxiv.org/abs/1706.06083",
            "arxiv_url": "https://arxiv.org/pdf/1706.06083"
        },
        {
            "id": "Mikolov_2012_a",
            "entry": "Tomas Mikolov. Statistical language models based on neural networks. PhD thesis, Brno University of Technology, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mikolov%2C%20Tomas%20Statistical%20language%20models%20based%20on%20neural%20networks%202012"
        },
        {
            "id": "Mikolov_et+al_2010_a",
            "entry": "Tomas Mikolov, Martin Karafiat, Lukas Burget, Jan Cernocky, and Sanjeev Khudanpur. Recurrent neural network based language model. In INTERSPEECH 2010, 11th Annual Conference of the International Speech Communication Association, Makuhari, Chiba, Japan, September 26-30, 2010, pp. 1045\u20131048, 2010. URL http://www.isca-speech.org/archive/interspeech_2010/i10_1045.html.",
            "url": "http://www.isca-speech.org/archive/interspeech_2010/i10_1045.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mikolov%2C%20Tomas%20Karafiat%2C%20Martin%20Burget%2C%20Lukas%20Cernocky%2C%20Jan%20Recurrent%20neural%20network%20based%20language%20model%202010-09-26"
        },
        {
            "id": "Papernot_et+al_2016_a",
            "entry": "Nicolas Papernot, Patrick D. McDaniel, Ananthram Swami, and Richard E. Harang. Crafting adversarial input sequences for recurrent neural networks. In 2016 IEEE Military Communications Conference, MILCOM 2016, Baltimore, MD, USA, November 1-3, 2016, pp. 49\u201354, 2016. doi: 10.1109/MILCOM.2016.7795300. URL https://doi.org/10.1109/MILCOM.2016.7795300.",
            "crossref": "https://dx.doi.org/10.1109/MILCOM.2016.7795300",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/MILCOM.2016.7795300"
        },
        {
            "id": "Papernot_et+al_2017_a",
            "entry": "Nicolas Papernot, Patrick D. McDaniel, Ian J. Goodfellow, Somesh Jha, Z. Berkay Celik, and Ananthram Swami. Practical black-box attacks against machine learning. In Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, AsiaCCS 2017, Abu Dhabi, United Arab Emirates, April 2-6, 2017, pp. 506\u2013519, 2017. doi: 10.1145/3052973.3053009. URL http://doi.acm.org/10.1145/3052973.3053009.",
            "crossref": "https://dx.doi.org/10.1145/3052973.3053009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/3052973.3053009"
        },
        {
            "id": "Samanta_2017_a",
            "entry": "Suranjana Samanta and Sameep Mehta. Towards crafting text adversarial samples. CoRR, abs/1707.02812, 2017. URL http://arxiv.org/abs/1707.02812.",
            "url": "http://arxiv.org/abs/1707.02812",
            "arxiv_url": "https://arxiv.org/pdf/1707.02812"
        },
        {
            "id": "Sutskever_et+al_2014_a",
            "entry": "Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. Sequence to sequence learning with neural networks. In Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems 2014, December 8-13 2014, Montreal, Quebec, Canada, pp. 3104\u20133112, 2014. URL http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.",
            "url": "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sutskever%2C%20Ilya%20Vinyals%2C%20Oriol%20Le%2C%20Quoc%20V.%20Sequence%20to%20sequence%20learning%20with%20neural%20networks%202014-12-08"
        },
        {
            "id": "Szegedy_et+al_2013_a",
            "entry": "Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J. Goodfellow, and Rob Fergus. Intriguing properties of neural networks. CoRR, abs/1312.6199, 2013. URL http://arxiv.org/abs/1312.6199.",
            "url": "http://arxiv.org/abs/1312.6199",
            "arxiv_url": "https://arxiv.org/pdf/1312.6199"
        },
        {
            "id": "Tibshirani_1994_a",
            "entry": "Robert Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society, Series B, 58:267\u2013288, 1994.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tibshirani%2C%20Robert%20Regression%20shrinkage%20and%20selection%20via%20the%20lasso%201994",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tibshirani%2C%20Robert%20Regression%20shrinkage%20and%20selection%20via%20the%20lasso%201994"
        },
        {
            "id": "Tiedemann_2009_a",
            "entry": "Jorg Tiedemann. News from OPUS - A collection of multilingual parallel corpora with tools and interfaces. In N. Nicolov, K. Bontcheva, G. Angelova, and R. Mitkov (eds.), Recent Advances in Natural Language Processing, volume V, pp. 237\u2013248. John Benjamins, Amsterdam/Philadelphia, Borovets, Bulgaria, 2009. ISBN 978 90 272 4825 1.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tiedemann%2C%20Jorg%20News%20from%20OPUS%20-%20A%20collection%20of%20multilingual%20parallel%20corpora%20with%20tools%20and%20interfaces%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tiedemann%2C%20Jorg%20News%20from%20OPUS%20-%20A%20collection%20of%20multilingual%20parallel%20corpora%20with%20tools%20and%20interfaces%202009"
        }
    ]
}

{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "OF WIKIPEDIA: KNOWLEDGE-POWERED CONVERSATIONAL AGENTS",
        "author": "Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, Jason Weston Facebook AI Research {edinan,roller,kshuster,angelafan,michaelauli,jase}@fb.com",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=r1l73iRqKm"
        },
        "abstract": "In open-domain dialogue intelligent agents should exhibit the use of knowledge, however there are few convincing demonstrations of this to date. The most popular sequence to sequence models typically \u201cgenerate and hope\u201d generic utterances that can be memorized in the weights of the model when mapping from input utterance(s) to output, rather than employing recalled knowledge as context. Use of knowledge has so far proved difficult, in part because of the lack of a supervised learning benchmark task which exhibits knowledgeable open dialogue with clear grounding. To that end we collect and release a large dataset with conversations directly grounded with knowledge retrieved from Wikipedia. We then design architectures capable of retrieving knowledge, reading and conditioning on it, and finally generating natural responses. Our best performing dialogue models are able to conduct knowledgeable discussions on open-domain topics as evaluated by automatic metrics and human evaluations, while our new benchmark allows for measuring further improvements in this important research direction."
    },
    "keywords": [
        {
            "term": "natural language",
            "url": "https://en.wikipedia.org/wiki/natural_language"
        },
        {
            "term": "Information Retrieval",
            "url": "https://en.wikipedia.org/wiki/Information_Retrieval"
        },
        {
            "term": "Wikipedia",
            "url": "https://en.wikipedia.org/wiki/Wikipedia"
        }
    ],
    "abbreviations": {
        "IR": "Information Retrieval",
        "K.D.": "knowledge dropout",
        "K. D.": "Knowledge dropout"
    },
    "highlights": [
        "One of the key goals of AI, and the ultimate the goal of natural language research, is for humans to be able to talk to machines",
        "In order to get close to this goal, machines must master a number of skills: to be able to comprehend language, employ memory to retain and recall knowledge, to reason about these concepts together, and output a response that both fulfills functional goals in the conversation while simultaneously being captivating to their human speaking partner",
        "To train and evaluate such models, we collect the Wizard of Wikipedia dataset, a large collection of open-domain dialogues grounded by Wikipedia knowledge, and demonstrated the effectiveness of our models in automatic and human experiments",
        "Our new publicly available benchmark aims to encourage further model exploration, and we expect such efforts will result in significant advances in this important research direction",
        "There is much future work to be explored using our task and dataset. Some of these include: (i) bridging the gap between the engagingness of retrieval responses versus the ability of generative models to work on new knowledge and topics, learning to retrieve and reason simultaneously rather than using a separate Information Retrieval component; and investigating the relationship between knowledge-grounded dialogue and existing QA tasks which employ such Information Retrieval systems"
    ],
    "key_statements": [
        "One of the key goals of AI, and the ultimate the goal of natural language research, is for humans to be able to talk to machines",
        "In order to get close to this goal, machines must master a number of skills: to be able to comprehend language, employ memory to retain and recall knowledge, to reason about these concepts together, and output a response that both fulfills functional goals in the conversation while simultaneously being captivating to their human speaking partner",
        "To train and evaluate such models, we collect the Wizard of Wikipedia dataset, a large collection of open-domain dialogues grounded by Wikipedia knowledge, and demonstrated the effectiveness of our models in automatic and human experiments",
        "Our new publicly available benchmark aims to encourage further model exploration, and we expect such efforts will result in significant advances in this important research direction",
        "There is much future work to be explored using our task and dataset. Some of these include: (i) bridging the gap between the engagingness of retrieval responses versus the ability of generative models to work on new knowledge and topics, learning to retrieve and reason simultaneously rather than using a separate Information Retrieval component; and investigating the relationship between knowledge-grounded dialogue and existing QA tasks which employ such Information Retrieval systems"
    ],
    "summary": [
        "One of the key goals of AI, and the ultimate the goal of natural language research, is for humans to be able to talk to machines.",
        "In the Two-stage version, we employ two separately trained models for each of these two tasks, knowledge selection and utterance prediction.",
        "Before looking at the full Wizard dialogue task, we assess the ability of models to predict the knowledge selected by human wizards in the dataset given the dialogue history.",
        "We use the best performing Transformer model reported here for our two-stage generative Memory Network in the full dialogue task.",
        "We evaluate our models on the full task of dialogue generation given knowledge in two settings: given the gold knowledge sentence chosen by a human, or where the model needs to predict which knowledge to use.",
        "Generative Experiments We compare our generative End-to-end and Two-stage Transformer Memory Network models to two more baselines: repeating the last utterance, and a generative Transformer model trained to respond to dialogue but without access to knowledge.",
        "We calculate a metric we call the Wiki F1 sore: the F1 overlap of the model\u2019s utterances with the first 10 sentences of the Wikipedia page for the chosen topic as a proxy for how much knowledge the model exhibits.",
        "The human engagingness differences between retriever models with and without knowledge are not significant, but note they both trend toward use of knowledge due to the candidate sentences retrieved, with the knowledgeable version obtaining significantly higher Wiki F1 scores in both seen and unseen test sets.",
        "In this work we build dialogue agents which are able to employ large memory systems containing encyclopedic knowledge about the world in order to conduct engaging open-domain conversations.",
        "We develop a set of architectures, Transformer Memory Network models, that are capable of retrieving and attending to such knowledge and outputting a response, either in retrieval or generative modes.",
        "To train and evaluate such models, we collect the Wizard of Wikipedia dataset, a large collection of open-domain dialogues grounded by Wikipedia knowledge, and demonstrated the effectiveness of our models in automatic and human experiments.",
        "Some of these include: (i) bridging the gap between the engagingness of retrieval responses versus the ability of generative models to work on new knowledge and topics, learning to retrieve and reason simultaneously rather than using a separate IR component; and investigating the relationship between knowledge-grounded dialogue and existing QA tasks which employ such IR systems.",
        "The aim is for those strands to come together to obtain an engaging and knowledgeable conversational agent"
    ],
    "headline": "We show their ability to execute engaging knowledgeable conversations with humans, compared to a number of baselines such as standard Memory Networks or Transformers",
    "reference_links": [
        {
            "id": "Bernsen_et+al_2012_a",
            "entry": "Niels O Bernsen, Hans Dybkj\u00e6r, and Laila Dybkj\u00e6r. Designing interactive speech systems: From first ideas to user testing. Springer Science & Business Media, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bernsen%2C%20Niels%20O.%20Dybkj%C3%A6r%2C%20Hans%20Dybkj%C3%A6r%2C%20Laila%20Designing%20interactive%20speech%20systems%3A%20From%20first%20ideas%20to%20user%20testing%202012"
        },
        {
            "id": "Antoine_2017_a",
            "entry": "Antoine Bordes, Y-Lan Boureau, and Jason Weston. Learning end-to-end goal-oriented dialog. In Proceedings of the International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Antoine%20Bordes%2C%20Y.-Lan%20Boureau%20Weston%2C%20Jason%20Learning%20end-to-end%20goal-oriented%20dialog%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Antoine%20Bordes%2C%20Y.-Lan%20Boureau%20Weston%2C%20Jason%20Learning%20end-to-end%20goal-oriented%20dialog%202017"
        },
        {
            "id": "Cer_et+al_2018_a",
            "entry": "Daniel Cer, Yinfei Yang, Sheng yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St. John, Noah Constant, Mario Guajardo-Cespedes, Steve Yuan, Chris Tar, Yun-Hsuan Sung, Brian Strope, and Ray Kurzweil. Universal sentence encoder. arXiv preprint arXiv:1803.11175, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.11175"
        },
        {
            "id": "Danqi_2017_a",
            "entry": "Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. Reading wikipedia to answer opendomain questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pp. 1870\u20131879. Association for Computational Linguistics, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Danqi%20Chen%20Adam%20Fisch%20Jason%20Weston%20and%20Antoine%20Bordes%20Reading%20wikipedia%20to%20answer%20opendomain%20questions%20In%20Proceedings%20of%20the%2055th%20Annual%20Meeting%20of%20the%20Association%20for%20Computational%20Linguistics%20pp%2018701879%20Association%20for%20Computational%20Linguistics%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Danqi%20Chen%20Adam%20Fisch%20Jason%20Weston%20and%20Antoine%20Bordes%20Reading%20wikipedia%20to%20answer%20opendomain%20questions%20In%20Proceedings%20of%20the%2055th%20Annual%20Meeting%20of%20the%20Association%20for%20Computational%20Linguistics%20pp%2018701879%20Association%20for%20Computational%20Linguistics%202017"
        },
        {
            "id": "Choi_et+al_2018_a",
            "entry": "Eunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih, Yejin Choi, Percy Liang, and Luke Zettlemoyer. QuAC: Question answering in context. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Choi%2C%20Eunsol%20He%2C%20He%20Iyyer%2C%20Mohit%20Yatskar%2C%20Mark%20QuAC%3A%20Question%20answering%20in%20context%202018-10",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Choi%2C%20Eunsol%20He%2C%20He%20Iyyer%2C%20Mohit%20Yatskar%2C%20Mark%20QuAC%3A%20Question%20answering%20in%20context%202018-10"
        },
        {
            "id": "Dodge_et+al_2016_a",
            "entry": "Jesse Dodge, Andreea Gane, Xiang Zhang, Antoine Bordes, Sumit Chopra, Alexander Miller, Arthur Szlam, and Jason Weston. Evaluating prerequisite qualities for learning end-to-end dialog systems. In Proceedings of the International Conference on Learning Representations (ICLR), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dodge%2C%20Jesse%20Gane%2C%20Andreea%20Zhang%2C%20Xiang%20Bordes%2C%20Antoine%20Evaluating%20prerequisite%20qualities%20for%20learning%20end-to-end%20dialog%20systems%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dodge%2C%20Jesse%20Gane%2C%20Andreea%20Zhang%2C%20Xiang%20Bordes%2C%20Antoine%20Evaluating%20prerequisite%20qualities%20for%20learning%20end-to-end%20dialog%20systems%202016"
        },
        {
            "id": "Asri_et+al_2017_a",
            "entry": "Layla El Asri, Hannes Schulz, Shikhar Sharma, Jeremie Zumer, Justin Harris, Emery Fine, Rahul Mehrotra, and Kaheer Suleman. Frames: a corpus for adding memory to goal-oriented dialogue systems. In Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue, pp. 207\u2013219, Saarbrucken, Germany, August 2017. Association for Computational Linguistics.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Asri%2C%20Layla%20El%20Schulz%2C%20Hannes%20Sharma%2C%20Shikhar%20Zumer%2C%20Jeremie%20Frames%3A%20a%20corpus%20for%20adding%20memory%20to%20goal-oriented%20dialogue%20systems%202017-08",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Asri%2C%20Layla%20El%20Schulz%2C%20Hannes%20Sharma%2C%20Shikhar%20Zumer%2C%20Jeremie%20Frames%3A%20a%20corpus%20for%20adding%20memory%20to%20goal-oriented%20dialogue%20systems%202017-08"
        },
        {
            "id": "Fan_et+al_2018_a",
            "entry": "Angela Fan, David Grangier, and Michael Auli. Controllable abstractive summarization. In Proceedings of the 2nd Workshop on Neural Machine Translation and Generation, pp. 45\u201354. Association for Computational Linguistics, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fan%2C%20Angela%20Grangier%2C%20David%20Auli%2C%20Michael%20Controllable%20abstractive%20summarization%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fan%2C%20Angela%20Grangier%2C%20David%20Auli%2C%20Michael%20Controllable%20abstractive%20summarization%202018"
        },
        {
            "id": "Ghazvininejad_et+al_2018_a",
            "entry": "Marjan Ghazvininejad, Chris Brockett, Ming-Wei Chang, Bill Dolan, Jianfeng Gao, Wen-tau Yih, and Michel Galley. A knowledge-grounded neural conversation model. In Proceedings of the Conference on Association for the Advancement of Artificial Intelligence (AAAI), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ghazvininejad%2C%20Marjan%20Brockett%2C%20Chris%20Chang%2C%20Ming-Wei%20Dolan%2C%20Bill%20A%20knowledge-grounded%20neural%20conversation%20model%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ghazvininejad%2C%20Marjan%20Brockett%2C%20Chris%20Chang%2C%20Ming-Wei%20Dolan%2C%20Bill%20A%20knowledge-grounded%20neural%20conversation%20model%202018"
        },
        {
            "id": "Henderson_et+al_2014_a",
            "entry": "Matthew Henderson, Blaise Thomson, and Jason D Williams. The second dialog state tracking challenge. In Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pp. 263\u2013272, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Henderson%2C%20Matthew%20Thomson%2C%20Blaise%20Williams%2C%20Jason%20D.%20The%20second%20dialog%20state%20tracking%20challenge%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Henderson%2C%20Matthew%20Thomson%2C%20Blaise%20Williams%2C%20Jason%20D.%20The%20second%20dialog%20state%20tracking%20challenge%202014"
        },
        {
            "id": "Henderson_et+al_2017_a",
            "entry": "Matthew Henderson, Rami Al-Rfou, Brian Strope, Yun-hsuan Sung, L\u2019aszl\u2019o Luk\u2019acs, Ruiqi Guo, Sanjiv Kumar, Balint Miklos, and Ray Kurzweil. Efficient Natural Language Response Suggestion for Smart Reply. arXiv preprint arXiv:1705.00652, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.00652"
        },
        {
            "id": "Li_et+al_2016_a",
            "entry": "Jiwei Li, Will Monroe, and Daniel Jurafsky. A simple, fast diverse decoding algorithm for neural generation. arXiv preprint arXiv:1611.08562, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.08562"
        },
        {
            "id": "Mazare_et+al_2018_a",
            "entry": "Pierre-Emmanuel Mazare, Samuel Humeau, Martin Raison, and Antoine Bordes. Training millions of personalized dialogue agents. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 2018. Association for Computational Linguistics.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mazare%2C%20Pierre-Emmanuel%20Humeau%2C%20Samuel%20Raison%2C%20Martin%20Bordes%2C%20Antoine%20Training%20millions%20of%20personalized%20dialogue%20agents%202018-10",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mazare%2C%20Pierre-Emmanuel%20Humeau%2C%20Samuel%20Raison%2C%20Martin%20Bordes%2C%20Antoine%20Training%20millions%20of%20personalized%20dialogue%20agents%202018-10"
        },
        {
            "id": "Moghe_et+al_2018_a",
            "entry": "Nikita Moghe, Siddhartha Arora, Suman Banerjee, and Mitesh M. Khapra. Towards exploiting background knowledge for building conversation systems. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 2322\u20132332. Association for Computational Linguistics, 2018. URL http://aclweb.org/anthology/D18-1255.",
            "url": "http://aclweb.org/anthology/D18-1255",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Moghe%2C%20Nikita%20Arora%2C%20Siddhartha%20Banerjee%2C%20Suman%20Khapra%2C%20Mitesh%20M.%20Towards%20exploiting%20background%20knowledge%20for%20building%20conversation%20systems%202018"
        },
        {
            "id": "Parthasarathi_2018_a",
            "entry": "Prasanna Parthasarathi and Joelle Pineau. Extending neural generative conversational model using external knowledge sources. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Parthasarathi%2C%20Prasanna%20Pineau%2C%20Joelle%20Extending%20neural%20generative%20conversational%20model%20using%20external%20knowledge%20sources%202018-10",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Parthasarathi%2C%20Prasanna%20Pineau%2C%20Joelle%20Extending%20neural%20generative%20conversational%20model%20using%20external%20knowledge%20sources%202018-10"
        },
        {
            "id": "Rajpurkar_et+al_2016_a",
            "entry": "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. SQuAD: 100,000+ questions for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pp. 2383\u20132392, Austin, Texas, November 2016. Association for Computational Linguistics.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rajpurkar%2C%20Pranav%20Zhang%2C%20Jian%20Lopyrev%2C%20Konstantin%20Liang%2C%20Percy%20SQuAD%3A%20100%2C000%2B%20questions%20for%20machine%20comprehension%20of%20text%202016-11",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rajpurkar%2C%20Pranav%20Zhang%2C%20Jian%20Lopyrev%2C%20Konstantin%20Liang%2C%20Percy%20SQuAD%3A%20100%2C000%2B%20questions%20for%20machine%20comprehension%20of%20text%202016-11"
        },
        {
            "id": "Sennrich_et+al_2016_a",
            "entry": "Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words with subword units. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pp. 1715\u20131725, Berlin, Germany, August 2016. Association for Computational Linguistics.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sennrich%2C%20Rico%20Haddow%2C%20Barry%20Birch%2C%20Alexandra%20Neural%20machine%20translation%20of%20rare%20words%20with%20subword%20units%202016-08",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sennrich%2C%20Rico%20Haddow%2C%20Barry%20Birch%2C%20Alexandra%20Neural%20machine%20translation%20of%20rare%20words%20with%20subword%20units%202016-08"
        },
        {
            "id": "Serban_et+al_2016_a",
            "entry": "Iulian Vlad Serban, Ryan Lowe, Laurent Charlin, and Joelle Pineau. Generative deep neural networks for dialogue: A short review. arXiv preprint arXiv:1611.06216, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.06216"
        },
        {
            "id": "Sordoni_et+al_2015_a",
            "entry": "Alessandro Sordoni, Michel Galley, Michael Auli, Chris Brockett, Yangfeng Ji, Margaret Mitchell, Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. A neural network approach to context-sensitive generation of conversational responses. arXiv preprint arXiv:1506.06714, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1506.06714"
        },
        {
            "id": "Sukhbaatar_et+al_2015_a",
            "entry": "Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, et al. End-to-end memory networks. In Advances in Neural Information Processing Systems, pp. 2440\u20132448, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sukhbaatar%2C%20Sainbayar%20Weston%2C%20Jason%20Fergus%2C%20Rob%20End-to-end%20memory%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sukhbaatar%2C%20Sainbayar%20Weston%2C%20Jason%20Fergus%2C%20Rob%20End-to-end%20memory%20networks%202015"
        },
        {
            "id": "Sutskever_et+al_2014_a",
            "entry": "Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks. In Advances in Neural Information Processing Systems, pp. 3104\u20133112, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sutskever%2C%20Ilya%20Vinyals%2C%20Oriol%20Le%2C%20Quoc%20V.%20Sequence%20to%20sequence%20learning%20with%20neural%20networks%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sutskever%2C%20Ilya%20Vinyals%2C%20Oriol%20Le%2C%20Quoc%20V.%20Sequence%20to%20sequence%20learning%20with%20neural%20networks%202014"
        },
        {
            "id": "Vaswani_et+al_2017_a",
            "entry": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in Neural Information Processing Systems, pp. 5998\u20136008, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ashish%20Vaswani%20Noam%20Shazeer%20Niki%20Parmar%20Jakob%20Uszkoreit%20Llion%20Jones%20Aidan%20N%20Gomez%20%C5%81ukasz%20Kaiser%20and%20Illia%20Polosukhin%20Attention%20is%20all%20you%20need%20In%20Advances%20in%20Neural%20Information%20Processing%20Systems%20pp%2059986008%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ashish%20Vaswani%20Noam%20Shazeer%20Niki%20Parmar%20Jakob%20Uszkoreit%20Llion%20Jones%20Aidan%20N%20Gomez%20%C5%81ukasz%20Kaiser%20and%20Illia%20Polosukhin%20Attention%20is%20all%20you%20need%20In%20Advances%20in%20Neural%20Information%20Processing%20Systems%20pp%2059986008%202017"
        },
        {
            "id": "Vijayakumar_et+al_2016_a",
            "entry": "Ashwin K. Vijayakumar, Michael Cogswell, Ramprasaath R. Selvaraju, Qing Sun, Stefan Lee, David J. Crandall, and Dhruv Batra. Diverse beam search: Decoding diverse solutions from neural sequence models. arXiv preprint arXiv:1610.02424, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1610.02424"
        },
        {
            "id": "Oriol_2015_a",
            "entry": "Oriol Vinyals and Quoc Le. A neural conversational model. In Proceedings of the 31st International Conference on Machine Learning, Deep Learning Workshop, Lille, France, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Oriol%20Vinyals%20and%20Quoc%20Le%20A%20neural%20conversational%20model%20In%20Proceedings%20of%20the%2031st%20International%20Conference%20on%20Machine%20Learning%20Deep%20Learning%20Workshop%20Lille%20France%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Oriol%20Vinyals%20and%20Quoc%20Le%20A%20neural%20conversational%20model%20In%20Proceedings%20of%20the%2031st%20International%20Conference%20on%20Machine%20Learning%20Deep%20Learning%20Workshop%20Lille%20France%202015"
        },
        {
            "id": "Published_2019_a",
            "entry": "Published as a conference paper at ICLR 2019 Tsung-Hsien Wen, David Vandyke, Nikola Mrksic, Milica Gasic, Lina M Rojas-Barahona, Pei-Hao",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Published%20as%20a%20conference%20paper%20at%20ICLR%202019%20TsungHsien%20Wen%20David%20Vandyke%20Nikola%20Mrksic%20Milica%20Gasic%20Lina%20M%20RojasBarahona%20PeiHao"
        },
        {
            "id": "Su_2016_a",
            "entry": "Su, Stefan Ultes, and Steve Young. A network-based end-to-end trainable task-oriented dialogue system. arXiv preprint arXiv:1604.04562, 2016. Ledell Wu, Adam Fisch, Sumit Chopra, Keith Adams, Antoine Bordes, and Jason Weston. Starspace: Embed all the things! arXiv preprint arXiv:1709.03856, 2017. Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason Weston. Personalizing dialogue agents: I have a dog, do you have pets too? In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, pp. 2204\u20132213, Melbourne, Australia, July 2018. Association for Computational Linguistics. Hao Zhou, Tom Young, Minlie Huang, Haizhou Zhao, Jingfang Xu, and Xiaoyan Zhu. Commonsense knowledge aware conversation generation with graph attention. In Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI), pp. 4623\u20134629. International Joint Conferences on Artificial Intelligence Organization, 7 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1604.04562"
        }
    ]
}

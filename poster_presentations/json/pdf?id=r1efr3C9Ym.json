{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "INTERPOLATION-PREDICTION NETWORKS FOR IRREGULARLY SAMPLED TIME SERIES",
        "author": "Satya Narayan Shukla College of Information and Computer Sciences University of Massachusetts Amherst snshukla@cs.umass.edu",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=r1efr3C9Ym"
        },
        "abstract": "In this paper, we present a new deep learning architecture for addressing the problem of supervised learning with sparse and irregularly sampled multivariate time series. The architecture is based on the use of a semi-parametric interpolation network followed by the application of a prediction network. The interpolation network allows for information to be shared across multiple dimensions of a multivariate time series during the interpolation stage, while any standard deep learning model can be used for the prediction network. This work is motivated by the analysis of physiological time series data in electronic health records, which are sparse, irregularly sampled, and multivariate. We investigate the performance of this architecture on both classification and regression tasks, showing that our approach outperforms a range of baseline and recently proposed models.1"
    },
    "keywords": [
        {
            "term": "gated recurrent unit",
            "url": "https://en.wikipedia.org/wiki/gated_recurrent_unit"
        },
        {
            "term": "supervised learning",
            "url": "https://en.wikipedia.org/wiki/supervised_learning"
        },
        {
            "term": "multivariate time series",
            "url": "https://en.wikipedia.org/wiki/multivariate_time_series"
        },
        {
            "term": "time series",
            "url": "https://en.wikipedia.org/wiki/time_series"
        },
        {
            "term": "deep learning",
            "url": "https://en.wikipedia.org/wiki/deep_learning"
        },
        {
            "term": "recurrent neural networks",
            "url": "https://en.wikipedia.org/wiki/recurrent_neural_networks"
        },
        {
            "term": "gaussian process",
            "url": "https://en.wikipedia.org/wiki/gaussian_process"
        },
        {
            "term": "Support Vector Machines",
            "url": "https://en.wikipedia.org/wiki/Support_Vector_Machines"
        },
        {
            "term": "electronic health records",
            "url": "https://en.wikipedia.org/wiki/electronic_health_records"
        },
        {
            "term": "Random Forests",
            "url": "https://en.wikipedia.org/wiki/Random_Forest"
        }
    ],
    "abbreviations": {
        "EHRs": "electronic health records",
        "GRU": "gated recurrent unit",
        "SVM": "Support Vector Machines",
        "RF": "Random Forests",
        "SVR": "Support Vector Regression",
        "RNNs": "recurrent neural networks",
        "EV": "explained variation"
    },
    "highlights": [
        "Over the last several years, there has been significant progress in developing specialized models and architectures that can accommodate sparse and irregularly sampled time series as input (<a class=\"ref-link\" id=\"cMarlin_et+al_2012_a\" href=\"#rMarlin_et+al_2012_a\"><a class=\"ref-link\" id=\"cMarlin_et+al_2012_a\" href=\"#rMarlin_et+al_2012_a\">Marlin et al, 2012</a></a>; <a class=\"ref-link\" id=\"cLi_2015_a\" href=\"#rLi_2015_a\"><a class=\"ref-link\" id=\"cLi_2015_a\" href=\"#rLi_2015_a\">Li & Marlin, 2015</a></a>; 2016; <a class=\"ref-link\" id=\"cLipton_et+al_2016_a\" href=\"#rLipton_et+al_2016_a\"><a class=\"ref-link\" id=\"cLipton_et+al_2016_a\" href=\"#rLipton_et+al_2016_a\">Lipton et al, 2016</a></a>; <a class=\"ref-link\" id=\"cFutoma_et+al_2017_a\" href=\"#rFutoma_et+al_2017_a\"><a class=\"ref-link\" id=\"cFutoma_et+al_2017_a\" href=\"#rFutoma_et+al_2017_a\">Futoma et al, 2017</a></a>; <a class=\"ref-link\" id=\"cChe_et+al_2018_a\" href=\"#rChe_et+al_2018_a\"><a class=\"ref-link\" id=\"cChe_et+al_2018_a\" href=\"#rChe_et+al_2018_a\">Che et al, 2018a</a></a>)",
        "The architecture is based on the use of several semi-parametric interpolation layers organized into an interpolation network, followed by the application of a prediction network that can leverage any standard deep learning model",
        "We present experiments based on both classification and regression tasks with sparse and irregularly sampled multivariate time series",
        "We test the model framework on two publicly available real-world datasets: MIMIC-III 3 \u2212 a multivariate time series dataset consisting of sparse and irregularly sampled physiological signals collected at Beth Israel Deaconess Medical Center from 2001 to 2012 (<a class=\"ref-link\" id=\"cJohnson_et+al_2016_a\" href=\"#rJohnson_et+al_2016_a\">Johnson et al, 2016</a>), and UWaveGesture 4 \u2212 a univariate time series data set consisting of simple gesture patterns divided into eight categories (<a class=\"ref-link\" id=\"cLiu_et+al_2009_a\" href=\"#rLiu_et+al_2009_a\">Liu et al, 2009</a>)",
        "We have presented a new framework for dealing with the problem of supervised learning in the presence of sparse and irregularly sampled time series",
        "It uses an interpolation network to accommodate the complexity that results from using sparse and irregularly sampled data as supervised learning inputs, followed by the application of a prediction network that operates over the regularly spaced and fully observed, multi-channel output provided by the interpolation network"
    ],
    "key_statements": [
        "Over the last several years, there has been significant progress in developing specialized models and architectures that can accommodate sparse and irregularly sampled time series as input (<a class=\"ref-link\" id=\"cMarlin_et+al_2012_a\" href=\"#rMarlin_et+al_2012_a\"><a class=\"ref-link\" id=\"cMarlin_et+al_2012_a\" href=\"#rMarlin_et+al_2012_a\">Marlin et al, 2012</a></a>; <a class=\"ref-link\" id=\"cLi_2015_a\" href=\"#rLi_2015_a\"><a class=\"ref-link\" id=\"cLi_2015_a\" href=\"#rLi_2015_a\">Li & Marlin, 2015</a></a>; 2016; <a class=\"ref-link\" id=\"cLipton_et+al_2016_a\" href=\"#rLipton_et+al_2016_a\"><a class=\"ref-link\" id=\"cLipton_et+al_2016_a\" href=\"#rLipton_et+al_2016_a\">Lipton et al, 2016</a></a>; <a class=\"ref-link\" id=\"cFutoma_et+al_2017_a\" href=\"#rFutoma_et+al_2017_a\"><a class=\"ref-link\" id=\"cFutoma_et+al_2017_a\" href=\"#rFutoma_et+al_2017_a\">Futoma et al, 2017</a></a>; <a class=\"ref-link\" id=\"cChe_et+al_2018_a\" href=\"#rChe_et+al_2018_a\"><a class=\"ref-link\" id=\"cChe_et+al_2018_a\" href=\"#rChe_et+al_2018_a\">Che et al, 2018a</a></a>)",
        "The architecture is based on the use of several semi-parametric interpolation layers organized into an interpolation network, followed by the application of a prediction network that can leverage any standard deep learning model",
        "The interpolation network serves the same purpose as the multivariate Gaussian process used in the work of <a class=\"ref-link\" id=\"cFutoma_et+al_2017_a\" href=\"#rFutoma_et+al_2017_a\">Futoma et al (2017</a>), but remove the restrictions associated with the need for a positive definite covariance matrix",
        "We propose a two-layer interpolation network with each layer performing a different type of interpolation",
        "We present experiments based on both classification and regression tasks with sparse and irregularly sampled multivariate time series",
        "We test the model framework on two publicly available real-world datasets: MIMIC-III 3 \u2212 a multivariate time series dataset consisting of sparse and irregularly sampled physiological signals collected at Beth Israel Deaconess Medical Center from 2001 to 2012 (<a class=\"ref-link\" id=\"cJohnson_et+al_2016_a\" href=\"#rJohnson_et+al_2016_a\">Johnson et al, 2016</a>), and UWaveGesture 4 \u2212 a univariate time series data set consisting of simple gesture patterns divided into eight categories (<a class=\"ref-link\" id=\"cLiu_et+al_2009_a\" href=\"#rLiu_et+al_2009_a\">Liu et al, 2009</a>)",
        "For non-neural network baselines, we evaluate Logistic Regression (<a class=\"ref-link\" id=\"cHosmer_et+al_2013_a\" href=\"#rHosmer_et+al_2013_a\">Hosmer Jr et al, 2013</a>), Support Vector Machines (SVM) (<a class=\"ref-link\" id=\"cCortes_1995_a\" href=\"#rCortes_1995_a\">Cortes & Vapnik, 1995</a>), Random Forests (RF) (Breiman, 2001) and AdaBoost (<a class=\"ref-link\" id=\"cFreund_1997_a\" href=\"#rFreund_1997_a\">Freund & Schapire, 1997</a>) for the classification task",
        "We evaluate the scalable end-to-end Gaussian process adapter (<a class=\"ref-link\" id=\"cLi_2016_a\" href=\"#rLi_2016_a\">Li & Marlin, 2016</a>) as well as multi-task Gaussian process recurrent neural networks classifier (<a class=\"ref-link\" id=\"cFutoma_et+al_2017_a\" href=\"#rFutoma_et+al_2017_a\">Futoma et al, 2017</a>) for irregularly sampled univariate and multivariate time series classification respectively",
        "We have presented a new framework for dealing with the problem of supervised learning in the presence of sparse and irregularly sampled time series",
        "It uses an interpolation network to accommodate the complexity that results from using sparse and irregularly sampled data as supervised learning inputs, followed by the application of a prediction network that operates over the regularly spaced and fully observed, multi-channel output provided by the interpolation network"
    ],
    "summary": [
        "Over the last several years, there has been significant progress in developing specialized models and architectures that can accommodate sparse and irregularly sampled time series as input (<a class=\"ref-link\" id=\"cMarlin_et+al_2012_a\" href=\"#rMarlin_et+al_2012_a\"><a class=\"ref-link\" id=\"cMarlin_et+al_2012_a\" href=\"#rMarlin_et+al_2012_a\">Marlin et al, 2012</a></a>; <a class=\"ref-link\" id=\"cLi_2015_a\" href=\"#rLi_2015_a\"><a class=\"ref-link\" id=\"cLi_2015_a\" href=\"#rLi_2015_a\">Li & Marlin, 2015</a></a>; 2016; <a class=\"ref-link\" id=\"cLipton_et+al_2016_a\" href=\"#rLipton_et+al_2016_a\"><a class=\"ref-link\" id=\"cLipton_et+al_2016_a\" href=\"#rLipton_et+al_2016_a\">Lipton et al, 2016</a></a>; <a class=\"ref-link\" id=\"cFutoma_et+al_2017_a\" href=\"#rFutoma_et+al_2017_a\"><a class=\"ref-link\" id=\"cFutoma_et+al_2017_a\" href=\"#rFutoma_et+al_2017_a\">Futoma et al, 2017</a></a>; <a class=\"ref-link\" id=\"cChe_et+al_2018_a\" href=\"#rChe_et+al_2018_a\"><a class=\"ref-link\" id=\"cChe_et+al_2018_a\" href=\"#rChe_et+al_2018_a\">Che et al, 2018a</a></a>).",
        "We present a new model architecture for supervised learning with multivariate sparse and irregularly sampled data: Interpolation-Prediction Networks.",
        "The problem of interest in this work is learning supervised machine learning models from sparse and irregularly sampled multivariate time series.",
        "Instead of pre-discretizing the inputs and viewing this information in terms of a binary observation mask or set of missing data indicators, we directly model the sequence of observation events as a point process in continuous time using a semi-parametric intensity function (Lasko, 2014).",
        "The interpolation network interpolates the multivariate, sparse, and irregularly sampled input time series against a set of reference time points r = [r1, ..., rT ].",
        "Following the application of the interpolation network, all D dimensions of the input multivariate time series have been re-represented in terms of C outputs defined on the regularly spaced set of reference time points r1, ..., rT.",
        "If mjdn = 1, we remove the data point as an input to the interpolation network, and include the predicted value of this time point when assessing the autoencoder loss.",
        "We present experiments based on both classification and regression tasks with sparse and irregularly sampled multivariate time series.",
        "The input to the prediction network is a sparse and irregularly sampled time series, and the output is a single scalar representing either the predicted class or the regression target variable.",
        "We test the model framework on two publicly available real-world datasets: MIMIC-III 3 \u2212 a multivariate time series dataset consisting of sparse and irregularly sampled physiological signals collected at Beth Israel Deaconess Medical Center from 2001 to 2012 (<a class=\"ref-link\" id=\"cJohnson_et+al_2016_a\" href=\"#rJohnson_et+al_2016_a\">Johnson et al, 2016</a>), and UWaveGesture 4 \u2212 a univariate time series data set consisting of simple gesture patterns divided into eight categories (<a class=\"ref-link\" id=\"cLiu_et+al_2009_a\" href=\"#rLiu_et+al_2009_a\">Liu et al, 2009</a>).",
        "Their work proposed to handle irregularly sampled and missing data using recurrent neural networks (RNNs) by introducing temporal decays in the input and/or hidden layers.",
        "It uses an interpolation network to accommodate the complexity that results from using sparse and irregularly sampled data as supervised learning inputs, followed by the application of a prediction network that operates over the regularly spaced and fully observed, multi-channel output provided by the interpolation network.",
        "Our framework introduces novel elements including the use of semi-parametric, feed-forward interpolation layers, and the decomposition of an irregularly sampled input time series into multiple distinct information channels."
    ],
    "headline": "We present a new deep learning architecture for addressing the problem of supervised learning with sparse and irregularly sampled multivariate time series",
    "reference_links": [
        {
            "id": "Batista_2003_a",
            "entry": "Gustavo EAPA Batista and Maria Carolina Monard. An analysis of four missing data treatment methods for supervised learning. Applied artificial intelligence, 17(5-6):519\u2013533, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Batista%2C%20Gustavo%20E.A.P.A.%20Monard%2C%20Maria%20Carolina%20An%20analysis%20of%20four%20missing%20data%20treatment%20methods%20for%20supervised%20learning%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Batista%2C%20Gustavo%20E.A.P.A.%20Monard%2C%20Maria%20Carolina%20An%20analysis%20of%20four%20missing%20data%20treatment%20methods%20for%20supervised%20learning%202003"
        },
        {
            "id": "Binkowski_et+al_2018_a",
            "entry": "Mikolaj Binkowski, Gautier Marti, and Philippe Donnat. Autoregressive convolutional neural networks for asynchronous time series. In Jennifer Dy and Andreas Krause (eds.), Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pp. 580\u2013589, Stockholmsmassan, Stockholm Sweden, 10\u201315 Jul 2018. PMLR. URL http://proceedings.mlr.press/v80/binkowski18a.html.",
            "url": "http://proceedings.mlr.press/v80/binkowski18a.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Binkowski%2C%20Mikolaj%20Marti%2C%20Gautier%20Donnat%2C%20Philippe%20Autoregressive%20convolutional%20neural%20networks%20for%20asynchronous%20time%20series%202018-07"
        },
        {
            "id": "Bonilla_et+al_2008_a",
            "entry": "Edwin V Bonilla, Kian M Chai, and Christopher Williams. Multi-task gaussian process prediction. In Advances in neural information processing systems, pp. 153\u2013160, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bonilla%2C%20Edwin%20V.%20Chai%2C%20Kian%20M.%20Williams%2C%20Christopher%20Multi-task%20gaussian%20process%20prediction%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bonilla%2C%20Edwin%20V.%20Chai%2C%20Kian%20M.%20Williams%2C%20Christopher%20Multi-task%20gaussian%20process%20prediction%202008"
        },
        {
            "id": "Forests_2001_a",
            "entry": "Leo Breiman. Random forests. Mach. Learn., 45(1):5\u201332, October 2001. ISSN 0885-6125. doi: 10.1023/A:1010933404324. URL https://doi.org/10.1023/A:1010933404324.",
            "crossref": "https://dx.doi.org/10.1023/A:1010933404324",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1023/A%3A1010933404324"
        },
        {
            "id": "Che_et+al_2018_a",
            "entry": "Zhengping Che, Sanjay Purushotham, Kyunghyun Cho, David Sontag, and Yan Liu. Recurrent neural networks for multivariate time series with missing values. Scientific Reports, 8(1):6085, 2018a. URL https://doi.org/10.1038/s41598-018-24271-9.",
            "crossref": "https://dx.doi.org/10.1038/s41598-018-24271-9",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1038/s41598-018-24271-9"
        },
        {
            "id": "Che_et+al_2018_b",
            "entry": "Zhengping Che, Sanjay Purushotham, Guangyu Li, Bo Jiang, and Yan Liu. Hierarchical deep generative models for multi-rate multivariate time series. In Jennifer Dy and Andreas Krause (eds.), Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pp. 784\u2013793, Stockholmsmassan, Stockholm Sweden, 10\u201315 Jul 2018b. PMLR. URL http://proceedings.mlr.press/v80/che18a.html.",
            "url": "http://proceedings.mlr.press/v80/che18a.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Che%2C%20Zhengping%20Purushotham%2C%20Sanjay%20Li%2C%20Guangyu%20Jiang%2C%20Bo%20Hierarchical%20deep%20generative%20models%20for%20multi-rate%20multivariate%20time%20series%202018-07"
        },
        {
            "id": "Chung_et+al_1412_a",
            "entry": "Junyoung Chung, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv e-prints, abs/1412.3555, 2014. URL https://arxiv.org/abs/1412.3555. Presented at the Deep Learning workshop at NIPS2014.",
            "url": "https://arxiv.org/abs/1412.3555",
            "arxiv_url": "https://arxiv.org/pdf/1412.3555"
        },
        {
            "id": "Clark_2004_a",
            "entry": "J.S. Clark and O.N. Bj\u00f8rnstad. Population time series: process variability, observation errors, missing values, lags, and hidden states. Ecology, 85(11):3140\u20133150, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Clark%2C%20J.S.%20Bj%C3%B8rnstad%2C%20O.N.%20Population%20time%20series%3A%20process%20variability%2C%20observation%20errors%2C%20missing%20values%2C%20lags%2C%20and%20hidden%20states%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Clark%2C%20J.S.%20Bj%C3%B8rnstad%2C%20O.N.%20Population%20time%20series%3A%20process%20variability%2C%20observation%20errors%2C%20missing%20values%2C%20lags%2C%20and%20hidden%20states%202004"
        },
        {
            "id": "Cortes_1995_a",
            "entry": "Corinna Cortes and Vladimir Vapnik. Support-vector networks. Machine Learning, 20(3):273\u2013 297, Sep 1995. ISSN 1573-0565. doi: 10.1007/BF00994018. URL https://doi.org/10.1007/BF00994018.",
            "crossref": "https://dx.doi.org/10.1007/BF00994018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1007/BF00994018"
        },
        {
            "id": "Davis_2006_a",
            "entry": "Jesse Davis and Mark Goadrich. The relationship between precision-recall and roc curves. In Proceedings of the 23rd International Conference on Machine Learning, ICML \u201906, pp. 233\u2013 240, New York, NY, USA, 2006. ACM. ISBN 1-59593-383-2. doi: 10.1145/1143844.1143874. URL http://doi.acm.org/10.1145/1143844.1143874.",
            "crossref": "https://dx.doi.org/10.1145/1143844.1143874",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/1143844.1143874"
        },
        {
            "id": "Drucker_1997_a",
            "entry": "Harris Drucker. Improving regressors using boosting techniques. In Proceedings of the Fourteenth International Conference on Machine Learning, ICML \u201997, pp. 107\u2013115, San Francisco, CA, USA, 1997. Morgan Kaufmann Publishers Inc. ISBN 1-55860-486-3. URL http://dl.acm.org/citation.cfm?id=645526.657132.",
            "url": "http://dl.acm.org/citation.cfm?id=645526.657132",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Drucker%2C%20Harris%20Improving%20regressors%20using%20boosting%20techniques%201997"
        },
        {
            "id": "Freund_1997_a",
            "entry": "Yoav Freund and Robert E Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. J. Comput. Syst. Sci., 55(1):119\u2013139, August 1997. ISSN 0022-0000. doi: 10.1006/jcss.1997.1504. URL http://dx.doi.org/10.1006/jcss.1997.1504.",
            "crossref": "https://dx.doi.org/10.1006/jcss.1997.1504",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1006/jcss.1997.1504"
        },
        {
            "id": "Futoma_et+al_2017_a",
            "entry": "Joseph Futoma, Sanjay Hariharan, and Katherine A. Heller. Learning to detect sepsis with a multitask gaussian process RNN classifier. In Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017, pp. 1174\u20131182, 2017. URL http://proceedings.mlr.press/v70/futoma17a.html.",
            "url": "http://proceedings.mlr.press/v70/futoma17a.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Futoma%2C%20Joseph%20Hariharan%2C%20Sanjay%20Heller%2C%20Katherine%20A.%20Learning%20to%20detect%20sepsis%20with%20a%20multitask%20gaussian%20process%20RNN%20classifier%202017-08-06"
        },
        {
            "id": "Harutyunyan_et+al_2017_a",
            "entry": "Hrayr Harutyunyan, Hrant Khachatrian, David Kale, and Aram Galstyan. Multitask learning and benchmarking with clinical time series data. 03 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Harutyunyan%2C%20Hrayr%20Khachatrian%2C%20Hrant%20Kale%2C%20David%20Galstyan%2C%20Aram%20Multitask%20learning%20and%20benchmarking%20with%20clinical%20time%20series%20data%202017"
        },
        {
            "id": "Hastie_et+al_2001_a",
            "entry": "Trevor Hastie, Robert Tibshirani, and Jerome Friedman. The Elements of Statistical Learning. Springer Series in Statistics. Springer New York Inc., New York, NY, USA, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hastie%2C%20Trevor%20Tibshirani%2C%20Robert%20Friedman%2C%20Jerome%20The%20Elements%20of%20Statistical%20Learning.%20Springer%20Series%20in%20Statistics%202001"
        },
        {
            "id": "Hosmer_et+al_2013_a",
            "entry": "David W Hosmer Jr, Stanley Lemeshow, and Rodney X Sturdivant. Applied logistic regression, volume 398. John Wiley & Sons, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hosmer%2C%20Jr%2C%20David%20W.%20Lemeshow%2C%20Stanley%20Sturdivant%2C%20Rodney%20X.%20Applied%20logistic%20regression%2C%20volume%20398%202013"
        },
        {
            "id": "Johnson_et+al_2016_a",
            "entry": "Alistair EW Johnson, Tom J Pollard, Lu Shen, H Lehman Li-wei, Mengling Feng, Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark. Mimic-iii, a freely accessible critical care database. Scientific data, 3:160035, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Alistair%20E.W.%20Pollard%2C%20Tom%20J.%20Lu%20Shen%2C%20H.Lehman%20Li-wei%20Feng%2C%20Mengling%20a%20freely%20accessible%20critical%20care%20database%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20Alistair%20E.W.%20Pollard%2C%20Tom%20J.%20Lu%20Shen%2C%20H.Lehman%20Li-wei%20Feng%2C%20Mengling%20a%20freely%20accessible%20critical%20care%20database%202016"
        },
        {
            "id": "Kingma_et+al_2015_a",
            "entry": "Diederik P Kingma, Tim Salimans, and Max Welling. Variational dropout and the local reparameterization trick. arXiv preprint arXiv:1506.02557, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1506.02557"
        },
        {
            "id": "Thomas_2014_a",
            "entry": "Thomas A Lasko. Efficient inference of gaussian-process-modulated renewal processes with application to medical event data. In Uncertainty in artificial intelligence: proceedings of the... conference. Conference on Uncertainty in Artificial Intelligence, volume 2014, pp. 469. NIH Public Access, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Thomas%20A%20Lasko%20Efficient%20inference%20of%20gaussianprocessmodulated%20renewal%20processes%20with%20application%20to%20medical%20event%20data%20In%20Uncertainty%20in%20artificial%20intelligence%20proceedings%20of%20the%20conference%20Conference%20on%20Uncertainty%20in%20Artificial%20Intelligence%20volume%202014%20pp%20469%20NIH%20Public%20Access%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Thomas%20A%20Lasko%20Efficient%20inference%20of%20gaussianprocessmodulated%20renewal%20processes%20with%20application%20to%20medical%20event%20data%20In%20Uncertainty%20in%20artificial%20intelligence%20proceedings%20of%20the%20conference%20Conference%20on%20Uncertainty%20in%20Artificial%20Intelligence%20volume%202014%20pp%20469%20NIH%20Public%20Access%202014"
        },
        {
            "id": "Li_2016_a",
            "entry": "Steven Cheng-Xian Li and Benjamin M Marlin. A scalable end-to-end gaussian process adapter for irregularly sampled time series classification. In Advances In Neural Information Processing Systems, pp. 1804\u20131812, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Steven%20Cheng-Xian%20Marlin%2C%20Benjamin%20M.%20A%20scalable%20end-to-end%20gaussian%20process%20adapter%20for%20irregularly%20sampled%20time%20series%20classification%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Steven%20Cheng-Xian%20Marlin%2C%20Benjamin%20M.%20A%20scalable%20end-to-end%20gaussian%20process%20adapter%20for%20irregularly%20sampled%20time%20series%20classification%202016"
        },
        {
            "id": "Li_2015_a",
            "entry": "Steven Cheng-Xian Li and Benjmain M. Marlin. Classification of sparse and irregularly sampled time series with mixtures of expected Gaussian kernels and random features. In 31st Conference on Uncertainty in Artificial Intelligence, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Steven%20Cheng-Xian%20Marlin%2C%20Benjmain%20M.%20Classification%20of%20sparse%20and%20irregularly%20sampled%20time%20series%20with%20mixtures%20of%20expected%20Gaussian%20kernels%20and%20random%20features%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Steven%20Cheng-Xian%20Marlin%2C%20Benjmain%20M.%20Classification%20of%20sparse%20and%20irregularly%20sampled%20time%20series%20with%20mixtures%20of%20expected%20Gaussian%20kernels%20and%20random%20features%202015"
        },
        {
            "id": "Lipton_et+al_2016_a",
            "entry": "Zachary C Lipton, David Kale, and Randall Wetzel. Directly modeling missing data in sequences with rnns: Improved classification of clinical time series. In Machine Learning for Healthcare Conference, pp. 253\u2013270, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lipton%2C%20Zachary%20C.%20Kale%2C%20David%20Wetzel%2C%20Randall%20Directly%20modeling%20missing%20data%20in%20sequences%20with%20rnns%3A%20Improved%20classification%20of%20clinical%20time%20series%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lipton%2C%20Zachary%20C.%20Kale%2C%20David%20Wetzel%2C%20Randall%20Directly%20modeling%20missing%20data%20in%20sequences%20with%20rnns%3A%20Improved%20classification%20of%20clinical%20time%20series%202016"
        },
        {
            "id": "Little_2014_a",
            "entry": "Roderick JA Little and Donald B Rubin. Statistical analysis with missing data, volume 333. John Wiley & Sons, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Little%2C%20Roderick%20J.A.%20Rubin%2C%20Donald%20B.%20Statistical%20analysis%20with%20missing%20data%2C%20volume%20333%202014"
        },
        {
            "id": "Liu_et+al_2009_a",
            "entry": "Jiayang Liu, Zhen Wang, Lin Zhong, Jehan Wickramasuriya, and Venu Vasudevan. uwave: Accelerometer-based personalized gesture recognition and its applications. In Proceedings of the 2009 IEEE International Conference on Pervasive Computing and Communications, PERCOM \u201909, pp. 1\u20139, Washington, DC, USA, 2009. IEEE Computer Society. ISBN temp-isbn. doi: 10.1109/PERCOM.2009.4912759. URL https://doi.org/10.1109/PERCOM.2009.4912759.",
            "crossref": "https://dx.doi.org/10.1109/PERCOM.2009.4912759",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/PERCOM.2009.4912759"
        },
        {
            "id": "Lu_et+al_2008_a",
            "entry": "Zhengdong Lu, Todd K. Leen, Yonghong Huang, and Deniz Erdogmus. A reproducing kernel hilbert space framework for pairwise time series distances. In Proceedings of the 25th International Conference on Machine Learning, ICML \u201908, pp. 624\u2013631, New York, NY, USA, 2008. ACM. ISBN 978-1-60558-205-4. doi: 10.1145/1390156.1390235. URL http://doi.acm.org/10.1145/1390156.1390235.",
            "crossref": "https://dx.doi.org/10.1145/1390156.1390235",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/1390156.1390235"
        },
        {
            "id": "Marlin_et+al_2012_a",
            "entry": "Benjamin M. Marlin, David C. Kale, Robinder G. Khemani, and Randall C. Wetzel. Unsupervised pattern discovery in electronic health care data using probabilistic clustering models. In Proceedings of the 2nd ACM SIGHIT International Health Informatics Symposium, pp. 389\u2013398, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Marlin%2C%20Benjamin%20M.%20Kale%2C%20David%20C.%20Khemani%2C%20Robinder%20G.%20Wetzel%2C%20Randall%20C.%20Unsupervised%20pattern%20discovery%20in%20electronic%20health%20care%20data%20using%20probabilistic%20clustering%20models%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Marlin%2C%20Benjamin%20M.%20Kale%2C%20David%20C.%20Khemani%2C%20Robinder%20G.%20Wetzel%2C%20Randall%20C.%20Unsupervised%20pattern%20discovery%20in%20electronic%20health%20care%20data%20using%20probabilistic%20clustering%20models%202012"
        },
        {
            "id": "Rasmussen_2006_a",
            "entry": "Carl Edward Rasmussen. Gaussian processes for machine learning. 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rasmussen%2C%20Carl%20Edward%20Gaussian%20processes%20for%20machine%20learning%202006"
        },
        {
            "id": "Ruf_1999_a",
            "entry": "T. Ruf. The lomb-scargle periodogram in biological rhythm research: analysis of incomplete and unequally spaced time-series. Biological Rhythm Research, 30(2):178\u2013201, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ruf%2C%20T.%20The%20lomb-scargle%20periodogram%20in%20biological%20rhythm%20research%3A%20analysis%20of%20incomplete%20and%20unequally%20spaced%20time-series%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ruf%2C%20T.%20The%20lomb-scargle%20periodogram%20in%20biological%20rhythm%20research%3A%20analysis%20of%20incomplete%20and%20unequally%20spaced%20time-series%201999"
        },
        {
            "id": "Salakhutdinov_et+al_2007_a",
            "entry": "Ruslan Salakhutdinov, Andriy Mnih, and Geoffrey Hinton. Restricted boltzmann machines for collaborative filtering. In Proceedings of the 24th international conference on Machine learning, pp. 791\u2013798. ACM, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Salakhutdinov%2C%20Ruslan%20Mnih%2C%20Andriy%20Hinton%2C%20Geoffrey%20Restricted%20boltzmann%20machines%20for%20collaborative%20filtering%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Salakhutdinov%2C%20Ruslan%20Mnih%2C%20Andriy%20Hinton%2C%20Geoffrey%20Restricted%20boltzmann%20machines%20for%20collaborative%20filtering%202007"
        },
        {
            "id": "Scargle_1982_a",
            "entry": "Jeffrey D Scargle. Studies in astronomical time series analysis. ii-statistical aspects of spectral analysis of unevenly spaced data. The Astrophysical Journal, 263:835\u2013853, 1982.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Scargle%2C%20Jeffrey%20D.%20Studies%20in%20astronomical%20time%20series%20analysis.%20ii-statistical%20aspects%20of%20spectral%20analysis%20of%20unevenly%20spaced%20data%201982",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Scargle%2C%20Jeffrey%20D.%20Studies%20in%20astronomical%20time%20series%20analysis.%20ii-statistical%20aspects%20of%20spectral%20analysis%20of%20unevenly%20spaced%20data%201982"
        },
        {
            "id": "Schulz_1997_a",
            "entry": "M. Schulz and K. Stattegger. Spectrum: Spectral analysis of unevenly spaced paleoclimatic time series. Computers & Geosciences, 23(9):929\u2013945, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schulz%2C%20M.%20Stattegger%2C%20K.%20Spectrum%3A%20Spectral%20analysis%20of%20unevenly%20spaced%20paleoclimatic%20time%20series%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schulz%2C%20M.%20Stattegger%2C%20K.%20Spectrum%3A%20Spectral%20analysis%20of%20unevenly%20spaced%20paleoclimatic%20time%20series%201997"
        },
        {
            "id": "Sterne_et+al_2009_a",
            "entry": "Jonathan AC Sterne, Ian R White, John B Carlin, Michael Spratt, Patrick Royston, Michael G Kenward, Angela M Wood, and James R Carpenter. Multiple imputation for missing data in epidemiological and clinical research: potential and pitfalls. Bmj, 338:b2393, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sterne%2C%20Jonathan%20A.C.%20White%2C%20Ian%20R.%20Carlin%2C%20John%20B.%20Spratt%2C%20Michael%20Multiple%20imputation%20for%20missing%20data%20in%20epidemiological%20and%20clinical%20research%3A%20potential%20and%20pitfalls%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sterne%2C%20Jonathan%20A.C.%20White%2C%20Ian%20R.%20Carlin%2C%20John%20B.%20Spratt%2C%20Michael%20Multiple%20imputation%20for%20missing%20data%20in%20epidemiological%20and%20clinical%20research%3A%20potential%20and%20pitfalls%202009"
        },
        {
            "id": "Williams_et+al_2005_a",
            "entry": "David Williams, Xuejun Liao, Ya Xue, and Lawrence Carin. Incomplete-data classification using logistic regression. In Proceedings of the 22nd International Conference on Machine learning, pp. 972\u2013979. ACM, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Williams%2C%20David%20Liao%2C%20Xuejun%20Xue%2C%20Ya%20Carin%2C%20Lawrence%20Incomplete-data%20classification%20using%20logistic%20regression%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Williams%2C%20David%20Liao%2C%20Xuejun%20Xue%2C%20Ya%20Carin%2C%20Lawrence%20Incomplete-data%20classification%20using%20logistic%20regression%202005"
        },
        {
            "id": "Yadav_et+al_2018_a",
            "entry": "Pranjul Yadav, Michael Steinbach, Vipin Kumar, and Gyorgy Simon. Mining electronic health records (ehrs): A survey. ACM Computing Surveys (CSUR), 50(6):85, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yadav%2C%20Pranjul%20Steinbach%2C%20Michael%20Kumar%2C%20Vipin%20Simon%2C%20Gyorgy%20Mining%20electronic%20health%20records%20%28ehrs%29%3A%20A%20survey%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yadav%2C%20Pranjul%20Steinbach%2C%20Michael%20Kumar%2C%20Vipin%20Simon%2C%20Gyorgy%20Mining%20electronic%20health%20records%20%28ehrs%29%3A%20A%20survey%202018"
        },
        {
            "id": "Yoon_et+al_2017_a",
            "entry": "Jinsung Yoon, William R. Zame, and Mihaela van der Schaar. Multi-directional recurrent neural networks: A novel method for estimating missing data. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yoon%2C%20Jinsung%20Zame%2C%20William%20R.%20van%20der%20Schaar%2C%20Mihaela%20Multi-directional%20recurrent%20neural%20networks%3A%20A%20novel%20method%20for%20estimating%20missing%20data%202017"
        },
        {
            "id": "We_2016_a",
            "entry": "We evaluate our model framework on the publicly available MIMIC-III dataset (Johnson et al., 2016). MIMIC-III is a de-identified dataset collected at Beth Israel Deaconess Medical Center from 2001 to 2012. It consists of approximately 58,000 hospital admission records. This data set contains sparse and irregularly sampled physiological signals, medications, diagnostic codes, inhospital mortality, length of stay and more. We focus on predicting in-hospital mortality and length of stay using the first 48 hours of data. We extracted 12 standard physiological variables from each of the 53,211 records obtained after removing hospital admission records with length of stay less than 48 hours. Table 2 shows the features, sampling rates (per hour) and their missingness information computed using the union of all time stamps that exist in any dimension of the input time series.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=We%20evaluate%20our%20model%20framework%20on%20the%20publicly%20available%20MIMICIII%20dataset%20Johnson%20et%20al%202016%20MIMICIII%20is%20a%20deidentified%20dataset%20collected%20at%20Beth%20Israel%20Deaconess%20Medical%20Center%20from%202001%20to%202012%20It%20consists%20of%20approximately%2058000%20hospital%20admission%20records%20This%20data%20set%20contains%20sparse%20and%20irregularly%20sampled%20physiological%20signals%20medications%20diagnostic%20codes%20inhospital%20mortality%20length%20of%20stay%20and%20more%20We%20focus%20on%20predicting%20inhospital%20mortality%20and%20length%20of%20stay%20using%20the%20first%2048%20hours%20of%20data%20We%20extracted%2012%20standard%20physiological%20variables%20from%20each%20of%20the%2053211%20records%20obtained%20after%20removing%20hospital%20admission%20records%20with%20length%20of%20stay%20less%20than%2048%20hours%20Table%202%20shows%20the%20features%20sampling%20rates%20per%20hour%20and%20their%20missingness%20information%20computed%20using%20the%20union%20of%20all%20time%20stamps%20that%20exist%20in%20any%20dimension%20of%20the%20input%20time%20series",
            "oa_query": "https://api.scholarcy.com/oa_version?query=We%20evaluate%20our%20model%20framework%20on%20the%20publicly%20available%20MIMICIII%20dataset%20Johnson%20et%20al%202016%20MIMICIII%20is%20a%20deidentified%20dataset%20collected%20at%20Beth%20Israel%20Deaconess%20Medical%20Center%20from%202001%20to%202012%20It%20consists%20of%20approximately%2058000%20hospital%20admission%20records%20This%20data%20set%20contains%20sparse%20and%20irregularly%20sampled%20physiological%20signals%20medications%20diagnostic%20codes%20inhospital%20mortality%20length%20of%20stay%20and%20more%20We%20focus%20on%20predicting%20inhospital%20mortality%20and%20length%20of%20stay%20using%20the%20first%2048%20hours%20of%20data%20We%20extracted%2012%20standard%20physiological%20variables%20from%20each%20of%20the%2053211%20records%20obtained%20after%20removing%20hospital%20admission%20records%20with%20length%20of%20stay%20less%20than%2048%20hours%20Table%202%20shows%20the%20features%20sampling%20rates%20per%20hour%20and%20their%20missingness%20information%20computed%20using%20the%20union%20of%20all%20time%20stamps%20that%20exist%20in%20any%20dimension%20of%20the%20input%20time%20series"
        }
    ]
}

{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "GLUE: A MULTI-TASK BENCHMARK AND ANALYSIS PLATFORM FOR NATURAL LANGUAGE UNDERSTAND-",
        "author": "Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, & Samuel R. Bowman, 1Courant Institute of Mathematical Sciences, New York University 2Paul G. Allen School of Computer Science & Engineering, University of Washington 3DeepMind {alexwang,amanpreet,bowman}@nyu.edu {julianjm,omerlevy}@cs.washington.edu felixhill@google.com",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=rJ4km2R5t7"
        },
        "abstract": "For natural language understanding (NLU) technology to be maximally useful, it must be able to process language in a way that is not exclusive to a single task, genre, or dataset. In pursuit of this objective, we introduce the General Language Understanding Evaluation (GLUE) benchmark, a collection of tools for evaluating the performance of models across a diverse set of existing NLU tasks. By including tasks with limited training data, GLUE is designed to favor and encourage models that share general linguistic knowledge across tasks. GLUE also includes a hand-crafted diagnostic test suite that enables detailed linguistic analysis of models. We evaluate baselines based on current methods for transfer and representation learning and find that multi-task training on all tasks performs better than training a separate model per task. However, the low absolute performance of our best model indicates the need for improved general NLU systems."
    },
    "keywords": [
        {
            "term": "question answering",
            "url": "https://en.wikipedia.org/wiki/question_answering"
        },
        {
            "term": "language understanding",
            "url": "https://en.wikipedia.org/wiki/language_understanding"
        },
        {
            "term": "natural language understanding",
            "url": "https://en.wikipedia.org/wiki/natural_language_understanding"
        },
        {
            "term": "sentiment analysis",
            "url": "https://en.wikipedia.org/wiki/sentiment_analysis"
        }
    ],
    "abbreviations": {
        "NLU": "natural language understanding",
        "GLUE": "General Language Understanding Evaluation",
        "RTE": "Recognizing Textual Entailment"
    },
    "highlights": [
        "The human ability to understand language is general, flexible, and robust",
        "Most natural language understanding models above the word level are designed for a specific task and struggle with out-of-domain data",
        "To facilitate research in this direction, we present the General Language Understanding Evaluation (GLUE) benchmark: a collection of natural language understanding tasks including question answering, sentiment analysis, and textual entailment, and an associated online platform for model evaluation, comparison, and analysis",
        "We evaluate a multi-task learning model trained on the General Language Understanding Evaluation tasks, as well as several variants based on recent pre-training methods",
        "For single-task and sentence representation models, we evaluate the best run for each individual task",
        "We introduce General Language Understanding Evaluation, a platform and collection of resources for evaluating and analyzing natural language understanding systems"
    ],
    "key_statements": [
        "The human ability to understand language is general, flexible, and robust",
        "Most natural language understanding models above the word level are designed for a specific task and struggle with out-of-domain data",
        "To facilitate research in this direction, we present the General Language Understanding Evaluation (GLUE) benchmark: a collection of natural language understanding tasks including question answering, sentiment analysis, and textual entailment, and an associated online platform for model evaluation, comparison, and analysis",
        "We evaluate a multi-task learning model trained on the General Language Understanding Evaluation tasks, as well as several variants based on recent pre-training methods",
        "For single-task and sentence representation models, we evaluate the best run for each individual task",
        "Looking at results per task, we find that the sentence representation models substantially underperform on CoLA compared to the models directly trained on the task",
        "The models trained on the General Language Understanding Evaluation tasks largely outperform the pretrained sentence representation models, with the exception of GenSen",
        "We introduce General Language Understanding Evaluation, a platform and collection of resources for evaluating and analyzing natural language understanding systems"
    ],
    "summary": [
        "The human ability to understand language is general, flexible, and robust.",
        "To facilitate research in this direction, we present the General Language Understanding Evaluation (GLUE) benchmark: a collection of NLU tasks including question answering, sentiment analysis, and textual entailment, and an associated online platform for model evaluation, comparison, and analysis.",
        "Though it is possible to train a single model for each task with no pretraining or other outside sources of knowledge and evaluate the resulting set of models on this benchmark, we expect that our inclusion of several data-scarce tasks will render this approach uncompetitive.",
        "We produce several pairs with different labels for a single source sentence, to have minimal sets of sentence pairs that are lexically and structurally very similar but correspond to different entailment relationships.",
        "Intended Use The diagnostic examples are hand-picked to address certain phenomena, and NLI is a task with no natural input distribution, so we do not expect performance on the diagnostic set to reflect overall performance or generalization in downstream applications.",
        "We evaluate a multi-task learning model trained on the GLUE tasks, as well as several variants based on recent pre-training methods.",
        "Sentence Representation Models we evaluate the following trained sentence-to-vector encoder models using our benchmark: average bag-of-words using GloVe embeddings (CBoW), Skip-Thought (<a class=\"ref-link\" id=\"cKiros_et+al_2015_a\" href=\"#rKiros_et+al_2015_a\">Kiros et al, 2015</a>), InferSent (<a class=\"ref-link\" id=\"cConneau_et+al_2017_a\" href=\"#rConneau_et+al_2017_a\">Conneau et al, 2017</a>), DisSent (<a class=\"ref-link\" id=\"cNie_et+al_2017_a\" href=\"#rNie_et+al_2017_a\">Nie et al, 2017</a>), and GenSen (<a class=\"ref-link\" id=\"cSubramanian_et+al_2018_a\" href=\"#rSubramanian_et+al_2018_a\">Subramanian et al, 2018</a>).",
        "Using CoVe has mixed effects over using only GloVe. Among the pre-trained sentence representation models, we observe fairly consistent gains moving from CBoW to Skip-Thought to Infersent and GenSen. Relative to the models trained directly on the GLUE tasks, InferSent is competitive and GenSen outperforms all but the two best.",
        "The models trained on the GLUE tasks largely outperform the pretrained sentence representation models, with the exception of GenSen. Using attention has a greater influence on diagnostic scores than using ELMo or CoVe, which we take to indicate that attention is especially important for generalization in NLI.",
        "There is evidence that going beyond sentence-to-vector representations, e.g. with an attention mechanism, might aid performance on out-of-domain data, and that transfer methods like ELMo and CoVe encode linguistic information specific to their supervision signal.",
        "We confirm the utility of attention mechanisms and transfer learning methods such as ELMo in NLU systems, which combine to outperform the best sentence representation models on the GLUE benchmark, but still leave room for improvement.",
        "The question of how to design general-purpose NLU models remains unanswered, and we believe that GLUE can provide fertile soil for addressing this challenge"
    ],
    "headline": "In pursuit of this objective, we introduce the General Language Understanding Evaluation benchmark, a collection of tools for evaluating the performance of models across a diverse set of existing natural language understanding tasks",
    "reference_links": [
        {
            "id": "Bahdanau_et+al_2015_a",
            "entry": "Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate. In Proceedings of the International Conference on Learning Representations, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bahdanau%2C%20Dzmitry%20Cho%2C%20Kyunghyun%20Bengio%2C%20Yoshua%20Neural%20machine%20translation%20by%20jointly%20learning%20to%20align%20and%20translate%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bahdanau%2C%20Dzmitry%20Cho%2C%20Kyunghyun%20Bengio%2C%20Yoshua%20Neural%20machine%20translation%20by%20jointly%20learning%20to%20align%20and%20translate%202015"
        },
        {
            "id": "Haim_et+al_2006_a",
            "entry": "Roy Bar Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Giampiccolo, Bernardo Magnini, and Idan Szpektor. The second PASCAL recognising textual entailment challenge. 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Haim%2C%20Roy%20Bar%20Dagan%2C%20Ido%20Dolan%2C%20Bill%20Ferro%2C%20Lisa%20The%20second%20PASCAL%20recognising%20textual%20entailment%20challenge%202006"
        },
        {
            "id": "Bentivogli_et+al_2009_a",
            "entry": "Luisa Bentivogli, Ido Dagan, Hoa Trang Dang, Danilo Giampiccolo, and Bernardo Magnini. The fifth PASCAL recognizing textual entailment challenge. 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bentivogli%2C%20Luisa%20Dagan%2C%20Ido%20Dang%2C%20Hoa%20Trang%20Giampiccolo%2C%20Danilo%20The%20fifth%20PASCAL%20recognizing%20textual%20entailment%20challenge%202009"
        },
        {
            "id": "Bowman_et+al_2015_a",
            "entry": "Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. A large annotated corpus for learning natural language inference. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 632\u2013642. Association for Computational Linguistics, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bowman%2C%20Samuel%20R.%20Angeli%2C%20Gabor%20Potts%2C%20Christopher%20Manning%2C%20Christopher%20D.%20A%20large%20annotated%20corpus%20for%20learning%20natural%20language%20inference%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bowman%2C%20Samuel%20R.%20Angeli%2C%20Gabor%20Potts%2C%20Christopher%20Manning%2C%20Christopher%20D.%20A%20large%20annotated%20corpus%20for%20learning%20natural%20language%20inference%202015"
        },
        {
            "id": "Cer_et+al_2017_a",
            "entry": "Daniel Cer, Mona Diab, Eneko Agirre, Inigo Lopez-Gazpio, and Lucia Specia. Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation. In Eleventh International Workshop on Semantic Evaluations, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cer%2C%20Daniel%20Diab%2C%20Mona%20Agirre%2C%20Eneko%20Lopez-Gazpio%2C%20Inigo%20Semeval-2017%20task%201%3A%20Semantic%20textual%20similarity-multilingual%20and%20cross-lingual%20focused%20evaluation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cer%2C%20Daniel%20Diab%2C%20Mona%20Agirre%2C%20Eneko%20Lopez-Gazpio%2C%20Inigo%20Semeval-2017%20task%201%3A%20Semantic%20textual%20similarity-multilingual%20and%20cross-lingual%20focused%20evaluation%202017"
        },
        {
            "id": "Chelba_et+al_2013_a",
            "entry": "Ciprian Chelba, Tomas Mikolov, Mike Schuster, Qi Ge, Thorsten Brants, Phillipp Koehn, and Tony Robinson. One billion word benchmark for measuring progress in statistical language modeling. arXiv preprint 1312.3005, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1312.3005"
        },
        {
            "id": "Collobert_et+al_2011_a",
            "entry": "Ronan Collobert, Jason Weston, Leon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. Natural language processing (almost) from scratch. Journal of Machine Learning Research, 12(Aug):2493\u20132537, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Collobert%2C%20Ronan%20Weston%2C%20Jason%20Bottou%2C%20Leon%20Karlen%2C%20Michael%20Natural%20language%20processing%20%28almost%29%20from%20scratch%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Collobert%2C%20Ronan%20Weston%2C%20Jason%20Bottou%2C%20Leon%20Karlen%2C%20Michael%20Natural%20language%20processing%20%28almost%29%20from%20scratch%202011"
        },
        {
            "id": "Conneau_2018_a",
            "entry": "Alexis Conneau and Douwe Kiela. SentEval: An evaluation toolkit for universal sentence representations. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Conneau%2C%20Alexis%20Kiela%2C%20Douwe%20SentEval%3A%20An%20evaluation%20toolkit%20for%20universal%20sentence%20representations%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Conneau%2C%20Alexis%20Kiela%2C%20Douwe%20SentEval%3A%20An%20evaluation%20toolkit%20for%20universal%20sentence%20representations%202018"
        },
        {
            "id": "Conneau_et+al_2017_a",
            "entry": "Alexis Conneau, Douwe Kiela, Holger Schwenk, Lo\u0131c Barrault, and Antoine Bordes. Supervised learning of universal sentence representations from natural language inference data. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, Copenhagen, Denmark, September 9-11, 2017, pp. 681\u2013691, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Conneau%2C%20Alexis%20Kiela%2C%20Douwe%20Schwenk%2C%20Holger%20Barrault%2C%20Lo%C4%B1c%20Supervised%20learning%20of%20universal%20sentence%20representations%20from%20natural%20language%20inference%20data%202017-09",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Conneau%2C%20Alexis%20Kiela%2C%20Douwe%20Schwenk%2C%20Holger%20Barrault%2C%20Lo%C4%B1c%20Supervised%20learning%20of%20universal%20sentence%20representations%20from%20natural%20language%20inference%20data%202017-09"
        },
        {
            "id": "Cooper_et+al_1996_a",
            "entry": "Robin Cooper, Dick Crouch, Jan Van Eijck, Chris Fox, Josef Van Genabith, Jan Jaspars, Hans Kamp, David Milward, Manfred Pinkal, Massimo Poesio, Steve Pulman, Ted Briscoe, Holger Maier, and Karsten Konrad. Using the framework. Technical report, The FraCaS Consortium, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cooper%2C%20Robin%20Crouch%2C%20Dick%20Eijck%2C%20Jan%20Van%20Fox%2C%20Chris%20Using%20the%20framework.%20Technical%20report%2C%20The%20FraCaS%20Consortium%201996"
        },
        {
            "id": "Demszky_et+al_2018_a",
            "entry": "Dorottya Demszky, Kelvin Guu, and Percy Liang. Transforming question answering datasets into natural language inference datasets. arXiv preprint 1809.02922, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1809.02922"
        },
        {
            "id": "Dolan_2005_a",
            "entry": "William B Dolan and Chris Brockett. Automatically constructing a corpus of sentential paraphrases. In Proceedings of the International Workshop on Paraphrasing, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dolan%2C%20William%20B.%20Brockett%2C%20Chris%20Automatically%20constructing%20a%20corpus%20of%20sentential%20paraphrases%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dolan%2C%20William%20B.%20Brockett%2C%20Chris%20Automatically%20constructing%20a%20corpus%20of%20sentential%20paraphrases%202005"
        },
        {
            "id": "Ettinger_et+al_2017_a",
            "entry": "Allyson Ettinger, Sudha Rao, Hal Daume III, and Emily M Bender. Towards linguistically generalizable NLP systems: A workshop and shared task. In First Workshop on Building Linguistically Generalizable NLP Systems, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ettinger%2C%20Allyson%20Rao%2C%20Sudha%20Daume%2C%20III%2C%20Hal%20Bender%2C%20Emily%20M.%20Towards%20linguistically%20generalizable%20NLP%20systems%3A%20A%20workshop%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ettinger%2C%20Allyson%20Rao%2C%20Sudha%20Daume%2C%20III%2C%20Hal%20Bender%2C%20Emily%20M.%20Towards%20linguistically%20generalizable%20NLP%20systems%3A%20A%20workshop%202017"
        },
        {
            "id": "Gardner_et+al_2017_a",
            "entry": "Matt Gardner, Joel Grus, Mark Neumann, Oyvind Tafjord, Pradeep Dasigi, Nelson F. Liu, Matthew Peters, Michael Schmitz, and Luke S. Zettlemoyer. AllenNLP: A deep semantic natural language processing platform. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gardner%2C%20Matt%20Grus%2C%20Joel%20Neumann%2C%20Mark%20Tafjord%2C%20Oyvind%20AllenNLP%3A%20A%20deep%20semantic%20natural%20language%20processing%20platform%202017"
        },
        {
            "id": "Giampiccolo_et+al_2007_a",
            "entry": "Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill Dolan. The third PASCAL recognizing textual entailment challenge. In Proceedings of the ACL-PASCAL workshop on textual entailment and paraphrasing, pp. 1\u20139. Association for Computational Linguistics, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Giampiccolo%2C%20Danilo%20Magnini%2C%20Bernardo%20Dagan%2C%20Ido%20Dolan%2C%20Bill%20The%20third%20PASCAL%20recognizing%20textual%20entailment%20challenge%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Giampiccolo%2C%20Danilo%20Magnini%2C%20Bernardo%20Dagan%2C%20Ido%20Dolan%2C%20Bill%20The%20third%20PASCAL%20recognizing%20textual%20entailment%20challenge%202007"
        },
        {
            "id": "Gorodkin_2004_a",
            "entry": "Jan Gorodkin. Comparing two k-category assignments by a k-category correlation coefficient. Comput. Biol. Chem., 28(5-6):367\u2013374, December 2004. ISSN 1476-9271.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gorodkin%2C%20Jan%20Comparing%20two%20k-category%20assignments%20by%20a%20k-category%20correlation%20coefficient.%20Comput%202004-12",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gorodkin%2C%20Jan%20Comparing%20two%20k-category%20assignments%20by%20a%20k-category%20correlation%20coefficient.%20Comput%202004-12"
        },
        {
            "id": "Gururangan_et+al_2018_a",
            "entry": "Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel R. Bowman, and Noah A. Smith. Annotation artifacts in natural language inference data. In Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gururangan%2C%20Suchin%20Swayamdipta%2C%20Swabha%20Levy%2C%20Omer%20Schwartz%2C%20Roy%20Annotation%20artifacts%20in%20natural%20language%20inference%20data%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gururangan%2C%20Suchin%20Swayamdipta%2C%20Swabha%20Levy%2C%20Omer%20Schwartz%2C%20Roy%20Annotation%20artifacts%20in%20natural%20language%20inference%20data%202018"
        },
        {
            "id": "Hashimoto_et+al_2017_a",
            "entry": "Kazuma Hashimoto, Caiming Xiong, Yoshimasa Tsuruoka, and Richard Socher. A joint many-task model: Growing a neural network for multiple nlp tasks. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hashimoto%2C%20Kazuma%20Xiong%2C%20Caiming%20Tsuruoka%2C%20Yoshimasa%20Socher%2C%20Richard%20A%20joint%20many-task%20model%3A%20Growing%20a%20neural%20network%20for%20multiple%20nlp%20tasks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hashimoto%2C%20Kazuma%20Xiong%2C%20Caiming%20Tsuruoka%2C%20Yoshimasa%20Socher%2C%20Richard%20A%20joint%20many-task%20model%3A%20Growing%20a%20neural%20network%20for%20multiple%20nlp%20tasks%202017"
        },
        {
            "id": "Hill_et+al_2016_a",
            "entry": "Felix Hill, Kyunghyun Cho, and Anna Korhonen. Learning distributed representations of sentences from unlabelled data. In Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hill%2C%20Felix%20Cho%2C%20Kyunghyun%20Korhonen%2C%20Anna%20Learning%20distributed%20representations%20of%20sentences%20from%20unlabelled%20data%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hill%2C%20Felix%20Cho%2C%20Kyunghyun%20Korhonen%2C%20Anna%20Learning%20distributed%20representations%20of%20sentences%20from%20unlabelled%20data%202016"
        },
        {
            "id": "Hu_2004_a",
            "entry": "Minqing Hu and Bing Liu. Mining and summarizing customer reviews. In Proceedings of the tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 168\u2013177. ACM, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hu%2C%20Minqing%20Liu%2C%20Bing%20Mining%20and%20summarizing%20customer%20reviews%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hu%2C%20Minqing%20Liu%2C%20Bing%20Mining%20and%20summarizing%20customer%20reviews%202004"
        },
        {
            "id": "Joulin_et+al_2016_a",
            "entry": "Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov. Bag of tricks for efficient text classification. arXiv preprint 1607.01759, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1607.01759"
        },
        {
            "id": "Kingma_2015_a",
            "entry": "Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Proceedings of the International Conference on Learning Representations, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Diederik%20P.%20Ba%2C%20Jimmy%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20Diederik%20P.%20Ba%2C%20Jimmy%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202015"
        },
        {
            "id": "Kiros_et+al_2015_a",
            "entry": "Ryan Kiros, Yukun Zhu, Ruslan R Salakhutdinov, Richard Zemel, Raquel Urtasun, Antonio Torralba, and Sanja Fidler. Skip-Thought vectors. In Advances in Neural Information Processing Systems, pp. 3294\u20133302, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kiros%2C%20Ryan%20Zhu%2C%20Yukun%20Salakhutdinov%2C%20Ruslan%20R.%20Zemel%2C%20Richard%20Skip-Thought%20vectors%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kiros%2C%20Ryan%20Zhu%2C%20Yukun%20Salakhutdinov%2C%20Ruslan%20R.%20Zemel%2C%20Richard%20Skip-Thought%20vectors%202015"
        },
        {
            "id": "Xing_2014_a",
            "entry": "Quoc Le and Tomas Mikolov. Distributed representations of sentences and documents. In Eric P. Xing and Tony Jebara (eds.), Proceedings of the 31st International Conference on Machine Learning, volume 32 of Proceedings of Machine Learning Research, pp. 1188\u20131196, Bejing, China, 22\u201324 Jun 2014. PMLR.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Quoc%20Le%20and%20Tomas%20Mikolov%20Distributed%20representations%20of%20sentences%20and%20documents%20In%20Eric%20P%20Xing%20and%20Tony%20Jebara%20eds%20Proceedings%20of%20the%2031st%20International%20Conference%20on%20Machine%20Learning%20volume%2032%20of%20Proceedings%20of%20Machine%20Learning%20Research%20pp%2011881196%20Bejing%20China%202224%20Jun%202014%20PMLR",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Quoc%20Le%20and%20Tomas%20Mikolov%20Distributed%20representations%20of%20sentences%20and%20documents%20In%20Eric%20P%20Xing%20and%20Tony%20Jebara%20eds%20Proceedings%20of%20the%2031st%20International%20Conference%20on%20Machine%20Learning%20volume%2032%20of%20Proceedings%20of%20Machine%20Learning%20Research%20pp%2011881196%20Bejing%20China%202224%20Jun%202014%20PMLR"
        },
        {
            "id": "Levesque_et+al_2011_a",
            "entry": "Hector J Levesque, Ernest Davis, and Leora Morgenstern. The Winograd schema challenge. In AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning, volume 46, pp. 47, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Levesque%2C%20Hector%20J.%20Davis%2C%20Ernest%20Morgenstern%2C%20Leora%20The%20Winograd%20schema%20challenge.%20In%20AAAI%20Spring%20Symposium%3A%20Logical%20Formalizations%20of%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Levesque%2C%20Hector%20J.%20Davis%2C%20Ernest%20Morgenstern%2C%20Leora%20The%20Winograd%20schema%20challenge.%20In%20AAAI%20Spring%20Symposium%3A%20Logical%20Formalizations%20of%202011"
        },
        {
            "id": "Matthews_1975_a",
            "entry": "Brian W Matthews. Comparison of the predicted and observed secondary structure of t4 phage lysozyme. Biochimica et Biophysica Acta (BBA)-Protein Structure, 405(2):442\u2013451, 1975.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Matthews%2C%20Brian%20W.%20Comparison%20of%20the%20predicted%20and%20observed%20secondary%20structure%20of%20t4%20phage%20lysozyme%201975",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Matthews%2C%20Brian%20W.%20Comparison%20of%20the%20predicted%20and%20observed%20secondary%20structure%20of%20t4%20phage%20lysozyme%201975"
        },
        {
            "id": "Mccann_et+al_2017_a",
            "entry": "Bryan McCann, James Bradbury, Caiming Xiong, and Richard Socher. Learned in translation: Contextualized word vectors. In Advances in Neural Information Processing Systems, pp. 6297\u2013 6308, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=McCann%2C%20Bryan%20Bradbury%2C%20James%20Xiong%2C%20Caiming%20Socher%2C%20Richard%20Learned%20in%20translation%3A%20Contextualized%20word%20vectors%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=McCann%2C%20Bryan%20Bradbury%2C%20James%20Xiong%2C%20Caiming%20Socher%2C%20Richard%20Learned%20in%20translation%3A%20Contextualized%20word%20vectors%202017"
        },
        {
            "id": "Mccann_et+al_2018_a",
            "entry": "Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, and Richard Socher. The natural language decathlon: Multitask learning as question answering. arXiv preprint 1806.08730, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1806.08730"
        },
        {
            "id": "Mccoy_2019_a",
            "entry": "R. Thomas McCoy and Tal Linzen. Non-entailed subsequences as a challenge for natural language inference. In Proceedings of the Society for Computation in Linguistics, volume 2, pp. 357\u2013360, 2019.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=McCoy%2C%20R.Thomas%20Linzen%2C%20Tal%20Non-entailed%20subsequences%20as%20a%20challenge%20for%20natural%20language%20inference%202019",
            "oa_query": "https://api.scholarcy.com/oa_version?query=McCoy%2C%20R.Thomas%20Linzen%2C%20Tal%20Non-entailed%20subsequences%20as%20a%20challenge%20for%20natural%20language%20inference%202019"
        },
        {
            "id": "Nie_et+al_2017_a",
            "entry": "Allen Nie, Erin D Bennett, and Noah D Goodman. Dissent: Sentence representation learning from explicit discourse relations. arXiv preprint 1710.04334, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.04334"
        },
        {
            "id": "Pang_2004_a",
            "entry": "Bo Pang and Lillian Lee. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, pp. 271. Association for Computational Linguistics, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pang%2C%20Bo%20Lee%2C%20Lillian%20A%20sentimental%20education%3A%20Sentiment%20analysis%20using%20subjectivity%20summarization%20based%20on%20minimum%20cuts%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pang%2C%20Bo%20Lee%2C%20Lillian%20A%20sentimental%20education%3A%20Sentiment%20analysis%20using%20subjectivity%20summarization%20based%20on%20minimum%20cuts%202004"
        },
        {
            "id": "Pang_2005_a",
            "entry": "Bo Pang and Lillian Lee. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pp. 115\u2013124. Association for Computational Linguistics, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pang%2C%20Bo%20Lee%2C%20Lillian%20Seeing%20stars%3A%20Exploiting%20class%20relationships%20for%20sentiment%20categorization%20with%20respect%20to%20rating%20scales%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pang%2C%20Bo%20Lee%2C%20Lillian%20Seeing%20stars%3A%20Exploiting%20class%20relationships%20for%20sentiment%20categorization%20with%20respect%20to%20rating%20scales%202005"
        },
        {
            "id": "Pennington_et+al_2014_a",
            "entry": "Jeffrey Pennington, Richard Socher, and Christopher Manning. GloVe: Global vectors for word representation. In Proceedings of the Conference on Empirical Methods in Natural Language processing, pp. 1532\u20131543, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pennington%2C%20Jeffrey%20Socher%2C%20Richard%20Manning%2C%20Christopher%20GloVe%3A%20Global%20vectors%20for%20word%20representation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pennington%2C%20Jeffrey%20Socher%2C%20Richard%20Manning%2C%20Christopher%20GloVe%3A%20Global%20vectors%20for%20word%20representation%202014"
        },
        {
            "id": "Peters_et+al_2018_a",
            "entry": "Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. Deep contextualized word representations. In Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Peters%2C%20Matthew%20E.%20Neumann%2C%20Mark%20Iyyer%2C%20Mohit%20Gardner%2C%20Matt%20Deep%20contextualized%20word%20representations%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Peters%2C%20Matthew%20E.%20Neumann%2C%20Mark%20Iyyer%2C%20Mohit%20Gardner%2C%20Matt%20Deep%20contextualized%20word%20representations%202018"
        },
        {
            "id": "Poliak_et+al_2018_a",
            "entry": "Adam Poliak, Jason Naradowsky, Aparajita Haldar, Rachel Rudinger, and Benjamin Van Durme. Hypothesis only baselines in natural language inference. In *SEM@NAACL-HLT, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Poliak%2C%20Adam%20Naradowsky%2C%20Jason%20Haldar%2C%20Aparajita%20Rudinger%2C%20Rachel%20Hypothesis%20only%20baselines%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Poliak%2C%20Adam%20Naradowsky%2C%20Jason%20Haldar%2C%20Aparajita%20Rudinger%2C%20Rachel%20Hypothesis%20only%20baselines%202018"
        },
        {
            "id": "Rajpurkar_et+al_2016_a",
            "entry": "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. SQuAD: 100,000+ questions for machine comprehension of text. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 2383\u20132392. Association for Computational Linguistics, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rajpurkar%2C%20Pranav%20Zhang%2C%20Jian%20Lopyrev%2C%20Konstantin%20Liang%2C%20Percy%20SQuAD%3A%20100%2C000%2B%20questions%20for%20machine%20comprehension%20of%20text%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rajpurkar%2C%20Pranav%20Zhang%2C%20Jian%20Lopyrev%2C%20Konstantin%20Liang%2C%20Percy%20SQuAD%3A%20100%2C000%2B%20questions%20for%20machine%20comprehension%20of%20text%202016"
        },
        {
            "id": "Rocktaschel_et+al_2016_a",
            "entry": "Tim Rocktaschel, Edward Grefenstette, Moritz Hermann, Karl, Tomas Kocisky, and Phil Blunsom. Reasoning about entailment with neural attention. In Proceedings of the International Conference on Learning Representations, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rocktaschel%2C%20Tim%20Grefenstette%2C%20Edward%20Hermann%2C%20Moritz%20Karl%2C%20Tomas%20Kocisky%20Reasoning%20about%20entailment%20with%20neural%20attention%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rocktaschel%2C%20Tim%20Grefenstette%2C%20Edward%20Hermann%2C%20Moritz%20Karl%2C%20Tomas%20Kocisky%20Reasoning%20about%20entailment%20with%20neural%20attention%202016"
        },
        {
            "id": "Ruder_et+al_2017_a",
            "entry": "Sebastian Ruder, Joachim Bingel, Isabelle Augenstein, and Anders S\u00f8gaard. Sluice networks: Learning what to share between loosely related tasks. arXiv preprint 1705.08142, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.08142"
        },
        {
            "id": "Schwartz_et+al_2017_a",
            "entry": "Roy Schwartz, Maarten Sap, Ioannis Konstas, Li Zilles, Yejin Choi, and Noah A. Smith. The effect of different writing tasks on linguistic style: A case study of the ROC story cloze task. In Proceedings of CoNLL, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schwartz%2C%20Roy%20Sap%2C%20Maarten%20Konstas%2C%20Ioannis%20Zilles%2C%20Li%20The%20effect%20of%20different%20writing%20tasks%20on%20linguistic%20style%3A%20A%20case%20study%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schwartz%2C%20Roy%20Sap%2C%20Maarten%20Konstas%2C%20Ioannis%20Zilles%2C%20Li%20The%20effect%20of%20different%20writing%20tasks%20on%20linguistic%20style%3A%20A%20case%20study%202017"
        },
        {
            "id": "Seo_et+al_2017_a",
            "entry": "Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, and Hannaneh Hajishirzi. Bidirectional attention flow for machine comprehension. In Proceedings of the International Conference of Learning Representations, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Seo%2C%20Minjoon%20Kembhavi%2C%20Aniruddha%20Farhadi%2C%20Ali%20Hajishirzi%2C%20Hannaneh%20Bidirectional%20attention%20flow%20for%20machine%20comprehension%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Seo%2C%20Minjoon%20Kembhavi%2C%20Aniruddha%20Farhadi%2C%20Ali%20Hajishirzi%2C%20Hannaneh%20Bidirectional%20attention%20flow%20for%20machine%20comprehension%202017"
        },
        {
            "id": "Socher_et+al_2013_a",
            "entry": "Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Ng, and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 1631\u20131642, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Socher%2C%20Richard%20Perelygin%2C%20Alex%20Wu%2C%20Jean%20Chuang%2C%20Jason%20Andrew%20Ng%2C%20and%20Christopher%20Potts.%20Recursive%20deep%20models%20for%20semantic%20compositionality%20over%20a%20sentiment%20treebank%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Socher%2C%20Richard%20Perelygin%2C%20Alex%20Wu%2C%20Jean%20Chuang%2C%20Jason%20Andrew%20Ng%2C%20and%20Christopher%20Potts.%20Recursive%20deep%20models%20for%20semantic%20compositionality%20over%20a%20sentiment%20treebank%202013"
        },
        {
            "id": "S_2016_a",
            "entry": "Anders S\u00f8gaard and Yoav Goldberg. Deep multi-task learning with low level tasks supervised at lower layers. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), volume 2, pp. 231\u2013235, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=S%C3%B8gaard%2C%20Anders%20Goldberg%2C%20Yoav%20Deep%20multi-task%20learning%20with%20low%20level%20tasks%20supervised%20at%20lower%20layers%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=S%C3%B8gaard%2C%20Anders%20Goldberg%2C%20Yoav%20Deep%20multi-task%20learning%20with%20low%20level%20tasks%20supervised%20at%20lower%20layers%202016"
        },
        {
            "id": "Subramanian_et+al_2018_a",
            "entry": "Sandeep Subramanian, Adam Trischler, Yoshua Bengio, and Christopher J. Pal. Learning general purpose distributed sentence representations via large scale multi-task learning. In Proceedings of the International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Subramanian%2C%20Sandeep%20Trischler%2C%20Adam%20Bengio%2C%20Yoshua%20Pal%2C%20Christopher%20J.%20Learning%20general%20purpose%20distributed%20sentence%20representations%20via%20large%20scale%20multi-task%20learning%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Subramanian%2C%20Sandeep%20Trischler%2C%20Adam%20Bengio%2C%20Yoshua%20Pal%2C%20Christopher%20J.%20Learning%20general%20purpose%20distributed%20sentence%20representations%20via%20large%20scale%20multi-task%20learning%202018"
        },
        {
            "id": "Tsuchiya_2018_a",
            "entry": "Masatoshi Tsuchiya. Performance Impact Caused by Hidden Bias of Training Data for Recognizing Textual Entailment. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), Miyazaki, Japan, May 7-12, 2018 2018. European Language Resources Association (ELRA).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tsuchiya%2C%20Masatoshi%20Performance%20Impact%20Caused%20by%20Hidden%20Bias%20of%20Training%20Data%20for%20Recognizing%20Textual%20Entailment%202018-05-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tsuchiya%2C%20Masatoshi%20Performance%20Impact%20Caused%20by%20Hidden%20Bias%20of%20Training%20Data%20for%20Recognizing%20Textual%20Entailment%202018-05-07"
        },
        {
            "id": "Vaswani_et+al_2017_a",
            "entry": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in Neural Information Processing Systems, pp. 6000\u20136010, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ashish%20Vaswani%20Noam%20Shazeer%20Niki%20Parmar%20Jakob%20Uszkoreit%20Llion%20Jones%20Aidan%20N%20Gomez%20%C5%81ukasz%20Kaiser%20and%20Illia%20Polosukhin%20Attention%20is%20all%20you%20need%20In%20Advances%20in%20Neural%20Information%20Processing%20Systems%20pp%2060006010%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ashish%20Vaswani%20Noam%20Shazeer%20Niki%20Parmar%20Jakob%20Uszkoreit%20Llion%20Jones%20Aidan%20N%20Gomez%20%C5%81ukasz%20Kaiser%20and%20Illia%20Polosukhin%20Attention%20is%20all%20you%20need%20In%20Advances%20in%20Neural%20Information%20Processing%20Systems%20pp%2060006010%202017"
        },
        {
            "id": "Voorhees_1999_a",
            "entry": "Ellen M Voorhees et al. The TREC-8 question answering track report. In TREC, volume 99, pp. 77\u201382, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Voorhees%2C%20Ellen%20M.%20The%20TREC-8%20question%20answering%20track%20report%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Voorhees%2C%20Ellen%20M.%20The%20TREC-8%20question%20answering%20track%20report%201999"
        },
        {
            "id": "Warstadt_et+al_2018_a",
            "entry": "Alex Warstadt, Amanpreet Singh, and Samuel R Bowman. Neural network acceptability judgments. arXiv preprint 1805.12471, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1805.12471"
        },
        {
            "id": "White_et+al_2017_a",
            "entry": "Aaron Steven White, Pushpendre Rastogi, Kevin Duh, and Benjamin Van Durme. Inference is everything: Recasting semantic resources into a unified evaluation framework. In Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers), volume 1, pp. 996\u20131005, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=White%2C%20Aaron%20Steven%20Rastogi%2C%20Pushpendre%20Duh%2C%20Kevin%20Durme%2C%20Benjamin%20Van%20Inference%20is%20everything%3A%20Recasting%20semantic%20resources%20into%20a%20unified%20evaluation%20framework%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=White%2C%20Aaron%20Steven%20Rastogi%2C%20Pushpendre%20Duh%2C%20Kevin%20Durme%2C%20Benjamin%20Van%20Inference%20is%20everything%3A%20Recasting%20semantic%20resources%20into%20a%20unified%20evaluation%20framework%202017"
        }
    ]
}

{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "DEEP ONLINE LEARNING VIA META-LEARNING: CONTINUAL ADAPTATION FOR MODEL-BASED RL",
        "author": "Anusha Nagabandi, Chelsea Finn & Sergey Levine University of California, Berkeley {nagaban,cbfinn,svlevine}@berkeley.edu",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=HyxAfnA5tm"
        },
        "abstract": "Humans and animals can learn complex predictive models that allow them to accurately and reliably reason about real-world phenomena, and they can adapt such models extremely quickly in the face of unexpected changes. Deep neural network models allow us to represent very complex functions, but lack this capacity for rapid online adaptation. The goal in this paper is to develop a method for continual online learning from an incoming stream of data, using deep neural network models. We formulate an online learning procedure that uses stochastic gradient descent to update model parameters, and an expectation maximization algorithm with a Chinese restaurant process prior to develop and maintain a mixture of models to handle non-stationary task distributions. This allows for all models to be adapted as necessary, with new models instantiated for task changes and old models recalled when previously seen tasks are encountered again. Furthermore, we observe that meta-learning can be used to meta-train a model such that this direct online adaptation with SGD is effective, which is otherwise not the case for large function approximators. In this work, we apply our meta-learning for online learning (MOLe) approach to model-based reinforcement learning, where adapting the predictive model is critical for control; we demonstrate that MOLe outperforms alternative prior methods, and enables effective continuous adaptation in non-stationary task distributions such as varying terrains, motor failures, and unexpected disturbances. Videos available at: https://sites.google.com/berkeley.edu/onlineviameta"
    },
    "keywords": [
        {
            "term": "neural network model",
            "url": "https://en.wikipedia.org/wiki/neural_network_model"
        },
        {
            "term": "reinforcement learning",
            "url": "https://en.wikipedia.org/wiki/reinforcement_learning"
        },
        {
            "term": "meta learning",
            "url": "https://en.wikipedia.org/wiki/meta_learning"
        },
        {
            "term": "expectation maximization",
            "url": "https://en.wikipedia.org/wiki/expectation_maximization"
        },
        {
            "term": "stochastic gradient descent",
            "url": "https://en.wikipedia.org/wiki/stochastic_gradient_descent"
        },
        {
            "term": "real world",
            "url": "https://en.wikipedia.org/wiki/real_world"
        },
        {
            "term": "new model",
            "url": "https://en.wikipedia.org/wiki/New_Model"
        },
        {
            "term": "Chinese restaurant process",
            "url": "https://en.wikipedia.org/wiki/Chinese_restaurant_process"
        },
        {
            "term": "online learning",
            "url": "https://en.wikipedia.org/wiki/online_learning"
        },
        {
            "term": "predictive model",
            "url": "https://en.wikipedia.org/wiki/predictive_model"
        }
    ],
    "abbreviations": {
        "MOLe": "meta-learning for online learning",
        "SGD": "stochastic gradient descent",
        "MAML": "model-agnostic meta-learning",
        "EM": "expectation maximization",
        "CRP": "Chinese restaurant process",
        "T \u2217": "the model p\u03b8t+1",
        "Ti": "Ti Calculate Pt"
    },
    "highlights": [
        "Human and animal learning is characterized not just by a capacity to acquire complex skills, but the ability to adapt rapidly when those skills must be carried out under new or changing conditions",
        "Since learning entirely new models on such short time-scales is impractical, we can devise algorithms that explicitly train models to adapt quickly from small amounts of data. Such online adaptation is crucial for intelligent systems operating in the real world, where changing factors and unexpected perturbations are the norm",
        "We propose an algorithm for fast and continuous online learning that utilizes deep neural network models to build and maintain a task distribution, allowing for the natural development of both generalization as well as task specialization",
        "We presented an online learning method for neural network models that can handle non-stationary, multi-task settings within each trial",
        "Our method adapts the model directly with stochastic gradient descent, where an expectation maximization algorithm uses a Chinese restaurant process prior to maintain a distribution over tasks and handle non-stationarity",
        "Our results showed that our method can develop its own notion of task, continuously adapt away from the prior as necessary, and recall tasks it has seen before"
    ],
    "key_statements": [
        "Human and animal learning is characterized not just by a capacity to acquire complex skills, but the ability to adapt rapidly when those skills must be carried out under new or changing conditions",
        "Since learning entirely new models on such short time-scales is impractical, we can devise algorithms that explicitly train models to adapt quickly from small amounts of data. Such online adaptation is crucial for intelligent systems operating in the real world, where changing factors and unexpected perturbations are the norm",
        "We propose an algorithm for fast and continuous online learning that utilizes deep neural network models to build and maintain a task distribution, allowing for the natural development of both generalization as well as task specialization",
        "A more natural formulation is one where the model receives a continuous stream of data and must adapt online to a potentially non-stationary task distribution",
        "We address non-stationary task distributions and do not assume that task boundaries are known",
        "It is straightforward to perform multiple steps of expectation maximization while still remaining fully online. We summarize this full online learning portion of meta-learning for online learning, and we outline it in Alg. 1",
        "We have extended these capabilities by enabling more evolution of knowledge through a temporally-extended online adaptation procedure",
        "While our procedure for continual online learning is still initialized with this meta-training for kshot adaptation, we found that this prior was sufficient to enable effective continual online adaptation at test time",
        "We show in Sec. 7 that our method outperforms both of these methods, but the mere ability to use this meta-learned prior in these ways makes the use of model-agnostic meta-learning enticing",
        "Standard automatic differentiation software can compute the corresponding meta-gradient. This is not substantially more complex than standard model-agnostic meta-learning; for longer trial lengths, truncated backpropagation is an option. Such a meta-training procedure better matches the way that the model is used during online adaptation, we found that it did not substantially improve our results",
        "The questions that we aimed to study from our experiments include: Can meta-learning for online learning 1) autonomously discover some task structure amid a stream of non-stationary data? 2) adapt to tasks that are further outside of the task distribution than can be handled by a k-shot learning approach? 3) recognize and revert to tasks it has seen before? 4) avoid overfitting to a recent task to prevent deterioration of performance upon the task switch? 5) outperform other methods?",
        "For the three meta-learning and adaptation methods, we expect continued adaptation with metalearning to perform poorly due to continuous gradient steps causing it to overfit to recent data; that is, we expect that experience on the upward slopes to lead to deterioration of performance on downward slopes, or something similar. Based on both our qualitative and quantitative results, we see that the meta-learning procedure seems to have initialized the agent with a parameter space in which these various \u201ctasks\u201d are not seen as substantially different, where online learning by stochastic gradient descent performs well",
        "We presented an online learning method for neural network models that can handle non-stationary, multi-task settings within each trial",
        "Our method adapts the model directly with stochastic gradient descent, where an expectation maximization algorithm uses a Chinese restaurant process prior to maintain a distribution over tasks and handle non-stationarity",
        "stochastic gradient descent generally makes for a poor online learning algorithm in the streaming setting for large parametric models such as deep neural networks, we observe that, by (1) meta-training the model for fast adaptation with model-agnostic meta-learning and (2) employing our online algorithm for probabilistic updates at test time, we can enable effective online learning with neural networks. We applied this approach to model-based RL, and we demonstrated that it could be used to adapt the behavior of simulated robots faced with various new and unexpected tasks",
        "Our results showed that our method can develop its own notion of task, continuously adapt away from the prior as necessary, and recall tasks it has seen before"
    ],
    "summary": [
        "Human and animal learning is characterized not just by a capacity to acquire complex skills, but the ability to adapt rapidly when those skills must be carried out under new or changing conditions.",
        "A more natural formulation is one where the model receives a continuous stream of data and must adapt online to a potentially non-stationary task distribution.",
        "The primary contribution of this paper is a meta-learning for online learning (MOLe) algorithm that uses expectation maximization, in conjunction with a Chinese restaurant process prior on the task distribution, to learn mixtures of neural network models that are each updated with online SGD.",
        "We demonstrate that MOLe outperforms a state-of-the-art prior method that does k-shot model-based meta-RL, as well as natural baselines such as continuous gradient updates for adaptation and online learning without meta-training.",
        "We aim to lift this restriction by using model-agnostic meta-learning (MAML) to explicitly pretrain a model that enables fast adaptation, which we use for continuous online adaptation via an expectation maximization algorithm with a Chinese restaurant process (Blei et al, 2003) prior for dynamic allocation of new tasks in a non-stationary task distribution.",
        "We discuss the process of obtaining a meta-learned prior in Sec. 5, but we first formulate an online adaptation algorithm using SGD with expectation maximization to maintain and adapt a mixture model over task model parameters.",
        "While our procedure for continual online learning is still initialized with this meta-training for kshot adaptation (i.e., MAML), we found that this prior was sufficient to enable effective continual online adaptation at test time.",
        "As shown in Fig. 2, neither model-based RL nor model-based RL with online gradient updates perform well on these out-of-distribution tasks, even though those models were trained on the same data that the meta- Figure 1: Half-cheetah agent, shown trained model received.",
        "Based on both our qualitative and quantitative results, we see that the meta-learning procedure seems to have initialized the agent with a parameter space in which these various \u201ctasks\u201d are not seen as substantially different, where online learning by SGD performs well.",
        "We presented an online learning method for neural network models that can handle non-stationary, multi-task settings within each trial.",
        "Our method adapts the model directly with SGD, where an EM algorithm uses a Chinese restaurant process prior to maintain a distribution over tasks and handle non-stationarity.",
        "SGD generally makes for a poor online learning algorithm in the streaming setting for large parametric models such as deep neural networks, we observe that, by (1) meta-training the model for fast adaptation with MAML and (2) employing our online algorithm for probabilistic updates at test time, we can enable effective online learning with neural networks."
    ],
    "headline": "The goal in this paper is to develop a method for continual online learning from an incoming stream of data, using deep neural network models",
    "reference_links": [
        {
            "id": "Al-Shedivat_et+al_2017_a",
            "entry": "Maruan Al-Shedivat, Trapit Bansal, Yuri Burda, Ilya Sutskever, Igor Mordatch, and Pieter Abbeel. Continuous adaptation via meta-learning in nonstationary and competitive environments. arXiv preprint arXiv:1710.03641, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.03641"
        },
        {
            "id": "Aljundi_et+al_2017_a",
            "entry": "Rahaf Aljundi, Punarjay Chakravarty, and Tinne Tuytelaars. Expert gate: Lifelong learning with a network of experts. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Aljundi%2C%20Rahaf%20Chakravarty%2C%20Punarjay%20Tuytelaars%2C%20Tinne%20Expert%20gate%3A%20Lifelong%20learning%20with%20a%20network%20of%20experts%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Aljundi%2C%20Rahaf%20Chakravarty%2C%20Punarjay%20Tuytelaars%2C%20Tinne%20Expert%20gate%3A%20Lifelong%20learning%20with%20a%20network%20of%20experts%202017"
        },
        {
            "id": "Anonymous_2019_a",
            "entry": "Anonymous. Modulating transfer between tasks in gradient-based meta-learning. 2019. URL https://openreview.net/forum?id=rkxLDyBuFX.under review.",
            "url": "https://openreview.net/forum?id=rkxLDyBuFX.under"
        },
        {
            "id": "Bengio_et+al_1992_a",
            "entry": "Samy Bengio, Yoshua Bengio, Jocelyn Cloutier, and Jan Gecsei. On the optimization of a synaptic learning rule. In Optimality in Artificial and Biological Neural Networks, 1992.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bengio%2C%20Samy%20Bengio%2C%20Yoshua%20Cloutier%2C%20Jocelyn%20Gecsei%2C%20Jan%20On%20the%20optimization%20of%20a%20synaptic%20learning%20rule%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bengio%2C%20Samy%20Bengio%2C%20Yoshua%20Cloutier%2C%20Jocelyn%20Gecsei%2C%20Jan%20On%20the%20optimization%20of%20a%20synaptic%20learning%20rule%201992"
        },
        {
            "id": "Blei_2003_a",
            "entry": "David M Blei, Andrew Y Ng, and Michael I Jordan. Latent dirichlet allocation. Journal of machine Learning research, 3(Jan):993\u20131022, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Blei%2C%20David%20M.%20Andrew%20Y%20Ng%2C%20and%20Michael%20I%20Jordan.%20Latent%20dirichlet%20allocation%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Blei%2C%20David%20M.%20Andrew%20Y%20Ng%2C%20and%20Michael%20I%20Jordan.%20Latent%20dirichlet%20allocation%202003"
        },
        {
            "id": "Bottou_1998_a",
            "entry": "Leon Bottou. Online learning and stochastic approximations. On-line learning in neural networks, 17(9):142, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bottou%2C%20Leon%20Online%20learning%20and%20stochastic%20approximations.%20On-line%20learning%20in%20neural%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bottou%2C%20Leon%20Online%20learning%20and%20stochastic%20approximations.%20On-line%20learning%20in%20neural%201998"
        },
        {
            "id": "Broderick_et+al_2013_a",
            "entry": "Tamara Broderick, Nicholas Boyd, Andre Wibisono, Ashia C Wilson, and Michael I Jordan. Streaming variational bayes. In Advances in Neural Information Processing Systems, pp. 1727\u20131735, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Broderick%2C%20Tamara%20Boyd%2C%20Nicholas%20Wibisono%2C%20Andre%20Wilson%2C%20Ashia%20C.%20Streaming%20variational%20bayes%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Broderick%2C%20Tamara%20Boyd%2C%20Nicholas%20Wibisono%2C%20Andre%20Wilson%2C%20Ashia%20C.%20Streaming%20variational%20bayes%202013"
        },
        {
            "id": "Doyon_2005_a",
            "entry": "Julien Doyon and Habib Benali. Reorganization and plasticity in the adult brain during learning of motor skills. Current opinion in neurobiology, 15(2):161\u2013167, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Doyon%2C%20Julien%20Benali%2C%20Habib%20Reorganization%20and%20plasticity%20in%20the%20adult%20brain%20during%20learning%20of%20motor%20skills%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Doyon%2C%20Julien%20Benali%2C%20Habib%20Reorganization%20and%20plasticity%20in%20the%20adult%20brain%20during%20learning%20of%20motor%20skills%202005"
        },
        {
            "id": "Duan_et+al_2016_a",
            "entry": "Yan Duan, John Schulman, Xi Chen, Peter L Bartlett, Ilya Sutskever, and Pieter Abbeel. Rl2: Fast reinforcement learning via slow reinforcement learning. arXiv:1611.02779, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.02779"
        },
        {
            "id": "Duchi_et+al_2011_a",
            "entry": "John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Duchi%2C%20John%20Hazan%2C%20Elad%20Singer%2C%20Yoram%20Adaptive%20subgradient%20methods%20for%20online%20learning%20and%20stochastic%20optimization%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Duchi%2C%20John%20Hazan%2C%20Elad%20Singer%2C%20Yoram%20Adaptive%20subgradient%20methods%20for%20online%20learning%20and%20stochastic%20optimization%202011"
        },
        {
            "id": "Finn_et+al_2017_a",
            "entry": "Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep networks. International Conference on Machine Learning (ICML), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Finn%2C%20Chelsea%20Abbeel%2C%20Pieter%20Levine%2C%20Sergey%20Model-agnostic%20meta-learning%20for%20fast%20adaptation%20of%20deep%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Finn%2C%20Chelsea%20Abbeel%2C%20Pieter%20Levine%2C%20Sergey%20Model-agnostic%20meta-learning%20for%20fast%20adaptation%20of%20deep%20networks%202017"
        },
        {
            "id": "Flanagan_1993_a",
            "entry": "J Randall Flanagan and Alan M Wing. Modulation of grip force with load force during point-to-point arm movements. Experimental Brain Research, 95(1):131\u2013143, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Flanagan%2C%20J.Randall%20Wing%2C%20Alan%20M.%20Modulation%20of%20grip%20force%20with%20load%20force%20during%20point-to-point%20arm%20movements%201993",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Flanagan%2C%20J.Randall%20Wing%2C%20Alan%20M.%20Modulation%20of%20grip%20force%20with%20load%20force%20during%20point-to-point%20arm%20movements%201993"
        },
        {
            "id": "Fortunato_et+al_2017_a",
            "entry": "Meire Fortunato, Charles Blundell, and Oriol Vinyals. Bayesian recurrent neural networks. arXiv preprint arXiv:1704.02798, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.02798"
        },
        {
            "id": "Hoffman_et+al_2010_a",
            "entry": "Matthew Hoffman, Francis R Bach, and David M Blei. Online learning for latent dirichlet allocation. In advances in neural information processing systems, pp. 856\u2013864, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hoffman%2C%20Matthew%20Bach%2C%20Francis%20R.%20Blei%2C%20David%20M.%20Online%20learning%20for%20latent%20dirichlet%20allocation%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hoffman%2C%20Matthew%20Bach%2C%20Francis%20R.%20Blei%2C%20David%20M.%20Online%20learning%20for%20latent%20dirichlet%20allocation%202010"
        },
        {
            "id": "Jafari_et+al_2001_a",
            "entry": "Amir Jafari, Amy Greenwald, David Gondek, and Gunes Ercal. On no-regret learning, fictitious play, and nash equilibrium. In ICML, volume 1, pp. 226\u2013233, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jafari%2C%20Amir%20Greenwald%2C%20Amy%20Gondek%2C%20David%20Ercal%2C%20Gunes%20On%20no-regret%20learning%2C%20fictitious%20play%2C%20and%20nash%20equilibrium%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jafari%2C%20Amir%20Greenwald%2C%20Amy%20Gondek%2C%20David%20Ercal%2C%20Gunes%20On%20no-regret%20learning%2C%20fictitious%20play%2C%20and%20nash%20equilibrium%202001"
        },
        {
            "id": "Kirkpatrick_et+al_2017_a",
            "entry": "James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic forgetting in neural networks. Proceedings of the National Academy of Sciences, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kirkpatrick%2C%20James%20Pascanu%2C%20Razvan%20Rabinowitz%2C%20Neil%20Veness%2C%20Joel%20Overcoming%20catastrophic%20forgetting%20in%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kirkpatrick%2C%20James%20Pascanu%2C%20Razvan%20Rabinowitz%2C%20Neil%20Veness%2C%20Joel%20Overcoming%20catastrophic%20forgetting%20in%20neural%20networks%202017"
        },
        {
            "id": "Krause_et+al_2016_a",
            "entry": "Ben Krause, Liang Lu, Iain Murray, and Steve Renals. Multiplicative lstm for sequence modelling. arXiv preprint arXiv:1609.07959, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1609.07959"
        },
        {
            "id": "Krause_et+al_2017_a",
            "entry": "Ben Krause, Emmanuel Kahembwe, Iain Murray, and Steve Renals. Dynamic evaluation of neural sequence models. CoRR, abs/1709.07432, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1709.07432"
        },
        {
            "id": "Lopez-Paz_2017_a",
            "entry": "David Lopez-Paz et al. Gradient episodic memory for continual learning. In Advances in Neural Information Processing Systems, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lopez-Paz%2C%20David%20Gradient%20episodic%20memory%20for%20continual%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lopez-Paz%2C%20David%20Gradient%20episodic%20memory%20for%20continual%20learning%202017"
        },
        {
            "id": "Munkhdalai_2017_a",
            "entry": "Tsendsuren Munkhdalai and Hong Yu. Meta networks. International Conference on Machine Learning (ICML), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Munkhdalai%2C%20Tsendsuren%20Yu%2C%20Hong%20Meta%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Munkhdalai%2C%20Tsendsuren%20Yu%2C%20Hong%20Meta%20networks%202017"
        },
        {
            "id": "Murphy_2002_a",
            "entry": "K. Murphy. Dynamic Bayesian Networks: Representation, Inference and Learning. PhD thesis, Dept. Computer Science, UC Berkeley, 2002. URL https://www.cs.ubc.ca/\u0303murphyk/Thesis/thesis.html.",
            "url": "https://www.cs.ubc.ca/\u0303murphyk/Thesis/thesis.html"
        },
        {
            "id": "Nagabandi_et+al_2018_a",
            "entry": "Anusha Nagabandi, Ignasi Clavera, Simin Liu, Ronald S Fearing, Pieter Abbeel, Sergey Levine, and Chelsea Finn. Learning to adapt: Meta-learning for model-based control. arXiv preprint arXiv:1803.11347, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.11347"
        },
        {
            "id": "Naik_1992_a",
            "entry": "Devang K Naik and RJ Mammone. Meta-neural networks that learn by learning. In International Joint Conference on Neural Netowrks (IJCNN), 1992.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Naik%2C%20Devang%20K.%20Mammone%2C%20R.J.%20Meta-neural%20networks%20that%20learn%20by%20learning%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Naik%2C%20Devang%20K.%20Mammone%2C%20R.J.%20Meta-neural%20networks%20that%20learn%20by%20learning%201992"
        },
        {
            "id": "Nguyen_et+al_2017_a",
            "entry": "Cuong V Nguyen, Yingzhen Li, Thang D Bui, and Richard E Turner. Variational continual learning. arXiv:1710.10628, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.10628"
        },
        {
            "id": "Rao_2009_a",
            "entry": "A. Rao. A survey of numerical methods for optimal control. In Advances in the Astronautical Sciences, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rao%2C%20A.%20A%20survey%20of%20numerical%20methods%20for%20optimal%20control%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rao%2C%20A.%20A%20survey%20of%20numerical%20methods%20for%20optimal%20control%202009"
        },
        {
            "id": "Ravi_2017_a",
            "entry": "Sachin Ravi and Hugo Larochelle. Optimization as a model for few-shot learning. In International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ravi%2C%20Sachin%20Larochelle%2C%20Hugo%20Optimization%20as%20a%20model%20for%20few-shot%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ravi%2C%20Sachin%20Larochelle%2C%20Hugo%20Optimization%20as%20a%20model%20for%20few-shot%20learning%202017"
        },
        {
            "id": "Rebuffi_et+al_2017_a",
            "entry": "Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, and Christoph H Lampert. icarl: Incremental classifier and representation learning. In Proc. CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rebuffi%2C%20Sylvestre-Alvise%20Kolesnikov%2C%20Alexander%20Lampert%2C%20Christoph%20H.%20icarl%3A%20Incremental%20classifier%20and%20representation%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rebuffi%2C%20Sylvestre-Alvise%20Kolesnikov%2C%20Alexander%20Lampert%2C%20Christoph%20H.%20icarl%3A%20Incremental%20classifier%20and%20representation%20learning%202017"
        },
        {
            "id": "Rei_2015_a",
            "entry": "Marek Rei. Online representation learning in recurrent neural language models. CoRR, abs/1508.03854, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1508.03854"
        },
        {
            "id": "Ritter_et+al_2018_a",
            "entry": "Samuel Ritter, Jane X Wang, Zeb Kurth-Nelson, Siddhant M Jayakumar, Charles Blundell, Razvan Pascanu, and Matthew Botvinick. Been there, done that: Meta-learning with episodic recall. arXiv preprint arXiv:1805.09692, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1805.09692"
        },
        {
            "id": "Rusu_et+al_2016_a",
            "entry": "Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell. Progressive neural networks. arXiv:1606.04671, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1606.04671"
        },
        {
            "id": "Sahoo_et+al_2017_a",
            "entry": "Doyen Sahoo, Quang Pham, Jing Lu, and Steven CH Hoi. Online deep learning: Learning deep neural networks on the fly. arXiv preprint arXiv:1711.03705, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.03705"
        },
        {
            "id": "Santoro_et+al_2016_a",
            "entry": "Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy Lillicrap. Metalearning with memory-augmented neural networks. In International Conference on Machine Learning (ICML), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Santoro%2C%20Adam%20Bartunov%2C%20Sergey%20Botvinick%2C%20Matthew%20Wierstra%2C%20Daan%20Metalearning%20with%20memory-augmented%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Santoro%2C%20Adam%20Bartunov%2C%20Sergey%20Botvinick%2C%20Matthew%20Wierstra%2C%20Daan%20Metalearning%20with%20memory-augmented%20neural%20networks%202016"
        },
        {
            "id": "Schmidhuber_1987_a",
            "entry": "Jurgen Schmidhuber. Evolutionary principles in self-referential learning. Diploma thesis, Institut f. Informatik, Tech. Univ. Munich, 1987.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schmidhuber%2C%20Jurgen%20Evolutionary%20principles%20in%20self-referential%20learning.%20Diploma%201987"
        },
        {
            "id": "Stimberg_et+al_2012_a",
            "entry": "Florian Stimberg, Andreas Ruttor, and Manfred Opper. Bayesian inference for change points in dynamical systems with reusable states-a chinese restaurant process approach. In Artificial Intelligence and Statistics, pp. 1117\u20131124, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stimberg%2C%20Florian%20Ruttor%2C%20Andreas%20Opper%2C%20Manfred%20Bayesian%20inference%20for%20change%20points%20in%20dynamical%20systems%20with%20reusable%20states-a%20chinese%20restaurant%20process%20approach%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Stimberg%2C%20Florian%20Ruttor%2C%20Andreas%20Opper%2C%20Manfred%20Bayesian%20inference%20for%20change%20points%20in%20dynamical%20systems%20with%20reusable%20states-a%20chinese%20restaurant%20process%20approach%202012"
        },
        {
            "id": "Thrun_1998_a",
            "entry": "Sebastian Thrun. Lifelong learning algorithms. In Learning to learn. Springer, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Thrun%2C%20Sebastian%20Lifelong%20learning%20algorithms.%20In%20Learning%20to%20learn%201998"
        },
        {
            "id": "Thrun_1998_b",
            "entry": "Sebastian Thrun and Lorien Pratt. Learning to learn. Springer Science & Business Media, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Thrun%2C%20Sebastian%20Pratt%2C%20Lorien%20Learning%20to%20learn%201998"
        },
        {
            "id": "Todorov_et+al_2012_a",
            "entry": "Emanuel Todorov, Tom Erez, and Yuval Tassa. Mujoco: A physics engine for model-based control. In Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International Conference on, pp. 5026\u2013 5033. IEEE, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Todorov%2C%20Emanuel%20Erez%2C%20Tom%20Tassa%2C%20Yuval%20Mujoco%3A%20A%20physics%20engine%20for%20model-based%20control%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Todorov%2C%20Emanuel%20Erez%2C%20Tom%20Tassa%2C%20Yuval%20Mujoco%3A%20A%20physics%20engine%20for%20model-based%20control%202012"
        },
        {
            "id": "Wang_et+al_2016_a",
            "entry": "Jane X Wang, Zeb Kurth-Nelson, Dhruva Tirumala, Hubert Soyer, Joel Z Leibo, Remi Munos, Charles Blundell, Dharshan Kumaran, and Matt Botvinick. Learning to reinforcement learn. arXiv:1611.05763, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.05763"
        },
        {
            "id": "Zenke_2017_a",
            "entry": "Published as a conference paper at ICLR 2019 Yu-Xiong Wang, Deva Ramanan, and Martial Hebert. Growing a brain: Fine-tuning by increasing model capacity. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), 2017. Grady Williams, Andrew Aldrich, and Evangelos Theodorou. Model predictive path integral control using covariance variable importance sampling. CoRR, abs/1509.01149, 2015. Friedemann Zenke, Ben Poole, and Surya Ganguli. Continual learning through synaptic intelligence. In International Conference on Machine Learning, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1509.01149"
        }
    ]
}

{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "REASONING ABOUT PHYSICAL INTERACTIONS WITH OBJECT-ORIENTED PREDICTION AND PLANNING",
        "author": "Michael Janner, Sergey Levine, William T. Freeman, Joshua B. Tenenbaum, Chelsea Finn, & Jiajun Wu, \u2020University of California, Berkeley \u2021Massachusetts Institute of Technology {janner,svlevine,cbfinn}@berkeley.edu {billf,jbt,jiajunwu}@mit.edu",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=HJx9EhC9tQ"
        },
        "abstract": "Object-based factorizations provide a useful level of abstraction for interacting with the world. Building explicit object representations, however, often requires supervisory signals that are difficult to obtain in practice. We present a paradigm for learning object-centric representations for physical scene understanding without direct supervision of object properties. Our model, Object-Oriented Prediction and Planning (O2P2), jointly learns a perception function to map from image observations to object representations, a pairwise physics interaction function to predict the time evolution of a collection of objects, and a rendering function to map objects back to pixels. For evaluation, we consider not only the accuracy of the physical predictions of the model, but also its utility for downstream tasks that require an actionable representation of intuitive physics. After training our model on an image prediction task, we can use its learned representations to build block towers more complicated than those observed during training."
    },
    "keywords": [
        {
            "term": "dynamics",
            "url": "https://en.wikipedia.org/wiki/dynamics"
        },
        {
            "term": "block tower",
            "url": "https://en.wikipedia.org/wiki/Block_Tower"
        },
        {
            "term": "physics engine",
            "url": "https://en.wikipedia.org/wiki/physics_engine"
        },
        {
            "term": "physical interaction",
            "url": "https://en.wikipedia.org/wiki/physical_interaction"
        }
    ],
    "abbreviations": {
        "CEM": "crossentropy method",
        "SAVP": "Stochastic adversarial video prediction"
    },
    "highlights": [
        "Consider the castle made out of toy blocks in Figure 1a",
        "We introduced a method of learning object-centric representations suitable for physical interactions",
        "We relied only on segment proposals and a factorized structure in a learned physics engine to guide the training of such representations",
        "We demonstrated that this approach is appropriate for a standard physics prediction task",
        "We showed that this method gives rise to object representations that can be used for difficult planning problems, in which object configurations differ from those seen during training, without further adaptation",
        "We evaluated our model on a block tower matching task and found that it outperformed object-agnostic approaches that made comparisons in pixel-space directly"
    ],
    "key_statements": [
        "Consider the castle made out of toy blocks in Figure 1a",
        "We introduced a method of learning object-centric representations suitable for physical interactions",
        "We relied only on segment proposals and a factorized structure in a learned physics engine to guide the training of such representations",
        "We demonstrated that this approach is appropriate for a standard physics prediction task",
        "We showed that this method gives rise to object representations that can be used for difficult planning problems, in which object configurations differ from those seen during training, without further adaptation",
        "We evaluated our model on a block tower matching task and found that it outperformed object-agnostic approaches that made comparisons in pixel-space directly"
    ],
    "summary": [
        "Consider the castle made out of toy blocks in Figure 1a.",
        "We jointly train a perception module, an object-factorized physics engine, and a neural renderer on a physics prediction task with pixel generation objective.",
        "Physics, and rendering modules jointly on an image reconstruction and prediction task.",
        "Given the observed segmented image S0, we predict object representations using the perception module O = fpercept(S0) and their time-evolution using the physics module O = fphysics(O).",
        "We describe the use of our perception, physics, and rendering modules in the representative planning task depicted in Figure 1, in which the goal is to build a block tower to match an observed image.",
        "We train a rendering function as part of our model, we guide the planning procedure for constructing towers solely through errors in the learned object representation space.",
        "The perception module encodes the segmented goal image into a set of object representations Ogoal.",
        "We view action sample am as an image segment sm and use the perception module to produce object vectors Om. Because the actions selected should produce a stable tower, we run these object representations through the physics engine to yield Om before comparing with Ogoal.",
        "Even when the model\u2019s predictions differed from the ground truth image, such as in the last row of the figure, the physics engine produced a plausible steady-state configuration of the observed scene.",
        "Because this ablation does not simulate the effect of dropping a block, its highly-scored action samples correspond almost exactly to the actual locations of the objects in the goal image.",
        "Instead of evaluating a sampled action by moving an appropriate block to the specified position and inferring object representations with the perception module, we trained a separate two-layer MLP to map directly from actions to object representations.",
        "In contrast to these prior methods, we consider not only the accuracy of the predictions of our model, but its utility for downstream tasks that are intentionally constructed to evaluate its ability to acquire an actionable representation of intuitive physics.",
        "We relied only on segment proposals and a factorized structure in a learned physics engine to guide the training of such representations.",
        "We evaluated our model on a block tower matching task and found that it outperformed object-agnostic approaches that made comparisons in pixel-space directly."
    ],
    "headline": "We present a paradigm for learning object-centric representations for physical scene understanding without direct supervision of object properties",
    "reference_links": [
        {
            "id": "Babaeizadeh_et+al_2018_a",
            "entry": "Mohammad Babaeizadeh, Chelsea Finn, Dumitru Erhan, Roy H. Campbell, and Sergey Levine. Stochastic variational video prediction. In International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Babaeizadeh%2C%20Mohammad%20Finn%2C%20Chelsea%20Erhan%2C%20Dumitru%20Campbell%2C%20Roy%20H.%20Stochastic%20variational%20video%20prediction%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Babaeizadeh%2C%20Mohammad%20Finn%2C%20Chelsea%20Erhan%2C%20Dumitru%20Campbell%2C%20Roy%20H.%20Stochastic%20variational%20video%20prediction%202018"
        },
        {
            "id": "Chang_et+al_2016_a",
            "entry": "Michael B Chang, Tomer Ullman, Antonio Torralba, and Joshua B Tenenbaum. A compositional object-based approach to learning physical dynamics. In International Conference on Learning Representations, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chang%2C%20Michael%20B.%20Ullman%2C%20Tomer%20Torralba%2C%20Antonio%20Tenenbaum%2C%20Joshua%20B.%20A%20compositional%20object-based%20approach%20to%20learning%20physical%20dynamics%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chang%2C%20Michael%20B.%20Ullman%2C%20Tomer%20Torralba%2C%20Antonio%20Tenenbaum%2C%20Joshua%20B.%20A%20compositional%20object-based%20approach%20to%20learning%20physical%20dynamics%202016"
        },
        {
            "id": "Devin_et+al_2017_a",
            "entry": "Coline Devin, Pieter Abbeel, Trevor Darrell, and Sergey Levine. Deep object-centric representations for generalizable robot learning. CoRR, abs/1708.04225, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1708.04225"
        },
        {
            "id": "Diuk_et+al_2008_a",
            "entry": "Carlos Diuk, Andre Cohen, and Michael L. Littman. An object-oriented representation for efficient reinforcement learning. In Proceedings of the 25th International Conference on Machine Learning, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Diuk%2C%20Carlos%20Cohen%2C%20Andre%20Littman%2C%20Michael%20L.%20An%20object-oriented%20representation%20for%20efficient%20reinforcement%20learning%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Diuk%2C%20Carlos%20Cohen%2C%20Andre%20Littman%2C%20Michael%20L.%20An%20object-oriented%20representation%20for%20efficient%20reinforcement%20learning%202008"
        },
        {
            "id": "Ehrhardt_et+al_2017_a",
            "entry": "Sebastien Ehrhardt, Aron Monszpart, Niloy J. Mitra, and Andrea Vedaldi. Taking Visual Motion Prediction To New Heightfields. arXiv preprint arXiv:1712.09448, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.09448"
        },
        {
            "id": "Eslami_et+al_2016_a",
            "entry": "S. M. Ali Eslami, Nicolas Heess, Theophane Weber, Yuval Tassa, David Szepesvari, Koray Kavukcuoglu, and Geoffrey E Hinton. Attend, infer, repeat: Fast scene understanding with generative models. In Advances in Neural Information Processing Systems 29. 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Eslami%2C%20S.M.Ali%20Heess%2C%20Nicolas%20Weber%2C%20Theophane%20Tassa%2C%20Yuval%20Attend%2C%20infer%2C%20repeat%3A%20Fast%20scene%20understanding%20with%20generative%20models%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Eslami%2C%20S.M.Ali%20Heess%2C%20Nicolas%20Weber%2C%20Theophane%20Tassa%2C%20Yuval%20Attend%2C%20infer%2C%20repeat%3A%20Fast%20scene%20understanding%20with%20generative%20models%202016"
        },
        {
            "id": "Fragkiadaki_et+al_2016_a",
            "entry": "Katerina Fragkiadaki, Pulkit Agrawal, Sergey Levine, and Jitendra Malik. Learning visual predictive models of physics for playing billiards. In International Conference on Learning Representations, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fragkiadaki%2C%20Katerina%20Agrawal%2C%20Pulkit%20Levine%2C%20Sergey%20Malik%2C%20Jitendra%20Learning%20visual%20predictive%20models%20of%20physics%20for%20playing%20billiards%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fragkiadaki%2C%20Katerina%20Agrawal%2C%20Pulkit%20Levine%2C%20Sergey%20Malik%2C%20Jitendra%20Learning%20visual%20predictive%20models%20of%20physics%20for%20playing%20billiards%202016"
        },
        {
            "id": "Goel_et+al_2018_a",
            "entry": "Vik Goel, Jameson Weng, and Pascal Poupart. Unsupervised video object segmentation for deep reinforcement learning. CoRR, abs/1805.07780, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1805.07780"
        },
        {
            "id": "Greff_et+al_2017_a",
            "entry": "Klaus Greff, Sjoerd van Steenkiste, and Jurgen Schmidhuber. Neural expectation maximization. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems 30. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Klaus%20Greff%20Sjoerd%20van%20Steenkiste%20and%20Jurgen%20Schmidhuber%20Neural%20expectation%20maximization%20In%20I%20Guyon%20U%20V%20Luxburg%20S%20Bengio%20H%20Wallach%20R%20Fergus%20S%20Vishwanathan%20and%20R%20Garnett%20eds%20Advances%20in%20Neural%20Information%20Processing%20Systems%2030%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Klaus%20Greff%20Sjoerd%20van%20Steenkiste%20and%20Jurgen%20Schmidhuber%20Neural%20expectation%20maximization%20In%20I%20Guyon%20U%20V%20Luxburg%20S%20Bengio%20H%20Wallach%20R%20Fergus%20S%20Vishwanathan%20and%20R%20Garnett%20eds%20Advances%20in%20Neural%20Information%20Processing%20Systems%2030%202017"
        },
        {
            "id": "Gupta_et+al_2010_a",
            "entry": "Abhinav Gupta, Alexei A. Efros, and Martial Hebert. Blocks world revisited: Image understanding using qualitative geometry and mechanics. In European Conference on Computer Vision(ECCV), 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gupta%2C%20Abhinav%20Efros%2C%20Alexei%20A.%20Hebert%2C%20Martial%20Blocks%20world%20revisited%3A%20Image%20understanding%20using%20qualitative%20geometry%20and%20mechanics%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gupta%2C%20Abhinav%20Efros%2C%20Alexei%20A.%20Hebert%2C%20Martial%20Blocks%20world%20revisited%3A%20Image%20understanding%20using%20qualitative%20geometry%20and%20mechanics%202010"
        },
        {
            "id": "Hamrick_et+al_2011_a",
            "entry": "Jessica B. Hamrick, Peter Battaglia, and Joshua B. Tenenbaum. Internal physics models guide probabilistic judgments about object dynamics. In Proceedings of the 33rd annual conference of the cognitive science society, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hamrick%2C%20Jessica%20B.%20Battaglia%2C%20Peter%20Tenenbaum%2C%20Joshua%20B.%20Internal%20physics%20models%20guide%20probabilistic%20judgments%20about%20object%20dynamics%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hamrick%2C%20Jessica%20B.%20Battaglia%2C%20Peter%20Tenenbaum%2C%20Joshua%20B.%20Internal%20physics%20models%20guide%20probabilistic%20judgments%20about%20object%20dynamics%202011"
        },
        {
            "id": "Jia_et+al_2015_a",
            "entry": "Z. Jia, A. C. Gallagher, A. Saxena, and T. Chen. 3d reasoning from blocks to stability. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jia%2C%20Z.%20Gallagher%2C%20A.C.%20Saxena%2C%20A.%20Chen%2C%20T.%203d%20reasoning%20from%20blocks%20to%20stability%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jia%2C%20Z.%20Gallagher%2C%20A.C.%20Saxena%2C%20A.%20Chen%2C%20T.%203d%20reasoning%20from%20blocks%20to%20stability%202015"
        },
        {
            "id": "Johnson_et+al_2016_a",
            "entry": "Justin Johnson, Alexandre Alahi, and Li Fei-Fei. Perceptual losses for real-time style transfer and super-resolution. In European Conference on Computer Vision, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Justin%20Alahi%2C%20Alexandre%20Fei-Fei%2C%20Li%20Perceptual%20losses%20for%20real-time%20style%20transfer%20and%20super-resolution%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20Justin%20Alahi%2C%20Alexandre%20Fei-Fei%2C%20Li%20Perceptual%20losses%20for%20real-time%20style%20transfer%20and%20super-resolution%202016"
        },
        {
            "id": "Keramati_et+al_2018_a",
            "entry": "Ramtin Keramati, Jay Whang, Patrick Cho, and Emma Brunskill. Strategic object oriented reinforcement learning. arXiv preprint arXiv:1806.00175, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1806.00175"
        },
        {
            "id": "Kingma_2015_a",
            "entry": "Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International Conference on Learning Representations, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Diederik%20P.%20Ba%2C%20Jimmy%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20Diederik%20P.%20Ba%2C%20Jimmy%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202015"
        },
        {
            "id": "Lee_et+al_2018_a",
            "entry": "Alex X. Lee, Richard Zhang, Frederik Ebert, Pieter Abbeel, Chelsea Finn, and Sergey Levine. Stochastic adversarial video prediction. arXiv preprint arXiv:1804.01523, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.01523"
        },
        {
            "id": "Lerer_et+al_2016_a",
            "entry": "Adam Lerer, Sam Gross, and Rob Fergus. Learning physical intuition of block towers by example. In Proceedings of the 33rd International Conference Machine Learning, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lerer%2C%20Adam%20Gross%2C%20Sam%20Fergus%2C%20Rob%20Learning%20physical%20intuition%20of%20block%20towers%20by%20example%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lerer%2C%20Adam%20Gross%2C%20Sam%20Fergus%2C%20Rob%20Learning%20physical%20intuition%20of%20block%20towers%20by%20example%202016"
        },
        {
            "id": "Li_et+al_2017_a",
            "entry": "W. Li, A. Leonardis, and M. Fritz. Visual stability prediction for robotic manipulation. In IEEE International Conference on Robotics and Automation, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20W.%20Leonardis%2C%20A.%20Fritz%2C%20M.%20Visual%20stability%20prediction%20for%20robotic%20manipulation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20W.%20Leonardis%2C%20A.%20Fritz%2C%20M.%20Visual%20stability%20prediction%20for%20robotic%20manipulation%202017"
        },
        {
            "id": "Mottaghi_et+al_2016_a",
            "entry": "Roozbeh Mottaghi, Hessam Bagherinezhad, Mohammad Rastegari, and Ali Farhadi. Newtonian scene understanding: Unfolding the dynamics of objects in static images. In IEEE Conference on Computer Vision and Pattern Recognition, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mottaghi%2C%20Roozbeh%20Bagherinezhad%2C%20Hessam%20Rastegari%2C%20Mohammad%20Farhadi%2C%20Ali%20Newtonian%20scene%20understanding%3A%20Unfolding%20the%20dynamics%20of%20objects%20in%20static%20images%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mottaghi%2C%20Roozbeh%20Bagherinezhad%2C%20Hessam%20Rastegari%2C%20Mohammad%20Farhadi%2C%20Ali%20Newtonian%20scene%20understanding%3A%20Unfolding%20the%20dynamics%20of%20objects%20in%20static%20images%202016"
        },
        {
            "id": "Roberts_1963_a",
            "entry": "Lawrence G. Roberts. Machine Perception of Three-Dimensional Solids. Outstanding Dissertations in the Computer Sciences. 1963.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Roberts%2C%20Lawrence%20G.%20Machine%20Perception%20of%20Three-Dimensional%20Solids.%20Outstanding%20Dissertations%20in%20the%20Computer%20Sciences%201963"
        },
        {
            "id": "Rubinstein_2004_a",
            "entry": "Reuven Y. Rubinstein and Dirk P. Kroese. The Cross Entropy Method: A Unified Approach To Combinatorial Optimization, Monte-carlo Simulation (Information Science and Statistics). SpringerVerlag, Berlin, Heidelberg, 2004. ISBN 038721240X.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rubinstein%2C%20Reuven%20Y.%20Kroese%2C%20Dirk%20P.%20The%20Cross%20Entropy%20Method%3A%20A%20Unified%20Approach%20To%20Combinatorial%20Optimization%2C%20Monte-carlo%20Simulation%20%28Information%20Science%20and%20Statistics%29%202004"
        },
        {
            "id": "Scholz_et+al_2014_a",
            "entry": "Jonathan Scholz, Martin Levihn, Charles Isbell, and David Wingate. A physics-based model prior for object-oriented mdps. In Proceedings of the 31st International Conference on Machine Learning, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Scholz%2C%20Jonathan%20Levihn%2C%20Martin%20Isbell%2C%20Charles%20Wingate%2C%20David%20A%20physics-based%20model%20prior%20for%20object-oriented%20mdps%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Scholz%2C%20Jonathan%20Levihn%2C%20Martin%20Isbell%2C%20Charles%20Wingate%2C%20David%20A%20physics-based%20model%20prior%20for%20object-oriented%20mdps%202014"
        },
        {
            "id": "Shao_et+al_0000_a",
            "entry": "Tianjia Shao, Aron Monszpart, Youyi Zheng, Bongjin Koo, Weiwei Xu, Kun Zhou, and Niloy Mitra. Imagining the unseen: Stability-based cuboid arrangements for scene understanding. ACM SIGGRAPH Asia 2014, 2014. * Joint first authors.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shao%2C%20Tianjia%20Monszpart%2C%20Aron%20Zheng%2C%20Youyi%20Koo%2C%20Bongjin%20Imagining%20the%20unseen%3A%20Stability-based%20cuboid%20arrangements%20for%20scene%20understanding",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shao%2C%20Tianjia%20Monszpart%2C%20Aron%20Zheng%2C%20Youyi%20Koo%2C%20Bongjin%20Imagining%20the%20unseen%3A%20Stability-based%20cuboid%20arrangements%20for%20scene%20understanding"
        },
        {
            "id": "Simonyan_2014_a",
            "entry": "K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. CoRR, abs/1409.1556, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1409.1556"
        },
        {
            "id": "Spelke_2007_a",
            "entry": "Elizabeth S. Spelke and Katherine D. Kinzler. Core knowledge. Developmental Science, 10(1): 89\u201396, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Spelke%2C%20Elizabeth%20S.%20Kinzler%2C%20Katherine%20D.%20Core%20knowledge%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Spelke%2C%20Elizabeth%20S.%20Kinzler%2C%20Katherine%20D.%20Core%20knowledge%202007"
        },
        {
            "id": "Todorov_et+al_2012_a",
            "entry": "Emanuel Todorov, Tom Erez, and Yuval Tassa. Mujoco: A physics engine for model-based control. In IROS, pp. 5026\u20135033, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Todorov%2C%20Emanuel%20Erez%2C%20Tom%20Tassa%2C%20Yuval%20Mujoco%3A%20A%20physics%20engine%20for%20model-based%20control%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Todorov%2C%20Emanuel%20Erez%2C%20Tom%20Tassa%2C%20Yuval%20Mujoco%3A%20A%20physics%20engine%20for%20model-based%20control%202012"
        },
        {
            "id": "Van_et+al_2018_a",
            "entry": "Sjoerd van Steenkiste, Michael Chang, Klaus Greff, and Jrgen Schmidhuber. Relational neural expectation maximization: Unsupervised discovery of objects and their interactions. In International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=van%20Steenkiste%2C%20Sjoerd%20Chang%2C%20Michael%20Greff%2C%20Klaus%20Schmidhuber%2C%20Jrgen%20Relational%20neural%20expectation%20maximization%3A%20Unsupervised%20discovery%20of%20objects%20and%20their%20interactions%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=van%20Steenkiste%2C%20Sjoerd%20Chang%2C%20Michael%20Greff%2C%20Klaus%20Schmidhuber%2C%20Jrgen%20Relational%20neural%20expectation%20maximization%3A%20Unsupervised%20discovery%20of%20objects%20and%20their%20interactions%202018"
        },
        {
            "id": "Watters_et+al_2017_a",
            "entry": "Nicholas Watters, Daniel Zoran, Theophane Weber, Peter Battaglia, Razvan Pascanu, and Andrea Tacchetti. Visual interaction networks: Learning a physics simulator from video. In Advances in Neural Information Processing Systems 30. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Watters%2C%20Nicholas%20Zoran%2C%20Daniel%20Weber%2C%20Theophane%20Battaglia%2C%20Peter%20Visual%20interaction%20networks%3A%20Learning%20a%20physics%20simulator%20from%20video%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Watters%2C%20Nicholas%20Zoran%2C%20Daniel%20Weber%2C%20Theophane%20Battaglia%2C%20Peter%20Visual%20interaction%20networks%3A%20Learning%20a%20physics%20simulator%20from%20video%202017"
        },
        {
            "id": "Winston_1970_a",
            "entry": "Patrick Henry Winston. Learning structural descriptions from examples. Technical report, 1970.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Winston%2C%20Patrick%20Henry%20Learning%20structural%20descriptions%20from%20examples%201970"
        },
        {
            "id": "Wu_et+al_2017_a",
            "entry": "Jiajun Wu, Erika Lu, Pushmeet Kohli, William T Freeman, and Joshua B Tenenbaum. Learning to see physics via visual de-animation. In Advances in Neural Information Processing Systems, 2017a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20Jiajun%20Lu%2C%20Erika%20Kohli%2C%20Pushmeet%20Freeman%2C%20William%20T.%20Learning%20to%20see%20physics%20via%20visual%20de-animation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20Jiajun%20Lu%2C%20Erika%20Kohli%2C%20Pushmeet%20Freeman%2C%20William%20T.%20Learning%20to%20see%20physics%20via%20visual%20de-animation%202017"
        },
        {
            "id": "Wu_et+al_2017_b",
            "entry": "Jiajun Wu, Joshua B Tenenbaum, and Pushmeet Kohli. Neural scene de-rendering. In IEEE Conference on Computer Vision and Pattern Recognition, 2017b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jiajun%20Wu%20Joshua%20B%20Tenenbaum%20and%20Pushmeet%20Kohli%20Neural%20scene%20derendering%20In%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%202017b",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jiajun%20Wu%20Joshua%20B%20Tenenbaum%20and%20Pushmeet%20Kohli%20Neural%20scene%20derendering%20In%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%202017b"
        },
        {
            "id": "Zheng_et+al_2014_a",
            "entry": "Bo Zheng, Yibiao Zhao, Joey C. Yu, Katsushi Ikeuchi, and Song-Chun Zhu. Scene understanding by reasoning stability and safety. International Journal of Computer Vision, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zheng%2C%20Bo%20Zhao%2C%20Yibiao%20Yu%2C%20Joey%20C.%20Ikeuchi%2C%20Katsushi%20Scene%20understanding%20by%20reasoning%20stability%20and%20safety%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zheng%2C%20Bo%20Zhao%2C%20Yibiao%20Yu%2C%20Joey%20C.%20Ikeuchi%2C%20Katsushi%20Scene%20understanding%20by%20reasoning%20stability%20and%20safety%202014"
        },
        {
            "id": "Objects_2015_a",
            "entry": "Objects were represented as 256-dimensional vectors. The perception module had four convolutional layers of {32, 64, 128, 256} channels, a kernel size of 4, and a stride of 2 followed by a single fully-connected layer with output size matching the object representation dimension. Both MLPs in the physics engine had two hidden layers each of size 512. The rendering networks had convolutional layers with {128, 64, 32, 3} channels (or 1 output channel in the case of the heatmap predictor), kernel sizes of {5, 5, 6, 6}, and strides of 2. We used the Adam optimizer (Kingma & Ba, 2015) with a learning rate of 1e-3.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Objects%20were%20represented%20as%20256dimensional%20vectors%20The%20perception%20module%20had%20four%20convolutional%20layers%20of%2032%2064%20128%20256%20channels%20a%20kernel%20size%20of%204%20and%20a%20stride%20of%202%20followed%20by%20a%20single%20fullyconnected%20layer%20with%20output%20size%20matching%20the%20object%20representation%20dimension%20Both%20MLPs%20in%20the%20physics%20engine%20had%20two%20hidden%20layers%20each%20of%20size%20512%20The%20rendering%20networks%20had%20convolutional%20layers%20with%20128%2064%2032%203%20channels%20or%201%20output%20channel%20in%20the%20case%20of%20the%20heatmap%20predictor%20kernel%20sizes%20of%205%205%206%206%20and%20strides%20of%202%20We%20used%20the%20Adam%20optimizer%20Kingma%20%20Ba%202015%20with%20a%20learning%20rate%20of%201e3",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Objects%20were%20represented%20as%20256dimensional%20vectors%20The%20perception%20module%20had%20four%20convolutional%20layers%20of%2032%2064%20128%20256%20channels%20a%20kernel%20size%20of%204%20and%20a%20stride%20of%202%20followed%20by%20a%20single%20fullyconnected%20layer%20with%20output%20size%20matching%20the%20object%20representation%20dimension%20Both%20MLPs%20in%20the%20physics%20engine%20had%20two%20hidden%20layers%20each%20of%20size%20512%20The%20rendering%20networks%20had%20convolutional%20layers%20with%20128%2064%2032%203%20channels%20or%201%20output%20channel%20in%20the%20case%20of%20the%20heatmap%20predictor%20kernel%20sizes%20of%205%205%206%206%20and%20strides%20of%202%20We%20used%20the%20Adam%20optimizer%20Kingma%20%20Ba%202015%20with%20a%20learning%20rate%20of%201e3"
        }
    ]
}

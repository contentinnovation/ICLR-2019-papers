{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "FLUCTUATION-DISSIPATION RELATIONS FOR",
        "author": "STOCHASTIC GRADIENT DESCENT",
        "date": 2018,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=SkNksoRctQ"
        },
        "abstract": "The notion of the stationary equilibrium ensemble has played a central role in statistical mechanics. In machine learning as well, training serves as generalized equilibration that drives the probability distribution of model parameters toward stationarity. Here, we derive stationary fluctuation-dissipation relations that link measurable quantities and hyperparameters in the stochastic gradient descent algorithm. These relations hold exactly for any stationary state and can in particular be used to adaptively set training schedule. We can further use the relations to efficiently extract information pertaining to a loss-function landscape such as the magnitudes of its Hessian and anharmonicity. Our claims are empirically verified."
    },
    "keywords": [
        {
            "term": "dynamics",
            "url": "https://en.wikipedia.org/wiki/dynamics"
        },
        {
            "term": "fluctuation-dissipation theorem",
            "url": "https://en.wikipedia.org/wiki/fluctuation-dissipation_theorem"
        },
        {
            "term": "mechanics",
            "url": "https://en.wikipedia.org/wiki/mechanics"
        },
        {
            "term": "stationary state",
            "url": "https://en.wikipedia.org/wiki/stationary_state"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        },
        {
            "term": "multilayer perceptron",
            "url": "https://en.wikipedia.org/wiki/multilayer_perceptron"
        },
        {
            "term": "stochastic gradient descent",
            "url": "https://en.wikipedia.org/wiki/stochastic_gradient_descent"
        },
        {
            "term": "probability distribution",
            "url": "https://en.wikipedia.org/wiki/probability_distribution"
        },
        {
            "term": "statistical mechanics",
            "url": "https://en.wikipedia.org/wiki/statistical_mechanics"
        },
        {
            "term": "stochastic differential equation",
            "url": "https://en.wikipedia.org/wiki/stochastic_differential_equation"
        }
    ],
    "abbreviations": {
        "FDT": "fluctuation-dissipation theorem",
        "SGD": "stochastic gradient descent",
        "SDE": "stochastic differential equation",
        "MLP": "multilayer perceptron",
        "CNN": "convolutional neural network"
    },
    "highlights": [
        "Equilibration rules the long-term fate of many macroscopic dynamical systems",
        "It is natural to wonder if there exist analogous fluctuation-dissipation relations that quantitatively link the noise in mini-batched data to the observable evolution of the model performance and that in turn facilitate the learning process",
        "\u2207f = 0. This is natural because there is no particular direction that the gradient picks on average as the model parameter stochastically bounces around the local minimum or, more generally, wanders around the loss-function landscape according to the stationary distribution",
        "Note that \u03b8 \u00b7 (\u2207f ) = (\u03b8 \u2212 \u03b8c) \u00b7 (\u2207f ) for an arbitrary constant vector \u03b8c because of the equation (8). This first fluctuation-dissipation relation is easy to evaluate on the fly during training, exactly holds without any approximation if sampled well from the stationary distribution, and can be used as the standard metric to check if learning has plateaued, just as similar relations can be used to check equilibration in Monte Carlo simulations of physical systems (Santen & Krauth, 2000). [It should be cautioned, that the fluctuation-dissipation relations are necessary but not sufficient to ensure stationarity (<a class=\"ref-link\" id=\"cOdriozola_2011_a\" href=\"#rOdriozola_2011_a\">Odriozola & Berthier, 2011</a>).] Such a metric can in turn be used to schedule changes in hyperparameters, as shall be demonstrated in Section 3.3.\n2.2",
        "In order to gain some intuition about the fluctuation-dissipation relations, let us momentarily employ the harmonic approximation, i.e., assume that there is a local minimum of the loss function at \u03b8 = \u03b8 and retain only up to quadratic terms of the Taylor expansions around it: f (\u03b8) \u2248",
        "It would be interesting to further elucidate the physics of machine learning by extending our formalism to incorporate nonstationary dynamics, linearly away from stationarity (<a class=\"ref-link\" id=\"cOnsager_1931_a\" href=\"#rOnsager_1931_a\">Onsager, 1931</a>; <a class=\"ref-link\" id=\"cGreen_1954_a\" href=\"#rGreen_1954_a\">Green, 1954</a>; <a class=\"ref-link\" id=\"cKubo_1957_a\" href=\"#rKubo_1957_a\">Kubo, 1957</a>) and beyond (<a class=\"ref-link\" id=\"cJarzynski_1997_a\" href=\"#rJarzynski_1997_a\">Jarzynski, 1997</a>; <a class=\"ref-link\" id=\"cCrooks_1999_a\" href=\"#rCrooks_1999_a\">Crooks, 1999</a>), so that it can in particular properly treat overfitting cascading dynamics and time-dependent sample distributions"
    ],
    "key_statements": [
        "Equilibration rules the long-term fate of many macroscopic dynamical systems",
        "It is natural to wonder if there exist analogous fluctuation-dissipation relations that quantitatively link the noise in mini-batched data to the observable evolution of the model performance and that in turn facilitate the learning process",
        "\u2207f = 0. This is natural because there is no particular direction that the gradient picks on average as the model parameter stochastically bounces around the local minimum or, more generally, wanders around the loss-function landscape according to the stationary distribution",
        "Note that \u03b8 \u00b7 (\u2207f ) = (\u03b8 \u2212 \u03b8c) \u00b7 (\u2207f ) for an arbitrary constant vector \u03b8c because of the equation (8). This first fluctuation-dissipation relation is easy to evaluate on the fly during training, exactly holds without any approximation if sampled well from the stationary distribution, and can be used as the standard metric to check if learning has plateaued, just as similar relations can be used to check equilibration in Monte Carlo simulations of physical systems (Santen & Krauth, 2000). [It should be cautioned, that the fluctuation-dissipation relations are necessary but not sufficient to ensure stationarity (<a class=\"ref-link\" id=\"cOdriozola_2011_a\" href=\"#rOdriozola_2011_a\">Odriozola & Berthier, 2011</a>).] Such a metric can in turn be used to schedule changes in hyperparameters, as shall be demonstrated in Section 3.3.\n2.2",
        "In order to gain some intuition about the fluctuation-dissipation relations, let us momentarily employ the harmonic approximation, i.e., assume that there is a local minimum of the loss function at \u03b8 = \u03b8 and retain only up to quadratic terms of the Taylor expansions around it: f (\u03b8) \u2248",
        "It would be interesting to further elucidate the physics of machine learning by extending our formalism to incorporate nonstationary dynamics, linearly away from stationarity (<a class=\"ref-link\" id=\"cOnsager_1931_a\" href=\"#rOnsager_1931_a\">Onsager, 1931</a>; <a class=\"ref-link\" id=\"cGreen_1954_a\" href=\"#rGreen_1954_a\">Green, 1954</a>; <a class=\"ref-link\" id=\"cKubo_1957_a\" href=\"#rKubo_1957_a\">Kubo, 1957</a>) and beyond (<a class=\"ref-link\" id=\"cJarzynski_1997_a\" href=\"#rJarzynski_1997_a\">Jarzynski, 1997</a>; <a class=\"ref-link\" id=\"cCrooks_1999_a\" href=\"#rCrooks_1999_a\">Crooks, 1999</a>), so that it can in particular properly treat overfitting cascading dynamics and time-dependent sample distributions"
    ],
    "summary": [
        "Equilibration rules the long-term fate of many macroscopic dynamical systems.",
        "It is natural to wonder if there exist analogous fluctuation-dissipation relations that quantitatively link the noise in mini-batched data to the observable evolution of the model performance and that in turn facilitate the learning process.",
        "The first relation (FDR1) offers the metric for assessing equilibration and yields an adaptive algorithm that sets learning-rate schedule on the fly.",
        "This is natural because there is no particular direction that the gradient picks on average as the model parameter stochastically bounces around the local minimum or, more generally, wanders around the loss-function landscape according to the stationary distribution.",
        "This first fluctuation-dissipation relation is easy to evaluate on the fly during training, exactly holds without any approximation if sampled well from the stationary distribution, and can be used as the standard metric to check if learning has plateaued, just as similar relations can be used to check equilibration in Monte Carlo simulations of physical systems (Santen & Krauth, 2000).",
        "Applying the master equation (FDT) on the full-batch loss function and Taylor-expanding it in the learning rate \u03b7 yields the closed-form expression f (\u03b8) = f \u03b8 \u2212 \u03b7\u2207f B (\u03b8) m.b.",
        "In order to gain some intuition about the fluctuation-dissipation relations, let us momentarily employ the harmonic approximation, i.e., assume that there is a local minimum of the loss function at \u03b8 = \u03b8 and retain only up to quadratic terms of the Taylor expansions around it: f (\u03b8) \u2248",
        "The half-running average of the full-batch observable OFB at the end of sufficiently long training, which is a good proxy for OFB , is plotted in the figure 3 as a function of the learning rate \u03b7.",
        "As predicted by the relation (FDR2), at small learning rates \u03b7, the observable OFB approaches zero; its slope \u2013 divided by Tr C if preferred \u2013 measures the magnitude of the Hessian matrix, component-wise averaged over directions in which the noise preferentially fluctuates.",
        "This invalidates the use of the quadratic harmonic approximation for the loss-function landscape and/or the assumption of the constant noise matrix for this model except at very small learning rates.",
        "Plotted in the figure 4 are results for SGD without momentum, with the Xavier initialization (<a class=\"ref-link\" id=\"cGlorot_2010_a\" href=\"#rGlorot_2010_a\">Glorot & Bengio, 2010</a>) and training through (i) preset training schedule with decrease of the learning rate by a factor of 10 for each 100 epochs, an adaptive scheduler with X = 0.01 (1% threshold) and",
        "It would be interesting to further elucidate the physics of machine learning by extending our formalism to incorporate nonstationary dynamics, linearly away from stationarity (<a class=\"ref-link\" id=\"cOnsager_1931_a\" href=\"#rOnsager_1931_a\"><a class=\"ref-link\" id=\"cOnsager_1931_a\" href=\"#rOnsager_1931_a\">Onsager, 1931</a></a>; <a class=\"ref-link\" id=\"cGreen_1954_a\" href=\"#rGreen_1954_a\"><a class=\"ref-link\" id=\"cGreen_1954_a\" href=\"#rGreen_1954_a\">Green, 1954</a></a>; <a class=\"ref-link\" id=\"cKubo_1957_a\" href=\"#rKubo_1957_a\"><a class=\"ref-link\" id=\"cKubo_1957_a\" href=\"#rKubo_1957_a\">Kubo, 1957</a></a>) and beyond (<a class=\"ref-link\" id=\"cJarzynski_1997_a\" href=\"#rJarzynski_1997_a\"><a class=\"ref-link\" id=\"cJarzynski_1997_a\" href=\"#rJarzynski_1997_a\">Jarzynski, 1997</a></a>; <a class=\"ref-link\" id=\"cCrooks_1999_a\" href=\"#rCrooks_1999_a\"><a class=\"ref-link\" id=\"cCrooks_1999_a\" href=\"#rCrooks_1999_a\">Crooks, 1999</a></a>), so that it can in particular properly treat overfitting cascading dynamics and time-dependent sample distributions"
    ],
    "headline": "Equilibration rules the long-term fate of many macroscopic dynamical systems",
    "reference_links": [
        {
            "id": "An_et+al_2018_a",
            "entry": "Jing An, Jianfeng Lu, and Lexing Ying. Stochastic modified equations for the asynchronous stochastic gradient descent. arXiv preprint arXiv:1805.08244, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1805.08244"
        },
        {
            "id": "Bottou_1991_a",
            "entry": "Leon Bottou. Stochastic gradient learning in neural networks. Proceedings of Neuro-N\u0131mes, 91(8): 12, 1991.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bottou%2C%20Leon%20Stochastic%20gradient%20learning%20in%20neural%20networks%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bottou%2C%20Leon%20Stochastic%20gradient%20learning%20in%20neural%20networks%201991"
        },
        {
            "id": "Bottou_et+al_2018_a",
            "entry": "Leon Bottou, Frank E Curtis, and Jorge Nocedal. Optimization methods for large-scale machine learning. SIAM Review, 60(2):223\u2013311, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bottou%2C%20Leon%20Curtis%2C%20Frank%20E.%20Nocedal%2C%20Jorge%20Optimization%20methods%20for%20large-scale%20machine%20learning%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bottou%2C%20Leon%20Curtis%2C%20Frank%20E.%20Nocedal%2C%20Jorge%20Optimization%20methods%20for%20large-scale%20machine%20learning%202018"
        },
        {
            "id": "Brown_( 21):_a",
            "entry": "Robert Brown. XXVII. A brief account of microscopical observations made in the months of June, July and August 1827, on the particles contained in the pollen of plants; and on the general existence of active molecules in organic and inorganic bodies. The Philosophical Magazine, 4 (21):161\u2013173, 1828.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Robert%20Brown%20XXVII%20A%20brief%20account%20of%20microscopical%20observations%20made%20in%20the%20months%20of%20June%20July%20and%20August%201827%20on%20the%20particles%20contained%20in%20the%20pollen%20of%20plants%20and%20on%20the%20general%20existence%20of%20active%20molecules%20in%20organic%20and%20inorganic%20bodies%20The%20Philosophical%20Magazine%204%2021161173%201828"
        },
        {
            "id": "Chaudhari_2017_a",
            "entry": "Pratik Chaudhari and Stefano Soatto. Stochastic gradient descent performs variational inference, converges to limit cycles for deep networks. arXiv preprint arXiv:1710.11029, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.11029"
        },
        {
            "id": "Crooks_1999_a",
            "entry": "Gavin E Crooks. Entropy production fluctuation theorem and the nonequilibrium work relation for free energy differences. Physical Review E, 60(3):2721\u20132726, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Crooks%2C%20Gavin%20E.%20Entropy%20production%20fluctuation%20theorem%20and%20the%20nonequilibrium%20work%20relation%20for%20free%20energy%20differences%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Crooks%2C%20Gavin%20E.%20Entropy%20production%20fluctuation%20theorem%20and%20the%20nonequilibrium%20work%20relation%20for%20free%20energy%20differences%201999"
        },
        {
            "id": "Einstein_1905_a",
            "entry": "Albert Einstein. Uber die von der molekularkinetischen Theorie der Warme geforderte Bewegung von in ruhenden Flussigkeiten suspendierten Teilchen. Annalen der physik, 322(8):549\u2013560, 1905.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Einstein%2C%20Albert%20Uber%20die%20von%20der%20molekularkinetischen%20Theorie%20der%20Warme%20geforderte%20Bewegung%20von%20in%20ruhenden%20Flussigkeiten%20suspendierten%20Teilchen%201905",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Einstein%2C%20Albert%20Uber%20die%20von%20der%20molekularkinetischen%20Theorie%20der%20Warme%20geforderte%20Bewegung%20von%20in%20ruhenden%20Flussigkeiten%20suspendierten%20Teilchen%201905"
        },
        {
            "id": "Gardiner_2009_a",
            "entry": "Crispin Gardiner. Stochastic methods, volume 4. Springer Berlin, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Crispin%20Gardiner%20Stochastic%20methods%20volume%204%20Springer%20Berlin%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Crispin%20Gardiner%20Stochastic%20methods%20volume%204%20Springer%20Berlin%202009"
        },
        {
            "id": "Glorot_2010_a",
            "entry": "Xavier Glorot and Yoshua Bengio. Understanding the difficulty of training deep feedforward neural networks. In Proceedings of the thirteenth international conference on artificial intelligence and statistics, pp. 249\u2013256, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Glorot%2C%20Xavier%20Bengio%2C%20Yoshua%20Understanding%20the%20difficulty%20of%20training%20deep%20feedforward%20neural%20networks%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Glorot%2C%20Xavier%20Bengio%2C%20Yoshua%20Understanding%20the%20difficulty%20of%20training%20deep%20feedforward%20neural%20networks%202010"
        },
        {
            "id": "Green_1954_a",
            "entry": "Melville S Green. Markoff random processes and the statistical mechanics of time-dependent phenomena. II. Irreversible processes in fluids. The Journal of Chemical Physics, 22(3):398\u2013413, 1954.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Green%2C%20Melville%20S.%20Markoff%20random%20processes%20and%20the%20statistical%20mechanics%20of%20time-dependent%20phenomena.%20II.%20Irreversible%20processes%20in%20fluids%201954",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Green%2C%20Melville%20S.%20Markoff%20random%20processes%20and%20the%20statistical%20mechanics%20of%20time-dependent%20phenomena.%20II.%20Irreversible%20processes%20in%20fluids%201954"
        },
        {
            "id": "Reddi_et+al_2018_a",
            "entry": "Sashank J. Reddi, Satyen Kale, and Sanjiv Kumar. On the convergence of Adam and beyond. In International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Reddi%2C%20Sashank%20J.%20Kale%2C%20Satyen%20Kumar%2C%20Sanjiv%20On%20the%20convergence%20of%20Adam%20and%20beyond%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Reddi%2C%20Sashank%20J.%20Kale%2C%20Satyen%20Kumar%2C%20Sanjiv%20On%20the%20convergence%20of%20Adam%20and%20beyond%202018"
        },
        {
            "id": "Jarzynski_1997_a",
            "entry": "Christopher Jarzynski. Nonequilibrium equality for free energy differences. Physical Review Letters, 78(14):2690\u20132693, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jarzynski%2C%20Christopher%20Nonequilibrium%20equality%20for%20free%20energy%20differences%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jarzynski%2C%20Christopher%20Nonequilibrium%20equality%20for%20free%20energy%20differences%201997"
        },
        {
            "id": "Jastrzebski_et+al_2017_a",
            "entry": "Stanislaw Jastrzebski, Zachary Kenton, Devansh Arpit, Nicolas Ballas, Asja Fischer, Yoshua Bengio, and Amos Storkey. Three factors influencing minima in SGD. arXiv preprint arXiv:1711.04623, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.04623"
        },
        {
            "id": "Karpathy_0000_a",
            "entry": "Andrej Karpathy. ConvNetJS CIFAR-10 demo. https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html, 2014. Last accessed on 2018-09-25.",
            "url": "https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html"
        },
        {
            "id": "Kingma_2014_a",
            "entry": "Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6980"
        },
        {
            "id": "Krizhevsky_2009_a",
            "entry": "Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images. Technical report, Citeseer, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Hinton%2C%20Geoffrey%20Learning%20multiple%20layers%20of%20features%20from%20tiny%20images%202009"
        },
        {
            "id": "Kubo_1957_a",
            "entry": "Ryogo Kubo. Statistical-mechanical theory of irreversible processes. I. General theory and simple applications to magnetic and conduction problems. Journal of the Physical Society of Japan, 12 (6):570\u2013586, 1957.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kubo%2C%20Ryogo%20Statistical-mechanical%20theory%20of%20irreversible%20processes.%20I.%20General%20theory%20and%20simple%20applications%20to%20magnetic%20and%20conduction%20problems%201957",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kubo%2C%20Ryogo%20Statistical-mechanical%20theory%20of%20irreversible%20processes.%20I.%20General%20theory%20and%20simple%20applications%20to%20magnetic%20and%20conduction%20problems%201957"
        },
        {
            "id": "Lecun_et+al_1998_a",
            "entry": "Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278\u20132324, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=LeCun%2C%20Yann%20Bottou%2C%20Leon%20Bengio%2C%20Yoshua%20Haffner%2C%20Patrick%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=LeCun%2C%20Yann%20Bottou%2C%20Leon%20Bengio%2C%20Yoshua%20Haffner%2C%20Patrick%20Gradient-based%20learning%20applied%20to%20document%20recognition%201998"
        },
        {
            "id": "Leen_1993_a",
            "entry": "Todd K Leen and John E Moody. Weight space probability densities in stochastic learning: I. Dynamics and equilibria. In Advances in Neural Information Processing Systems, pp. 451\u2013458, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Leen%2C%20Todd%20K.%20Moody%2C%20John%20E.%20Weight%20space%20probability%20densities%20in%20stochastic%20learning%3A%20I%201993",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Leen%2C%20Todd%20K.%20Moody%2C%20John%20E.%20Weight%20space%20probability%20densities%20in%20stochastic%20learning%3A%20I%201993"
        },
        {
            "id": "Li_et+al_2017_a",
            "entry": "Chris Junchi Li, Lei Li, Junyang Qian, and Jian-Guo Liu. Batch size matters: A diffusion approximation framework on nonconvex stochastic gradient descent. arXiv preprint arXiv:1705.07562v1, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.07562v1"
        },
        {
            "id": "Li_et+al_2015_a",
            "entry": "Qianxiao Li, Cheng Tai, and Weinan E. Stochastic modified equations and adaptive stochastic gradient algorithms. arXiv preprint arXiv:1511.06251, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06251"
        },
        {
            "id": "Mandt_et+al_2015_a",
            "entry": "Stephan Mandt, Matthew D Hoffman, and David M Blei. Continuous-time limit of stochastic gradient descent revisited. In 8th NIPS Workshop on Optimization for Machine Learning, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mandt%2C%20Stephan%20Hoffman%2C%20Matthew%20D.%20Blei%2C%20David%20M.%20Continuous-time%20limit%20of%20stochastic%20gradient%20descent%20revisited%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mandt%2C%20Stephan%20Hoffman%2C%20Matthew%20D.%20Blei%2C%20David%20M.%20Continuous-time%20limit%20of%20stochastic%20gradient%20descent%20revisited%202015"
        },
        {
            "id": "Mandt_et+al_2017_a",
            "entry": "Stephan Mandt, Matthew D Hoffman, and David M Blei. Stochastic gradient descent as approximate Bayesian inference. The Journal of Machine Learning Research, 18(1):4873\u20134907, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mandt%2C%20Stephan%20Hoffman%2C%20Matthew%20D.%20Blei%2C%20David%20M.%20Stochastic%20gradient%20descent%20as%20approximate%20Bayesian%20inference%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mandt%2C%20Stephan%20Hoffman%2C%20Matthew%20D.%20Blei%2C%20David%20M.%20Stochastic%20gradient%20descent%20as%20approximate%20Bayesian%20inference%202017"
        },
        {
            "id": "Nado_et+al_2018_a",
            "entry": "Zachary Nado, Jasper Snoek, Roger Grosse, David Duvenaud, Bowen Xu, and James Martens. Stochastic gradient Langevin dynamics that exploit neural network structure, 2018. URL https://openreview.net/forum?id=ry-Se9kvG.",
            "url": "https://openreview.net/forum?id=ry-Se9kvG"
        },
        {
            "id": "Neyshabur_et+al_2014_a",
            "entry": "Behnam Neyshabur, Ryota Tomioka, and Nathan Srebro. In search of the real inductive bias: On the role of implicit regularization in deep learning. arXiv preprint arXiv:1412.6614, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6614"
        },
        {
            "id": "Neyshabur_et+al_2017_a",
            "entry": "Behnam Neyshabur, Srinadh Bhojanapalli, David McAllester, and Nati Srebro. Exploring generalization in deep learning. In Advances in Neural Information Processing Systems, pp. 5947\u20135956, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Neyshabur%2C%20Behnam%20Bhojanapalli%2C%20Srinadh%20McAllester%2C%20David%20Srebro%2C%20Nati%20Exploring%20generalization%20in%20deep%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Neyshabur%2C%20Behnam%20Bhojanapalli%2C%20Srinadh%20McAllester%2C%20David%20Srebro%2C%20Nati%20Exploring%20generalization%20in%20deep%20learning%202017"
        },
        {
            "id": "Odriozola_2011_a",
            "entry": "Gerardo Odriozola and Ludovic Berthier. Equilibrium equation of state of a hard sphere binary mixture at very large densities using replica exchange Monte Carlo simulations. The Journal of Chemical Physics, 134(5):054504, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Odriozola%2C%20Gerardo%20Berthier%2C%20Ludovic%20Equilibrium%20equation%20of%20state%20of%20a%20hard%20sphere%20binary%20mixture%20at%20very%20large%20densities%20using%20replica%20exchange%20Monte%20Carlo%20simulations%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Odriozola%2C%20Gerardo%20Berthier%2C%20Ludovic%20Equilibrium%20equation%20of%20state%20of%20a%20hard%20sphere%20binary%20mixture%20at%20very%20large%20densities%20using%20replica%20exchange%20Monte%20Carlo%20simulations%202011"
        },
        {
            "id": "Onsager_1931_a",
            "entry": "Lars Onsager. Reciprocal relations in irreversible processes. I. Physical Review, 37(4):405\u2013426, 1931.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Onsager%2C%20Lars%20Reciprocal%20relations%20in%20irreversible%20processes%201931",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Onsager%2C%20Lars%20Reciprocal%20relations%20in%20irreversible%20processes%201931"
        },
        {
            "id": "Risken_1984_a",
            "entry": "Hannes Risken. The Fokker-Planck equation: methods of solution and applications. Springer, 1984. Herbert Robbins and Sutton Monro. A stochastic approximation method. The Annals of Mathematical Statistics, 22(3):400\u2013407, 1951. Ludger Santen and Werner Krauth. Absence of thermodynamic phase transition in a model glass former. Nature, 405(6786):550\u2013551, 2000. Samuel L Smith and Quoc V Le. A Bayesian perspective on generalization and stochastic gradient descent. arXiv preprint arXiv:1710.06451, 2018. Daniel Soudry, Elad Hoffer, Mor Shpigel Nacson, and Nathan Srebro. The implicit bias of gradient descent on separable data. In International Conference on Learning Representations, 2018. Yee Whye Teh, Alexandre H Thiery, and Sebastian J Vollmer. Consistency and fluctuations for stochastic gradient Langevin dynamics. The Journal of Machine Learning Research, 17(1):193\u2013 225, 2016. Nicolaas Godfried Van Kampen. Stochastic processes in physics and chemistry, volume 1.",
            "arxiv_url": "https://arxiv.org/pdf/1710.06451"
        },
        {
            "id": "Elsevier_1906_a",
            "entry": "Elsevier, 1992. Marian Von Smoluchowski. Zur kinetischen theorie der brownschen molekularbewegung und der suspensionen. Annalen der physik, 326(14):756\u2013780, 1906. Max Welling and Yee W Teh. Bayesian learning via stochastic gradient Langevin dynamics. In Proceedings of the 28th International Conference on Machine Learning, pp. 681\u2013688, 2011. Zhanxing Zhu, Jingfeng Wu, Bing Yu, Lei Wu, and Jinwen Ma. The anisotropic noise in stochastic gradient descent: Its behavior of escaping from minima and regularization effects. arXiv preprint arXiv:1803.00195, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.00195"
        }
    ]
}

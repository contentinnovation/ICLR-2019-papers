{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "VISUAL SEMANTIC NAVIGATION USING SCENE PRIORS",
        "author": "Wei Yang, Xiaolong Wang, Ali Farhadi, Abhinav Gupta, Roozbeh Mottaghi, 1 The Chinese University of Hong Kong 2 Carnegie Mellon University 3 Facebook AI Research 4 University of Washington 5 Allen Institute for AI",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=HJeRkh05Km"
        },
        "abstract": "How do humans navigate to target objects in novel scenes? Do we use the semantic/functional priors we have built over years to efficiently search and navigate? For example, to search for mugs, we search cabinets near the coffee machine and for fruits we try the fridge. In this work, we focus on incorporating semantic priors in the task of semantic navigation. We propose to use Graph Convolutional Networks for incorporating the prior knowledge into a deep reinforcement learning framework. The agent uses the features from the knowledge graph to predict the actions. For evaluation, we use the AI2-THOR framework. Our experiments show how semantic knowledge improves performance significantly. More importantly, we show improvement in generalization to unseen scenes and/or objects."
    },
    "keywords": [
        {
            "term": "deep reinforcement learning",
            "url": "https://en.wikipedia.org/wiki/deep_reinforcement_learning"
        },
        {
            "term": "mobile robot",
            "url": "https://en.wikipedia.org/wiki/mobile_robot"
        },
        {
            "term": "coffee machine",
            "url": "https://en.wikipedia.org/wiki/coffee_machine"
        },
        {
            "term": "THOR",
            "url": "https://en.wikipedia.org/wiki/THOR"
        },
        {
            "term": "reinforcement learning",
            "url": "https://en.wikipedia.org/wiki/reinforcement_learning"
        },
        {
            "term": "knowledge graph",
            "url": "https://en.wikipedia.org/wiki/knowledge_graph"
        }
    ],
    "abbreviations": {
        "GCNs": "Graph Convolutional Networks",
        "GCN": "GRAPH CONVOLUTIONAL NETWORK"
    },
    "highlights": [
        "Consider the kitchen scene shown in Figure 1(a) and the task of finding an object such as a mug",
        "We propose to use Graph Convolutional Networks (GCNs) (<a class=\"ref-link\" id=\"cKipf_2017_a\" href=\"#rKipf_2017_a\">Kipf & Welling, 2017</a>) to incorporate the prior knowledge into a Deep Reinforcement Learning framework",
        "We propose an approach to integrate semantic and functional priors with a deep reinforcement learning model for the task of navigation",
        "We use Graph Convolutional Networks to encode the prior knowledge and to update the knowledge according to the observations from the current scene",
        "Our experiments show that prior knowledge improves generalization to unseen scenes and targets",
        "The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the ARO or the U.S Government"
    ],
    "key_statements": [
        "Consider the kitchen scene shown in Figure 1(a) and the task of finding an object such as a mug",
        "We propose to use Graph Convolutional Networks (GCNs) (<a class=\"ref-link\" id=\"cKipf_2017_a\" href=\"#rKipf_2017_a\">Kipf & Welling, 2017</a>) to incorporate the prior knowledge into a Deep Reinforcement Learning framework",
        "(2) We show that semantic prior knowledge can significantly improve the navigation performance",
        "In contrast to all these approaches, we incorporate semantic and functional priors to improve navigation performance and better generalize to unseen scenes and objects",
        "We provide the background for Graph Convolutional Networks",
        "We propose an approach to integrate semantic and functional priors with a deep reinforcement learning model for the task of navigation",
        "We use Graph Convolutional Networks to encode the prior knowledge and to update the knowledge according to the observations from the current scene",
        "Our experiments show that prior knowledge improves generalization to unseen scenes and targets",
        "The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the ARO or the U.S Government"
    ],
    "summary": [
        "Consider the kitchen scene shown in Figure 1(a) and the task of finding an object such as a mug.",
        "We use the semantic/functional priors to navigate to unseen objects as well.",
        "We propose to use Graph Convolutional Networks (GCNs) (<a class=\"ref-link\" id=\"cKipf_2017_a\" href=\"#rKipf_2017_a\"><a class=\"ref-link\" id=\"cKipf_2017_a\" href=\"#rKipf_2017_a\">Kipf & Welling, 2017</a></a>) to incorporate the prior knowledge into a Deep Reinforcement Learning framework.",
        "We show the results of the model on the challenging setting where the scene and/or the object are new to the agent.",
        "In contrast to all these approaches, we incorporate semantic and functional priors to improve navigation performance and better generalize to unseen scenes and objects.",
        "We use contextual reasoning for an interactive navigation task, where the agent updates its belief based on the current observation and the prior knowledge as it moves in the environment.",
        "We use knowledge graphs in an RL setting for the interactive task of visual navigation.",
        "Our goal is to navigate from a random starting location in a scene to a specified target object category given only egocentric RGB perception of the agent.",
        "The input of our A3C model is the joint representation of the current state and the semantic task objective, which is a 1024-d feature vector made by concatenating the outputs of the visual network and the semantic network.",
        "We incorporate semantic knowledge in the form of graph representation and use Graph Convolutional Networks (GCNs) (<a class=\"ref-link\" id=\"cKipf_2017_a\" href=\"#rKipf_2017_a\"><a class=\"ref-link\" id=\"cKipf_2017_a\" href=\"#rKipf_2017_a\">Kipf & Welling, 2017</a></a>) to compute relational features on the graph.",
        "We provide the background for GCNs. we delve into the details of how we incorporate GCNs for the task of visual semantic navigation and how it helps generalization to unseen scenes and novel object categories.",
        "Our knowledge graph for visual navigation provides two main advantages: (1) It encodes spatial relationships between different object categories.",
        "We initialize each node based on the current state and perform information propagation to compute a semantic knowledge vector that is passed as another feature vector to the policy function.",
        "We provide the results of navigation using GCNs. We evaluate our model in scenarios where the scenes are unseen and/or the target objects are novel to the agent.",
        "We propose an approach to integrate semantic and functional priors with a deep reinforcement learning model for the task of navigation.",
        "We use Graph Convolutional Networks to encode the prior knowledge and to update the knowledge according to the observations from the current scene.",
        "The U.S Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein"
    ],
    "headline": "We focus on incorporating semantic priors in the task of semantic navigation",
    "reference_links": [
        {
            "id": "Abadi_et+al_2015_a",
            "entry": "Mart\u0131n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Mane, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viegas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. URL https://www.tensorflow.org/. Software available from tensorflow.org.",
            "url": "https://www.tensorflow.org/"
        },
        {
            "id": "Anderson_et+al_2018_a",
            "entry": "Peter Anderson, Angel X. Chang, Devendra Singh Chaplot, Alexey Dosovitskiy, Saurabh Gupta, Vladlen Koltun, Jana Kosecka, Jitendra Malik, Roozbeh Mottaghi, Manolis Savva, and Amir Roshan Zamir. On evaluation of embodied navigation agents. arXiv, 2018a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Anderson%2C%20Peter%20Chang%2C%20Angel%20X.%20Chaplot%2C%20Devendra%20Singh%20Dosovitskiy%2C%20Alexey%20On%20evaluation%20of%20embodied%20navigation%20agents%202018"
        },
        {
            "id": "Anderson_et+al_2018_b",
            "entry": "Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark Johnson, Niko Sunderhauf, Ian Reid, Stephen Gould, and Anton van den Hengel. Vision-and-language navigation: Interpreting visually-grounded navigation instructions in real environments. In CVPR, 2018b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Anderson%2C%20Peter%20Wu%2C%20Qi%20Teney%2C%20Damien%20Bruce%2C%20Jake%20Vision-and-language%20navigation%3A%20Interpreting%20visually-grounded%20navigation%20instructions%20in%20real%20environments%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Anderson%2C%20Peter%20Wu%2C%20Qi%20Teney%2C%20Damien%20Bruce%2C%20Jake%20Vision-and-language%20navigation%3A%20Interpreting%20visually-grounded%20navigation%20instructions%20in%20real%20environments%202018"
        },
        {
            "id": "Borenstein_1991_a",
            "entry": "Johann Borenstein and Yoram Koren. The vector field histogram and fast obstacle-avoidance for mobile robots. IEEE Trans. on Robotics and Automation, 1991.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Borenstein%2C%20Johann%20Koren%2C%20Yoram%20The%20vector%20field%20histogram%20and%20fast%20obstacle-avoidance%20for%20mobile%20robots%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Borenstein%2C%20Johann%20Koren%2C%20Yoram%20The%20vector%20field%20histogram%20and%20fast%20obstacle-avoidance%20for%20mobile%20robots%201991"
        },
        {
            "id": "Brahmbhatt_2017_a",
            "entry": "Samarth Brahmbhatt and James Hays. Deepnav: Learning to navigate large cities. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Brahmbhatt%2C%20Samarth%20Hays%2C%20James%20Deepnav%3A%20Learning%20to%20navigate%20large%20cities%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Brahmbhatt%2C%20Samarth%20Hays%2C%20James%20Deepnav%3A%20Learning%20to%20navigate%20large%20cities%202017"
        },
        {
            "id": "Chaplot_et+al_2018_a",
            "entry": "Devendra Singh Chaplot, Kanthashree Mysore Sathyendra, Rama Kumar Pasumarthi, Dheeraj Rajagopal, and Ruslan Salakhutdinov. Gated-attention architectures for task-oriented language grounding. In AAAI, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chaplot%2C%20Devendra%20Singh%20Sathyendra%2C%20Kanthashree%20Mysore%20Pasumarthi%2C%20Rama%20Kumar%20Rajagopal%2C%20Dheeraj%20Gated-attention%20architectures%20for%20task-oriented%20language%20grounding%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chaplot%2C%20Devendra%20Singh%20Sathyendra%2C%20Kanthashree%20Mysore%20Pasumarthi%2C%20Rama%20Kumar%20Rajagopal%2C%20Dheeraj%20Gated-attention%20architectures%20for%20task-oriented%20language%20grounding%202018"
        },
        {
            "id": "Chen_et+al_2015_a",
            "entry": "Chenyi Chen, Ary Seff, Alain L. Kornhauser, and Jianxiong Xiao. Deepdriving: Learning affordance for direct perception in autonomous driving. In ICCV, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Chenyi%20Seff%2C%20Ary%20Kornhauser%2C%20Alain%20L.%20Xiao%2C%20Jianxiong%20Deepdriving%3A%20Learning%20affordance%20for%20direct%20perception%20in%20autonomous%20driving%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Chenyi%20Seff%2C%20Ary%20Kornhauser%2C%20Alain%20L.%20Xiao%2C%20Jianxiong%20Deepdriving%3A%20Learning%20affordance%20for%20direct%20perception%20in%20autonomous%20driving%202015"
        },
        {
            "id": "Desai_et+al_2009_a",
            "entry": "Chaitanya Desai, Deva Ramanan, and Charless. Fowlkes. Discriminative models for multi-class object layout. In ICCV, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Desai%2C%20Chaitanya%20Ramanan%2C%20Deva%20Fowlkes%2C%20Charless%20Discriminative%20models%20for%20multi-class%20object%20layout%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Desai%2C%20Chaitanya%20Ramanan%2C%20Deva%20Fowlkes%2C%20Charless%20Discriminative%20models%20for%20multi-class%20object%20layout%202009"
        },
        {
            "id": "Divvala_et+al_2009_a",
            "entry": "Santosh Kumar Divvala, Derek Hoiem, James Hays, Alexei A. Efros, and Martial Hebert. An empirical study of context in object detection. In CVPR, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Divvala%2C%20Santosh%20Kumar%20Hoiem%2C%20Derek%20Hays%2C%20James%20Efros%2C%20Alexei%20A.%20An%20empirical%20study%20of%20context%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Divvala%2C%20Santosh%20Kumar%20Hoiem%2C%20Derek%20Hays%2C%20James%20Efros%2C%20Alexei%20A.%20An%20empirical%20study%20of%20context%202009"
        },
        {
            "id": "Feder_et+al_1999_a",
            "entry": "Hans Jacob S. Feder, John J. Leonard, and Christopher M. Smith. Adaptive mobile robot navigation and mapping. Intl. J. of Robotics Research, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Feder%2C%20Hans%20Jacob%20S.%20Leonard%2C%20John%20J.%20Smith%2C%20Christopher%20M.%20Adaptive%20mobile%20robot%20navigation%20and%20mapping%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Feder%2C%20Hans%20Jacob%20S.%20Leonard%2C%20John%20J.%20Smith%2C%20Christopher%20M.%20Adaptive%20mobile%20robot%20navigation%20and%20mapping%201999"
        },
        {
            "id": "Gupta_et+al_2017_a",
            "entry": "Saurabh Gupta, James Davidson, Sergey Levine, Rahul Sukthankar, and Jitendra Malik. Cognitive mapping and planning for visual navigation. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gupta%2C%20Saurabh%20Davidson%2C%20James%20Levine%2C%20Sergey%20Sukthankar%2C%20Rahul%20Cognitive%20mapping%20and%20planning%20for%20visual%20navigation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gupta%2C%20Saurabh%20Davidson%2C%20James%20Levine%2C%20Sergey%20Sukthankar%2C%20Rahul%20Cognitive%20mapping%20and%20planning%20for%20visual%20navigation%202017"
        },
        {
            "id": "Harrison_et+al_2017_a",
            "entry": "James Harrison, Animesh Garg, Boris Ivanovic, Yuke Zhu, Silvio Savarese, Li Fei-Fei, and Marco Pavone. AdaPT: Zero-shot adaptive policy transfer for stochastic dynamical systems. In ISRR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Harrison%2C%20James%20Garg%2C%20Animesh%20Ivanovic%2C%20Boris%20Zhu%2C%20Yuke%20AdaPT%3A%20Zero-shot%20adaptive%20policy%20transfer%20for%20stochastic%20dynamical%20systems%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Harrison%2C%20James%20Garg%2C%20Animesh%20Ivanovic%2C%20Boris%20Zhu%2C%20Yuke%20AdaPT%3A%20Zero-shot%20adaptive%20policy%20transfer%20for%20stochastic%20dynamical%20systems%202017"
        },
        {
            "id": "He_et+al_2016_a",
            "entry": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "Hermann_et+al_2017_a",
            "entry": "Karl Moritz Hermann, Felix Hill, Simon Green, Fumin Wang, Ryan Faulkner, Hubert Soyer, David Szepesvari, Wojciech Marian Czarnecki, Max Jaderberg, Denis Teplyashin, Marcus Wainwright, Chris Apps, Demis Hassabis, and Phil Blunsom. Grounded language learning in a simulated 3d world. arXiv, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hermann%2C%20Karl%20Moritz%20Hill%2C%20Felix%20Green%2C%20Simon%20Wang%2C%20Fumin%20Demis%20Hassabis%2C%20and%20Phil%20Blunsom.%20Grounded%20language%20learning%20in%20a%20simulated%203d%20world%202017"
        },
        {
            "id": "Higgins_et+al_2017_a",
            "entry": "Irina Higgins, Arka Pal, Andrei Rusu, Loic Matthey, Christopher Burgess, Alexander Pritzel, Matthew Botvinick, Charles Blundell, and Alexander Lerchner. Darla: Improving zero-shot transfer in reinforcement learning. In ICML, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Higgins%2C%20Irina%20Pal%2C%20Arka%20Rusu%2C%20Andrei%20Matthey%2C%20Loic%20Darla%3A%20Improving%20zero-shot%20transfer%20in%20reinforcement%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Higgins%2C%20Irina%20Pal%2C%20Arka%20Rusu%2C%20Andrei%20Matthey%2C%20Loic%20Darla%3A%20Improving%20zero-shot%20transfer%20in%20reinforcement%20learning%202017"
        },
        {
            "id": "Hoiem_et+al_2005_a",
            "entry": "Derek Hoiem, Alexei A. Efros, and Martial Hebert. Geometric context from a single image. In ICCV, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hoiem%2C%20Derek%20Efros%2C%20Alexei%20A.%20Hebert%2C%20Martial%20Geometric%20context%20from%20a%20single%20image%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hoiem%2C%20Derek%20Efros%2C%20Alexei%20A.%20Hebert%2C%20Martial%20Geometric%20context%20from%20a%20single%20image%202005"
        },
        {
            "id": "Hu_et+al_2017_a",
            "entry": "Ronghang Hu, Marcus Rohrbach, Jacob Andreas, Trevor Darrell, and Kate Saenko. Modeling relationships in referential expressions with compositional modular networks. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hu%2C%20Ronghang%20Rohrbach%2C%20Marcus%20Andreas%2C%20Jacob%20Darrell%2C%20Trevor%20Modeling%20relationships%20in%20referential%20expressions%20with%20compositional%20modular%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hu%2C%20Ronghang%20Rohrbach%2C%20Marcus%20Andreas%2C%20Jacob%20Darrell%2C%20Trevor%20Modeling%20relationships%20in%20referential%20expressions%20with%20compositional%20modular%20networks%202017"
        },
        {
            "id": "Johnson_et+al_2015_a",
            "entry": "Justin Johnson, Ranjay Krishna, Michael Stark, Jia Li, Michael Bernstein, and Li Fei-Fei. Image retrieval using scene graphs. In CVPR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Justin%20Krishna%2C%20Ranjay%20Stark%2C%20Michael%20Li%2C%20Jia%20Image%20retrieval%20using%20scene%20graphs%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20Justin%20Krishna%2C%20Ranjay%20Stark%2C%20Michael%20Li%2C%20Jia%20Image%20retrieval%20using%20scene%20graphs%202015"
        },
        {
            "id": "Johnson_et+al_2017_a",
            "entry": "Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei, C Lawrence Zitnick, and Ross Girshick. CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Justin%20Hariharan%2C%20Bharath%20van%20der%20Maaten%2C%20Laurens%20Li%20Fei-Fei%2C%20C.Lawrence%20Zitnick%20CLEVR%3A%20A%20diagnostic%20dataset%20for%20compositional%20language%20and%20elementary%20visual%20reasoning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20Justin%20Hariharan%2C%20Bharath%20van%20der%20Maaten%2C%20Laurens%20Li%20Fei-Fei%2C%20C.Lawrence%20Zitnick%20CLEVR%3A%20A%20diagnostic%20dataset%20for%20compositional%20language%20and%20elementary%20visual%20reasoning%202017"
        },
        {
            "id": "Jones_2011_a",
            "entry": "Eagle S. Jones and Stefano Soatto. Visual-inertial navigation, mapping and localization: A scalable real-time causal approach. Intl. J. of Robotics Research, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jones%2C%20Eagle%20S.%20Soatto%2C%20Stefano%20Visual-inertial%20navigation%2C%20mapping%20and%20localization%3A%20A%20scalable%20real-time%20causal%20approach%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jones%2C%20Eagle%20S.%20Soatto%2C%20Stefano%20Visual-inertial%20navigation%2C%20mapping%20and%20localization%3A%20A%20scalable%20real-time%20causal%20approach%202011"
        },
        {
            "id": "Joulin_et+al_2016_a",
            "entry": "Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov. Bag of tricks for efficient text classification. arXiv, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Joulin%2C%20Armand%20Grave%2C%20Edouard%20Bojanowski%2C%20Piotr%20Mikolov%2C%20Tomas%20Bag%20of%20tricks%20for%20efficient%20text%20classification%202016"
        },
        {
            "id": "Kahn_et+al_2018_a",
            "entry": "Gregory Kahn, Adam Villaflor, Bosen Ding, Pieter Abbeel, and Sergey Levine. Self-supervised deep reinforcement learning with generalized computation graphs for robot navigation. In ICRA, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kahn%2C%20Gregory%20Villaflor%2C%20Adam%20Ding%2C%20Bosen%20Abbeel%2C%20Pieter%20Self-supervised%20deep%20reinforcement%20learning%20with%20generalized%20computation%20graphs%20for%20robot%20navigation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kahn%2C%20Gregory%20Villaflor%2C%20Adam%20Ding%2C%20Bosen%20Abbeel%2C%20Pieter%20Self-supervised%20deep%20reinforcement%20learning%20with%20generalized%20computation%20graphs%20for%20robot%20navigation%202018"
        },
        {
            "id": "Dongsung_1999_a",
            "entry": "Dongsung Kim and Ramakant Nevatia. Symbolic navigation with a generic map. Autonomous Robots, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dongsung%20Kim%20and%20Ramakant%20Nevatia%20Symbolic%20navigation%20with%20a%20generic%20map%20Autonomous%20Robots%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dongsung%20Kim%20and%20Ramakant%20Nevatia%20Symbolic%20navigation%20with%20a%20generic%20map%20Autonomous%20Robots%201999"
        },
        {
            "id": "Kipf_2017_a",
            "entry": "Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kipf%2C%20Thomas%20N.%20Welling%2C%20Max%20Semi-supervised%20classification%20with%20graph%20convolutional%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kipf%2C%20Thomas%20N.%20Welling%2C%20Max%20Semi-supervised%20classification%20with%20graph%20convolutional%20networks%202017"
        },
        {
            "id": "Kolve_et+al_2017_a",
            "entry": "Eric Kolve, Roozbeh Mottaghi, Daniel Gordon, Yuke Zhu, Abhinav Gupta, and Ali Farhadi. AI2-THOR: An Interactive 3D Environment for Visual AI. arXiv, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kolve%2C%20Eric%20Mottaghi%2C%20Roozbeh%20Gordon%2C%20Daniel%20Zhu%2C%20Yuke%20AI2-THOR%3A%20An%20Interactive%203D%20Environment%20for%20Visual%20AI%202017"
        },
        {
            "id": "Krishna_et+al_2017_a",
            "entry": "Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David A Shamma, et al. Visual genome: Connecting language and vision using crowdsourced dense image annotations. IJCV, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krishna%2C%20Ranjay%20Zhu%2C%20Yuke%20Groth%2C%20Oliver%20Johnson%2C%20Justin%20Visual%20genome%3A%20Connecting%20language%20and%20vision%20using%20crowdsourced%20dense%20image%20annotations%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krishna%2C%20Ranjay%20Zhu%2C%20Yuke%20Groth%2C%20Oliver%20Johnson%2C%20Justin%20Visual%20genome%3A%20Connecting%20language%20and%20vision%20using%20crowdsourced%20dense%20image%20annotations%202017"
        },
        {
            "id": "Li_et+al_2017_a",
            "entry": "Ruiyu Li, Makarand Tapaswi, Renjie Liao, Jiaya Jia, Raquel Urtasun, and Sanja Fidler. Situation recognition with graph neural networks. In ICCV, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Ruiyu%20Tapaswi%2C%20Makarand%20Liao%2C%20Renjie%20Jia%2C%20Jiaya%20Situation%20recognition%20with%20graph%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Ruiyu%20Tapaswi%2C%20Makarand%20Liao%2C%20Renjie%20Jia%2C%20Jiaya%20Situation%20recognition%20with%20graph%20neural%20networks%202017"
        },
        {
            "id": "Malisiewicz_2009_a",
            "entry": "Tomasz Malisiewicz and Alexei A. Efros. Beyond categories: The visual memex model for reasoning about object relationships. In NIPS, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Malisiewicz%2C%20Tomasz%20Efros%2C%20Alexei%20A.%20Beyond%20categories%3A%20The%20visual%20memex%20model%20for%20reasoning%20about%20object%20relationships%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Malisiewicz%2C%20Tomasz%20Efros%2C%20Alexei%20A.%20Beyond%20categories%3A%20The%20visual%20memex%20model%20for%20reasoning%20about%20object%20relationships%202009"
        },
        {
            "id": "Marino_et+al_2017_a",
            "entry": "Kenneth Marino, Ruslan Salakhutdinov, and Abhinav Gupta. The more you know: Using knowledge graphs for image classification. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Marino%2C%20Kenneth%20Salakhutdinov%2C%20Ruslan%20Gupta%2C%20Abhinav%20The%20more%20you%20know%3A%20Using%20knowledge%20graphs%20for%20image%20classification%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Marino%2C%20Kenneth%20Salakhutdinov%2C%20Ruslan%20Gupta%2C%20Abhinav%20The%20more%20you%20know%3A%20Using%20knowledge%20graphs%20for%20image%20classification%202017"
        },
        {
            "id": "Marszalek_et+al_2009_a",
            "entry": "Marcin Marszalek, Ivan Laptev, and Cordelia Schmid. Actions in context. In CVPR, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Marcin%20Marszalek%20Ivan%20Laptev%20and%20Cordelia%20Schmid%20Actions%20in%20context%20In%20CVPR%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Marcin%20Marszalek%20Ivan%20Laptev%20and%20Cordelia%20Schmid%20Actions%20in%20context%20In%20CVPR%202009"
        },
        {
            "id": "Matthies_1987_a",
            "entry": "Larry H. Matthies and Steven A. Shafer. Error modeling in stereo navigation. IEEE J. Robotics and Automation, 1987.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Matthies%2C%20Larry%20H.%20Shafer%2C%20Steven%20A.%20Error%20modeling%20in%20stereo%20navigation%201987",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Matthies%2C%20Larry%20H.%20Shafer%2C%20Steven%20A.%20Error%20modeling%20in%20stereo%20navigation%201987"
        },
        {
            "id": "Mei_et+al_2016_a",
            "entry": "Hongyuan Mei, Mohit Bansal, and Matthew R. Walter. Listen, attend, and walk: Neural mapping of navigational instructions to action sequences. In AAAI, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mei%2C%20Hongyuan%20Bansal%2C%20Mohit%20Listen%2C%20Matthew%20R.Walter%20attend%20and%20walk%3A%20Neural%20mapping%20of%20navigational%20instructions%20to%20action%20sequences%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mei%2C%20Hongyuan%20Bansal%2C%20Mohit%20Listen%2C%20Matthew%20R.Walter%20attend%20and%20walk%3A%20Neural%20mapping%20of%20navigational%20instructions%20to%20action%20sequences%202016"
        },
        {
            "id": "Meng_1993_a",
            "entry": "Min Meng and Avinash C. Kak. Neuro-nav: A neural network based architecture for vision-guided mobile robot navigation using non-metrical models of the environment. In ICRA, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Meng%2C%20Min%20Kak%2C%20Avinash%20C.%20Neuro-nav%3A%20A%20neural%20network%20based%20architecture%20for%20vision-guided%20mobile%20robot%20navigation%20using%20non-metrical%20models%20of%20the%20environment%201993",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Meng%2C%20Min%20Kak%2C%20Avinash%20C.%20Neuro-nav%3A%20A%20neural%20network%20based%20architecture%20for%20vision-guided%20mobile%20robot%20navigation%20using%20non-metrical%20models%20of%20the%20environment%201993"
        },
        {
            "id": "Mirowski_et+al_2017_a",
            "entry": "Piotr Mirowski, Razvan Pascanu, Fabio Viola, Hubert Soyer, Andrew J. Ballard, Andrea Banino, Misha Denil, Ross Goroshin, Laurent Sifre, Koray Kavukcuoglu, Dharshan Kumaran, and Raia Hadsell. Learning to navigate in complex environments. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mirowski%2C%20Piotr%20Pascanu%2C%20Razvan%20Viola%2C%20Fabio%20Soyer%2C%20Hubert%20Learning%20to%20navigate%20in%20complex%20environments%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mirowski%2C%20Piotr%20Pascanu%2C%20Razvan%20Viola%2C%20Fabio%20Soyer%2C%20Hubert%20Learning%20to%20navigate%20in%20complex%20environments%202017"
        },
        {
            "id": "Misra_et+al_2017_a",
            "entry": "Dipendra Kumar Misra, John Langford, and Yoav Artzi. Mapping instructions and visual observations to actions with reinforcement learning. In EMNLP, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Misra%2C%20Dipendra%20Kumar%20Langford%2C%20John%20Artzi%2C%20Yoav%20Mapping%20instructions%20and%20visual%20observations%20to%20actions%20with%20reinforcement%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Misra%2C%20Dipendra%20Kumar%20Langford%2C%20John%20Artzi%2C%20Yoav%20Mapping%20instructions%20and%20visual%20observations%20to%20actions%20with%20reinforcement%20learning%202017"
        },
        {
            "id": "Mnih_et+al_2016_a",
            "entry": "Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. Asynchronous methods for deep reinforcement learning. In ICML, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mnih%2C%20Volodymyr%20Badia%2C%20Adria%20Puigdomenech%20Mirza%2C%20Mehdi%20Graves%2C%20Alex%20Asynchronous%20methods%20for%20deep%20reinforcement%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mnih%2C%20Volodymyr%20Badia%2C%20Adria%20Puigdomenech%20Mirza%2C%20Mehdi%20Graves%2C%20Alex%20Asynchronous%20methods%20for%20deep%20reinforcement%20learning%202016"
        },
        {
            "id": "Mottaghi_et+al_2014_a",
            "entry": "Roozbeh Mottaghi, Xianjie Chen, Xiaobai Liu, Nam-Gyu Cho, Seong-Whan Lee, Sanja Fidler, Raquel Urtasun, and Alan Yuille. The role of context for object detection and semantic segmentation in the wild. In CVPR, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mottaghi%2C%20Roozbeh%20Chen%2C%20Xianjie%20Liu%2C%20Xiaobai%20Cho%2C%20Nam-Gyu%20The%20role%20of%20context%20for%20object%20detection%20and%20semantic%20segmentation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mottaghi%2C%20Roozbeh%20Chen%2C%20Xianjie%20Liu%2C%20Xiaobai%20Cho%2C%20Nam-Gyu%20The%20role%20of%20context%20for%20object%20detection%20and%20semantic%20segmentation%202014"
        },
        {
            "id": "Mousavian_et+al_2018_a",
            "entry": "Arsalan Mousavian, Alexander Toshev, Marek Fiser, Jana Kosecka, and James Davidson. Visual representations for semantic target driven navigation. In ECCV Workshop on Visual Learning and Embodied Agents in Simulation Environments, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mousavian%2C%20Arsalan%20Toshev%2C%20Alexander%20Fiser%2C%20Marek%20Kosecka%2C%20Jana%20Visual%20representations%20for%20semantic%20target%20driven%20navigation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mousavian%2C%20Arsalan%20Toshev%2C%20Alexander%20Fiser%2C%20Marek%20Kosecka%2C%20Jana%20Visual%20representations%20for%20semantic%20target%20driven%20navigation%202018"
        },
        {
            "id": "Nagaraja_et+al_2016_a",
            "entry": "Varun K. Nagaraja, Vlad I. Morariu, and Larry S. Davis. Modeling context between objects for referring expression understanding. In ECCV, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nagaraja%2C%20Varun%20K.%20Morariu%2C%20Vlad%20I.%20Davis%2C%20Larry%20S.%20Modeling%20context%20between%20objects%20for%20referring%20expression%20understanding%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nagaraja%2C%20Varun%20K.%20Morariu%2C%20Vlad%20I.%20Davis%2C%20Larry%20S.%20Modeling%20context%20between%20objects%20for%20referring%20expression%20understanding%202016"
        },
        {
            "id": "Oh_et+al_2017_a",
            "entry": "Junhyuk Oh, Satinder Singh, Honglak Lee, and Pushmeet Kohli. Zero-shot task generalization with multi-task deep reinforcement learning. In ICML, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Oh%2C%20Junhyuk%20Singh%2C%20Satinder%20Lee%2C%20Honglak%20Kohli%2C%20Pushmeet%20Zero-shot%20task%20generalization%20with%20multi-task%20deep%20reinforcement%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Oh%2C%20Junhyuk%20Singh%2C%20Satinder%20Lee%2C%20Honglak%20Kohli%2C%20Pushmeet%20Zero-shot%20task%20generalization%20with%20multi-task%20deep%20reinforcement%20learning%202017"
        },
        {
            "id": "Pathak_et+al_2018_a",
            "entry": "Deepak Pathak, Parsa Mahmoudieh, Guanghao Luo, Pulkit Agrawal, Dian Chen, Fred Shentu, Evan Shelhamer, Jitendra Malik, Alexei A. Efros, and Trevor Darrell. Zero-shot visual imitation. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pathak%2C%20Deepak%20Mahmoudieh%2C%20Parsa%20Luo%2C%20Guanghao%20Agrawal%2C%20Pulkit%20Zero-shot%20visual%20imitation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pathak%2C%20Deepak%20Mahmoudieh%2C%20Parsa%20Luo%2C%20Guanghao%20Agrawal%2C%20Pulkit%20Zero-shot%20visual%20imitation%202018"
        },
        {
            "id": "Rabinovich_et+al_2005_a",
            "entry": "Andrew Rabinovich, Andrea Vedaldi, Carolina Galleguillos, Eric Wiewiora, and Serge Belongie. Objects in context. In ICCV, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Andrew%20Rabinovich%20Andrea%20Vedaldi%20Carolina%20Galleguillos%20Eric%20Wiewiora%20and%20Serge%20Belongie%20Objects%20in%20context%20In%20ICCV%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Andrew%20Rabinovich%20Andrea%20Vedaldi%20Carolina%20Galleguillos%20Eric%20Wiewiora%20and%20Serge%20Belongie%20Objects%20in%20context%20In%20ICCV%202005"
        },
        {
            "id": "Sadeghi_2017_a",
            "entry": "Fereshteh Sadeghi and Sergey Levine. CAD2RL: real single-image flight without a single real image. In RSS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sadeghi%2C%20Fereshteh%20Levine%2C%20Sergey%20CAD2RL%3A%20real%20single-image%20flight%20without%20a%20single%20real%20image%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sadeghi%2C%20Fereshteh%20Levine%2C%20Sergey%20CAD2RL%3A%20real%20single-image%20flight%20without%20a%20single%20real%20image%202017"
        },
        {
            "id": "Savinov_et+al_2018_a",
            "entry": "Nikolay Savinov, Alexey Dosovitskiy, and Vladlen Koltun. Semi-parametric topological memory for navigation. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Savinov%2C%20Nikolay%20Dosovitskiy%2C%20Alexey%20Koltun%2C%20Vladlen%20Semi-parametric%20topological%20memory%20for%20navigation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Savinov%2C%20Nikolay%20Dosovitskiy%2C%20Alexey%20Koltun%2C%20Vladlen%20Semi-parametric%20topological%20memory%20for%20navigation%202018"
        },
        {
            "id": "Shrivastava_2014_a",
            "entry": "Abhinav Shrivastava and Abhinav Gupta. Contextual priming and feedback for faster r-cnn. In ECCV, 2016. Christian Siagian, Chin-Kai Chang, and Laurent Itti. Autonomous mobile robot localization and navigation using a hierarchical map representation primarily guided by vision. J. Field Robotics, 2014. Sebastian Thrun. Learning metric-topological maps for indoor mobile robot navigation. Artificial Intelligence, 1998. Tijmen Tieleman and Geoffrey Hinton. RMSprop gradient optimization. URL http://www.cs.toronto.",
            "url": "http://www.cs.toronto",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abhinav%20Shrivastava%20and%20Abhinav%20Gupta%20Contextual%20priming%20and%20feedback%20for%20faster%20rcnn%20In%20ECCV%202016%20Christian%20Siagian%20ChinKai%20Chang%20and%20Laurent%20Itti%20Autonomous%20mobile%20robot%20localization%20and%20navigation%20using%20a%20hierarchical%20map%20representation%20primarily%20guided%20by%20vision%20J%20Field%20Robotics%202014%20Sebastian%20Thrun%20Learning%20metrictopological%20maps%20for%20indoor%20mobile%20robot%20navigation%20Artificial%20Intelligence%201998%20Tijmen%20Tieleman%20and%20Geoffrey%20Hinton%20RMSprop%20gradient%20optimization%20URL%20httpwwwcstoronto"
        }
    ]
}

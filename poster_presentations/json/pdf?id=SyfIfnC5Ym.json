{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "IMPROVING THE GENERALIZATION OF ADVERSARIAL TRAINING WITH DOMAIN ADAPTATION",
        "author": "Chuanbiao Song Department of Computer Science Huazhong University of Science and Technology Wuhan 430074, China cbsong@hust.edu.cn",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=SyfIfnC5Ym"
        },
        "abstract": "By injecting adversarial examples into training data, adversarial training is promising for improving the robustness of deep learning models. However, most existing adversarial training approaches are based on a specific type of adversarial attack. It may not provide sufficiently representative samples from the adversarial domain, leading to a weak generalization ability on adversarial examples from other attacks. Moreover, during the adversarial training, adversarial perturbations on inputs are usually crafted by fast single-step adversaries so as to scale to large datasets. This work is mainly focused on the adversarial training yet efficient FGSM adversary. In this scenario, it is difficult to train a model with great generalization due to the lack of representative adversarial samples, aka the samples are unable to accurately reflect the adversarial domain. To alleviate this problem, we propose a novel Adversarial Training with Domain Adaptation (ATDA) method. Our intuition is to regard the adversarial training on FGSM adversary as a domain adaption task with limited number of target domain samples. The main idea is to learn a representation that is semantically meaningful and domain invariant on the clean domain as well as the adversarial domain. Empirical evaluations on Fashion-MNIST, SVHN, CIFAR-10 and CIFAR-100 demonstrate that ATDA can greatly improve the generalization of adversarial training and the smoothness of the learned models, and outperforms state-of-the-art methods on standard benchmark datasets. To show the transfer ability of our method, we also extend ATDA to the adversarial training on iterative attacks such as PGD-Adversial Training (PAT) and the defense performance is improved considerably."
    },
    "keywords": [
        {
            "term": "domain adaptation",
            "url": "https://en.wikipedia.org/wiki/domain_adaptation"
        },
        {
            "term": "image classification",
            "url": "https://en.wikipedia.org/wiki/image_classification"
        },
        {
            "term": "computer vision",
            "url": "https://en.wikipedia.org/wiki/computer_vision"
        }
    ],
    "abbreviations": {
        "ATDA": "Adversarial Training with Domain Adaptation",
        "PAT": "PGD-Adversarial Training",
        "DA": "domain adaptation",
        "FGSM": "Fast Gradient Sign Method",
        "PGD": "Projected Gradient Descent",
        "MIM": "Momentum Iterative Method",
        "CORAL": "CORrelation ALignment",
        "MMD": "Maximum Mean Discrepancy",
        "UDA": "Unsupervised Domain Adaptation",
        "SDA": "supervised domain adaptation",
        "NT": "Normal Training",
        "SAT": "Standard Adversarial Training",
        "EAT": "Ensemble Adversarial Training",
        "PRT": "Provably Robust Training"
    },
    "highlights": [
        "Deep learning techniques have shown impressive performance on image classification and many other computer vision tasks",
        "We propose an Adversarial Training with Domain Adaptation (ATDA) method to defense adversarial attacks and expect the learned models generalize well for various adversarial examples",
        "To effectively utilize the labeled data in the adversarial domain, we introduce a supervised domain adaptation (SDA) by proposing a new loss function, denoted as margin loss, to minimize the intra-class variations and maximize the inter-class variations on samples of different domains",
        "We generate new adversarial examples by the variant of Fast Gradient Sign Method attack shown in Eq (11), we use the following loss function to meet the criteria of domain adaptation while training a strong classifier",
        "By combining adversarial training on Fast Gradient Sign Method adversary with unsupervised and supervised domain adaptation, the generalization ability on adversarial examples from various attacks and the smoothness on the learned models can be highly improved for robust defense",
        "The experimental results on several benchmark datasets suggest that the proposed Adversarial Training with Domain Adaptation and its extension PATDA achieve significantly better generalization results as compared with current competing adversarial training methods"
    ],
    "key_statements": [
        "Deep learning techniques have shown impressive performance on image classification and many other computer vision tasks",
        "Recent works have revealed that deep learning models are often vulnerable to adversarial examples (<a class=\"ref-link\" id=\"cSzegedy_et+al_2014_a\" href=\"#rSzegedy_et+al_2014_a\">Szegedy et al, 2014</a>; Goodfellow et al.; <a class=\"ref-link\" id=\"cPapernot_et+al_2016_a\" href=\"#rPapernot_et+al_2016_a\">Papernot et al, 2016</a>), which are maliciously designed to deceive the target model by generating carefully crafted adversarial perturbations on original clean inputs",
        "Denote the clean data domain and the adversarial data domain by D and A respectively, we consider a classifier based on a neural network f (x) : Rd \u2192 Rk. f (x) outputs the probability distribution for an input x \u2208 [0, 1]d, and k denotes the number of classes in the classification task",
        "We propose an Adversarial Training with Domain Adaptation (ATDA) method to defense adversarial attacks and expect the learned models generalize well for various adversarial examples",
        "To effectively utilize the labeled data in the adversarial domain, we introduce a supervised domain adaptation (SDA) by proposing a new loss function, denoted as margin loss, to minimize the intra-class variations and maximize the inter-class variations on samples of different domains",
        "We generate new adversarial examples by the variant of Fast Gradient Sign Method attack shown in Eq (11), we use the following loss function to meet the criteria of domain adaptation while training a strong classifier",
        "The results suggest that adversarial training methods do increase the smoothness of the model as compared with the normal training and Adversarial Training with Domain Adaptation performs the best",
        "The comparisons are illustrated in Figure 2 and we report the detailed Maximum Mean Discrepancy distances across domains in Table 3",
        "As shown in Table 4, we evaluate the defense performance of Projected Gradient Descent-Adversarial Training and PATDA on various datasets",
        "By combining adversarial training on Fast Gradient Sign Method adversary with unsupervised and supervised domain adaptation, the generalization ability on adversarial examples from various attacks and the smoothness on the learned models can be highly improved for robust defense",
        "The experimental results on several benchmark datasets suggest that the proposed Adversarial Training with Domain Adaptation and its extension PATDA achieve significantly better generalization results as compared with current competing adversarial training methods"
    ],
    "summary": [
        "Deep learning techniques have shown impressive performance on image classification and many other computer vision tasks.",
        "Goodfellow et al proposed to increase the robustness by feeding the model with both original and adversarial examples generated by FGSM and by learning with the modified objective function.",
        "We propose an Adversarial Training with Domain Adaptation (ATDA) method to defense adversarial attacks and expect the learned models generalize well for various adversarial examples.",
        "We generate new adversarial examples by the variant of FGSM attack shown in Eq (11), we use the following loss function to meet the criteria of domain adaptation while training a strong classifier.",
        "1: Randomly initialize network f (x) and logits centers {cj | j = 1, 2, ..., k}; 2: Number of iterations t \u2190 0; 3: repeat 4: t \u2190 t + 1; 5: Read a minibatch of data Db = {x1, ..., xm} from the training set; 6: Use the current state of network f to generate adversarial examples Ab = {x1adv, ..., xamdv}",
        "To evaluate the generalization power on adversarial examples in both the white-box and black-box settings, we report the clean test accuracy, the defense accuracy on FGSM, PGD, R+FGSM and MIM in the non-targeted way.",
        "As compared to SAT, ATDA achieves stronger generalization ability on adversarial examples from various attacks and higher accuracy on the white-box adversaries, at the same time it only loses a negligible performance on clean data.",
        "Compared to SAT, ATDA achieves better generalization on various adversarial examples and it does not degrade the performance on clean data.",
        "The results suggest that adversarial training methods do increase the smoothness of the model as compared with the normal training and ATDA performs the best.",
        "The results illustrate that, by aligning the covariance matrix and mean vector of the clean and adversarial examples, UDA plays a key role in improving the generalization of SAT on various attacks.",
        "By combining adversarial training on FGSM adversary with unsupervised and supervised domain adaptation, the generalization ability on adversarial examples from various attacks and the smoothness on the learned models can be highly improved for robust defense.",
        "ATDA can be extended to adversarial training on iterative attacks (e.g., PGD) to improve the defense performance.",
        "The experimental results on several benchmark datasets suggest that the proposed ATDA and its extension PATDA achieve significantly better generalization results as compared with current competing adversarial training methods."
    ],
    "headline": "We propose a novel Adversarial Training with Domain Adaptation method",
    "reference_links": [
        {
            "id": "Arpit_et+al_2017_a",
            "entry": "Devansh Arpit, Stanislaw K. Jastrzebski, Nicolas Ballas, David Krueger, Emmanuel Bengio, Maxinder S. Kanwal, Tegan Maharaj, Asja Fischer, Aaron C. Courville, Yoshua Bengio, and Simon Lacoste-Julien. A closer look at memorization in deep networks. In Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017, pp. 233\u2013242, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arpit%2C%20Devansh%20Jastrzebski%2C%20Stanislaw%20K.%20Ballas%2C%20Nicolas%20Krueger%2C%20David%20A%20closer%20look%20at%20memorization%20in%20deep%20networks%202017-08",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arpit%2C%20Devansh%20Jastrzebski%2C%20Stanislaw%20K.%20Ballas%2C%20Nicolas%20Krueger%2C%20David%20A%20closer%20look%20at%20memorization%20in%20deep%20networks%202017-08"
        },
        {
            "id": "Borgwardt_et+al_2006_a",
            "entry": "Karsten M Borgwardt, Arthur Gretton, Malte J Rasch, Hans-Peter Kriegel, Bernhard Scholkopf, and Alex J Smola. Integrating structured biological data by kernel maximum mean discrepancy. Bioinformatics, 22(14):e49\u2013e57, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Borgwardt%2C%20Karsten%20M.%20Gretton%2C%20Arthur%20Rasch%2C%20Malte%20J.%20Kriegel%2C%20Hans-Peter%20Integrating%20structured%20biological%20data%20by%20kernel%20maximum%20mean%20discrepancy%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Borgwardt%2C%20Karsten%20M.%20Gretton%2C%20Arthur%20Rasch%2C%20Malte%20J.%20Kriegel%2C%20Hans-Peter%20Integrating%20structured%20biological%20data%20by%20kernel%20maximum%20mean%20discrepancy%202006"
        },
        {
            "id": "Clevert_et+al_2015_a",
            "entry": "Djork-Arne Clevert, Thomas Unterthiner, and Sepp Hochreiter. Fast and accurate deep network learning by exponential linear units (elus). arXiv preprint arXiv:1511.07289, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.07289"
        },
        {
            "id": "Dong_et+al_2018_a",
            "entry": "Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, and Jianguo Li. Boosting adversarial attacks with momentum. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dong%2C%20Yinpeng%20Liao%2C%20Fangzhou%20Pang%2C%20Tianyu%20Su%2C%20Hang%20Boosting%20adversarial%20attacks%20with%20momentum%202018-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dong%2C%20Yinpeng%20Liao%2C%20Fangzhou%20Pang%2C%20Tianyu%20Su%2C%20Hang%20Boosting%20adversarial%20attacks%20with%20momentum%202018-06"
        },
        {
            "id": "Goodfellow_et+al_2014_a",
            "entry": "Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples (2014). arXiv preprint arXiv:1412.6572.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6572"
        },
        {
            "id": "Krizhevsky_2009_a",
            "entry": "Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images. Technical report, Citeseer, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Hinton%2C%20Geoffrey%20Learning%20multiple%20layers%20of%20features%20from%20tiny%20images%202009"
        },
        {
            "id": "Kurakin_et+al_0000_a",
            "entry": "Alexey Kurakin, Ian Goodfellow, and Samy Bengio. Adversarial examples in the physical world. arXiv preprint arXiv:1607.02533, 2016a.",
            "arxiv_url": "https://arxiv.org/pdf/1607.02533"
        },
        {
            "id": "Kurakin_et+al_0000_b",
            "entry": "Alexey Kurakin, Ian Goodfellow, and Samy Bengio. Adversarial machine learning at scale. arXiv preprint arXiv:1611.01236, 2016b.",
            "arxiv_url": "https://arxiv.org/pdf/1611.01236"
        },
        {
            "id": "Liao_et+al_2018_a",
            "entry": "Fangzhou Liao, Ming Liang, Yinpeng Dong, Tianyu Pang, Jun Zhu, and Xiaolin Hu. Defense against adversarial attacks using high-level representation guided denoiser. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1778\u20131787, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liao%2C%20Fangzhou%20Liang%2C%20Ming%20Dong%2C%20Yinpeng%20Pang%2C%20Tianyu%20Defense%20against%20adversarial%20attacks%20using%20high-level%20representation%20guided%20denoiser%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liao%2C%20Fangzhou%20Liang%2C%20Ming%20Dong%2C%20Yinpeng%20Pang%2C%20Tianyu%20Defense%20against%20adversarial%20attacks%20using%20high-level%20representation%20guided%20denoiser%202018"
        },
        {
            "id": "Liu_et+al_2017_a",
            "entry": "Yanpei Liu, Xinyun Chen, Chang Liu, and Dawn Song. Delving into transferable adversarial examples and black-box attacks. In International Conference on Learning Representations(ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Yanpei%20Chen%2C%20Xinyun%20Liu%2C%20Chang%20Song%2C%20Dawn%20Delving%20into%20transferable%20adversarial%20examples%20and%20black-box%20attacks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Yanpei%20Chen%2C%20Xinyun%20Liu%2C%20Chang%20Song%2C%20Dawn%20Delving%20into%20transferable%20adversarial%20examples%20and%20black-box%20attacks%202017"
        },
        {
            "id": "Van_2008_a",
            "entry": "Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine learning research, 9(Nov):2579\u20132605, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=van%20der%20Maaten%2C%20Laurens%20Hinton%2C%20Geoffrey%20Visualizing%20data%20using%20t-sne%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=van%20der%20Maaten%2C%20Laurens%20Hinton%2C%20Geoffrey%20Visualizing%20data%20using%20t-sne%202008"
        },
        {
            "id": "Madry_et+al_2018_a",
            "entry": "Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. In International Conference on Learning Representations(ICLR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Madry%2C%20Aleksander%20Makelov%2C%20Aleksandar%20Schmidt%2C%20Ludwig%20Tsipras%2C%20Dimitris%20Towards%20deep%20learning%20models%20resistant%20to%20adversarial%20attacks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Madry%2C%20Aleksander%20Makelov%2C%20Aleksandar%20Schmidt%2C%20Ludwig%20Tsipras%2C%20Dimitris%20Towards%20deep%20learning%20models%20resistant%20to%20adversarial%20attacks%202018"
        },
        {
            "id": "Netzer_et+al_2011_a",
            "entry": "Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading digits in natural images with unsupervised feature learning. In NIPS workshop on deep learning and unsupervised feature learning, volume 2011, pp. 5, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Netzer%2C%20Yuval%20Wang%2C%20Tao%20Coates%2C%20Adam%20Bissacco%2C%20Alessandro%20Reading%20digits%20in%20natural%20images%20with%20unsupervised%20feature%20learning%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Netzer%2C%20Yuval%20Wang%2C%20Tao%20Coates%2C%20Adam%20Bissacco%2C%20Alessandro%20Reading%20digits%20in%20natural%20images%20with%20unsupervised%20feature%20learning%202011"
        },
        {
            "id": "N_2015_a",
            "entry": "Arild N\u00f8kland. Improving back-propagation by adding an adversarial gradient. arXiv preprint arXiv:1510.04189, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1510.04189"
        },
        {
            "id": "Papernot_et+al_2016_a",
            "entry": "Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z Berkay Celik, and Ananthram Swami. The limitations of deep learning in adversarial settings. In Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372\u2013387, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Papernot%2C%20Nicolas%20McDaniel%2C%20Patrick%20Jha%2C%20Somesh%20Matt%20Fredrikson%2C%20Z.Berkay%20Celik%20The%20limitations%20of%20deep%20learning%20in%20adversarial%20settings%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Papernot%2C%20Nicolas%20McDaniel%2C%20Patrick%20Jha%2C%20Somesh%20Matt%20Fredrikson%2C%20Z.Berkay%20Celik%20The%20limitations%20of%20deep%20learning%20in%20adversarial%20settings%202016"
        },
        {
            "id": "Papernot_et+al_2017_a",
            "entry": "Nicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z Berkay Celik, and Ananthram Swami. Practical black-box attacks against machine learning. In Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506\u2013519, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Papernot%2C%20Nicolas%20McDaniel%2C%20Patrick%20Goodfellow%2C%20Ian%20Somesh%20Jha%2C%20Z.Berkay%20Celik%20Practical%20black-box%20attacks%20against%20machine%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Papernot%2C%20Nicolas%20McDaniel%2C%20Patrick%20Goodfellow%2C%20Ian%20Somesh%20Jha%2C%20Z.Berkay%20Celik%20Practical%20black-box%20attacks%20against%20machine%20learning%202017"
        },
        {
            "id": "Russakovsky_et+al_2015_a",
            "entry": "Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael S. Bernstein, Alexander C. Berg, and Fei-Fei Li. Imagenet large scale visual recognition challenge. International Journal of Computer Vision, 115(3):211\u2013252, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Russakovsky%2C%20Olga%20Deng%2C%20Jia%20Su%2C%20Hao%20Krause%2C%20Jonathan%20Imagenet%20large%20scale%20visual%20recognition%20challenge%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Russakovsky%2C%20Olga%20Deng%2C%20Jia%20Su%2C%20Hao%20Krause%2C%20Jonathan%20Imagenet%20large%20scale%20visual%20recognition%20challenge%202015"
        },
        {
            "id": "Sun_2016_a",
            "entry": "Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In European Conference on Computer Vision, pp. 443\u2013450, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sun%2C%20Baochen%20Saenko%2C%20Kate%20Deep%20coral%3A%20Correlation%20alignment%20for%20deep%20domain%20adaptation%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sun%2C%20Baochen%20Saenko%2C%20Kate%20Deep%20coral%3A%20Correlation%20alignment%20for%20deep%20domain%20adaptation%202016"
        },
        {
            "id": "Szegedy_et+al_2014_a",
            "entry": "Christian Szegedy, Google Inc, Wojciech Zaremba, Ilya Sutskever, Google Inc, Joan Bruna, Dumitru Erhan, Google Inc, Ian Goodfellow, and Rob Fergus. Intriguing properties of neural networks. In International Conference on Learning Representations(ICLR), 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szegedy%2C%20Christian%20Inc%2C%20Google%20Zaremba%2C%20Wojciech%20Sutskever%2C%20Ilya%20Intriguing%20properties%20of%20neural%20networks%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Szegedy%2C%20Christian%20Inc%2C%20Google%20Zaremba%2C%20Wojciech%20Sutskever%2C%20Ilya%20Intriguing%20properties%20of%20neural%20networks%202014"
        },
        {
            "id": "Tabacof_2016_a",
            "entry": "Pedro Tabacof and Eduardo Valle. Exploring the space of adversarial images. In 2016 International Joint Conference on Neural Networks (IJCNN), pp. 426\u2013433. IEEE, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tabacof%2C%20Pedro%20Valle%2C%20Eduardo%20Exploring%20the%20space%20of%20adversarial%20images%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tabacof%2C%20Pedro%20Valle%2C%20Eduardo%20Exploring%20the%20space%20of%20adversarial%20images%202016"
        },
        {
            "id": "Antonio_2011_a",
            "entry": "Antonio Torralba and Alexei A Efros. Unbiased look at dataset bias. In Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on, pp. 1521\u20131528. IEEE, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Antonio%20Torralba%20and%20Alexei%20A%20Efros%20Unbiased%20look%20at%20dataset%20bias%20In%20Computer%20Vision%20and%20Pattern%20Recognition%20CVPR%202011%20IEEE%20Conference%20on%20pp%2015211528%20IEEE%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Antonio%20Torralba%20and%20Alexei%20A%20Efros%20Unbiased%20look%20at%20dataset%20bias%20In%20Computer%20Vision%20and%20Pattern%20Recognition%20CVPR%202011%20IEEE%20Conference%20on%20pp%2015211528%20IEEE%202011"
        },
        {
            "id": "Tramer_et+al_2017_a",
            "entry": "Florian Tramer, Nicolas Papernot, Ian J. Goodfellow, Dan Boneh, and Patrick D. McDaniel. The space of transferable adversarial examples. arXiv preprint arXiv:1704.03453, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.03453"
        },
        {
            "id": "Tramer_et+al_2018_a",
            "entry": "Florian Tramer, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan Boneh, and Patrick McDaniel. Ensemble adversarial training: Attacks and defenses. In International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tramer%2C%20Florian%20Kurakin%2C%20Alexey%20Papernot%2C%20Nicolas%20Goodfellow%2C%20Ian%20Ensemble%20adversarial%20training%3A%20Attacks%20and%20defenses%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tramer%2C%20Florian%20Kurakin%2C%20Alexey%20Papernot%2C%20Nicolas%20Goodfellow%2C%20Ian%20Ensemble%20adversarial%20training%3A%20Attacks%20and%20defenses%202018"
        },
        {
            "id": "Wen_et+al_2016_a",
            "entry": "Yandong Wen, Kaipeng Zhang, Zhifeng Li, and Yu Qiao. A discriminative feature learning approach for deep face recognition. In European Conference on Computer Vision, pp. 499\u2013515, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wen%2C%20Yandong%20Zhang%2C%20Kaipeng%20Li%2C%20Zhifeng%20Qiao%2C%20Yu%20A%20discriminative%20feature%20learning%20approach%20for%20deep%20face%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wen%2C%20Yandong%20Zhang%2C%20Kaipeng%20Li%2C%20Zhifeng%20Qiao%2C%20Yu%20A%20discriminative%20feature%20learning%20approach%20for%20deep%20face%20recognition%202016"
        },
        {
            "id": "Wong_2018_a",
            "entry": "Eric Wong and J. Zico Kolter. Provable defenses against adversarial examples via the convex outer adversarial polytope. In Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsmassan, Stockholm, Sweden, July 10-15, 2018, pp. 5283\u20135292, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wong%2C%20Eric%20Kolter%2C%20J.Zico%20Provable%20defenses%20against%20adversarial%20examples%20via%20the%20convex%20outer%20adversarial%20polytope%202018-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wong%2C%20Eric%20Kolter%2C%20J.Zico%20Provable%20defenses%20against%20adversarial%20examples%20via%20the%20convex%20outer%20adversarial%20polytope%202018-07"
        },
        {
            "id": "Wu_2018_a",
            "entry": "Yuxin Wu and Kaiming He. Group normalization. arXiv preprint arXiv:1803.08494, 2018. Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1803.08494"
        }
    ]
}

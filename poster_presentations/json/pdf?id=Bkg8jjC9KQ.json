{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "From Nash Equilibria to Chain Recurrent Sets: An Algorithmic Solution Concept for Game Theory",
        "author": "Christos Papadimitriou, Georgios Piliouras",
        "date": 2018,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=Bkg8jjC9KQ",
            "doi": "10.3390/e20100782"
        },
        "journal": "Entropy",
        "volume": "20",
        "abstract": "In 1950, Nash proposed a natural equilibrium solution concept for games hence called Nash equilibrium, and proved that all finite games have at least one. The proof is through a simple yet ingenious application of Brouwer\u2019s (or, in another version Kakutani\u2019s) fixed point theorem, the most sophisticated result in his era\u2019s topology\u2014in fact, recent algorithmic work has established that Nash equilibria are computationally equivalent to fixed points. In this paper, we propose a new class of universal non-equilibrium solution concepts arising from an important theorem in the topology of dynamical systems that was unavailable to Nash. This approach starts with both a game and a learning dynamics, defined over mixed strategies. The Nash equilibria are fixpoints of the dynamics, but the system behavior is captured by an object far more general than the Nash equilibrium that is known in dynamical systems theory as chain recurrent set. Informally, once we focus on this solution concept\u2014this notion of \u201cthe outcome of the game\u201d\u2014every game behaves like a potential game with the dynamics converging to these states. In other words, unlike Nash equilibria, this solution concept is algorithmic in the sense that it has a constructive proof of existence. We characterize this solution for simple benchmark games under replicator dynamics, arguably the best known evolutionary dynamics in game theory. For (weighted) potential games, the new concept coincides with the fixpoints/equilibria of the dynamics. However, in (variants of) zero-sum games with fully mixed (i.e., interior) Nash equilibria, it covers the whole state space, as the dynamics satisfy specific information theoretic constants of motion. We discuss numerous novel computational, as well as structural, combinatorial questions raised by this chain recurrence conception of games.",
        "pages": "782"
    },
    "keywords": [
        {
            "term": "dynamics",
            "url": "https://en.wikipedia.org/wiki/dynamics"
        },
        {
            "term": "dynamical system",
            "url": "https://en.wikipedia.org/wiki/dynamical_system"
        },
        {
            "term": "topology",
            "url": "https://en.wikipedia.org/wiki/topology"
        },
        {
            "term": "recurrent set",
            "url": "https://en.wikipedia.org/wiki/recurrent_set"
        },
        {
            "term": "potential game",
            "url": "https://en.wikipedia.org/wiki/potential_game"
        },
        {
            "term": "equilibria",
            "url": "https://en.wikipedia.org/wiki/equilibria"
        },
        {
            "term": "gradient descent",
            "url": "https://en.wikipedia.org/wiki/gradient_descent"
        },
        {
            "term": "solution concept",
            "url": "https://en.wikipedia.org/wiki/solution_concept"
        },
        {
            "term": "nash equilibria",
            "url": "https://en.wikipedia.org/wiki/nash_equilibria"
        },
        {
            "term": "game theory",
            "url": "https://en.wikipedia.org/wiki/game_theory"
        },
        {
            "term": "generative adversarial networks",
            "url": "https://en.wikipedia.org/wiki/generative_adversarial_networks"
        },
        {
            "term": "variational inequality",
            "url": "https://en.wikipedia.org/wiki/variational_inequality"
        },
        {
            "term": "equilibrium",
            "url": "https://en.wikipedia.org/wiki/equilibrium"
        },
        {
            "term": "NIPS",
            "url": "https://en.wikipedia.org/wiki/NIPS"
        },
        {
            "term": "saddle point",
            "url": "https://en.wikipedia.org/wiki/saddle_point"
        },
        {
            "term": "optimism",
            "url": "https://en.wikipedia.org/wiki/optimism"
        }
    ],
    "abbreviations": {
        "GANs": "generative adversarial networks",
        "OGD": "optimistic gradient descent",
        "GD": "gradient descent",
        "SP": "Suppose that",
        "VI": "variational inequality",
        "MD": "mirror descent",
        "MW": "multiplicative weights",
        "OMD": "optimistic mirror descent",
        "GMMs": "Gaussian mixture models"
    },
    "highlights": [
        "The surge of recent breakthroughs in deep learning has sparked significant interest in solving optimization problems that are universally considered hard",
        "The extra-gradient technique is often referred to as optimistic mirror descent (OMD) [Rakhlin & Sridharan, 2013] and its effectiveness in generative adversarial networks training was recently examined by <a class=\"ref-link\" id=\"cDaskalakis_et+al_2018_a\" href=\"#rDaskalakis_et+al_2018_a\">Daskalakis et al [2018</a>] and Yadav et al [2018]",
        "We show that optimistic mirror descent converges with probability 1 even in stochastic saddle-point problems that are strictly coherent",
        "For the experimental validation of our theoretical results, we began by evaluating the extra-gradient add-on in a highly multi-modal mixture of 16 Gaussians arranged in a 4 \u00d7 4 grid as in <a class=\"ref-link\" id=\"cMetz_et+al_2017_a\" href=\"#rMetz_et+al_2017_a\">Metz et al [2017</a>]",
        "We present in Fig. 4 an ensemble of samples generated at the end of the training period",
        "The dichotomy between strict and null coherence provides a justification of why this is so: optimism eliminates cycles and, in so doing, stabilizes the method. We find this property appealing"
    ],
    "key_statements": [
        "The surge of recent breakthroughs in deep learning has sparked significant interest in solving optimization problems that are universally considered hard",
        "The need for an effective theory has two different sides: first, a deeper understanding would help demystify the reasons behind the success and/or failures of different training algorithms; second, theoretical advances can inspire effective algorithmic tweaks leading to concrete performance gains",
        "We focus on a class of non-monotone problems whose solutions are related to those of a naturally associated variational inequality, a property which we call coherence",
        "We show that if a problem is strictly coherent, mirror descent converges almost surely, even in stochastic problems (Theorem 3.1)",
        "The extra-gradient technique is often referred to as optimistic mirror descent (OMD) [Rakhlin & Sridharan, 2013] and its effectiveness in generative adversarial networks training was recently examined by <a class=\"ref-link\" id=\"cDaskalakis_et+al_2018_a\" href=\"#rDaskalakis_et+al_2018_a\">Daskalakis et al [2018</a>] and Yadav et al [2018]",
        "We show that optimistic mirror descent converges with probability 1 even in stochastic saddle-point problems that are strictly coherent",
        "May fail to form a neighborhood basis of p, so the convergence of Xn to p does not necessarily imply that D(p, Xn) \u2192 0; we provide an example of this behavior in Appendix B",
        "Theorem 4.1 includes as a special case the analysis of <a class=\"ref-link\" id=\"cFacchinei_2003_a\" href=\"#rFacchinei_2003_a\">Facchinei & Pang [2003</a>, Theorem 12.1.11] for optimistic gradient descent and the more recent results of <a class=\"ref-link\" id=\"cNoor_et+al_2011_a\" href=\"#rNoor_et+al_2011_a\">Noor et al [2011</a>] for pseudo-monotone problems",
        "Theorem 4.1 shows that the extra-gradient step plays a crucial role in stabilizing (MD): not only does (OMD) converge in problems where (MD) provably fails, but this convergence is, monotonic",
        "The maximum allowable step-size is controlled by the strong convexity modulus of h, suggesting that the choice of distance-generating function can be fine-tuned further to allow for more aggressive step-size policies \u2013 a key benefit of mirror descent methods.\n5 Experimental results",
        "For the experimental validation of our theoretical results, we began by evaluating the extra-gradient add-on in a highly multi-modal mixture of 16 Gaussians arranged in a 4 \u00d7 4 grid as in <a class=\"ref-link\" id=\"cMetz_et+al_2017_a\" href=\"#rMetz_et+al_2017_a\">Metz et al [2017</a>]",
        "We present in Fig. 4 an ensemble of samples generated at the end of the training period",
        "The dichotomy between strict and null coherence provides a justification of why this is so: optimism eliminates cycles and, in so doing, stabilizes the method. We find this property appealing"
    ],
    "summary": [
        "The surge of recent breakthroughs in deep learning has sparked significant interest in solving optimization problems that are universally considered hard.",
        "The extra-gradient technique is often referred to as optimistic mirror descent (OMD) [Rakhlin & Sridharan, 2013] and its effectiveness in GAN training was recently examined by <a class=\"ref-link\" id=\"cDaskalakis_et+al_2018_a\" href=\"#rDaskalakis_et+al_2018_a\"><a class=\"ref-link\" id=\"cDaskalakis_et+al_2018_a\" href=\"#rDaskalakis_et+al_2018_a\">Daskalakis et al [2018</a></a>] and Yadav et al [2018].",
        "The reason for this is that convexity guarantees \u2013 via Jensen\u2019s inequality and gradient monotonicity \u2013 that a regret-based analysis of (MD) can lead to explicit rates for the convergence of Xn to the solution set of (SP)",
        "When the problem is not convex-concave, the standard proof techniques for establishing convergence of the method\u2019s ergodic average no longer apply; instead, we need to examine the convergence properties of the generating sequence Xn of (MD)",
        "Since bilinear models include all finite two-player, zero-sum games, Corollary 3.3 encapsulates the non-convergence results of <a class=\"ref-link\" id=\"cDaskalakis_et+al_2018_a\" href=\"#rDaskalakis_et+al_2018_a\"><a class=\"ref-link\" id=\"cDaskalakis_et+al_2018_a\" href=\"#rDaskalakis_et+al_2018_a\">Daskalakis et al [2018</a></a>] and <a class=\"ref-link\" id=\"cBailey_2018_a\" href=\"#rBailey_2018_a\">Bailey & Piliouras [2018</a>] for gradient descent and FTRL respectively.",
        "In his original analysis, <a class=\"ref-link\" id=\"cNemirovski_2004_a\" href=\"#rNemirovski_2004_a\">Nemirovski [2004</a>] considered the ergodic average (3.7) of the algorithm\u2019s iterates and established an O(1/n) convergence rate in monotone problems.",
        "Theorem 4.1 includes as a special case the analysis of <a class=\"ref-link\" id=\"cFacchinei_2003_a\" href=\"#rFacchinei_2003_a\">Facchinei & Pang [2003</a>, Theorem 12.1.11] for optimistic gradient descent and the more recent results of <a class=\"ref-link\" id=\"cNoor_et+al_2011_a\" href=\"#rNoor_et+al_2011_a\">Noor et al [2011</a>] for pseudo-monotone problems.",
        "Theorem 4.1 shows that the extra-gradient step plays a crucial role in stabilizing (MD): not only does (OMD) converge in problems where (MD) provably fails, but this convergence is, monotonic.",
        "Suppose that (SP) is strictly coherent and (OMD) is run with a gradient oracle satisfying (3.6) and a variable step-size sequence \u03b3n such that",
        "The maximum allowable step-size is controlled by the strong convexity modulus of h, suggesting that the choice of distance-generating function can be fine-tuned further to allow for more aggressive step-size policies \u2013 a key benefit of mirror descent methods.",
        "Figure 2: Different algorithmic benchmarks (RMSprop and Adam): adding an extra-gradient step allows the training method to accurately learn the target data distribution and eliminates cycling and oscillatory instabilities.",
        "Our results suggest that the implementation of an optimistic, extra-gradient step is a flexible add-on that can be attached to a wide variety of GAN training methods (RMSProp, Adam, SGA, etc.), and provides noticeable gains in performance and stability."
    ],
    "headline": "We propose a new class of universal non-equilibrium solution concepts arising from an important theorem in the topology of dynamical systems that was unavailable to Nash",
    "reference_links": [
        {
            "id": "Alvarez_et+al_2004_a",
            "entry": "Felipe Alvarez, J\u00e9r\u00f4me Bolte, and Olivier Brahic. Hessian Riemannian gradient flows in convex programming. SIAM Journal on Control and Optimization, 43(2):477\u2013501, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Alvarez%2C%20Felipe%20Bolte%2C%20J%C3%A9r%C3%B4me%20Brahic%2C%20Olivier%20Hessian%20Riemannian%20gradient%20flows%20in%20convex%20programming%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Alvarez%2C%20Felipe%20Bolte%2C%20J%C3%A9r%C3%B4me%20Brahic%2C%20Olivier%20Hessian%20Riemannian%20gradient%20flows%20in%20convex%20programming%202004"
        },
        {
            "id": "Mart_2017_a",
            "entry": "Mart\u00edn Arjovsky, Soumith Chintala, and L\u00e9on Bottou. Wasserstein generative adversarial networks. In Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017, pp. 214\u2013223, 2017. URL http://proceedings.mlr.press/v70/arjovsky17a.html.",
            "url": "http://proceedings.mlr.press/v70/arjovsky17a.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mart%C3%ADn%20Arjovsky%2C%20Soumith%20Chintala%20Bottou%2C%20L%C3%A9on%20Wasserstein%20generative%20adversarial%20networks%202017-08-06"
        },
        {
            "id": "Arora_et+al_2012_a",
            "entry": "Sanjeev Arora, Elad Hazan, and Satyen Kale. The multiplicative weights update method: A meta-algorithm and applications. Theory of Computing, 8(1):121\u2013164, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arora%2C%20Sanjeev%20Hazan%2C%20Elad%20Kale%2C%20Satyen%20The%20multiplicative%20weights%20update%20method%3A%20A%20meta-algorithm%20and%20applications%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arora%2C%20Sanjeev%20Hazan%2C%20Elad%20Kale%2C%20Satyen%20The%20multiplicative%20weights%20update%20method%3A%20A%20meta-algorithm%20and%20applications%202012"
        },
        {
            "id": "Peter_1995_a",
            "entry": "Peter Auer, Nicol\u00f2 Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. Gambling in a rigged casino: The adversarial multi-armed bandit problem. In Proceedings of the 36th Annual Symposium on Foundations of Computer Science, 1995.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Peter%20Auer%2C%20Nicol%C3%B2%20Cesa-Bianchi%2C%20Yoav%20Freund%20Schapire%2C%20Robert%20E.%20Gambling%20in%20a%20rigged%20casino%3A%20The%20adversarial%20multi-armed%20bandit%20problem%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Peter%20Auer%2C%20Nicol%C3%B2%20Cesa-Bianchi%2C%20Yoav%20Freund%20Schapire%2C%20Robert%20E.%20Gambling%20in%20a%20rigged%20casino%3A%20The%20adversarial%20multi-armed%20bandit%20problem%201995"
        },
        {
            "id": "Bailey_2018_a",
            "entry": "James P Bailey and Georgios Piliouras. Multiplicative weights update in zero-sum games. In Proceedings of the 2018 ACM Conference on Economics and Computation, pp. 321\u2013338. ACM, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bailey%2C%20James%20P.%20Piliouras%2C%20Georgios%20Multiplicative%20weights%20update%20in%20zero-sum%20games%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bailey%2C%20James%20P.%20Piliouras%2C%20Georgios%20Multiplicative%20weights%20update%20in%20zero-sum%20games%202018"
        },
        {
            "id": "Bailey_2019_a",
            "entry": "James P Bailey and Georgios Piliouras. Multi-agent learning in network zero-sum games is a Hamiltonian system. In Int. Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2019. 9",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bailey%2C%20James%20P.%20Piliouras%2C%20Georgios%20Multi-agent%20learning%20in%20network%20zero-sum%20games%20is%20a%20Hamiltonian%20system%202019",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bailey%2C%20James%20P.%20Piliouras%2C%20Georgios%20Multi-agent%20learning%20in%20network%20zero-sum%20games%20is%20a%20Hamiltonian%20system%202019"
        },
        {
            "id": "Balduzzi_et+al_2018_a",
            "entry": "David Balduzzi, S\u00e9bastien Racani\u00e8re, James Martens, Jakob N. Foerster, Karl Tuyls, and Thore Graepel. The mechanics of n-player differentiable games. In ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Balduzzi%2C%20David%20Racani%C3%A8re%2C%20S%C3%A9bastien%20Martens%2C%20James%20Foerster%2C%20Jakob%20N.%20and%20Thore%20Graepel.%20The%20mechanics%20of%20n-player%20differentiable%20games%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Balduzzi%2C%20David%20Racani%C3%A8re%2C%20S%C3%A9bastien%20Martens%2C%20James%20Foerster%2C%20Jakob%20N.%20and%20Thore%20Graepel.%20The%20mechanics%20of%20n-player%20differentiable%20games%202018"
        },
        {
            "id": "Bauschke_2017_a",
            "entry": "Heinz H. Bauschke and Patrick L. Combettes. Convex Analysis and Monotone Operator Theory in Hilbert Spaces. Springer, New York, NY, USA, 2 edition, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bauschke%2C%20Heinz%20H.%20L%2C%20Patrick%20Combettes.%20Convex%20Analysis%20and%20Monotone%20Operator%20Theory%20in%20Hilbert%20Spaces%202017"
        },
        {
            "id": "Bhojanapalli_et+al_2016_a",
            "entry": "Srinadh Bhojanapalli, Behnam Neyshabur, and Nati Srebro. Global optimality of local search for low rank matrix recovery. In Advances in Neural Information Processing Systems, pp. 3873\u20133881, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bhojanapalli%2C%20Srinadh%20Neyshabur%2C%20Behnam%20Srebro%2C%20Nati%20Global%20optimality%20of%20local%20search%20for%20low%20rank%20matrix%20recovery%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bhojanapalli%2C%20Srinadh%20Neyshabur%2C%20Behnam%20Srebro%2C%20Nati%20Global%20optimality%20of%20local%20search%20for%20low%20rank%20matrix%20recovery%202016"
        },
        {
            "id": "Bottou_1998_a",
            "entry": "L\u00e9on Bottou. Online learning and stochastic approximations. On-line learning in neural networks, 17(9):142, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bottou%2C%20L%C3%A9on%20Online%20learning%20and%20stochastic%20approximations.%20On-line%20learning%20in%20neural%201998",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bottou%2C%20L%C3%A9on%20Online%20learning%20and%20stochastic%20approximations.%20On-line%20learning%20in%20neural%201998"
        },
        {
            "id": "Bravo_et+al_2018_a",
            "entry": "Mario Bravo, David S. Leslie, and Panayotis Mertikopoulos. Bandit learning in concave N-person games. In NIPS \u201918: Proceedings of the 32nd International Conference on Neural Information Processing Systems, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bravo%2C%20Mario%20Leslie%2C%20David%20S.%20Mertikopoulos%2C%20Panayotis%20Bandit%20learning%20in%20concave%20N-person%20games.%20In%20NIPS%E2%80%99%2018%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bravo%2C%20Mario%20Leslie%2C%20David%20S.%20Mertikopoulos%2C%20Panayotis%20Bandit%20learning%20in%20concave%20N-person%20games.%20In%20NIPS%E2%80%99%2018%202018"
        },
        {
            "id": "Bregman_1967_a",
            "entry": "Lev M. Bregman. The relaxation method of finding the common point of convex sets and its application to the solution of problems in convex programming. USSR Computational Mathematics and Mathematical Physics, 7(3):200\u2013217, 1967.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bregman%2C%20Lev%20M.%20The%20relaxation%20method%20of%20finding%20the%20common%20point%20of%20convex%20sets%20and%20its%20application%20to%20the%20solution%20of%20problems%20in%20convex%20programming%201967",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bregman%2C%20Lev%20M.%20The%20relaxation%20method%20of%20finding%20the%20common%20point%20of%20convex%20sets%20and%20its%20application%20to%20the%20solution%20of%20problems%20in%20convex%20programming%201967"
        },
        {
            "id": "Bubeck_2015_a",
            "entry": "S\u00e9bastien Bubeck. Convex optimization: Algorithms and complexity. Foundations and Trends in Machine Learning, 8(3-4):231\u2013358, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bubeck%2C%20S%C3%A9bastien%20Convex%20optimization%3A%20Algorithms%20and%20complexity%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bubeck%2C%20S%C3%A9bastien%20Convex%20optimization%3A%20Algorithms%20and%20complexity%202015"
        },
        {
            "id": "Chen_1993_a",
            "entry": "Gong Chen and Marc Teboulle. Convergence analysis of a proximal-like minimization algorithm using Bregman functions. SIAM Journal on Optimization, 3(3):538\u2013543, August 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Gong%20Teboulle%2C%20Marc%20Convergence%20analysis%20of%20a%20proximal-like%20minimization%20algorithm%20using%20Bregman%20functions%201993-08",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Gong%20Teboulle%2C%20Marc%20Convergence%20analysis%20of%20a%20proximal-like%20minimization%20algorithm%20using%20Bregman%20functions%201993-08"
        },
        {
            "id": "Cohen_et+al_2017_a",
            "entry": "Johanne Cohen, Am\u00e9lie H\u00e9liou, and Panayotis Mertikopoulos. Learning with bandit feedback in potential games. In NIPS \u201917: Proceedings of the 31st International Conference on Neural Information Processing Systems, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cohen%2C%20Johanne%20H%C3%A9liou%2C%20Am%C3%A9lie%20Mertikopoulos%2C%20Panayotis%20Learning%20with%20bandit%20feedback%20in%20potential%20games.%20In%20NIPS%E2%80%99%2017%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cohen%2C%20Johanne%20H%C3%A9liou%2C%20Am%C3%A9lie%20Mertikopoulos%2C%20Panayotis%20Learning%20with%20bandit%20feedback%20in%20potential%20games.%20In%20NIPS%E2%80%99%2017%202017"
        },
        {
            "id": "Daskalakis_et+al_2018_a",
            "entry": "Constantinos Daskalakis, Andrew Ilyas, Vasilis Syrgkanis, and Haoyang Zeng. Training GANs with optimism. In ICLR \u201918: Proceedings of the 2018 International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Daskalakis%2C%20Constantinos%20Ilyas%2C%20Andrew%20Syrgkanis%2C%20Vasilis%20Zeng%2C%20Haoyang%20Training%20GANs%20with%20optimism.%20In%20ICLR%E2%80%99%2018%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Daskalakis%2C%20Constantinos%20Ilyas%2C%20Andrew%20Syrgkanis%2C%20Vasilis%20Zeng%2C%20Haoyang%20Training%20GANs%20with%20optimism.%20In%20ICLR%E2%80%99%2018%202018"
        },
        {
            "id": "Facchinei_2003_a",
            "entry": "Francisco Facchinei and Jong-Shi Pang. Finite-Dimensional Variational Inequalities and Complementarity Problems. Springer Series in Operations Research. Springer, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Facchinei%2C%20Francisco%20Pang%2C%20Jong-Shi%20Finite-Dimensional%20Variational%20Inequalities%20and%20Complementarity%20Problems.%20Springer%20Series%20in%20Operations%20Research%202003"
        },
        {
            "id": "Freund_1999_a",
            "entry": "Yoav Freund and Robert E. Schapire. Adaptive game playing using multiplicative weights. Games and Economic Behavior, 29:79\u2013103, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Freund%2C%20Yoav%20Schapire%2C%20Robert%20E.%20Adaptive%20game%20playing%20using%20multiplicative%20weights%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Freund%2C%20Yoav%20Schapire%2C%20Robert%20E.%20Adaptive%20game%20playing%20using%20multiplicative%20weights%201999"
        },
        {
            "id": "Fudenberg_1998_a",
            "entry": "Drew Fudenberg and David K. Levine. The Theory of Learning in Games, volume 2 of Economic learning and social evolution. MIT Press, Cambridge, MA, 1998.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fudenberg%2C%20Drew%20Levine%2C%20David%20K.%20The%20Theory%20of%20Learning%20in%20Games%2C%20volume%202%20of%20Economic%20learning%20and%20social%20evolution%201998"
        },
        {
            "id": "Ge_et+al_2015_a",
            "entry": "Rong Ge, Furong Huang, Chi Jin, and Yang Yuan. Escaping from saddle points online stochastic gradient for tensor decomposition. In Conference on Learning Theory, pp. 797\u2013842, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ge%2C%20Rong%20Huang%2C%20Furong%20Jin%2C%20Chi%20Yuan%2C%20Yang%20Escaping%20from%20saddle%20points%20online%20stochastic%20gradient%20for%20tensor%20decomposition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ge%2C%20Rong%20Huang%2C%20Furong%20Jin%2C%20Chi%20Yuan%2C%20Yang%20Escaping%20from%20saddle%20points%20online%20stochastic%20gradient%20for%20tensor%20decomposition%202015"
        },
        {
            "id": "Ge_et+al_2017_a",
            "entry": "Rong Ge, Chi Jin, and Yi Zheng. No spurious local minima in nonconvex low rank problems: A unified geometric analysis. In ICML, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ge%2C%20Rong%20Jin%2C%20Chi%20Zheng%2C%20Yi%20No%20spurious%20local%20minima%20in%20nonconvex%20low%20rank%20problems%3A%20A%20unified%20geometric%20analysis%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ge%2C%20Rong%20Jin%2C%20Chi%20Zheng%2C%20Yi%20No%20spurious%20local%20minima%20in%20nonconvex%20low%20rank%20problems%3A%20A%20unified%20geometric%20analysis%202017"
        },
        {
            "id": "Gidel_et+al_2018_a",
            "entry": "Gauthier Gidel, Hugo Berard, Pascal Vincent, and Simon Lacoste-Julien. A variational inequality perspective on generative adversarial networks. https://arxiv.org/pdf/1802.10551.pdf, February 2018.",
            "url": "https://arxiv.org/pdf/1802.10551.pdf",
            "arxiv_url": "https://arxiv.org/pdf/1802.10551"
        },
        {
            "id": "Goodfellow_et+al_2014_a",
            "entry": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems, pp. 2672\u20132680, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "Gulrajani_et+al_2017_a",
            "entry": "Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron Courville. Improved training of wasserstein gans. In Advances in Neural Information Processing Systems 30 (NIPS 2017), pp. 5769\u20135779. Curran Associates, Inc., December 2017. URL https://papers.nips.cc/paper/7159-improved-training-of-wasserstein-gans.arxiv:1704.00028.",
            "url": "https://papers.nips.cc/paper/7159-improved-training-of-wasserstein-gans.arxiv:1704.00028",
            "arxiv_url": "https://arxiv.org/pdf/1704.00028"
        },
        {
            "id": "Hall_1980_a",
            "entry": "P. Hall and C. C. Heyde. Martingale Limit Theory and Its Application. Probability and Mathematical Statistics. Academic Press, New York, 1980.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hall%2C%20P.%20Heyde%2C%20C.C.%20Martingale%20Limit%20Theory%20and%20Its%20Application.%20Probability%20and%20Mathematical%20Statistics%201980"
        },
        {
            "id": "Juditsky_et+al_2011_a",
            "entry": "Anatoli Juditsky, Arkadi Semen Nemirovski, and Claire Tauvel. Solving variational inequalities with stochastic mirror-prox algorithm. Stochastic Systems, 1(1):17\u201358, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Juditsky%2C%20Anatoli%20Nemirovski%2C%20Arkadi%20Semen%20Tauvel%2C%20Claire%20Solving%20variational%20inequalities%20with%20stochastic%20mirror-prox%20algorithm%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Juditsky%2C%20Anatoli%20Nemirovski%2C%20Arkadi%20Semen%20Tauvel%2C%20Claire%20Solving%20variational%20inequalities%20with%20stochastic%20mirror-prox%20algorithm%202011"
        },
        {
            "id": "Kingma_2014_a",
            "entry": "Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. 12 2014. G. M. Korpelevich. The extragradient method for finding saddle points and other problems. \u00c8konom. i Mat.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Diederik%20Kingma%20and%20Jimmy%20Ba%20Adam%20A%20method%20for%20stochastic%20optimization%2012%202014%20G%20M%20Korpelevich%20The%20extragradient%20method%20for%20finding%20saddle%20points%20and%20other%20problems%20%C3%88konom%20i%20Mat"
        },
        {
            "id": "Metody_1976_a",
            "entry": "Metody, 12:747\u2013756, 1976. Jason D Lee, Max Simchowitz, Michael I Jordan, and Benjamin Recht. Gradient descent only converges to minimizers. In Conference on Learning Theory, pp. 1246\u20131257, 2016. Jason D Lee, Ioannis Panageas, Georgios Piliouras, Max Simchowitz, Michael I Jordan, and Benjamin Recht.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Metody%20Gradient%20descent%20only%20converges%20to%20minimizers%201976",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Metody%20Gradient%20descent%20only%20converges%20to%20minimizers%201976"
        },
        {
            "id": "First-order_2018_a",
            "entry": "First-order methods almost always avoid strict saddle points. Mathematical Programming, 2019. Panayotis Mertikopoulos and Mathias Staudigl. On the convergence of gradient-like flows with noisy gradient input. SIAM Journal on Optimization, 28(1):163\u2013197, January 2018. Panayotis Mertikopoulos, Christos H. Papadimitriou, and Georgios Piliouras. Cycles in adversarial regularized learning. In SODA \u201918: Proceedings of the 29th annual ACM-SIAM Symposium on Discrete Algorithms, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Firstorder%20methods%20almost%20always%20avoid%20strict%20saddle%20points%20Mathematical%20Programming%202019%20Panayotis%20Mertikopoulos%20and%20Mathias%20Staudigl%20On%20the%20convergence%20of%20gradientlike%20flows%20with%20noisy%20gradient%20input%20SIAM%20Journal%20on%20Optimization%20281163197%20January%202018%20Panayotis%20Mertikopoulos%20Christos%20H%20Papadimitriou%20and%20Georgios%20Piliouras%20Cycles%20in%20adversarial%20regularized%20learning%20In%20SODA%2018%20Proceedings%20of%20the%2029th%20annual%20ACMSIAM%20Symposium%20on%20Discrete%20Algorithms%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Firstorder%20methods%20almost%20always%20avoid%20strict%20saddle%20points%20Mathematical%20Programming%202019%20Panayotis%20Mertikopoulos%20and%20Mathias%20Staudigl%20On%20the%20convergence%20of%20gradientlike%20flows%20with%20noisy%20gradient%20input%20SIAM%20Journal%20on%20Optimization%20281163197%20January%202018%20Panayotis%20Mertikopoulos%20Christos%20H%20Papadimitriou%20and%20Georgios%20Piliouras%20Cycles%20in%20adversarial%20regularized%20learning%20In%20SODA%2018%20Proceedings%20of%20the%2029th%20annual%20ACMSIAM%20Symposium%20on%20Discrete%20Algorithms%202018"
        },
        {
            "id": "Mescheder_et+al_2018_a",
            "entry": "Lars Mescheder, Andreas Geiger, and Sebastian Nowozin. Which training methods for GANs do actually converge? In ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mescheder%2C%20Lars%20Geiger%2C%20Andreas%20Nowozin%2C%20Sebastian%20Which%20training%20methods%20for%20GANs%20do%20actually%20converge%3F%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mescheder%2C%20Lars%20Geiger%2C%20Andreas%20Nowozin%2C%20Sebastian%20Which%20training%20methods%20for%20GANs%20do%20actually%20converge%3F%202018"
        },
        {
            "id": "Metz_et+al_2017_a",
            "entry": "Luke Metz, Ben Poole, David Pfau, and Jascha Sohl-Dickstein. Unrolled generative adversarial networks. ICLR Proceedings, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Metz%2C%20Luke%20Poole%2C%20Ben%20Pfau%2C%20David%20Sohl-Dickstein%2C%20Jascha%20Unrolled%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Metz%2C%20Luke%20Poole%2C%20Ben%20Pfau%2C%20David%20Sohl-Dickstein%2C%20Jascha%20Unrolled%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "Nemirovski_2004_a",
            "entry": "Arkadi Semen Nemirovski. Prox-method with rate of convergence O(1/t) for variational inequalities with Lipschitz continuous monotone operators and smooth convex-concave saddle point problems. SIAM Journal on Optimization, 15(1):229\u2013251, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nemirovski%2C%20Arkadi%20Semen%20Prox-method%20with%20rate%20of%20convergence%20O%281/t%29%20for%20variational%20inequalities%20with%20Lipschitz%20continuous%20monotone%20operators%20and%20smooth%20convex-concave%20saddle%20point%20problems%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nemirovski%2C%20Arkadi%20Semen%20Prox-method%20with%20rate%20of%20convergence%20O%281/t%29%20for%20variational%20inequalities%20with%20Lipschitz%20continuous%20monotone%20operators%20and%20smooth%20convex-concave%20saddle%20point%20problems%202004"
        },
        {
            "id": "Nemirovski_1983_a",
            "entry": "Arkadi Semen Nemirovski and David Berkovich Yudin. Problem Complexity and Method Efficiency in Optimization. Wiley, New York, NY, 1983.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nemirovski%2C%20Arkadi%20Semen%20Yudin%2C%20David%20Berkovich%20Problem%20Complexity%20and%20Method%20Efficiency%20in%20Optimization%201983"
        },
        {
            "id": "Nemirovski_et+al_2009_a",
            "entry": "Arkadi Semen Nemirovski, Anatoli Juditsky, Guanghui Lan, and Alexander Shapiro. Robust stochastic approximation approach to stochastic programming. SIAM Journal on Optimization, 19(4):1574\u20131609, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nemirovski%2C%20Arkadi%20Semen%20Juditsky%2C%20Anatoli%20Lan%2C%20Guanghui%20Shapiro%2C%20Alexander%20Robust%20stochastic%20approximation%20approach%20to%20stochastic%20programming%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nemirovski%2C%20Arkadi%20Semen%20Juditsky%2C%20Anatoli%20Lan%2C%20Guanghui%20Shapiro%2C%20Alexander%20Robust%20stochastic%20approximation%20approach%20to%20stochastic%20programming%202009"
        },
        {
            "id": "Nesterov_2007_a",
            "entry": "Yurii Nesterov. Dual extrapolation and its applications to solving variational inequalities and related problems. Mathematical Programming, 109(2):319\u2013344, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nesterov%2C%20Yurii%20Dual%20extrapolation%20and%20its%20applications%20to%20solving%20variational%20inequalities%20and%20related%20problems%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nesterov%2C%20Yurii%20Dual%20extrapolation%20and%20its%20applications%20to%20solving%20variational%20inequalities%20and%20related%20problems%202007"
        },
        {
            "id": "Nesterov_2009_a",
            "entry": "Yurii Nesterov. Primal-dual subgradient methods for convex problems. Mathematical Programming, 120(1): 221\u2013259, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nesterov%2C%20Yurii%20Primal-dual%20subgradient%20methods%20for%20convex%20problems%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nesterov%2C%20Yurii%20Primal-dual%20subgradient%20methods%20for%20convex%20problems%202009"
        },
        {
            "id": "Noor_et+al_2011_a",
            "entry": "Muhammad Aslam Noor, Eisa Al-Said, Khalida Inayat Noor, and Yonghong Yao. Extragradient methods for solving nonconvex variational inequalities. Journal of Computational and Applied Mathematics, 235(9): 3104\u20133108, March 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Noor%2C%20Muhammad%20Aslam%20Al-Said%2C%20Eisa%20Noor%2C%20Khalida%20Inayat%20Yao%2C%20Yonghong%20Extragradient%20methods%20for%20solving%20nonconvex%20variational%20inequalities%202011-03",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Noor%2C%20Muhammad%20Aslam%20Al-Said%2C%20Eisa%20Noor%2C%20Khalida%20Inayat%20Yao%2C%20Yonghong%20Extragradient%20methods%20for%20solving%20nonconvex%20variational%20inequalities%202011-03"
        },
        {
            "id": "Palaiopanos_et+al_2017_a",
            "entry": "Gerasimos Palaiopanos, Ioannis Panageas, and Georgios Piliouras. Multiplicative weights update with constant step-size in congestion games: Convergence, limit cycles and chaos. In NIPS \u201917: Proceedings of the 31st International Conference on Neural Information Processing Systems, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Palaiopanos%2C%20Gerasimos%20Panageas%2C%20Ioannis%20Piliouras%2C%20Georgios%20Multiplicative%20weights%20update%20with%20constant%20step-size%20in%20congestion%20games%3A%20Convergence%2C%20limit%20cycles%20and%20chaos.%20In%20NIPS%E2%80%99%2017%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Palaiopanos%2C%20Gerasimos%20Panageas%2C%20Ioannis%20Piliouras%2C%20Georgios%20Multiplicative%20weights%20update%20with%20constant%20step-size%20in%20congestion%20games%3A%20Convergence%2C%20limit%20cycles%20and%20chaos.%20In%20NIPS%E2%80%99%2017%202017"
        },
        {
            "id": "Panageas_2017_a",
            "entry": "Ioannis Panageas and Georgios Piliouras. Gradient descent only converges to minimizers: Non-isolated critical points and invariant regions. In Innovations of Theoretical Computer Science (ITCS), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Panageas%2C%20Ioannis%20Piliouras%2C%20Georgios%20Gradient%20descent%20only%20converges%20to%20minimizers%3A%20Non-isolated%20critical%20points%20and%20invariant%20regions%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Panageas%2C%20Ioannis%20Piliouras%2C%20Georgios%20Gradient%20descent%20only%20converges%20to%20minimizers%3A%20Non-isolated%20critical%20points%20and%20invariant%20regions%202017"
        },
        {
            "id": "Christos_2018_b",
            "entry": "Christos Papadimitriou and Georgios Piliouras. From nash equilibria to chain recurrent sets: An algorithmic solution concept for game theory. Entropy, 20(10), 2018. ISSN 1099-4300. doi: 10.3390/e20100782. URL http://www.mdpi.com/1099-4300/20/10/782.",
            "crossref": "https://dx.doi.org/10.3390/e20100782",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.3390/e20100782"
        },
        {
            "id": "Piliouras_2014_a",
            "entry": "Georgios Piliouras and Jeff S Shamma. Optimization despite chaos: Convex relaxations to complex limit sets via poincar\u00e9 recurrence. In Proceedings of the twenty-fifth annual ACM-SIAM symposium on Discrete algorithms, pp. 861\u2013873. SIAM, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Piliouras%2C%20Georgios%20Shamma%2C%20Jeff%20S.%20Optimization%20despite%20chaos%3A%20Convex%20relaxations%20to%20complex%20limit%20sets%20via%20poincar%C3%A9%20recurrence%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Piliouras%2C%20Georgios%20Shamma%2C%20Jeff%20S.%20Optimization%20despite%20chaos%3A%20Convex%20relaxations%20to%20complex%20limit%20sets%20via%20poincar%C3%A9%20recurrence%202014"
        },
        {
            "id": "Piliouras_et+al_2014_b",
            "entry": "Georgios Piliouras, Carlos Nieto-Granda, Henrik I. Christensen, and Jeff S. Shamma. Persistent patterns: Multi-agent learning beyond equilibrium and utility. In AAMAS, pp. 181\u2013188, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Piliouras%2C%20Georgios%20Nieto-Granda%2C%20Carlos%20Christensen%2C%20Henrik%20I.%20Shamma%2C%20Jeff%20S.%20Persistent%20patterns%3A%20Multi-agent%20learning%20beyond%20equilibrium%20and%20utility%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Piliouras%2C%20Georgios%20Nieto-Granda%2C%20Carlos%20Christensen%2C%20Henrik%20I.%20Shamma%2C%20Jeff%20S.%20Persistent%20patterns%3A%20Multi-agent%20learning%20beyond%20equilibrium%20and%20utility%202014"
        },
        {
            "id": "Radford_et+al_2016_a",
            "entry": "A. Radford, L. Metz, and S. Chintala. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. In International Conference on Learning Representations (ICLR), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Radford%2C%20A.%20Metz%2C%20L.%20Chintala%2C%20S.%20Unsupervised%20Representation%20Learning%20with%20Deep%20Convolutional%20Generative%20Adversarial%20Networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Radford%2C%20A.%20Metz%2C%20L.%20Chintala%2C%20S.%20Unsupervised%20Representation%20Learning%20with%20Deep%20Convolutional%20Generative%20Adversarial%20Networks%202016"
        },
        {
            "id": "Rakhlin_et+al_2013_a",
            "entry": "Alexander Rakhlin and Karthik Sridharan. Optimization, learning, and games with predictable sequences. In NIPS \u201913: Proceedings of the 26th International Conference on Neural Information Processing Systems, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rakhlin%2C%20Alexander%20Optimization%2C%20Karthik%20Sridharan%20learning%20and%20games%20with%20predictable%20sequences.%20In%20NIPS%E2%80%99%2013%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rakhlin%2C%20Alexander%20Optimization%2C%20Karthik%20Sridharan%20learning%20and%20games%20with%20predictable%20sequences.%20In%20NIPS%E2%80%99%2013%202013"
        },
        {
            "id": "for_2017_a",
            "entry": "for all x, x \u2208 X [Bauschke & Combettes, 2017]. Thus, setting x \u2190 x\u2217 in (A.3) and invoking (SVI), we get g(x), x \u2212 x\u2217 \u2265 g(x\u2217), x \u2212 x\u2217 \u2265 0, (A.4)",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=for%20all%20x%20x%20%20X%20Bauschke%20%20Combettes%202017%20Thus%20setting%20x%20%20x%20in%20A3%20and%20invoking%20SVI%20we%20get%20gx%20x%20%20x%20%20gx%20x%20%20x%20%200%20A4",
            "oa_query": "https://api.scholarcy.com/oa_version?query=for%20all%20x%20x%20%20X%20Bauschke%20%20Combettes%202017%20Thus%20setting%20x%20%20x%20in%20A3%20and%20invoking%20SVI%20we%20get%20gx%20x%20%20x%20%20gx%20x%20%20x%20%200%20A4"
        },
        {
            "id": "In_2009_a",
            "entry": "In this appendix, we provide some auxiliary results and estimates that are used throughout the convergence analysis of Appendix C. Some of the results we present here (or close variants thereof) are not new [see e.g., Nemirovski et al., 2009; Juditsky et al., 2011]. However, the hypotheses used to obtain them vary wildly in the literature, so we provide all the necessary details for completeness.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=In%20this%20appendix%20we%20provide%20some%20auxiliary%20results%20and%20estimates%20that%20are%20used%20throughout%20the%20convergence%20analysis%20of%20Appendix%20C%20Some%20of%20the%20results%20we%20present%20here%20or%20close%20variants%20thereof%20are%20not%20new%20see%20eg%20Nemirovski%20et%20al%202009%20Juditsky%20et%20al%202011%20However%20the%20hypotheses%20used%20to%20obtain%20them%20vary%20wildly%20in%20the%20literature%20so%20we%20provide%20all%20the%20necessary%20details%20for%20completeness",
            "oa_query": "https://api.scholarcy.com/oa_version?query=In%20this%20appendix%20we%20provide%20some%20auxiliary%20results%20and%20estimates%20that%20are%20used%20throughout%20the%20convergence%20analysis%20of%20Appendix%20C%20Some%20of%20the%20results%20we%20present%20here%20or%20close%20variants%20thereof%20are%20not%20new%20see%20eg%20Nemirovski%20et%20al%202009%20Juditsky%20et%20al%202011%20However%20the%20hypotheses%20used%20to%20obtain%20them%20vary%20wildly%20in%20the%20literature%20so%20we%20provide%20all%20the%20necessary%20details%20for%20completeness"
        },
        {
            "id": "By_1970_b",
            "entry": "By standard results in convex analysis [Rockafellar, 1970, Chap. 26], h\u2217 is differentiable on Y and its gradient satisfies the identity \u2207h\u2217(y) = arg max{ y, x \u2212 h(x)}.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=By%20standard%20results%20in%20convex%20analysis%20Rockafellar%201970%20Chap%2026%20h%20is%20differentiable%20on%20Y%20and%20its%20gradient%20satisfies%20the%20identity%20hy%20%20arg%20max%20y%20x%20%20hx",
            "oa_query": "https://api.scholarcy.com/oa_version?query=By%20standard%20results%20in%20convex%20analysis%20Rockafellar%201970%20Chap%2026%20h%20is%20differentiable%20on%20Y%20and%20its%20gradient%20satisfies%20the%20identity%20hy%20%20arg%20max%20y%20x%20%20hx"
        },
        {
            "id": "We_1993_a",
            "entry": "We continue with some basic bounds on the Bregman divergence before and after a prox step. The basic ingredient for these bounds is a generalization of the (Euclidean) law of cosines which is known in the literature as the \u201cthree-point identity\u201d [Chen & Teboulle, 1993]: Lemma B.2. Let h be a distance-generating function on X. Then, for all p \u2208 X and all x, x \u2208",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=We%20continue%20with%20some%20basic%20bounds%20on%20the%20Bregman%20divergence%20before%20and%20after%20a%20prox%20step%20The%20basic%20ingredient%20for%20these%20bounds%20is%20a%20generalization%20of%20the%20Euclidean%20law%20of%20cosines%20which%20is%20known%20in%20the%20literature%20as%20the%20threepoint%20identity%20Chen%20%20Teboulle%201993%20Lemma%20B2%20Let%20h%20be%20a%20distancegenerating%20function%20on%20X%20Then%20for%20all%20p%20%20X%20and%20all%20x%20x",
            "oa_query": "https://api.scholarcy.com/oa_version?query=We%20continue%20with%20some%20basic%20bounds%20on%20the%20Bregman%20divergence%20before%20and%20after%20a%20prox%20step%20The%20basic%20ingredient%20for%20these%20bounds%20is%20a%20generalization%20of%20the%20Euclidean%20law%20of%20cosines%20which%20is%20known%20in%20the%20literature%20as%20the%20threepoint%20identity%20Chen%20%20Teboulle%201993%20Lemma%20B2%20Let%20h%20be%20a%20distancegenerating%20function%20on%20X%20Then%20for%20all%20p%20%20X%20and%20all%20x%20x"
        },
        {
            "id": "Therefore,_0000_c",
            "entry": "Therefore, by Young\u2019s inequality [Rockafellar, 1970], we get y, x+ \u2212 x",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Therefore%20by%20Youngs%20inequality%20Rockafellar%201970%20we%20get%20y%20x%20%20x",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Therefore%20by%20Youngs%20inequality%20Rockafellar%201970%20we%20get%20y%20x%20%20x"
        },
        {
            "id": "Our_1980_a",
            "entry": "Our first step is to prove Proposition C.2. To do this, we first recall the following law of large numbers for L2 martingales: Theorem (Hall & Heyde, 1980, Theorem 2.18). Let Yn =",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Our%20first%20step%20is%20to%20prove%20Proposition%20C2%20To%20do%20this%20we%20first%20recall%20the%20following%20law%20of%20large%20numbers%20for%20L2%20martingales%20Theorem%20Hall%20%20Heyde%201980%20Theorem%20218%20Let%20Yn",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Our%20first%20step%20is%20to%20prove%20Proposition%20C2%20To%20do%20this%20we%20first%20recall%20the%20following%20law%20of%20large%20numbers%20for%20L2%20martingales%20Theorem%20Hall%20%20Heyde%201980%20Theorem%20218%20Let%20Yn"
        },
        {
            "id": "Therefore,_0000_d",
            "entry": "Therefore, by the law of large numbers for L2 martingales stated above [Hall & Heyde, 1980, Theorem 2.18], we conclude that \u03c4\u2212n1 n k=1 \u03b3k \u03bek+1 converges to with probability",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Therefore%20by%20the%20law%20of%20large%20numbers%20for%20L2%20martingales%20stated%20above%20Hall%20%20Heyde%201980%20Theorem%20218%20we%20conclude%20that%20%CF%84n1%20n%20k1%20%CE%B3k%20%CE%BEk1%20converges%20to%20with%20probability"
        },
        {
            "id": "1",
            "entry": "1. Finally, for the last term of (C.4), let S n+1 = k=1 k=1 so S n is bounded in L1. Hence, by Doob\u2019s submartingale convergence theorem [Hall & Heyde, 1980, Theorem 2.5], we conclude that S n converges to some (almost surely finite) random variable S \u221e with 3\u20444[S \u221e] < \u221e, implying in turn that limn\u2192\u221e S n+1/\u03c4n = 0 (a.s.).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Finally%20for%20the%20last%20term%20of%20%28C.4%29%2C%20let%20S%20n%2B1%20%3D%20k%3D1%20k%3D1%20so%20S%20n%20is%20bounded%20in%20L1.%20Hence%2C%20by%20Doob%E2%80%99s%20submartingale%20convergence%20theorem%201980",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Finally%20for%20the%20last%20term%20of%20%28C.4%29%2C%20let%20S%20n%2B1%20%3D%20k%3D1%20k%3D1%20so%20S%20n%20is%20bounded%20in%20L1.%20Hence%2C%20by%20Doob%E2%80%99s%20submartingale%20convergence%20theorem%201980"
        },
        {
            "id": "Ie_1980_a",
            "entry": "i.e., Rn is uniformly bounded in L1. Thus, by Doob\u2019s convergence theorem for supermartingales [Hall & Heyde, 1980, Theorem 2.5], it follows that Rn converges (a.s.) to some finite random variable R\u221e with 3\u20444[R\u221e] < \u221e. In turn, by inverting the definition of Rn, this shows that Dn converges (a.s.) to some random variable D(x\u2217) with 3\u20444[D(x\u2217)] < \u221e, as claimed.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=ie%20Rn%20is%20uniformly%20bounded%20in%20L1.%20Thus%2C%20by%20Doob%E2%80%99s%20convergence%20theorem%20for%20supermartingales%201980",
            "oa_query": "https://api.scholarcy.com/oa_version?query=ie%20Rn%20is%20uniformly%20bounded%20in%20L1.%20Thus%2C%20by%20Doob%E2%80%99s%20convergence%20theorem%20for%20supermartingales%201980"
        }
    ]
}

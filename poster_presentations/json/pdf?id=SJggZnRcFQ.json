{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "LEARNING PROGRAMMATICALLY STRUCTURED REPRESENTATIONS WITH PERCEPTOR GRADIENTS",
        "author": "Svetlin Penkov 1, Subramanian Ramamoorthy 1, 2 1The University of Edinburgh, 2FiveAI {sv.penkov, s.ramamoorthy}@ed.ac.uk",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=SJggZnRcFQ"
        },
        "abstract": "We present the perceptor gradients algorithm \u2013 a novel approach to learning symbolic representations based on the idea of decomposing an agent\u2019s policy into i) a perceptor network extracting symbols from raw observation data and ii) a task encoding program which maps the input symbols to output actions. We show that the proposed algorithm is able to learn representations that can be directly fed into a Linear-Quadratic Regulator (LQR) or a general purpose A* planner. Our experimental results confirm that the perceptor gradients algorithm is able to efficiently learn transferable symbolic representations as well as generate new observations according to a semantically meaningful specification."
    },
    "keywords": [
        {
            "term": "dynamics",
            "url": "https://en.wikipedia.org/wiki/dynamics"
        },
        {
            "term": "Markov decision process",
            "url": "https://en.wikipedia.org/wiki/Markov_decision_process"
        },
        {
            "term": "physics",
            "url": "https://en.wikipedia.org/wiki/physics"
        },
        {
            "term": "deep reinforcement learning",
            "url": "https://en.wikipedia.org/wiki/deep_reinforcement_learning"
        },
        {
            "term": "graphics",
            "url": "https://en.wikipedia.org/wiki/graphics"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "reinforcement learning",
            "url": "https://en.wikipedia.org/wiki/reinforcement_learning"
        }
    ],
    "abbreviations": {
        "LQR": "Linear-Quadratic Regulator",
        "MDP": "Markov decision process"
    },
    "highlights": [
        "Learning representations that are useful for devising autonomous agent policies to act, from raw data, remains a major challenge",
        "The symbolic representation carries semantic content that can be grounded to objects, relations or, in general, any pattern of interest in the environment. We address this problem by introducing the perceptor gradients algorithm which decomposes a typical policy, mapping from observations to actions, into i) a perceptor network that maps observations to symbolic representations and ii) a user-provided task encoding program which is executed on the perceived symbols in order to generate an action",
        "The cart-pole system is well studied in optimal control theory and it is typically balanced with an Linear-Quadratic Regulator (<a class=\"ref-link\" id=\"cZhou_et+al_1996_a\" href=\"#rZhou_et+al_1996_a\">Zhou et al, 1996</a>)",
        "In this paper we introduced the perceptor gradients algorithm for learning programmatically structured representations",
        "Our approach achieves faster learning rates compared to methods based solely on neural networks and yields transferable task related symbolic representations which carry semantic content",
        "Our results clearly demonstrate that programmatic regularisation is a general technique for structured representation learning"
    ],
    "key_statements": [
        "Learning representations that are useful for devising autonomous agent policies to act, from raw data, remains a major challenge",
        "The symbolic representation carries semantic content that can be grounded to objects, relations or, in general, any pattern of interest in the environment. We address this problem by introducing the perceptor gradients algorithm which decomposes a typical policy, mapping from observations to actions, into i) a perceptor network that maps observations to symbolic representations and ii) a user-provided task encoding program which is executed on the perceived symbols in order to generate an action",
        "The cart-pole system is well studied in optimal control theory and it is typically balanced with an Linear-Quadratic Regulator (<a class=\"ref-link\" id=\"cZhou_et+al_1996_a\" href=\"#rZhou_et+al_1996_a\">Zhou et al, 1996</a>)",
        "In this paper we introduced the perceptor gradients algorithm for learning programmatically structured representations",
        "Our approach achieves faster learning rates compared to methods based solely on neural networks and yields transferable task related symbolic representations which carry semantic content",
        "Our results clearly demonstrate that programmatic regularisation is a general technique for structured representation learning"
    ],
    "summary": [
        "Learning representations that are useful for devising autonomous agent policies to act, from raw data, remains a major challenge.",
        "We explore the specific hypothesis that a programmatic task description provides inductive bias that enables significantly more efficient learning of symbolic representations from raw data.",
        "We address this problem by introducing the perceptor gradients algorithm which decomposes a typical policy, mapping from observations to actions, into i) a perceptor network that maps observations to symbolic representations and ii) a user-provided task encoding program which is executed on the perceived symbols in order to generate an action.",
        "We demonstrate that the proposed algorithm is not only able to efficiently learn transferable symbolic representations, but enables the generation of new observations according to a semantically meaningful specification.",
        "Decomposing the policy into a program and a perceptor enables the description of programmatically structured policies, while being able to learn the required symbolic representation from data.",
        "We first consider the problem of balancing a cart-pole system by learning symbolic representations from the raw image observations.",
        "Task Description We apply the perceptor gradients algorithm to the problem of navigating to a certain pose in the environment by learning symbolic representations from images.",
        "A symbolic representation of the task together with the 2.5D rendering of the environment and the autoencoding perceptor, which we train, are shown in Figure 5.",
        "In this experimental setup the perceptor is able to learn the symbolic representations required by the A* planner from raw image observations.",
        "The results, summarised in the confusion matrices in Figure 7, indicate that the perceptor has learnt to correctly ground the symbolic state description to the observed data.",
        "Stacked Perceptors In the cart-pole experiment the controller balances the system around a fixed state, whereas in the navigation experiment the A* planner takes the agent to a randomly chosen, but known, goal pose.",
        "Learning to recognise both the pose of the agent and the position of the item is an ill posed problem since there is not a fixed frame of reference \u2013 the same sequence of actions can be successfully applied to the same relative configuration of the initial state and the goal, which can appear anywhere in the environment.",
        "5.3.1 LEARNING PERFORMANCE As shown in Figure 10 the agent is quickly able to solve the task with the stacked configuration of perceptors.",
        "In Figure 11 we have shown a set of generated state samples from a symbolic specification over the joint latent space.",
        "Our approach achieves faster learning rates compared to methods based solely on neural networks and yields transferable task related symbolic representations which carry semantic content.",
        "Our results clearly demonstrate that programmatic regularisation is a general technique for structured representation learning"
    ],
    "headline": "We present the perceptor gradients algorithm \u2013 a novel approach to learning symbolic representations based on the idea of decomposing an agent\u2019s policy into i) a perceptor network extracting symbols from raw observation data and ii) a task encoding program which maps the input symbols to output actions",
    "reference_links": [
        {
            "id": "Arulkumaran_et+al_2017_a",
            "entry": "Kai Arulkumaran, Marc Peter Deisenroth, Miles Brundage, and Anil Anthony Bharath. Deep reinforcement learning: A brief survey. IEEE Signal Processing Magazine, 34(6):26\u201338, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arulkumaran%2C%20Kai%20Deisenroth%2C%20Marc%20Peter%20Brundage%2C%20Miles%20Bharath%2C%20Anil%20Anthony%20Deep%20reinforcement%20learning%3A%20A%20brief%20survey%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arulkumaran%2C%20Kai%20Deisenroth%2C%20Marc%20Peter%20Brundage%2C%20Miles%20Bharath%2C%20Anil%20Anthony%20Deep%20reinforcement%20learning%3A%20A%20brief%20survey%202017"
        },
        {
            "id": "Barlow_et+al_1989_a",
            "entry": "Horace B Barlow, Tej P Kaushal, and Graeme J Mitchison. Finding minimum entropy codes. Neural Computation, 1(3):412\u2013423, 1989.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Barlow%2C%20Horace%20B.%20Kaushal%2C%20Tej%20P.%20Mitchison%2C%20Graeme%20J.%20Finding%20minimum%20entropy%20codes%201989",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Barlow%2C%20Horace%20B.%20Kaushal%2C%20Tej%20P.%20Mitchison%2C%20Graeme%20J.%20Finding%20minimum%20entropy%20codes%201989"
        },
        {
            "id": "Bengio_et+al_2013_a",
            "entry": "Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new perspectives. IEEE transactions on pattern analysis and machine intelligence, 35(8):1798\u20131828, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bengio%2C%20Yoshua%20Courville%2C%20Aaron%20Vincent%2C%20Pascal%20Representation%20learning%3A%20A%20review%20and%20new%20perspectives%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bengio%2C%20Yoshua%20Courville%2C%20Aaron%20Vincent%2C%20Pascal%20Representation%20learning%3A%20A%20review%20and%20new%20perspectives%202013"
        },
        {
            "id": "Bezenac_et+al_2018_a",
            "entry": "Emmanuel Bezenac, Arthur Pajot, and Patrick Gallinari. Deep learning for physical processes: Incorporating prior scientific knowledge. In International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bezenac%2C%20Emmanuel%20Pajot%2C%20Arthur%20Gallinari%2C%20Patrick%20Deep%20learning%20for%20physical%20processes%3A%20Incorporating%20prior%20scientific%20knowledge%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bezenac%2C%20Emmanuel%20Pajot%2C%20Arthur%20Gallinari%2C%20Patrick%20Deep%20learning%20for%20physical%20processes%3A%20Incorporating%20prior%20scientific%20knowledge%202018"
        },
        {
            "id": "Chen_et+al_2018_a",
            "entry": "Tian Qi Chen, Xuechen Li, Roger Grosse, and David Duvenaud. Isolating sources of disentanglement in variational autoencoders. arXiv preprint arXiv:1802.04942, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.04942"
        },
        {
            "id": "Chen_et+al_2016_a",
            "entry": "Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. Infogan: Interpretable representation learning by information maximizing generative adversarial nets. In Advances in Neural Information Processing Systems, pp. 2172\u20132180, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Xi%20Duan%2C%20Yan%20Houthooft%2C%20Rein%20Schulman%2C%20John%20Infogan%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Xi%20Duan%2C%20Yan%20Houthooft%2C%20Rein%20Schulman%2C%20John%20Infogan%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016"
        },
        {
            "id": "Duan_et+al_2016_a",
            "entry": "Yan Duan, Xi Chen, Rein Houthooft, John Schulman, and Pieter Abbeel. Benchmarking deep reinforcement learning for continuous control. In International Conference on Machine Learning, pp. 1329\u20131338, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Duan%2C%20Yan%20Chen%2C%20Xi%20Houthooft%2C%20Rein%20Schulman%2C%20John%20Benchmarking%20deep%20reinforcement%20learning%20for%20continuous%20control%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Duan%2C%20Yan%20Chen%2C%20Xi%20Houthooft%2C%20Rein%20Schulman%2C%20John%20Benchmarking%20deep%20reinforcement%20learning%20for%20continuous%20control%202016"
        },
        {
            "id": "Ellis_et+al_2018_a",
            "entry": "Kevin Ellis, Daniel Ritchie, Armando Solar-Lezama, and Joshua B Tenenbaum. Learning to infer graphics programs from hand-drawn images. In Advances in Neural Information Processing Systems, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ellis%2C%20Kevin%20Ritchie%2C%20Daniel%20Solar-Lezama%2C%20Armando%20Tenenbaum%2C%20Joshua%20B.%20Learning%20to%20infer%20graphics%20programs%20from%20hand-drawn%20images%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ellis%2C%20Kevin%20Ritchie%2C%20Daniel%20Solar-Lezama%2C%20Armando%20Tenenbaum%2C%20Joshua%20B.%20Learning%20to%20infer%20graphics%20programs%20from%20hand-drawn%20images%202018"
        },
        {
            "id": "Fraccaro_et+al_2017_a",
            "entry": "Marco Fraccaro, Simon Kamronn, Ulrich Paquet, and Ole Winther. A disentangled recognition and nonlinear dynamics model for unsupervised learning. In Advances in Neural Information Processing Systems, pp. 3604\u20133613, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fraccaro%2C%20Marco%20Kamronn%2C%20Simon%20Paquet%2C%20Ulrich%20Winther%2C%20Ole%20A%20disentangled%20recognition%20and%20nonlinear%20dynamics%20model%20for%20unsupervised%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fraccaro%2C%20Marco%20Kamronn%2C%20Simon%20Paquet%2C%20Ulrich%20Winther%2C%20Ole%20A%20disentangled%20recognition%20and%20nonlinear%20dynamics%20model%20for%20unsupervised%20learning%202017"
        },
        {
            "id": "D_et+al_2018_a",
            "entry": "Artur d\u2019Avila Garcez, Aimore Resende Riquetti Dutra, and Eduardo Alonso. Towards symbolic reinforcement learning with common sense. arXiv preprint arXiv:1804.08597, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.08597"
        },
        {
            "id": "Garnelo_et+al_2016_a",
            "entry": "Marta Garnelo, Kai Arulkumaran, and Murray Shanahan. Towards deep symbolic reinforcement learning. arXiv preprint arXiv:1609.05518, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1609.05518"
        },
        {
            "id": "Gaunt_et+al_2017_a",
            "entry": "Alexander L. Gaunt, Marc Brockschmidt, Nate Kushman, and Daniel Tarlow. Differentiable programs with neural libraries. In Proceedings of the 34th International Conference on Machine Learning, volume 70 of Proceedings of Machine Learning Research, pp. 1213\u20131222, International Convention Centre, Sydney, Australia, August 2017. PMLR.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gaunt%2C%20Alexander%20L.%20Brockschmidt%2C%20Marc%20Kushman%2C%20Nate%20Tarlow%2C%20Daniel%20Differentiable%20programs%20with%20neural%20libraries%202017-08",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gaunt%2C%20Alexander%20L.%20Brockschmidt%2C%20Marc%20Kushman%2C%20Nate%20Tarlow%2C%20Daniel%20Differentiable%20programs%20with%20neural%20libraries%202017-08"
        },
        {
            "id": "Gulwani_et+al_2017_a",
            "entry": "Sumit Gulwani, Oleksandr Polozov, and Rishabh Singh. Program synthesis. Foundations and Trends in Programming Languages, 4(1-2):1\u2013119, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gulwani%2C%20Sumit%20Polozov%2C%20Oleksandr%20Singh%2C%20Rishabh%20Program%20synthesis%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gulwani%2C%20Sumit%20Polozov%2C%20Oleksandr%20Singh%2C%20Rishabh%20Program%20synthesis%202017"
        },
        {
            "id": "Higgins_et+al_2017_a",
            "entry": "Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. \u03b2-vae: Learning basic visual concepts with a constrained variational framework. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Higgins%2C%20Irina%20Matthey%2C%20Loic%20Pal%2C%20Arka%20Burgess%2C%20Christopher%20%CE%B2-vae%3A%20Learning%20basic%20visual%20concepts%20with%20a%20constrained%20variational%20framework%202017"
        },
        {
            "id": "Higgins_et+al_2018_a",
            "entry": "Irina Higgins, Nicolas Sonnerat, Loic Matthey, Arka Pal, Christopher P Burgess, Matthew Botvinick, Demis Hassabis, and Alexander Lerchner. Scan: learning abstract hierarchical compositional visual concepts. International Conference on Learning Representations (ICLR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Higgins%2C%20Irina%20Sonnerat%2C%20Nicolas%20Matthey%2C%20Loic%20Pal%2C%20Arka%20Scan%3A%20learning%20abstract%20hierarchical%20compositional%20visual%20concepts%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Higgins%2C%20Irina%20Sonnerat%2C%20Nicolas%20Matthey%2C%20Loic%20Pal%2C%20Arka%20Scan%3A%20learning%20abstract%20hierarchical%20compositional%20visual%20concepts%202018"
        },
        {
            "id": "Iten_et+al_2018_a",
            "entry": "Raban Iten, Tony Metger, Henrik Wilming, Lidia del Rio, and Renato Renner. Discovering physical concepts with neural networks. arXiv preprint arXiv:1807.10300, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1807.10300"
        },
        {
            "id": "Jang_et+al_2016_a",
            "entry": "Eric Jang, Shixiang Gu, and Ben Poole. Categorical reparameterization with gumbel-softmax. arXiv preprint arXiv:1611.01144, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.01144"
        },
        {
            "id": "Kansky_et+al_2017_a",
            "entry": "Ken Kansky, Tom Silver, David A Mely, Mohamed Eldawy, Miguel Lazaro-Gredilla, Xinghua Lou, Nimrod Dorfman, Szymon Sidor, Scott Phoenix, and Dileep George. Schema networks: Zeroshot transfer with a generative causal model of intuitive physics. In International Conference on Machine Learning, pp. 1809\u20131818, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kansky%2C%20Ken%20Silver%2C%20Tom%20Mely%2C%20David%20A.%20Eldawy%2C%20Mohamed%20Schema%20networks%3A%20Zeroshot%20transfer%20with%20a%20generative%20causal%20model%20of%20intuitive%20physics%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kansky%2C%20Ken%20Silver%2C%20Tom%20Mely%2C%20David%20A.%20Eldawy%2C%20Mohamed%20Schema%20networks%3A%20Zeroshot%20transfer%20with%20a%20generative%20causal%20model%20of%20intuitive%20physics%202017"
        },
        {
            "id": "Kaplan_et+al_2017_a",
            "entry": "Russell Kaplan, Christopher Sauer, and Alexander Sosa. Beating atari with natural language guided reinforcement learning. arXiv preprint arXiv:1704.05539, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.05539"
        },
        {
            "id": "Karl_et+al_2017_a",
            "entry": "Maximilian Karl, Maximilian Soelch, Justin Bayer, and Patrick van der Smagt. Deep variational bayes filters: Unsupervised learning of state space models from raw data. In International Conference on Learning Representations, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Karl%2C%20Maximilian%20Soelch%2C%20Maximilian%20Bayer%2C%20Justin%20van%20der%20Smagt%2C%20Patrick%20Deep%20variational%20bayes%20filters%3A%20Unsupervised%20learning%20of%20state%20space%20models%20from%20raw%20data%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Karl%2C%20Maximilian%20Soelch%2C%20Maximilian%20Bayer%2C%20Justin%20van%20der%20Smagt%2C%20Patrick%20Deep%20variational%20bayes%20filters%3A%20Unsupervised%20learning%20of%20state%20space%20models%20from%20raw%20data%202017"
        },
        {
            "id": "Hyunjik_2018_a",
            "entry": "Hyunjik Kim and Andriy Mnih. Disentangling by factorising. arXiv preprint arXiv:1802.05983, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.05983"
        },
        {
            "id": "Kingma_2014_a",
            "entry": "Diederik P Kingma and Max Welling. Auto-encoding variational bayes. In International Conference on Learning Representations, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Diederik%20P.%20Welling%2C%20Max%20Auto-encoding%20variational%20bayes%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20Diederik%20P.%20Welling%2C%20Max%20Auto-encoding%20variational%20bayes%202014"
        },
        {
            "id": "Kser_et+al_2017_a",
            "entry": "John Kser, Marc Brockschmidt, Alexander Gaunt, and Daniel Tarlow. Differentiable functional program interpreters. arXiv preprint arXiv:1611.01988v2, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1611.01988v2"
        },
        {
            "id": "Kulkarni_et+al_2014_a",
            "entry": "Tejas D Kulkarni, Vikash K Mansinghka, Pushmeet Kohli, and Joshua B Tenenbaum. Inverse graphics with probabilistic cad models. arXiv preprint arXiv:1407.1339, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1407.1339"
        },
        {
            "id": "Kulkarni_et+al_2015_a",
            "entry": "Tejas D Kulkarni, Pushmeet Kohli, Joshua B Tenenbaum, and Vikash Mansinghka. Picture: A probabilistic programming language for scene perception. In Proceedings of the ieee conference on computer vision and pattern recognition, pp. 4390\u20134399, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kulkarni%2C%20Tejas%20D.%20Kohli%2C%20Pushmeet%20Tenenbaum%2C%20Joshua%20B.%20Mansinghka%2C%20Vikash%20Picture%3A%20A%20probabilistic%20programming%20language%20for%20scene%20perception%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kulkarni%2C%20Tejas%20D.%20Kohli%2C%20Pushmeet%20Tenenbaum%2C%20Joshua%20B.%20Mansinghka%2C%20Vikash%20Picture%3A%20A%20probabilistic%20programming%20language%20for%20scene%20perception%202015"
        },
        {
            "id": "Kusner_et+al_2017_a",
            "entry": "Matt J Kusner, Brooks Paige, and Jose Miguel Hernandez-Lobato. Grammar variational autoencoder. In International Conference on Machine Learning, pp. 1945\u20131954, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Matt%20J%20Kusner%20Brooks%20Paige%20and%20Jose%20Miguel%20HernandezLobato%20Grammar%20variational%20autoencoder%20In%20International%20Conference%20on%20Machine%20Learning%20pp%2019451954%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Matt%20J%20Kusner%20Brooks%20Paige%20and%20Jose%20Miguel%20HernandezLobato%20Grammar%20variational%20autoencoder%20In%20International%20Conference%20on%20Machine%20Learning%20pp%2019451954%202017"
        },
        {
            "id": "Lam_2004_a",
            "entry": "Johnny Lam. Control of an inverted pendulum, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lam%2C%20Johnny%20Control%20of%20an%20inverted%20pendulum%202004"
        },
        {
            "id": "Levesque_2005_a",
            "entry": "Hector J. Levesque. Planning with loops. In Proceedings of the 19th International Joint Conference on Artificial Intelligence, IJCAI\u201905, pp. 509\u2013515, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Levesque%2C%20Hector%20J.%20Planning%20with%20loops%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Levesque%2C%20Hector%20J.%20Planning%20with%20loops%202005"
        },
        {
            "id": "Lieberman_et+al_2006_a",
            "entry": "Henry Lieberman, Fabio Paterno, Markus Klann, and Volker Wulf. End-User Development: An Emerging Paradigm, pp. 1\u20138. Springer Netherlands, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lieberman%2C%20Henry%20Paterno%2C%20Fabio%20Klann%2C%20Markus%20Wulf%2C%20Volker%20End-User%20Development%3A%20An%20Emerging%20Paradigm%202006"
        },
        {
            "id": "Mansinghka_et+al_2013_a",
            "entry": "Vikash K Mansinghka, Tejas D Kulkarni, Yura N Perov, and Josh Tenenbaum. Approximate bayesian image interpretation using generative probabilistic graphics programs. In Advances in Neural Information Processing Systems, pp. 1520\u20131528, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mansinghka%2C%20Vikash%20K.%20Kulkarni%2C%20Tejas%20D.%20Perov%2C%20Yura%20N.%20Tenenbaum%2C%20Josh%20Approximate%20bayesian%20image%20interpretation%20using%20generative%20probabilistic%20graphics%20programs%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mansinghka%2C%20Vikash%20K.%20Kulkarni%2C%20Tejas%20D.%20Perov%2C%20Yura%20N.%20Tenenbaum%2C%20Josh%20Approximate%20bayesian%20image%20interpretation%20using%20generative%20probabilistic%20graphics%20programs%202013"
        },
        {
            "id": "Mnih_et+al_2015_a",
            "entry": "Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, et al. Human-level control through deep reinforcement learning. Nature, 518(7540):529\u2013533, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mnih%2C%20Volodymyr%20Kavukcuoglu%2C%20Koray%20Silver%2C%20David%20Rusu%2C%20Andrei%20A.%20Human-level%20control%20through%20deep%20reinforcement%20learning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mnih%2C%20Volodymyr%20Kavukcuoglu%2C%20Koray%20Silver%2C%20David%20Rusu%2C%20Andrei%20A.%20Human-level%20control%20through%20deep%20reinforcement%20learning%202015"
        },
        {
            "id": "Siddharth_et+al_2017_a",
            "entry": "Siddharth Narayanaswamy, T Brooks Paige, Jan-Willem van de Meent, Alban Desmaison, Noah Goodman, Pushmeet Kohli, Frank Wood, and Philip Torr. Learning disentangled representations with semi-supervised deep generative models. In Advances in Neural Information Processing Systems, pp. 5927\u20135937, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Siddharth%20Narayanaswamy%2C%20T.Brooks%20Paige%20van%20de%20Meent%2C%20Jan-Willem%20Desmaison%2C%20Alban%20Goodman%2C%20Noah%20Learning%20disentangled%20representations%20with%20semi-supervised%20deep%20generative%20models%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Siddharth%20Narayanaswamy%2C%20T.Brooks%20Paige%20van%20de%20Meent%2C%20Jan-Willem%20Desmaison%2C%20Alban%20Goodman%2C%20Noah%20Learning%20disentangled%20representations%20with%20semi-supervised%20deep%20generative%20models%202017"
        },
        {
            "id": "Penkov_2017_a",
            "entry": "Svetlin Penkov and Subramanian Ramamoorthy. Using program induction to interpret transition system dynamics. In Proceedings of ICML Workshop on Human Interpretability in Machine Learning, Sydney, August 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Penkov%2C%20Svetlin%20Ramamoorthy%2C%20Subramanian%20Using%20program%20induction%20to%20interpret%20transition%20system%20dynamics%202017-08",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Penkov%2C%20Svetlin%20Ramamoorthy%2C%20Subramanian%20Using%20program%20induction%20to%20interpret%20transition%20system%20dynamics%202017-08"
        },
        {
            "id": "Schmidhuber_1992_a",
            "entry": "Jurgen Schmidhuber. Learning factorial codes by predictability minimization. Neural Computation, 4(6):863\u2013879, 1992.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schmidhuber%2C%20Jurgen%20Learning%20factorial%20codes%20by%20predictability%20minimization%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schmidhuber%2C%20Jurgen%20Learning%20factorial%20codes%20by%20predictability%20minimization%201992"
        },
        {
            "id": "Srivastava_et+al_2014_a",
            "entry": "Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, 15(1):1929\u20131958, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Srivastava%2C%20Nitish%20Hinton%2C%20Geoffrey%20Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Dropout%3A%20a%20simple%20way%20to%20prevent%20neural%20networks%20from%20overfitting%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Srivastava%2C%20Nitish%20Hinton%2C%20Geoffrey%20Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Dropout%3A%20a%20simple%20way%20to%20prevent%20neural%20networks%20from%20overfitting%202014"
        },
        {
            "id": "Verma_et+al_2018_a",
            "entry": "Abhinav Verma, Vijayaraghavan Murali, Rishabh Singh, Pushmeet Kohli, and Swarat Chaudhuri. Programmatically interpretable reinforcement learning. arXiv preprint arXiv:1804.02477, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.02477"
        },
        {
            "id": "Watter_et+al_2015_a",
            "entry": "Manuel Watter, Jost Springenberg, Joschka Boedecker, and Martin Riedmiller. Embed to control: A locally linear latent dynamics model for control from raw images. In Advances in neural information processing systems, pp. 2746\u20132754, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Watter%2C%20Manuel%20Springenberg%2C%20Jost%20Boedecker%2C%20Joschka%20Riedmiller%2C%20Martin%20Embed%20to%20control%3A%20A%20locally%20linear%20latent%20dynamics%20model%20for%20control%20from%20raw%20images%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Watter%2C%20Manuel%20Springenberg%2C%20Jost%20Boedecker%2C%20Joschka%20Riedmiller%2C%20Martin%20Embed%20to%20control%3A%20A%20locally%20linear%20latent%20dynamics%20model%20for%20control%20from%20raw%20images%202015"
        },
        {
            "id": "Wu_et+al_2017_a",
            "entry": "Jiajun Wu, Erika Lu, Pushmeet Kohli, Bill Freeman, and Josh Tenenbaum. Learning to see physics via visual de-animation. In Advances in Neural Information Processing Systems, pp. 153\u2013164, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wu%2C%20Jiajun%20Lu%2C%20Erika%20Kohli%2C%20Pushmeet%20Freeman%2C%20Bill%20Learning%20to%20see%20physics%20via%20visual%20de-animation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wu%2C%20Jiajun%20Lu%2C%20Erika%20Kohli%2C%20Pushmeet%20Freeman%2C%20Bill%20Learning%20to%20see%20physics%20via%20visual%20de-animation%202017"
        },
        {
            "id": "Zhou_et+al_1996_a",
            "entry": "Kemin Zhou, John Comstock Doyle, Keith Glover, et al. Robust and optimal control, volume 40. Prentice hall New Jersey, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhou%2C%20Kemin%20Doyle%2C%20John%20Comstock%20Glover%2C%20Keith%20Robust%20and%20optimal%20control%2C%20volume%2040%201996"
        }
    ]
}

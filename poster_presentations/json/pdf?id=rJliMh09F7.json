{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "DIVERSITY-SENSITIVE CONDITIONAL GENERATIVE ADVERSARIAL NETWORKS",
        "author": "Dingdong Yang, Seunghoon Hong, Yunseok Jang, Tianchen Zhao, Honglak Lee,\u2021 \u2020 University of Michigan, Ann Arbor, MI, USA \u2021 Google Brain, Mountain View, CA, USA",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=rJliMh09F7"
        },
        "abstract": "We propose a simple yet highly effective method that addresses the mode-collapse problem in the Conditional Generative Adversarial Network (cGAN). Although conditional distributions are multi-modal (i.e., having many modes) in practice, most cGAN approaches tend to learn an overly simplified distribution where an input is always mapped to a single output regardless of variations in latent code. To address such issue, we propose to explicitly regularize the generator to produce diverse outputs depending on latent codes. The proposed regularization is simple, general, and can be easily integrated into most conditional GAN objectives. Additionally, explicit regularization on generator allows our method to control a balance between visual quality and diversity. We demonstrate the effectiveness of our method on three conditional generation tasks: image-to-image translation, image inpainting, and future video prediction. We show that simple addition of our regularization to existing models leads to surprisingly diverse generations, substantially outperforming the previous approaches for multi-modal conditional generation specifically designed in each individual task."
    },
    "keywords": [
        {
            "term": "Synthesis",
            "url": "https://en.wikipedia.org/wiki/Synthesis"
        },
        {
            "term": "image translation",
            "url": "https://en.wikipedia.org/wiki/image_translation"
        },
        {
            "term": "Amazon Mechanical Turk",
            "url": "https://en.wikipedia.org/wiki/Amazon_Mechanical_Turk"
        },
        {
            "term": "generative adversarial networks",
            "url": "https://en.wikipedia.org/wiki/generative_adversarial_networks"
        },
        {
            "term": "conditional distribution",
            "url": "https://en.wikipedia.org/wiki/conditional_distribution"
        },
        {
            "term": "generative model",
            "url": "https://en.wikipedia.org/wiki/generative_model"
        }
    ],
    "abbreviations": {
        "cGAN": "conditional Generative Adversarial Network",
        "VAE": "Variational Autoencoder",
        "G(z)": "generator by minimizing z \u2212E",
        "LPIPS": "Learned Perceptual Image Path Similarity",
        "FID": "Frechet Inception Distance",
        "AMT": "Amazon Mechanical Turk"
    },
    "highlights": [
        "The objective of conditional generative models is learning a mapping function from input to output distributions",
        "Since many conditional distributions are inherently ambiguous, the ideal generative model should be able to learn a multi-modal mapping from inputs to outputs",
        "In conditional GAN, the generator learns a deterministic mapping from input to output distributions, where the multi-modal nature of the mapping is handled by sampling random latent codes from a prior distribution",
        "We introduce a simple method to regularize the generator in conditional GAN to resolve the mode-collapse problem",
        "We demonstrate the effectiveness of the proposed method in three representative conditional generation tasks, where most existing conditional Generative Adversarial Network approaches produces deterministic outputs: Image-to-image translation, image inpainting and video prediction",
        "We investigate a way to resolve a mode-collapsing in conditional GAN by regularizing generator"
    ],
    "key_statements": [
        "The objective of conditional generative models is learning a mapping function from input to output distributions",
        "Since many conditional distributions are inherently ambiguous, the ideal generative model should be able to learn a multi-modal mapping from inputs to outputs",
        "In conditional GAN, the generator learns a deterministic mapping from input to output distributions, where the multi-modal nature of the mapping is handled by sampling random latent codes from a prior distribution",
        "We introduce a simple method to regularize the generator in conditional GAN to resolve the mode-collapse problem",
        "We propose to encourage the generator to produce different outputs depending on the latent code, so as to learn a one-to-one mapping from the latent codes to outputs instead of many-to-one",
        "We show that the proposed method is widely applicable to various conditional Generative Adversarial Network architectures and tasks, and outperforms more complicated methods proposed to achieve multi-modal conditional",
        "We demonstrate the effectiveness of the proposed method in three representative conditional generation tasks, where most existing conditional Generative Adversarial Network approaches produces deterministic outputs: Image-to-image translation, image inpainting and video prediction",
        "We demonstrate the effectiveness of the proposed regularization in three representative conditional generation tasks that most existing methods suffer from mode-collapse: imageto-image translation, image inpainting and future frame prediction",
        "To measure realism of the generated images, we present human evaluation results using Amazon Mechanical Turk (AMT)",
        "In addition to Frechet Inception Distance and Learned Perceptual Image Path Similarity scores, we compute the segmentation accuracy to measure the visual quality of the generated images",
        "Since there is no prior work on stochastic image inpainting to our best knowledge, we present comparisons of conditional Generative Adversarial Network",
        "We investigate a way to resolve a mode-collapsing in conditional GAN by regularizing generator"
    ],
    "summary": [
        "The objective of conditional generative models is learning a mapping function from input to output distributions.",
        "In conditional GAN, the generator learns a deterministic mapping from input to output distributions, where the multi-modal nature of the mapping is handled by sampling random latent codes from a prior distribution.",
        "We demonstrate the effectiveness of the proposed method in three representative conditional generation tasks, where most existing cGAN approaches produces deterministic outputs: Image-to-image translation, image inpainting and video prediction.",
        "We show that simple addition of the proposed regularization to the existing cGAN models effectively induces stochasticity from the generator outputs.",
        "These approaches are designed to achieve multi-modal generation in each specific task, and there has been no unified solution that addresses the mode-collapse problem for general conditional GANs. Consider a problem of learning a conditional mapping function G : X \u2192 Y, which generates an output y \u2208 Y conditioned on the input x \u2208 X .",
        "We demonstrate the effectiveness of the proposed regularization in three representative conditional generation tasks that most existing methods suffer from mode-collapse: imageto-image translation, image inpainting and future frame prediction.",
        "We choose an appropriate cGAN baseline from the previous literature, which produces realistic but deterministic outputs, and apply our method by adding our regularization to their objective function.",
        "We conduct comparison experiments with BicycleGAN (Zhu et al, 2017b), which is proposed to achieve multi-modal conditional generation in image-to-image translation.",
        "Compared to the cGAN baseline, both our method and BicycleGAN are effective to learn multi-modal output distributions as shwon in higher LPIPS scores.",
        "Note that applying BicycleGAN to baseline cGAN requires non-trivial modifications in network architecture and obejctive function, while the proposed regularization can be integrated into the objective function without any modifications.",
        "As illustrated in the results, both our method and SAVP can predict diverse futures compared to the baseline cGAN that produces deterministic outputs.",
        "As shown in KTH results, SAVP still suffers from a mode-collapse problem when the training videos have limited diversity, whereas our method generally works well in both cases.",
        "The proposed regularization is simple, general, and can be integrated into existing conditional GANs with broad classes of loss function, network architecture, and data modality.",
        "We apply our regularization for three conditional generation tasks and show that simple addition of our regularization to existing cGAN objective effectively induces the diversity.",
        "We believe that achieving an appropriate balance between realism and diversity by learning \u03bb and \u03c4 such that the learned distribution matches an actual data distribution would be an interesting future work"
    ],
    "headline": "We propose a simple yet highly effective method that addresses the mode-collapse problem in the Conditional Generative Adversarial Network",
    "reference_links": [
        {
            "id": "Arjovsky_2017_a",
            "entry": "Mart\u0131n Arjovsky and Leon Bottou. Towards Principled Methods for Training Generative Adversarial Networks. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arjovsky%2C%20Mart%C4%B1n%20Bottou%2C%20Leon%20Towards%20Principled%20Methods%20for%20Training%20Generative%20Adversarial%20Networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arjovsky%2C%20Mart%C4%B1n%20Bottou%2C%20Leon%20Towards%20Principled%20Methods%20for%20Training%20Generative%20Adversarial%20Networks%202017"
        },
        {
            "id": "Arjovsky_et+al_2017_b",
            "entry": "Martin Arjovsky, Soumith Chintala, and Leon Bottou. Wasserstein Generative Adversarial Networks. In ICML, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arjovsky%2C%20Martin%20Chintala%2C%20Soumith%20Bottou%2C%20Leon%20Wasserstein%20Generative%20Adversarial%20Networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arjovsky%2C%20Martin%20Chintala%2C%20Soumith%20Bottou%2C%20Leon%20Wasserstein%20Generative%20Adversarial%20Networks%202017"
        },
        {
            "id": "Chen_et+al_2018_a",
            "entry": "Liang-Chieh Chen, Yukun Zhu, George Papandreou, Florian Schroff, and Hartwig Adam. EncoderDecoder with Atrous Separable Convolution for Semantic Image Segmentation. In ECCV, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Liang-Chieh%20Zhu%2C%20Yukun%20Papandreou%2C%20George%20Schroff%2C%20Florian%20EncoderDecoder%20with%20Atrous%20Separable%20Convolution%20for%20Semantic%20Image%20Segmentation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Liang-Chieh%20Zhu%2C%20Yukun%20Papandreou%2C%20George%20Schroff%2C%20Florian%20EncoderDecoder%20with%20Atrous%20Separable%20Convolution%20for%20Semantic%20Image%20Segmentation%202018"
        },
        {
            "id": "Cordts_et+al_2016_a",
            "entry": "Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The Cityscapes Dataset for Semantic Urban Scene Understanding. In CVPR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cordts%2C%20Marius%20Omran%2C%20Mohamed%20Ramos%2C%20Sebastian%20Rehfeld%2C%20Timo%20The%20Cityscapes%20Dataset%20for%20Semantic%20Urban%20Scene%20Understanding%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cordts%2C%20Marius%20Omran%2C%20Mohamed%20Ramos%2C%20Sebastian%20Rehfeld%2C%20Timo%20The%20Cityscapes%20Dataset%20for%20Semantic%20Urban%20Scene%20Understanding%202016"
        },
        {
            "id": "Denton_2018_a",
            "entry": "Emily Denton and Rob Fergus. Stochastic Video Generation with a Learned Prior. In ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Denton%2C%20Emily%20Fergus%2C%20Rob%20Stochastic%20Video%20Generation%20with%20a%20Learned%20Prior%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Denton%2C%20Emily%20Fergus%2C%20Rob%20Stochastic%20Video%20Generation%20with%20a%20Learned%20Prior%202018"
        },
        {
            "id": "Ebert_et+al_2017_a",
            "entry": "Frederik Ebert, Chelsea Finn, Alex X Lee, and Sergey Levine. Self-Supervised Visual Planning with Temporal Skip Connections. In CoRL, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ebert%2C%20Frederik%20Finn%2C%20Chelsea%20Lee%2C%20Alex%20X.%20Levine%2C%20Sergey%20Self-Supervised%20Visual%20Planning%20with%20Temporal%20Skip%20Connections%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ebert%2C%20Frederik%20Finn%2C%20Chelsea%20Lee%2C%20Alex%20X.%20Levine%2C%20Sergey%20Self-Supervised%20Visual%20Planning%20with%20Temporal%20Skip%20Connections%202017"
        },
        {
            "id": "Gulrajani_et+al_2017_a",
            "entry": "Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville. Improved Training of Wasserstein GANs. In NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ishaan%20Gulrajani%20Faruk%20Ahmed%20Martin%20Arjovsky%20Vincent%20Dumoulin%20and%20Aaron%20C%20Courville%20Improved%20Training%20of%20Wasserstein%20GANs%20In%20NIPS%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ishaan%20Gulrajani%20Faruk%20Ahmed%20Martin%20Arjovsky%20Vincent%20Dumoulin%20and%20Aaron%20C%20Courville%20Improved%20Training%20of%20Wasserstein%20GANs%20In%20NIPS%202017"
        },
        {
            "id": "Heusel_et+al_2017_a",
            "entry": "Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, Gunter Klambauer, and Sepp Hochreiter. GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium. In NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Heusel%2C%20Martin%20Ramsauer%2C%20Hubert%20Unterthiner%2C%20Thomas%20Nessler%2C%20Bernhard%20GANs%20Trained%20by%20a%20Two%20Time-Scale%20Update%20Rule%20Converge%20to%20a%20Local%20Nash%20Equilibrium%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Heusel%2C%20Martin%20Ramsauer%2C%20Hubert%20Unterthiner%2C%20Thomas%20Nessler%2C%20Bernhard%20GANs%20Trained%20by%20a%20Two%20Time-Scale%20Update%20Rule%20Converge%20to%20a%20Local%20Nash%20Equilibrium%202017"
        },
        {
            "id": "Hong_et+al_2018_a",
            "entry": "Seunghoon Hong, Dingdong Yang, Jongwook Choi, and Honglak Lee. Inferring Semantic Layout for Hierarchical Text-to-Image Synthesis. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hong%2C%20Seunghoon%20Yang%2C%20Dingdong%20Choi%2C%20Jongwook%20Lee%2C%20Honglak%20Inferring%20Semantic%20Layout%20for%20Hierarchical%20Text-to-Image%20Synthesis%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hong%2C%20Seunghoon%20Yang%2C%20Dingdong%20Choi%2C%20Jongwook%20Lee%2C%20Honglak%20Inferring%20Semantic%20Layout%20for%20Hierarchical%20Text-to-Image%20Synthesis%202018"
        },
        {
            "id": "Huang_et+al_2017_a",
            "entry": "Xun Huang, Yixuan Li, Omid Poursaeed, John Hopcroft, and Serge Belongie. Stacked generative adversarial networks. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20Xun%20Li%2C%20Yixuan%20Poursaeed%2C%20Omid%20Hopcroft%2C%20John%20Stacked%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20Xun%20Li%2C%20Yixuan%20Poursaeed%2C%20Omid%20Hopcroft%2C%20John%20Stacked%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "Huang_et+al_2018_a",
            "entry": "Xun Huang, Ming-Yu Liu, Serge Belongie, and Jan Kautz. Multimodal Unsupervised Image-toImage Translation. In ECCV, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20Xun%20Liu%2C%20Ming-Yu%20Belongie%2C%20Serge%20Kautz%2C%20Jan%20Multimodal%20Unsupervised%20Image-toImage%20Translation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20Xun%20Liu%2C%20Ming-Yu%20Belongie%2C%20Serge%20Kautz%2C%20Jan%20Multimodal%20Unsupervised%20Image-toImage%20Translation%202018"
        },
        {
            "id": "Iizuka_et+al_2017_a",
            "entry": "Satoshi Iizuka, Edgar Simo-Serra, and Hiroshi Ishikawa. Globally and Locally Consistent Image Completion. In SIGGRAPH, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Satoshi%20Iizuka%20Edgar%20SimoSerra%20and%20Hiroshi%20Ishikawa%20Globally%20and%20Locally%20Consistent%20Image%20Completion%20In%20SIGGRAPH%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Satoshi%20Iizuka%20Edgar%20SimoSerra%20and%20Hiroshi%20Ishikawa%20Globally%20and%20Locally%20Consistent%20Image%20Completion%20In%20SIGGRAPH%202017"
        },
        {
            "id": "Isola_et+al_2017_a",
            "entry": "Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-Image Translation with Conditional Adversarial Networks. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Isola%2C%20Phillip%20Zhu%2C%20Jun-Yan%20Zhou%2C%20Tinghui%20and%20Alexei%20A%20Efros.%20Image-to-Image%20Translation%20with%20Conditional%20Adversarial%20Networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Isola%2C%20Phillip%20Zhu%2C%20Jun-Yan%20Zhou%2C%20Tinghui%20and%20Alexei%20A%20Efros.%20Image-to-Image%20Translation%20with%20Conditional%20Adversarial%20Networks%202017"
        },
        {
            "id": "Jang_et+al_2018_a",
            "entry": "Yunseok Jang, Gunhee Kim, and Yale Song. Video Prediction with Appearance and Motion Conditions. In ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jang%2C%20Yunseok%20Kim%2C%20Gunhee%20Song%2C%20Yale%20Video%20Prediction%20with%20Appearance%20and%20Motion%20Conditions%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jang%2C%20Yunseok%20Kim%2C%20Gunhee%20Song%2C%20Yale%20Video%20Prediction%20with%20Appearance%20and%20Motion%20Conditions%202018"
        },
        {
            "id": "Krizhevsky_et+al_2012_a",
            "entry": "Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. ImageNet Classification with Deep Convolutional Neural Networks. In NIPS, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Hinton%2C%20Geoffrey%20E.%20ImageNet%20Classification%20with%20Deep%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Hinton%2C%20Geoffrey%20E.%20ImageNet%20Classification%20with%20Deep%202012"
        },
        {
            "id": "Kurach_et+al_2018_a",
            "entry": "Karol Kurach, Mario Lucic, Xiaohua Zhai, Marcin Michalski, and Sylvain Gelly. The GAN Landscape: Losses, Architectures, Regularization, and Normalization. arXiv:1807.04720, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1807.04720"
        },
        {
            "id": "Lee_et+al_2018_a",
            "entry": "Alex X. Lee, Richard Zhang, Frederik Ebert, Pieter Abbeel, Chelsea Finn, and Sergey Levine. Stochastic Adversarial Video Prediction. arXiv:1804.01523, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.01523"
        },
        {
            "id": "Li_2016_a",
            "entry": "Chuan Li and Michael Wand. Precomputed Real-Time Texture Synthesis with Markovian Generative Adversarial Networks. In ECCV, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Chuan%20Wand%2C%20Michael%20Precomputed%20Real-Time%20Texture%20Synthesis%20with%20Markovian%20Generative%20Adversarial%20Networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Chuan%20Wand%2C%20Michael%20Precomputed%20Real-Time%20Texture%20Synthesis%20with%20Markovian%20Generative%20Adversarial%20Networks%202016"
        },
        {
            "id": "Liu_et+al_2015_a",
            "entry": "Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep Learning Face Attributes in the Wild. In ICCV, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Ziwei%20Luo%2C%20Ping%20Wang%2C%20Xiaogang%20Tang%2C%20Xiaoou%20Deep%20Learning%20Face%20Attributes%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Ziwei%20Luo%2C%20Ping%20Wang%2C%20Xiaogang%20Tang%2C%20Xiaoou%20Deep%20Learning%20Face%20Attributes%202015"
        },
        {
            "id": "Metz_et+al_2017_a",
            "entry": "Luke Metz, Ben Poole, David Pfau, and Jascha Sohl-Dickstein. Unrolled Generative Adversarial Networks. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Luke%20Metz%20Ben%20Poole%20David%20Pfau%20and%20Jascha%20SohlDickstein%20Unrolled%20Generative%20Adversarial%20Networks%20In%20ICLR%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Luke%20Metz%20Ben%20Poole%20David%20Pfau%20and%20Jascha%20SohlDickstein%20Unrolled%20Generative%20Adversarial%20Networks%20In%20ICLR%202017"
        },
        {
            "id": "Miyato_et+al_2018_a",
            "entry": "Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral Normalization for Generative Adversarial Networks. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Miyato%2C%20Takeru%20Kataoka%2C%20Toshiki%20Koyama%2C%20Masanori%20Yoshida%2C%20Yuichi%20Spectral%20Normalization%20for%20Generative%20Adversarial%20Networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Miyato%2C%20Takeru%20Kataoka%2C%20Toshiki%20Koyama%2C%20Masanori%20Yoshida%2C%20Yuichi%20Spectral%20Normalization%20for%20Generative%20Adversarial%20Networks%202018"
        },
        {
            "id": "Pathak_et+al_2016_a",
            "entry": "Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and Alexei A Efros. Context Encoders: Feature Learning by Inpainting. In CVPR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pathak%2C%20Deepak%20Krahenbuhl%2C%20Philipp%20Donahue%2C%20Jeff%20Darrell%2C%20Trevor%20and%20Alexei%20A%20Efros.%20Context%20Encoders%3A%20Feature%20Learning%20by%20Inpainting%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pathak%2C%20Deepak%20Krahenbuhl%2C%20Philipp%20Donahue%2C%20Jeff%20Darrell%2C%20Trevor%20and%20Alexei%20A%20Efros.%20Context%20Encoders%3A%20Feature%20Learning%20by%20Inpainting%202016"
        },
        {
            "id": "Tylecek_2013_a",
            "entry": "Radim Sara Radim Tylecek. Spatial Pattern Templates for Recognition of Objects with Regular Structure. In GCPR, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tylecek%2C%20Radim%20Sara%20Radim%20Spatial%20Pattern%20Templates%20for%20Recognition%20of%20Objects%20with%20Regular%20Structure%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tylecek%2C%20Radim%20Sara%20Radim%20Spatial%20Pattern%20Templates%20for%20Recognition%20of%20Objects%20with%20Regular%20Structure%202013"
        },
        {
            "id": "Ronneberger_et+al_2015_a",
            "entry": "Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-Net: Convolutional Networks for Biomedical Image Segmentation. In MICCAI, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Olaf%20Ronneberger%20Philipp%20Fischer%20and%20Thomas%20Brox%20UNet%20Convolutional%20Networks%20for%20Biomedical%20Image%20Segmentation%20In%20MICCAI%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Olaf%20Ronneberger%20Philipp%20Fischer%20and%20Thomas%20Brox%20UNet%20Convolutional%20Networks%20for%20Biomedical%20Image%20Segmentation%20In%20MICCAI%202015"
        },
        {
            "id": "Salimans_et+al_2016_a",
            "entry": "Tim Salimans, Ian J. Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved Techniques for Training GANs. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Salimans%2C%20Tim%20Goodfellow%2C%20Ian%20J.%20Zaremba%2C%20Wojciech%20Cheung%2C%20Vicki%20Improved%20Techniques%20for%20Training%20GANs%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Salimans%2C%20Tim%20Goodfellow%2C%20Ian%20J.%20Zaremba%2C%20Wojciech%20Cheung%2C%20Vicki%20Improved%20Techniques%20for%20Training%20GANs%202016"
        },
        {
            "id": "Schuldt_et+al_2004_a",
            "entry": "Christian Schuldt, Ivan Laptev, and Barbara Caputo. Recognizing Human Actions: A Local SVM Approach. In ICPR, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schuldt%2C%20Christian%20Laptev%2C%20Ivan%20Caputo%2C%20Barbara%20Recognizing%20Human%20Actions%3A%20A%20Local%20SVM%20Approach%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schuldt%2C%20Christian%20Laptev%2C%20Ivan%20Caputo%2C%20Barbara%20Recognizing%20Human%20Actions%3A%20A%20Local%20SVM%20Approach%202004"
        },
        {
            "id": "Simonyan_2015_a",
            "entry": "Karen Simonyan and Andrew Zisserman. Very Deep Convolutional Networks for Large-Scale Image Recognition. In ICLR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Simonyan%2C%20Karen%20Zisserman%2C%20Andrew%20Very%20Deep%20Convolutional%20Networks%20for%20Large-Scale%20Image%20Recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Simonyan%2C%20Karen%20Zisserman%2C%20Andrew%20Very%20Deep%20Convolutional%20Networks%20for%20Large-Scale%20Image%20Recognition%202015"
        },
        {
            "id": "Srivastava_et+al_2017_a",
            "entry": "Akash Srivastava, Lazar Valkoz, Chris Russell, Michael U Gutmann, and Charles Sutton. VEEGAN: Reducing Mode Collapse in GANs using Implicit Variational Learning. In NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Srivastava%2C%20Akash%20Valkoz%2C%20Lazar%20Russell%2C%20Chris%20Gutmann%2C%20Michael%20U.%20VEEGAN%3A%20Reducing%20Mode%20Collapse%20in%20GANs%20using%20Implicit%20Variational%20Learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Srivastava%2C%20Akash%20Valkoz%2C%20Lazar%20Russell%2C%20Chris%20Gutmann%2C%20Michael%20U.%20VEEGAN%3A%20Reducing%20Mode%20Collapse%20in%20GANs%20using%20Implicit%20Variational%20Learning%202017"
        },
        {
            "id": "Szegedy_et+al_2015_a",
            "entry": "Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going Deeper with Convolutions. In CVPR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szegedy%2C%20Christian%20Liu%2C%20Wei%20Jia%2C%20Yangqing%20Sermanet%2C%20Pierre%20Going%20Deeper%20with%20Convolutions%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Szegedy%2C%20Christian%20Liu%2C%20Wei%20Jia%2C%20Yangqing%20Sermanet%2C%20Pierre%20Going%20Deeper%20with%20Convolutions%202015"
        },
        {
            "id": "Villegas_et+al_2017_a",
            "entry": "Ruben Villegas, Jimei Yang, Seunghoon Hong, Xunyu Lin, and Honglak Lee. Decomposing Motion and Content for Natural Video Sequence Prediction. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Villegas%2C%20Ruben%20Yang%2C%20Jimei%20Hong%2C%20Seunghoon%20Lin%2C%20Xunyu%20Decomposing%20Motion%20and%20Content%20for%20Natural%20Video%20Sequence%20Prediction%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Villegas%2C%20Ruben%20Yang%2C%20Jimei%20Hong%2C%20Seunghoon%20Lin%2C%20Xunyu%20Decomposing%20Motion%20and%20Content%20for%20Natural%20Video%20Sequence%20Prediction%202017"
        },
        {
            "id": "Wang_et+al_2018_a",
            "entry": "Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Andrew Tao, Jan Kautz, and Bryan Catanzaro. HighResolution Image Synthesis and Semantic Manipulation with Conditional GANs. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Ting-Chun%20Liu%2C%20Ming-Yu%20Zhu%2C%20Jun-Yan%20Tao%2C%20Andrew%20HighResolution%20Image%20Synthesis%20and%20Semantic%20Manipulation%20with%20Conditional%20GANs%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Ting-Chun%20Liu%2C%20Ming-Yu%20Zhu%2C%20Jun-Yan%20Tao%2C%20Andrew%20HighResolution%20Image%20Synthesis%20and%20Semantic%20Manipulation%20with%20Conditional%20GANs%202018"
        },
        {
            "id": "White_2016_a",
            "entry": "Tom White. Sampling Generative Networks. arXiv:1609.04468, 2016. SHI Xingjian, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-Kin Wong, and Wang-chun Woo.",
            "arxiv_url": "https://arxiv.org/pdf/1609.04468"
        },
        {
            "id": "Yu_2015_a",
            "entry": "Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting. In NIPS, 2015. Aron Yu and Kristen Grauman. Fine-Grained Visual Comparisons with Local Learning. In CVPR, 2014. Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, and Oliver Wang. The Unreasonable Effectiveness of Deep Features as a Perceptual Metric. In CVPR, 2018. Jun-Yan Zhu, Philipp Krahenbuhl, Eli Shechtman, and Alexei A Efros. Generative Visual Manipulation on the Natural Image Manifold. In ECCV, 2016. Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks. In ICCV, 2017a. Jun-Yan Zhu, Richard Zhang, Deepak Pathak, Trevor Darrell, Alexei A Efros, Oliver Wang, and Eli Shechtman. Toward Multimodal Image-to-Image Translation. In NIPS, 2017b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yu%20Grauman%2C%20Kristen%20Convolutional%20LSTM%20Network%3A%20A%20Machine%20Learning%20Approach%20for%20Precipitation%20Nowcasting%202015-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yu%20Grauman%2C%20Kristen%20Convolutional%20LSTM%20Network%3A%20A%20Machine%20Learning%20Approach%20for%20Precipitation%20Nowcasting%202015-06"
        }
    ]
}

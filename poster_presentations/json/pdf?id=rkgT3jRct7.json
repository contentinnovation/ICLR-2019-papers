{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "LARGE-SCALE ANSWERER IN QUESTIONER\u2019S MIND FOR VISUAL DIALOG QUESTION GENERATION",
        "author": "Sang-Woo Lee, Tong Gao, Sohee Yang, Jaejun Yoo, & Jung-Woo Ha Clova AI Research, NAVER Corp. {sang.woo.lee,tong.gao,sh.yang,jaejun.yoo,jungwoo.ha}@navercorp.com",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=rkgT3jRct7"
        },
        "abstract": "Answerer in Questioner\u2019s Mind (AQM) is an information-theoretic framework that has been recently proposed for task-oriented dialog systems. AQM benefits from asking a question that would maximize the information gain when it is asked. However, due to its intrinsic nature of explicitly calculating the information gain, AQM has a limitation when the solution space is very large. To address this, we propose AQM+ that can deal with a large-scale problem and ask a question that is more coherent to the current context of the dialog. We evaluate our method on GuessWhich, a challenging task-oriented visual dialog problem, where the number of candidate classes is near 10K. Our experimental results and ablation studies show that AQM+ outperforms the state-of-the-art models by a remarkable margin with a reasonable approximation. In particular, the proposed AQM+ reduces more than 60% of error as the dialog proceeds, while the comparative algorithms diminish the error by less than 6%. Based on our results, we argue that AQM+ is a general task-oriented dialog algorithm that can be applied for non-yes-or-no responses."
    },
    "keywords": [
        {
            "term": "information gain",
            "url": "https://en.wikipedia.org/wiki/information_gain"
        },
        {
            "term": "reinforcement learning",
            "url": "https://en.wikipedia.org/wiki/reinforcement_learning"
        },
        {
            "term": "dialog system",
            "url": "https://en.wikipedia.org/wiki/dialog_system"
        },
        {
            "term": "supervised learning",
            "url": "https://en.wikipedia.org/wiki/supervised_learning"
        }
    ],
    "abbreviations": {
        "AQM": "Answerer in Questioners Mind",
        "SL": "supervised learning",
        "RL": "reinforcement learning",
        "PMR": "percentile mean rank",
        "VQA": "visual question answering",
        "Qbot": "questioner bot",
        "Abot": "answerer bot",
        "NSML": "NAVER Smart Machine Learening",
        "20M": "2500 times as many calculations",
        "MAML": "model-agnostic meta learning"
    },
    "highlights": [
        "Recent advances in deep learning have led an end-to-end neural approach to task-oriented dialog problems that can reduce a laborious labeling task on states and intents (Bordes & Weston, 2017)",
        "We proposed Answerer in Questioners Mind+ algorithm that is a large-scale extension of Answerer in Questioners Mind framework",
        "Answerer in Questioners Mind+ can ask an appropriate question considering the context of the dialog, handle the responses in a sentence form, and efficiently estimate information gain of the target class with a given question",
        "Answerer in Questioners Mind+ not only outperforms the comparative supervised learning and reinforcement learning algorithms, but enlarges the gap between Answerer in Questioners Mind+ and the comparative algorithms comparing to the performance gaps reported in GuessWhat",
        "Answerer in Questioners Mind+ acheives more than 60% error decreases through the dialog, whereas the comparative algorithms only achieve 6% error decreases",
        "The performance of Answerer in Questioners Mind+ can be boosted further by employing the models recently proposed in the visual dialog field such as other question generator models (Jain et al, 2018) and question answering models (Kottur et al, 2018)"
    ],
    "key_statements": [
        "Recent advances in deep learning have led an end-to-end neural approach to task-oriented dialog problems that can reduce a laborious labeling task on states and intents (Bordes & Weston, 2017)",
        "The supervised learning approach typically requires a lot of training data to deal with unseen scenarios and cover all trajectories of the vast action space of dialog systems (<a class=\"ref-link\" id=\"cWen_et+al_2016_a\" href=\"#rWen_et+al_2016_a\">Wen et al, 2016</a>)",
        "We propose Answerer in Questioners Mind+ that extends the Answerer in Questioners Mind framework toward the more general and complicated tasks",
        "Under the Answerer in Questioners Mind framework, at each turn t, questioner bot generates an appropriate question qt and guesses the target class c given a previous history of the dialog ht\u22121 = (q1:t\u22121, a1:t\u22121, h0)",
        "We propose Answerer in Questioners Mind+ algorithm, which uses sampling-based approximation, for tackling the large-scale task-oriented dialog problem",
        "In depA setting of Answerer in Questioners Mind approach, aprxAgen is trained from the questions in the training data and following answers obtained in the conversation between questioner bot and answerer bot",
        "Figure 3a corresponds to the non-delta setting in the original paper (Das et al, 2017b) and Figure 3b corresponds to the delta setting proposed in the Github code",
        "We see that supervised learning-Q and reinforcement learning-QA do not significantly improve the performance after a few rounds, especially for the delta setting",
        "DIFFICULTY OF GUESSWHICH According to our results, we infer that percentile mean rank degradation of comparative supervised learning and reinforcement learning models during the dialog is not caused by forgetting dialog context to ask an appropriate question",
        "Comparative results between Answerer in Questioners Mind+ and Guesser show that the improvement from Answerer in Questioners Mind+\u2019s Qpost is significant, which implies that the major constraint of supervised learning and reinforcement learning is the limited capacity of RNN and its softmax score function",
        "Applying Answerer in Questioners Mind+ to the GuessWhich problem means that we not only solve a very complicated problem, but find that the Answerer in Questioners Mind framework is applicable to the situation where the answer has high uncertainty.\n5.2",
        "NOTES ON COMPARATIVE ANALYSIS Fine-tuning both questioner bot and answerer bot through reinforcement learning Though reinforcement learning-QA is the main setting in the work of Das et al (2017b), there are some reports indicating that fine-tuning both questioner bot and answerer bot is unfair",
        "Even if we use only 100 candidate answers, which is in the Visual Dialog dataset (Das et al, 2017a), the previous Answerer in Questioners Mind requires 2500 times as many calculations (20M) as Answerer in Questioners Mind+",
        "We proposed Answerer in Questioners Mind+ algorithm that is a large-scale extension of Answerer in Questioners Mind framework",
        "Answerer in Questioners Mind+ can ask an appropriate question considering the context of the dialog, handle the responses in a sentence form, and efficiently estimate information gain of the target class with a given question",
        "Answerer in Questioners Mind+ not only outperforms the comparative supervised learning and reinforcement learning algorithms, but enlarges the gap between Answerer in Questioners Mind+ and the comparative algorithms comparing to the performance gaps reported in GuessWhat",
        "Answerer in Questioners Mind+ acheives more than 60% error decreases through the dialog, whereas the comparative algorithms only achieve 6% error decreases",
        "The performance of Answerer in Questioners Mind+ can be boosted further by employing the models recently proposed in the visual dialog field such as other question generator models (Jain et al, 2018) and question answering models (Kottur et al, 2018)"
    ],
    "summary": [
        "Recent advances in deep learning have led an end-to-end neural approach to task-oriented dialog problems that can reduce a laborious labeling task on states and intents (Bordes & Weston, 2017).",
        "It is noticeable that AQM achieved high performance even with a retrieval-based approach in GuessWhat by making the candidate set of questions form the training set.",
        "Under the AQM framework, at each turn t, Qbot generates an appropriate question qt and guesses the target class c given a previous history of the dialog ht\u22121 = (q1:t\u22121, a1:t\u22121, h0).",
        "We propose AQM+ algorithm, which uses sampling-based approximation, for tackling the large-scale task-oriented dialog problem.",
        "In all SL, RL, and AQM frameworks, Qbot needs to be trained to approximate the answer-generating probability distribution of Abot.",
        "In depA setting of AQM approach, aprxAgen is trained from the questions in the training data and following answers obtained in the conversation between Qbot and Abot.",
        "Random Candidate Answers Experiment One of our main arguments is that generating candidate questions from Qscore and candidate answers from aprxAgen at every turn makes AQM+ effectively deal with general and complicated task-oriented dialogs.",
        "Number of QAC Experiment We changed the size of subset K = |Qt,gen|=|At,topk|=|Ct,topk| to check our efficiency of information gain approximation, using non-delta setting.",
        "We compare selected examples of generated dialog of SL-Q, RL-QA, and AQM+ w/ indA for delta setting.",
        "According to Das et al (2017a), they discovered a variety of models, one of which is used in both the study of Das et al (2017b) and our experiments, and can already reach 41.2% for answer retrieval accuracy from 100 candidate answers, solely using the question without exploiting image and history information.",
        "5.2 NOTES ON COMPARATIVE ANALYSIS Fine-tuning both Qbot and Abot through RL Though RL-QA is the main setting in the work of Das et al (2017b), there are some reports indicating that fine-tuning both Qbot and Abot is unfair, as one of the ultimate goals in this field is to make a questioner be able to talk with human.",
        "Even if we use only 100 candidate answers, which is in the Visual Dialog dataset (Das et al, 2017a), the previous AQM requires 2500 times as many calculations (20M) as AQM+.",
        "AQM+ can ask an appropriate question considering the context of the dialog, handle the responses in a sentence form, and efficiently estimate information gain of the target class with a given question.",
        "The performance of AQM+ can be boosted further by employing the models recently proposed in the visual dialog field such as other question generator models (Jain et al, 2018) and question answering models (Kottur et al, 2018)."
    ],
    "headline": "We propose Answerer in Questioners Mind+ that can deal with a large-scale problem and ask a question that is more coherent to the current context of the dialog",
    "reference_links": [
        {
            "id": "Belghazi_et+al_2018_a",
            "entry": "Ishmael Belghazi, Sai Rajeswar, Aristide Baratin, R Devon Hjelm, and Aaron Courville. Mine: mutual information neural estimation. arXiv preprint arXiv:1801.04062, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1801.04062"
        },
        {
            "id": "Liu_2017_a",
            "entry": "Fei Liu and Julien Perez. Gated end-to-end memory networks. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, volume 1, pp. 1\u201310, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Fei%20Perez%2C%20Julien%20Gated%20end-to-end%20memory%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Fei%20Perez%2C%20Julien%20Gated%20end-to-end%20memory%20networks%202017"
        },
        {
            "id": "Lu_et+al_2017_a",
            "entry": "Jiasen Lu, Anitha Kannan, Jianwei Yang, Devi Parikh, and Dhruv Batra. Best of both worlds: Transferring knowledge from discriminative learning to a generative visual dialog model. In Advances in Neural Information Processing Systems, pp. 314\u2013324, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lu%2C%20Jiasen%20Kannan%2C%20Anitha%20Yang%2C%20Jianwei%20Parikh%2C%20Devi%20Best%20of%20both%20worlds%3A%20Transferring%20knowledge%20from%20discriminative%20learning%20to%20a%20generative%20visual%20dialog%20model%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lu%2C%20Jiasen%20Kannan%2C%20Anitha%20Yang%2C%20Jianwei%20Parikh%2C%20Devi%20Best%20of%20both%20worlds%3A%20Transferring%20knowledge%20from%20discriminative%20learning%20to%20a%20generative%20visual%20dialog%20model%202017"
        },
        {
            "id": "Modhe_et+al_2018_a",
            "entry": "Nirbhay Modhe, Viraj Prabhu, Michael Cogswell, Satwik Kottur, Abhishek Das, Stefan Lee, Devi Parikh, and Dhruv Batra. Visdial-rl-pytorch. https://github.com/batra-mlp-lab/visdial-rl.git, 2018.",
            "url": "https://github.com/batra-mlp-lab/visdial-rl.git"
        },
        {
            "id": "Rao_2018_a",
            "entry": "Sudha Rao and Hal Daume III. Learning to ask good questions: Ranking clarification questions using neural expected value of perfect information. arXiv preprint arXiv:1805.04655, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1805.04655"
        },
        {
            "id": "Seo_et+al_2017_a",
            "entry": "Minjoon Seo, Sewon Min, Ali Farhadi, and Hannaneh Hajishirzi. Query-reduction networks for question answering. In ICLR, 2017a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Seo%2C%20Minjoon%20Min%2C%20Sewon%20Farhadi%2C%20Ali%20Hajishirzi%2C%20Hannaneh%20Query-reduction%20networks%20for%20question%20answering%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Seo%2C%20Minjoon%20Min%2C%20Sewon%20Farhadi%2C%20Ali%20Hajishirzi%2C%20Hannaneh%20Query-reduction%20networks%20for%20question%20answering%202017"
        },
        {
            "id": "Seo_et+al_2018_a",
            "entry": "Minjoon Seo, Sewon Min, Ali Farhadi, and Hannaneh Hajishirzi. Neural speed reading via skim-rnn. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Seo%2C%20Minjoon%20Min%2C%20Sewon%20Farhadi%2C%20Ali%20Hajishirzi%2C%20Hannaneh%20Neural%20speed%20reading%20via%20skim-rnn%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Seo%2C%20Minjoon%20Min%2C%20Sewon%20Farhadi%2C%20Ali%20Hajishirzi%2C%20Hannaneh%20Neural%20speed%20reading%20via%20skim-rnn%202018"
        },
        {
            "id": "Seo_et+al_2017_b",
            "entry": "Paul Hongsuck Seo, Andreas Lehrmann, Bohyung Han, and Leonid Sigal. Visual reference resolution using attention memory for visual dialog. In Advances in neural information processing systems, pp. 3719\u20133729, 2017b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Seo%2C%20Paul%20Hongsuck%20Lehrmann%2C%20Andreas%20Han%2C%20Bohyung%20Sigal%2C%20Leonid%20Visual%20reference%20resolution%20using%20attention%20memory%20for%20visual%20dialog%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Seo%2C%20Paul%20Hongsuck%20Lehrmann%2C%20Andreas%20Han%2C%20Bohyung%20Sigal%2C%20Leonid%20Visual%20reference%20resolution%20using%20attention%20memory%20for%20visual%20dialog%202017"
        },
        {
            "id": "Strub_et+al_2017_a",
            "entry": "Florian Strub, Harm de Vries, Jeremie Mary, Bilal Piot, Aaron Courville, and Olivier Pietquin. End-to-end optimization of goal-driven and visually grounded dialogue systems. arXiv preprint arXiv:1703.05423, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.05423"
        },
        {
            "id": "Sung_et+al_2017_a",
            "entry": "Nako Sung, Minkyu Kim, Hyunwoo Jo, Youngil Yang, Jingwoong Kim, Leonard Lausen, Youngkwan Kim, Gayoung Lee, Donghyun Kwak, Jung-Woo Ha, et al. Nsml: A machine learning platform that enables you to focus on your models. arXiv preprint arXiv:1712.05902, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.05902"
        },
        {
            "id": "Vaswani_et+al_2017_a",
            "entry": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in Neural Information Processing Systems, pp. 5998\u20136008, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ashish%20Vaswani%20Noam%20Shazeer%20Niki%20Parmar%20Jakob%20Uszkoreit%20Llion%20Jones%20Aidan%20N%20Gomez%20%C5%81ukasz%20Kaiser%20and%20Illia%20Polosukhin%20Attention%20is%20all%20you%20need%20In%20Advances%20in%20Neural%20Information%20Processing%20Systems%20pp%2059986008%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ashish%20Vaswani%20Noam%20Shazeer%20Niki%20Parmar%20Jakob%20Uszkoreit%20Llion%20Jones%20Aidan%20N%20Gomez%20%C5%81ukasz%20Kaiser%20and%20Illia%20Polosukhin%20Attention%20is%20all%20you%20need%20In%20Advances%20in%20Neural%20Information%20Processing%20Systems%20pp%2059986008%202017"
        },
        {
            "id": "Vijayakumar_et+al_2016_a",
            "entry": "Ashwin K Vijayakumar, Michael Cogswell, Ramprasath R Selvaraju, Qing Sun, Stefan Lee, David Crandall, and Dhruv Batra. Diverse beam search: Decoding diverse solutions from neural sequence models. arXiv preprint arXiv:1610.02424, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1610.02424"
        },
        {
            "id": "Vinyals_2015_a",
            "entry": "Oriol Vinyals and Quoc Le. A neural conversational model. In ICML Deep Learning Workshop, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vinyals%2C%20Oriol%20Le%2C%20Quoc%20A%20neural%20conversational%20model%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vinyals%2C%20Oriol%20Le%2C%20Quoc%20A%20neural%20conversational%20model%202015"
        },
        {
            "id": "Wen_et+al_2016_a",
            "entry": "Tsung-Hsien Wen, David Vandyke, Nikola Mrksic, Milica Gasic, Lina M Rojas-Barahona, Pei-Hao Su, Stefan Ultes, and Steve Young. A network-based end-to-end trainable task-oriented dialogue system. arXiv preprint arXiv:1604.04562, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1604.04562"
        },
        {
            "id": "Yu_et+al_2018_a",
            "entry": "Adams Wei Yu, David Dohan, Minh-Thang Luong, Rui Zhao, Kai Chen, Mohammad Norouzi, and Quoc V Le. Qanet: Combining local convolution with global self-attention for reading comprehension. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yu%2C%20Adams%20Wei%20Dohan%2C%20David%20Luong%2C%20Minh-Thang%20Zhao%2C%20Rui%20Qanet%3A%20Combining%20local%20convolution%20with%20global%20self-attention%20for%20reading%20comprehension%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yu%2C%20Adams%20Wei%20Dohan%2C%20David%20Luong%2C%20Minh-Thang%20Zhao%2C%20Rui%20Qanet%3A%20Combining%20local%20convolution%20with%20global%20self-attention%20for%20reading%20comprehension%202018"
        },
        {
            "id": "Yu_2018_b",
            "entry": "Zeping Yu and Gongshen Liu. Sliced recurrent neural networks. arXiv preprint arXiv:1807.02291, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1807.02291"
        },
        {
            "id": "Zhang_et+al_0000_a",
            "entry": "Jiaping Zhang, Tiancheng Zhao, and Zhou Yu. Multimodal hierarchical reinforcement learning policy for task-oriented visual dialog. arXiv preprint arXiv:1805.03257, 2018a.",
            "arxiv_url": "https://arxiv.org/pdf/1805.03257"
        },
        {
            "id": "Zhang_et+al_0000_b",
            "entry": "Junjie Zhang, Qi Wu, Chunhua Shen, Jian Zhang, Jianfeng Lu, and Anton Van Den Hengel. Goal-oriented visual question generation via intermediate rewards. In Proceedings of the European Conference on Computer Vision (ECCV), pp. 186\u2013201, 2018b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Junjie%20Wu%2C%20Qi%20Shen%2C%20Chunhua%20Zhang%2C%20Jian%20Goal-oriented%20visual%20question%20generation%20via%20intermediate%20rewards",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Junjie%20Wu%2C%20Qi%20Shen%2C%20Chunhua%20Zhang%2C%20Jian%20Goal-oriented%20visual%20question%20generation%20via%20intermediate%20rewards"
        },
        {
            "id": "Zhao_2016_a",
            "entry": "Tiancheng Zhao and Maxine Eskenazi. Towards end-to-end learning for dialog state tracking and management using deep reinforcement learning. arXiv preprint arXiv:1606.02560, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1606.02560"
        },
        {
            "id": "Zhao_et+al_2017_a",
            "entry": "Tiancheng Zhao, Allen Lu, Kyusong Lee, and Maxine Eskenazi. Generative encoder-decoder models for taskoriented spoken dialog systems with chatting capability. In Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue, pp. 27\u201336, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhao%2C%20Tiancheng%20Lu%2C%20Allen%20Lee%2C%20Kyusong%20Eskenazi%2C%20Maxine%20Generative%20encoder-decoder%20models%20for%20taskoriented%20spoken%20dialog%20systems%20with%20chatting%20capability%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhao%2C%20Tiancheng%20Lu%2C%20Allen%20Lee%2C%20Kyusong%20Eskenazi%2C%20Maxine%20Generative%20encoder-decoder%20models%20for%20taskoriented%20spoken%20dialog%20systems%20with%20chatting%20capability%202017"
        },
        {
            "id": "Zhao_et+al_2018_a",
            "entry": "Tiancheng Zhao, Kyusong Lee, and Maxine Eskenazi. Unsupervised discrete sentence representation learning for interpretable neural dialog generation. arXiv preprint arXiv:1804.08069, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.08069"
        },
        {
            "id": "Zhu_et+al_2017_a",
            "entry": "Yan Zhu, Shaoting Zhang, and Dimitris Metaxas. Interactive reinforcement learning for object grounding via self-talking. arXiv preprint arXiv:1712.00576, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.00576"
        }
    ]
}

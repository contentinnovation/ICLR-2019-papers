{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "APPROXIMATING CNNS WITH BAG-OF-LOCALFEATURES MODELS WORKS SURPRISINGLY WELL ON IMAGENET",
        "author": "Wieland Brendel and Matthias Bethge",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=SkfMWhAqYQ"
        },
        "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 33 \u00d7 33 px features and Alexnet performance for 17 \u00d7 17 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies."
    },
    "keywords": [
        {
            "term": "spatial relationship",
            "url": "https://en.wikipedia.org/wiki/spatial_relationship"
        },
        {
            "term": "deep convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/deep_convolutional_neural_network"
        },
        {
            "term": "deep learning",
            "url": "https://en.wikipedia.org/wiki/deep_learning"
        },
        {
            "term": "Intelligence Advanced Research Projects Activity",
            "url": "https://en.wikipedia.org/wiki/Intelligence_Advanced_Research_Projects_Activity"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        },
        {
            "term": "image feature",
            "url": "https://en.wikipedia.org/wiki/image_feature"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        }
    ],
    "abbreviations": {
        "DNNs": "Deep Neural Networks",
        "IARPA": "Intelligence Advanced Research Projects Activity"
    },
    "highlights": [
        "A big obstacle in understanding the decision-making of Deep Neural Networks is due to the complex dependencies between input and hidden activations: for one, the effect of any part of the input on a hidden activation depends on the state of many other parts of the input",
        "Our architecture is inspired by bag-of-feature (BoF) models which \u2014 alongside extensions such as VLAD encoding or Fisher Vectors \u2014 have been the most successful approaches to large-scale object recognition before the advent of deep learning and classify images based on the counts, but not the spatial relationships, of a set of local image features",
        "VGG-16 is most affected by the masking of local patches while deeper and more performant architectures are more robust to the relatively small masks, which again suggests that deeper architectures take into account larger spatial relationships.\n5 DISCUSSION & OUTLOOK",
        "In this paper we introduced and analysed a novel interpretable Deep Neural Networks architecture \u2014 coined BagNets \u2014 that classifies images based on linear bag-of-local-features representations",
        "The results demonstrate that even complex perceptual tasks like ImageNet can be solved just based on small image features and without any notion of spatial relationships",
        "In addition we showed that the key properties of BagNets, in particlar invariance to spatial relationships as well as weak interactions between image features, are present to varying degrees in many common computer vision models like ResNet-50"
    ],
    "key_statements": [
        "A big obstacle in understanding the decision-making of Deep Neural Networks is due to the complex dependencies between input and hidden activations: for one, the effect of any part of the input on a hidden activation depends on the state of many other parts of the input",
        "Our architecture is inspired by bag-of-feature (BoF) models which \u2014 alongside extensions such as VLAD encoding or Fisher Vectors \u2014 have been the most successful approaches to large-scale object recognition before the advent of deep learning and classify images based on the counts, but not the spatial relationships, of a set of local image features",
        "VGG-16 is most affected by the masking of local patches while deeper and more performant architectures are more robust to the relatively small masks, which again suggests that deeper architectures take into account larger spatial relationships.\n5 DISCUSSION & OUTLOOK",
        "In this paper we introduced and analysed a novel interpretable Deep Neural Networks architecture \u2014 coined BagNets \u2014 that classifies images based on linear bag-of-local-features representations",
        "The results demonstrate that even complex perceptual tasks like ImageNet can be solved just based on small image features and without any notion of spatial relationships",
        "In addition we showed that the key properties of BagNets, in particlar invariance to spatial relationships as well as weak interactions between image features, are present to varying degrees in many common computer vision models like ResNet-50",
        "In contrast to the perceived \u201cleap\u201d in performance from bag-of-feature models to deep neural networks, the representations learnt by Deep Neural Networks may in the end still be similar to the pre-deep learning era"
    ],
    "summary": [
        "A big obstacle in understanding the decision-making of DNNs is due to the complex dependencies between input and hidden activations: for one, the effect of any part of the input on a hidden activation depends on the state of many other parts of the input.",
        "These similarities suggest that current network architectures base their decisions on a large number of relatively weak and local statistical regularities and are not sufficiently encouraged - either through their architecture, training procedure or task specification - to learn more holistic features that can better appreciate causal relationships between different parts of the image.",
        "Based on this insight we construct a linear DNN-based BoF model as follows: first, we infer a 2048 dimensional feature representation from each image patch of size q \u00d7 q pixels using multiple stacked ResNet blocks and apply a linear classifier to infer the class evidence for each patch.",
        "Thereafter we compare the behaviour of BagNets with several widely used high-performance DNNs (e.g. VGG-16, ResNet-50, DenseNet-169) and show evidence that their decision-making shares many similarities.",
        "For each q \u00d7 q patch the model infers evidence for each ImageNet classes, yielding a highresolution and very precise heatmap that shows which parts of the image contributes most to certain decisions.",
        "In the paragraphs we investigate how similar the decision-making of BagNets is to highperformance DNNs like VGG-16, ResNet-50, ResNet-152 and DenseNet-169.",
        "Image parts that are relevant to BagNets are relevant for the classification of normal DNNs. VGG-16 is most affected by the masking of local patches while deeper and more performant architectures are more robust to the relatively small masks, which again suggests that deeper architectures take into account larger spatial relationships.",
        "In this paper we introduced and analysed a novel interpretable DNN architecture \u2014 coined BagNets \u2014 that classifies images based on linear bag-of-local-features representations.",
        "In addition we showed that the key properties of BagNets, in particlar invariance to spatial relationships as well as weak interactions between image features, are present to varying degrees in many common computer vision models like ResNet-50",
        "VGG-16, suggesting that the decision-making of many DNNs trained on ImageNet follows at least in part a similar bag-of-feature strategy.",
        "In contrast to the perceived \u201cleap\u201d in performance from bag-of-feature models to deep neural networks, the representations learnt by DNNs may in the end still be similar to the pre-deep learning era.",
        "VGG-16 is close to bag-of-feature models, as demonstrated by the weak interactions (Figure 6) and the sensitivity to the same small image patches as BagNets (Figure 8)."
    ],
    "headline": "In this paper we show that it is possible to combine the performance and flexibility of Deep Neural Networks with the interpretability of BoF models, and that the resulting model family is able to reach high accuracy on ImageNet even if limited to fairly small image patches",
    "reference_links": [
        {
            "id": "Marco_2017_a",
            "entry": "Marco Ancona, Enea Ceolini, Cengiz \u00d6ztireli, and Markus Gross. Towards better understanding of gradient-based attribution methods for deep neural networks, 2017. URL http://arxiv.org/abs/1711.06104.",
            "url": "http://arxiv.org/abs/1711.06104",
            "arxiv_url": "https://arxiv.org/pdf/1711.06104"
        },
        {
            "id": "Arandjelovic_et+al_2015_a",
            "entry": "Relja Arandjelovic, Petr Gron\u00e1t, Akihiko Torii, Tom\u00e1s Pajdla, and Josef Sivic. Netvlad: CNN architecture for weakly supervised place recognition. CoRR, abs/1511.07247, 2015. URL http://arxiv.org/abs/1511.07247.",
            "url": "http://arxiv.org/abs/1511.07247",
            "arxiv_url": "https://arxiv.org/pdf/1511.07247"
        },
        {
            "id": "Babenko_2015_a",
            "entry": "Artem Babenko and Victor S. Lempitsky. Aggregating deep convolutional features for image retrieval. CoRR, abs/1510.07493, 2015. URL http://arxiv.org/abs/1510.07493.",
            "url": "http://arxiv.org/abs/1510.07493",
            "arxiv_url": "https://arxiv.org/pdf/1510.07493"
        },
        {
            "id": "Baehrens_et+al_2010_a",
            "entry": "David Baehrens, Timon Schroeter, Stefan Harmeling, Motoaki Kawanabe, Katja Hansen, and KlausRobert M\u00fcller. How to explain individual classification decisions. Journal of Machine Learning Research, 11:1803\u20131831, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Baehrens%2C%20David%20Schroeter%2C%20Timon%20Harmeling%2C%20Stefan%20Kawanabe%2C%20Motoaki%20How%20to%20explain%20individual%20classification%20decisions%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Baehrens%2C%20David%20Schroeter%2C%20Timon%20Harmeling%2C%20Stefan%20Kawanabe%2C%20Motoaki%20How%20to%20explain%20individual%20classification%20decisions%202010"
        },
        {
            "id": "Cao_et+al_2017_a",
            "entry": "Jiewei Cao, Zi Huang, and Heng Tao Shen. Local deep descriptors in bag-of-words for image retrieval. In Proceedings of the on Thematic Workshops of ACM Multimedia 2017, Thematic Workshops \u201917, pp. 52\u201358, New York, NY, USA, 2017. ACM. ISBN 978-1-4503-5416-5. doi: 10.1145/3126686.3127018.",
            "crossref": "https://dx.doi.org/10.1145/3126686.3127018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/3126686.3127018"
        },
        {
            "id": "Chatfield_et+al_2014_a",
            "entry": "Ken Chatfield, Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. Return of the devil in the details: Delving deep into convolutional nets. In Michel Fran\u00e7ois Valstar, Andrew P. French, and Tony P. Pridmore (eds.), BMVC. BMVA Press, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chatfield%2C%20Ken%20Simonyan%2C%20Karen%20Vedaldi%2C%20Andrea%20Zisserman%2C%20Andrew%20Return%20of%20the%20devil%20in%20the%20details%3A%20Delving%20deep%20into%20convolutional%20nets%202014"
        },
        {
            "id": "Chen_et+al_2018_a",
            "entry": "Chaofan Chen, Oscar Li, Alina Barnett, Jonathan Su, and Cynthia Rudin. This looks like that: deep learning for interpretable image recognition. CoRR, abs/1806.10574, 2018. URL http://arxiv.org/abs/1806.10574.",
            "url": "http://arxiv.org/abs/1806.10574",
            "arxiv_url": "https://arxiv.org/pdf/1806.10574"
        },
        {
            "id": "Csurka_et+al_2004_a",
            "entry": "G. Csurka, C. Bray, C. Dance, and L. Fan. Visual categorization with bags of keypoints. Workshop on Statistical Learning in Computer Vision, ECCV, pp. 1\u201322, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Csurka%2C%20G.%20Bray%2C%20C.%20Dance%2C%20C.%20Fan%2C%20L.%20Visual%20categorization%20with%20bags%20of%20keypoints%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Csurka%2C%20G.%20Bray%2C%20C.%20Dance%2C%20C.%20Fan%2C%20L.%20Visual%20categorization%20with%20bags%20of%20keypoints%202004"
        },
        {
            "id": "Feng_et+al_2017_a",
            "entry": "Jiangfan Feng, Yuanyuan Liu, and Lin Wu. Bag of visual words model with deep spatial features for geographical scene classification. Comp. Int. and Neurosc., 2017:5169675:1\u20135169675:14, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Feng%2C%20Jiangfan%20Liu%2C%20Yuanyuan%20Wu%2C%20Lin%20Bag%20of%20visual%20words%20model%20with%20deep%20spatial%20features%20for%20geographical%20scene%20classification%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Feng%2C%20Jiangfan%20Liu%2C%20Yuanyuan%20Wu%2C%20Lin%20Bag%20of%20visual%20words%20model%20with%20deep%20spatial%20features%20for%20geographical%20scene%20classification%202017"
        },
        {
            "id": "Gatys_et+al_2015_a",
            "entry": "Leon A. Gatys, Alexander S. Ecker, and Matthias Bethge. Texture synthesis and the controlled generation of natural stimuli using convolutional neural networks. CoRR, abs/1505.07376, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1505.07376"
        },
        {
            "id": "Gong_et+al_0000_a",
            "entry": "Yunchao Gong, Liwei Wang, Ruiqi Guo, and Svetlana Lazebnik. Multi-scale orderless pooling of deep convolutional activation features. In David J. Fleet, Tom\u00e1s Pajdla, Bernt Schiele, and Tinne Tuytelaars (eds.), ECCV (7), volume 8695 of Lecture Notes in Computer Science, pp. 392\u2013407.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gong%2C%20Yunchao%20Wang%2C%20Liwei%20Guo%2C%20Ruiqi%20Lazebnik%2C%20Svetlana%20Multi-scale%20orderless%20pooling%20of%20deep%20convolutional%20activation%20features",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gong%2C%20Yunchao%20Wang%2C%20Liwei%20Guo%2C%20Ruiqi%20Lazebnik%2C%20Svetlana%20Multi-scale%20orderless%20pooling%20of%20deep%20convolutional%20activation%20features"
        },
        {
            "id": "Springer_2014_a",
            "entry": "Springer, 2014. ISBN 978-3-319-10583-3.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Springer%202014%20ISBN%209783319105833"
        },
        {
            "id": "He_et+al_2015_a",
            "entry": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. CoRR, abs/1512.03385, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1512.03385"
        },
        {
            "id": "Hinton_et+al_2015_a",
            "entry": "Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hinton%2C%20Geoffrey%20Vinyals%2C%20Oriol%20Dean%2C%20Jeff%20Distilling%20the%20knowledge%20in%20a%20neural%20network%202015"
        },
        {
            "id": "Jurie_2005_a",
            "entry": "Fr\u00e9d\u00e9ric Jurie and Bill Triggs. Creating efficient codebooks for visual recognition. In ICCV, pp. 604\u2013610, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jurie%2C%20Fr%C3%A9d%C3%A9ric%20Triggs%2C%20Bill%20Creating%20efficient%20codebooks%20for%20visual%20recognition%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jurie%2C%20Fr%C3%A9d%C3%A9ric%20Triggs%2C%20Bill%20Creating%20efficient%20codebooks%20for%20visual%20recognition%202005"
        },
        {
            "id": "Khan_et+al_2016_a",
            "entry": "Fahad Shahbaz Khan, Joost van de Weijer, Rao Muhammad Anwer, Andrew D. Bagdanov, Michael Felsberg, and Jorma Laaksonen. Scale coding bag of deep features for human attribute and action recognition. CoRR, abs/1612.04884, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1612.04884"
        },
        {
            "id": "Kindermans_et+al_2018_a",
            "entry": "Pieter-Jan Kindermans, Kristof T Sch\u00fctt, Maximilian Alber, Klaus-Robert M\u00fcller, Dumitru Erhan, Been Kim, and Sven D\u00e4hne. Learning how to explain neural networks: Patternnet and patternattribution. In 6th International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kindermans%2C%20Pieter-Jan%20Sch%C3%BCtt%2C%20Kristof%20T.%20Alber%2C%20Maximilian%20M%C3%BCller%2C%20Klaus-Robert%20Learning%20how%20to%20explain%20neural%20networks%3A%20Patternnet%20and%20patternattribution%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kindermans%2C%20Pieter-Jan%20Sch%C3%BCtt%2C%20Kristof%20T.%20Alber%2C%20Maximilian%20M%C3%BCller%2C%20Klaus-Robert%20Learning%20how%20to%20explain%20neural%20networks%3A%20Patternnet%20and%20patternattribution%202018"
        },
        {
            "id": "Krizhevsky_et+al_2012_a",
            "entry": "Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pp. 1097\u20131105, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Hinton%2C%20Geoffrey%20E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Hinton%2C%20Geoffrey%20E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012"
        },
        {
            "id": "Lazebnik_et+al_2006_a",
            "entry": "Svetlana Lazebnik, Cordelia Schmid, and Jean Ponce. Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories. 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lazebnik%2C%20Svetlana%20Schmid%2C%20Cordelia%20Ponce%2C%20Jean%20Beyond%20bags%20of%20features%3A%20Spatial%20pyramid%20matching%20for%20recognizing%20natural%20scene%20categories%202006"
        },
        {
            "id": "Li_et+al_2017_a",
            "entry": "Oscar Li, Hao Liu, Chaofan Chen, and Cynthia Rudin. Deep learning for case-based reasoning through prototypes: A neural network that explains its predictions. CoRR, abs/1710.04806, 2017. URL http://arxiv.org/abs/1710.04806.",
            "url": "http://arxiv.org/abs/1710.04806",
            "arxiv_url": "https://arxiv.org/pdf/1710.04806"
        },
        {
            "id": "Mohedano_et+al_2016_a",
            "entry": "Eva Mohedano, Kevin McGuinness, Noel E. O\u2019Connor, Amaia Salvador, Ferran Marques, and Xavier Giro-i Nieto. Bags of local convolutional features for scalable instance search. In Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval, ICMR \u201916, pp. 327\u2013331, New York, NY, USA, 2016. ACM. ISBN 978-1-4503-4359-6. doi: 10.1145/2911996.2912061. URL http://doi.acm.org/10.1145/2911996.2912061.",
            "crossref": "https://dx.doi.org/10.1145/2911996.2912061",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/2911996.2912061"
        },
        {
            "id": "Ng_et+al_2015_a",
            "entry": "Joe Yue-Hei Ng, Fan Yang, and Larry S. Davis. Exploiting local features from deep networks for image retrieval. In CVPR Workshops, pp. 53\u201361. IEEE Computer Society, 2015. ISBN 978-1-4673-6759-2.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ng%2C%20Joe%20Yue-Hei%20Yang%2C%20Fan%20Davis%2C%20Larry%20S.%20Exploiting%20local%20features%20from%20deep%20networks%20for%20image%20retrieval%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ng%2C%20Joe%20Yue-Hei%20Yang%2C%20Fan%20Davis%2C%20Larry%20S.%20Exploiting%20local%20features%20from%20deep%20networks%20for%20image%20retrieval%202015"
        },
        {
            "id": "O_2011_a",
            "entry": "Stephen O\u2019Hara and Bruce A. Draper. Introduction to the bag of features paradigm for image classification and retrieval. abs/1101.3354, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=O%E2%80%99Hara%2C%20Stephen%20Draper%2C%20Bruce%20A.%20Introduction%20to%20the%20bag%20of%20features%20paradigm%20for%20image%20classification%20and%20retrieval%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=O%E2%80%99Hara%2C%20Stephen%20Draper%2C%20Bruce%20A.%20Introduction%20to%20the%20bag%20of%20features%20paradigm%20for%20image%20classification%20and%20retrieval%202011"
        },
        {
            "id": "Oyallon_et+al_2017_a",
            "entry": "Edouard Oyallon, Eugene Belilovsky, and Sergey Zagoruyko. Scaling the scattering transform: Deep hybrid networks. CoRR, abs/1703.08961, 2017. URL http://arxiv.org/abs/1703.08961.",
            "url": "http://arxiv.org/abs/1703.08961",
            "arxiv_url": "https://arxiv.org/pdf/1703.08961"
        },
        {
            "id": "Pinheiro_2014_a",
            "entry": "Pedro H. O. Pinheiro and Ronan Collobert. Weakly supervised semantic segmentation with convolutional networks. CoRR, abs/1411.6228, 2014. URL http://arxiv.org/abs/1411.6228.",
            "url": "http://arxiv.org/abs/1411.6228",
            "arxiv_url": "https://arxiv.org/pdf/1411.6228"
        },
        {
            "id": "Shrikumar_et+al_2017_a",
            "entry": "Avanti Shrikumar, Peyton Greenside, and Anshul Kundaje. Learning important features through propagating activation differences. CoRR, abs/1704.02685, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.02685"
        },
        {
            "id": "Sundararajan_et+al_2017_a",
            "entry": "Mukund Sundararajan, Ankur Taly, and Qiqi Yan. Axiomatic attribution for deep networks. CoRR, abs/1703.01365, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.01365"
        },
        {
            "id": "Tang_et+al_2016_a",
            "entry": "Peng Tang, Xinggang Wang, Baoguang Shi, Xiang Bai, Wenyu Liu, and Zhuowen Tu. Deep fishernet for object classification. CoRR, abs/1608.00182, 2016. URL http://arxiv.org/abs/1608.00182.",
            "url": "http://arxiv.org/abs/1608.00182",
            "arxiv_url": "https://arxiv.org/pdf/1608.00182"
        },
        {
            "id": "Tang_et+al_2017_a",
            "entry": "Peng Tang, Xinggang Wang, Zilong Huang, Xiang Bai, and Wenyu Liu. Deep patch learning for weakly supervised object classification and discovery. CoRR, abs/1705.02429, 2017. URL http://arxiv.org/abs/1705.02429.",
            "url": "http://arxiv.org/abs/1705.02429",
            "arxiv_url": "https://arxiv.org/pdf/1705.02429"
        },
        {
            "id": "Wei_et+al_2016_a",
            "entry": "Yunchao Wei, Wei Xia, Min Lin, Junshi Huang, Bingbing Ni, Jian Dong, Yao Zhao, and Shuicheng Yan. Hcp: A flexible cnn framework for multi-label image classification. IEEE Trans. Pattern Anal. Mach. Intell., 38, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wei%2C%20Yunchao%20Xia%2C%20Wei%20Lin%2C%20Min%20Huang%2C%20Junshi%20Hcp%3A%20A%20flexible%20cnn%20framework%20for%20multi-label%20image%20classification%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wei%2C%20Yunchao%20Xia%2C%20Wei%20Lin%2C%20Min%20Huang%2C%20Junshi%20Hcp%3A%20A%20flexible%20cnn%20framework%20for%20multi-label%20image%20classification%202016"
        },
        {
            "id": "Xiao_et+al_2015_a",
            "entry": "Tianjun Xiao, Yichong Xu, Kuiyuan Yang, Jiaxing Zhang, Yuxin Peng, and Zheng Zhang. The application of two-level attention models in deep convolutional neural network for fine-grained image classification. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2015, Boston, MA, USA, June 7-12, 2015, pp. 842\u2013850, 2015. doi: 10.1109/CVPR.2015.7298685. URL https://doi.org/10.1109/CVPR.2015.7298685.",
            "crossref": "https://dx.doi.org/10.1109/CVPR.2015.7298685",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/CVPR.2015.7298685"
        },
        {
            "id": "Zhang_et+al_2007_a",
            "entry": "Jianguo Zhang, Marcin Marszalek, Svetlana Lazebnik, and Cordelia Schmid. Local features and kernels for classification of texture and object categories: A comprehensive study. International Journal of Computer Vision, 73(2):213\u2013238, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Jianguo%20Marszalek%2C%20Marcin%20Lazebnik%2C%20Svetlana%20Schmid%2C%20Cordelia%20Local%20features%20and%20kernels%20for%20classification%20of%20texture%20and%20object%20categories%3A%20A%20comprehensive%20study%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Jianguo%20Marszalek%2C%20Marcin%20Lazebnik%2C%20Svetlana%20Schmid%2C%20Cordelia%20Local%20features%20and%20kernels%20for%20classification%20of%20texture%20and%20object%20categories%3A%20A%20comprehensive%20study%202007"
        },
        {
            "id": "Zhou_et+al_2015_a",
            "entry": "Bolei Zhou, Aditya Khosla, \u00c0gata Lapedriza, Aude Oliva, and Antonio Torralba. Learning deep features for discriminative localization. CoRR, abs/1512.04150, 2015. URL http://arxiv.org/abs/1512.04150.",
            "url": "http://arxiv.org/abs/1512.04150",
            "arxiv_url": "https://arxiv.org/pdf/1512.04150"
        },
        {
            "id": "Zintgraf_et+al_2017_a",
            "entry": "Luisa M. Zintgraf, Taco S. Cohen, Tameem Adel, and Max Welling. Visualizing deep neural network decisions: Prediction difference analysis. CoRR, abs/1702.04595, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.04595"
        },
        {
            "id": "The_0000_a",
            "entry": "The architecture of the BagNets is detailed in Figure A.1. Training of the models was performed in PyTorch using the default ImageNet training script of Torchvision (https://github.com/pytorch/vision, commit 8a4786a)with default parameters. In brief, we used SGD with momentum (0.9), a batchsize of 256 and an initial learning rate of 0.01 which we decreased by a factor of 10 every 30 epochs. Images were resized to 256 pixels (shortest side)after which we extracted a random crop of size 224 \u00d7 224 pixels.",
            "url": "https://github.com/pytorch/vision"
        }
    ]
}

{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "CHARACTERIZING AUDIO ADVERSARIAL EXAMPLES USING TEMPORAL DEPENDENCY",
        "author": "Zhuolin Yang Shanghai Jiao Tong University",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=r1g4E3C9t7"
        },
        "abstract": "Recent studies have highlighted adversarial examples as a ubiquitous threat to different neural network models and many downstream applications. Nonetheless, as unique data properties have inspired distinct and powerful learning principles, this paper aims to explore their potentials towards mitigating adversarial inputs. In particular, our results reveal the importance of using the temporal dependency in audio data to gain discriminate power against adversarial examples. Tested on the automatic speech recognition (ASR) tasks and three recent audio adversarial attacks, we find that (i) input transformation developed from image adversarial defense provides limited robustness improvement and is subtle to advanced attacks; (ii) temporal dependency can be exploited to gain discriminative power against audio adversarial examples and is resistant to adaptive attacks considered in our experiments. Our results not only show promising means of improving the robustness of ASR systems but also offer novel insights in exploiting domain-specific data properties to mitigate negative effects of adversarial examples."
    },
    "keywords": [
        {
            "term": "area under curve",
            "url": "https://en.wikipedia.org/wiki/area_under_curve"
        },
        {
            "term": "adversarial input",
            "url": "https://en.wikipedia.org/wiki/adversarial_input"
        },
        {
            "term": "automatic speech",
            "url": "https://en.wikipedia.org/wiki/automatic_speech"
        },
        {
            "term": "speech recognition",
            "url": "https://en.wikipedia.org/wiki/speech_recognition"
        },
        {
            "term": "Genetic Algorithm",
            "url": "https://en.wikipedia.org/wiki/Genetic_Algorithm"
        },
        {
            "term": "deep neural network",
            "url": "https://en.wikipedia.org/wiki/deep_neural_network"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "error rate",
            "url": "https://en.wikipedia.org/wiki/error_rate"
        },
        {
            "term": "convolutional neural networks",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_networks"
        },
        {
            "term": "recurrent neural networks",
            "url": "https://en.wikipedia.org/wiki/recurrent_neural_networks"
        },
        {
            "term": "automatic speech recognition",
            "url": "https://en.wikipedia.org/wiki/automatic_speech_recognition"
        },
        {
            "term": "Mel Frequency Cepstral Coefficients",
            "url": "https://en.wikipedia.org/wiki/Mel_Frequency_Cepstral_Coefficients"
        },
        {
            "term": "word error rate",
            "url": "https://en.wikipedia.org/wiki/word_error_rate"
        }
    ],
    "abbreviations": {
        "ASR": "automatic speech recognition",
        "DNNs": "Deep Neural Networks",
        "MFCCs": "Mel Frequency Cepstral Coefficients",
        "CNN": "convolutional neural networks",
        "RNNs": "recurrent neural networks",
        "WER": "word error rate",
        "Opt": "Optimization based attack",
        "CER": "character error rate",
        "ER": "error rate",
        "AUC": "area under curve",
        "LCP": "longest common prefix",
        "GA": "Genetic Algorithm"
    },
    "highlights": [
        "Deep Neural Networks (DNNs) have been widely adopted in a variety of machine learning applications (<a class=\"ref-link\" id=\"cKrizhevsky_et+al_2012_a\" href=\"#rKrizhevsky_et+al_2012_a\"><a class=\"ref-link\" id=\"cKrizhevsky_et+al_2012_a\" href=\"#rKrizhevsky_et+al_2012_a\">Krizhevsky et al, 2012</a></a>; <a class=\"ref-link\" id=\"cHinton_et+al_2012_a\" href=\"#rHinton_et+al_2012_a\"><a class=\"ref-link\" id=\"cHinton_et+al_2012_a\" href=\"#rHinton_et+al_2012_a\">Hinton et al, 2012</a></a>; <a class=\"ref-link\" id=\"cLevine_et+al_2016_a\" href=\"#rLevine_et+al_2016_a\"><a class=\"ref-link\" id=\"cLevine_et+al_2016_a\" href=\"#rLevine_et+al_2016_a\">Levine et al, 2016</a></a>)",
        "We aim to address the following fundamental questions: (a) do lessons learned from image adversarial examples transfer to the audio domain?; and (b) can temporal dependency be used to discriminate audio adversarial examples? studying the discriminative power of temporal dependency in audios not only highlights the importance of using unique data properties towards building robust machine learning models but aids in devising principles for investigating more complex data such as videos or multimodal cases",
        "In our experiments we find that audio input transformations based on waveform quantization, temporal filtering, signal downsampling or autoencoder reformation suffers from similar weakness: the tested model with input transformation becomes fragile to adversarial examples when one adopts the attack considering gradient obfuscation as in (<a class=\"ref-link\" id=\"cAthalye_et+al_2018_a\" href=\"#rAthalye_et+al_2018_a\">Athalye et al, 2018</a>)",
        "This paper proposes to exploit the temporal dependency property in audio data to characterize audio adversarial examples",
        "Our experimental results show that while four primitive input transformations on audio fail to withstand adaptive adversarial attacks, temporal dependency is shown to be resistant to these attacks",
        "We demonstrate the power of temporal dependency for characterizing adversarial examples generated by three state-of-the-art audio adversarial attacks"
    ],
    "key_statements": [
        "Deep Neural Networks (DNNs) have been widely adopted in a variety of machine learning applications (<a class=\"ref-link\" id=\"cKrizhevsky_et+al_2012_a\" href=\"#rKrizhevsky_et+al_2012_a\"><a class=\"ref-link\" id=\"cKrizhevsky_et+al_2012_a\" href=\"#rKrizhevsky_et+al_2012_a\">Krizhevsky et al, 2012</a></a>; <a class=\"ref-link\" id=\"cHinton_et+al_2012_a\" href=\"#rHinton_et+al_2012_a\"><a class=\"ref-link\" id=\"cHinton_et+al_2012_a\" href=\"#rHinton_et+al_2012_a\">Hinton et al, 2012</a></a>; <a class=\"ref-link\" id=\"cLevine_et+al_2016_a\" href=\"#rLevine_et+al_2016_a\"><a class=\"ref-link\" id=\"cLevine_et+al_2016_a\" href=\"#rLevine_et+al_2016_a\">Levine et al, 2016</a></a>)",
        "Recent work has demonstrated that Deep Neural Networks are vulnerable to adversarial perturbations (<a class=\"ref-link\" id=\"cSzegedy_et+al_2014_a\" href=\"#rSzegedy_et+al_2014_a\">Szegedy et al, 2014</a>; <a class=\"ref-link\" id=\"cGoodfellow_et+al_2015_a\" href=\"#rGoodfellow_et+al_2015_a\">Goodfellow et al, 2015</a>)",
        "The temporal dependency in audio data is an innate characteristic that has already been widely adopted in the machine learning models",
        "We note that this paper focuses on the case of audio adversarial examples, the methodology of leveraging unique data properties to improve model robustness could be naturally extended to different domains",
        "We aim to address the following fundamental questions: (a) do lessons learned from image adversarial examples transfer to the audio domain?; and (b) can temporal dependency be used to discriminate audio adversarial examples? studying the discriminative power of temporal dependency in audios not only highlights the importance of using unique data properties towards building robust machine learning models but aids in devising principles for investigating more complex data such as videos or multimodal cases",
        "In our experiments we find that audio input transformations based on waveform quantization, temporal filtering, signal downsampling or autoencoder reformation suffers from similar weakness: the tested model with input transformation becomes fragile to adversarial examples when one adopts the attack considering gradient obfuscation as in (<a class=\"ref-link\" id=\"cAthalye_et+al_2018_a\" href=\"#rAthalye_et+al_2018_a\">Athalye et al, 2018</a>)",
        "Temporal dependency possesses strong discriminative power against adversarial examples in automatic speech recognition Instead of input transformation, in this paper, we propose to exploit the inherent temporal dependency in audio data to discriminate adversarial examples",
        "Tested on the automatic speech recognition (ASR) tasks, we find that the proposed methodology can effectively detect audio adversarial examples while minimally affecting the recognition performance on normal examples",
        "Due to the fact that audio sequence has an explicit temporal dependency, here we aim to explore if such temporal dependency will be affected by adversarial perturbations",
        "The presentation flows of the experimental results are summarized as follows",
        "We will first introduce the datasets, target learning models, attack methods, and evaluation metrics for different defense/detection methods that we focus on",
        "We show that due to different data properties, the autoencoder based defense cannot effectively recover the ground truth for adversarial audios and may have negative effects on benign instances as well",
        "Input transformation is less effective in defending adversarial audio than images",
        "The proposed TD method can effectively detect adversarial audios generated by different attacks targeting on various learning tasks",
        "We show that these strong adaptive attacks are not able to generate effective adversarial audio against TD and we provide some case studies to further understand the performance of TD.\n4.1",
        "It shows that for classification tasks, such input transformation is more effective in mitigating the negative effects of adversarial perturbation. This potential reason could be that classification tasks do not rely on audio temporal dependency but focus on local features, while speech-to-text task will be harder to defend based on the tested input transformations",
        "Commander We evaluate our input transformation method against the Commander Song attack (<a class=\"ref-link\" id=\"cYuan_et+al_2018_a\" href=\"#rYuan_et+al_2018_a\">Yuan et al, 2018</a>), which implemented an Air-to-API adversarial attack",
        "We evaluate several primitive signal processing methods as input transformation under word error rate and character error rate metrics in Table A1 and A2",
        "From Tables A1 and A2 we showed that most of the input transformations (e.g., Median-4, Downsampling and Quan-256) effectively reduce the adversarial perturbation without affecting the original audio too much",
        "These input transformations show certain effectiveness in defending against adversarial audios, we find that it is still possible to generate adversarial audios by adaptive attacks in Section 4.4",
        "Genetic Algorithm We presented our results in Table 1 that against classification attack, Autoencoder did not perform well by only reducing attack success rate to 8.2% defeat by other input transformation methods",
        "We only evaluate our TD method on speech-to-text attacks (Commander and Optimization based attack) because of the audio in the Speech Commands dataset for classification attack is just a single command lasting for one second and its temporal dependency is not obvious",
        "Optimization based attack Here we show the empirical performance of distinguishing adversarial audios by leveraging the temporal dependency of audio data",
        "This paper proposes to exploit the temporal dependency property in audio data to characterize audio adversarial examples",
        "Our experimental results show that while four primitive input transformations on audio fail to withstand adaptive adversarial attacks, temporal dependency is shown to be resistant to these attacks",
        "We demonstrate the power of temporal dependency for characterizing adversarial examples generated by three state-of-the-art audio adversarial attacks"
    ],
    "summary": [
        "Deep Neural Networks (DNNs) have been widely adopted in a variety of machine learning applications (<a class=\"ref-link\" id=\"cKrizhevsky_et+al_2012_a\" href=\"#rKrizhevsky_et+al_2012_a\"><a class=\"ref-link\" id=\"cKrizhevsky_et+al_2012_a\" href=\"#rKrizhevsky_et+al_2012_a\">Krizhevsky et al, 2012</a></a>; <a class=\"ref-link\" id=\"cHinton_et+al_2012_a\" href=\"#rHinton_et+al_2012_a\"><a class=\"ref-link\" id=\"cHinton_et+al_2012_a\" href=\"#rHinton_et+al_2012_a\">Hinton et al, 2012</a></a>; <a class=\"ref-link\" id=\"cLevine_et+al_2016_a\" href=\"#rLevine_et+al_2016_a\"><a class=\"ref-link\" id=\"cLevine_et+al_2016_a\" href=\"#rLevine_et+al_2016_a\">Levine et al, 2016</a></a>).",
        "In our experiments we find that audio input transformations based on waveform quantization, temporal filtering, signal downsampling or autoencoder reformation suffers from similar weakness: the tested model with input transformation becomes fragile to adversarial examples when one adopts the attack considering gradient obfuscation as in (<a class=\"ref-link\" id=\"cAthalye_et+al_2018_a\" href=\"#rAthalye_et+al_2018_a\">Athalye et al, 2018</a>).",
        "Experimental results show that a considered adaptive adversarial attack, even when knowing every detail of the deployed temporal dependency method, cannot generate adversarial examples that bypass the proposed temporal dependency-based approach.",
        "We will introduce the effect of basic input transformations on audio adversarial examples, and analyze temporal dependency in audio data.",
        "Even when some input transformation is effective for recovering some adversarial audio data, we find that it is easy to perform adaptive attacks against them.",
        "The proposed TD method can effectively detect adversarial audios generated by different attacks targeting on various learning tasks.",
        "Evaluation Metrics For defense method such as input transformation, since it aims to recover the ground truth from adversarial instances, we use the word error rate (WER) and character error rate (CER) (<a class=\"ref-link\" id=\"cLevenshtein_1966_a\" href=\"#rLevenshtein_1966_a\">Levenshtein, 1966</a>) as evaluation metrics to measure the recovery efficiency.",
        "We measured our defense method of autoencoder based defense and input transformation defense for classification attack (GA) and speech-to-text attack (Commander and Opt).",
        "We perform the primitive input transformation for audio classification targeted attacks and evaluate the corresponding effects.",
        "This potential reason could be that classification tasks do not rely on audio temporal dependency but focus on local features, while speech-to-text task will be harder to defend based on the tested input transformations.",
        "From Tables A1 and A2 we showed that most of the input transformations (e.g., Median-4, Downsampling and Quan-256) effectively reduce the adversarial perturbation without affecting the original audio too much.",
        "GA We presented our results in Table 1 that against classification attack, Autoencoder did not perform well by only reducing attack success rate to 8.2% defeat by other input transformation methods.",
        "We only evaluate our TD method on speech-to-text attacks (Commander and Opt) because of the audio in the Speech Commands dataset for classification attack is just a single command lasting for one second and its temporal dependency is not obvious.",
        "These results suggest that the temporal dependency based method would suggest an easy-implemented but effective method for characterizing adversarial audio attacks.",
        "Our experimental results show that while four primitive input transformations on audio fail to withstand adaptive adversarial attacks, temporal dependency is shown to be resistant to these attacks.",
        "We believe our results shed new lights in exploiting unique data properties toward adversarial robustness"
    ],
    "headline": "As unique data properties have inspired distinct and powerful learning principles, this paper aims to explore their potentials towards mitigating adversarial inputs",
    "reference_links": [
        {
            "id": "Alzantot_et+al_2018_a",
            "entry": "Moustafa Alzantot, Bharathan Balaji, and Mani Srivastava. Did you hear that? adversarial examples against automatic speech recognition. arXiv preprint arXiv:1801.00554, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1801.00554"
        },
        {
            "id": "Athalye_et+al_2018_a",
            "entry": "Anish Athalye, Nicholas Carlini, and David Wagner. Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples. arXiv preprint arXiv:1802.00420, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.00420"
        },
        {
            "id": "Carlini_2017_a",
            "entry": "Nicholas Carlini and David Wagner. Towards evaluating the robustness of neural networks. In IEEE Symposium on Security and Privacy, 2017, 2017a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Carlini%2C%20Nicholas%20Wagner%2C%20David%20Towards%20evaluating%20the%20robustness%20of%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Carlini%2C%20Nicholas%20Wagner%2C%20David%20Towards%20evaluating%20the%20robustness%20of%20neural%20networks%202017"
        },
        {
            "id": "Carlini_0000_a",
            "entry": "Nicholas Carlini and David Wagner. Adversarial examples are not easily detected: Bypassing ten detection methods. In ACM Workshop on Artificial Intelligence and Security, pp. 3\u201314, 2017b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Carlini%2C%20Nicholas%20Wagner%2C%20David%20Adversarial%20examples%20are%20not%20easily%20detected%3A%20Bypassing%20ten%20detection%20methods",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Carlini%2C%20Nicholas%20Wagner%2C%20David%20Adversarial%20examples%20are%20not%20easily%20detected%3A%20Bypassing%20ten%20detection%20methods"
        },
        {
            "id": "Carlini_0000_b",
            "entry": "Nicholas Carlini and David Wagner. Magnet and\u201d efficient defenses against adversarial attacks\u201d are not robust to adversarial examples. arXiv preprint arXiv:1711.08478, 2017c.",
            "arxiv_url": "https://arxiv.org/pdf/1711.08478"
        },
        {
            "id": "Carlini_2018_a",
            "entry": "Nicholas Carlini and David Wagner. Audio adversarial examples: Targeted attacks on speech-totext. arXiv preprint arXiv:1801.01944, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1801.01944"
        },
        {
            "id": "Chen_et+al_0000_a",
            "entry": "Hongge Chen, Huan Zhang, Pin-Yu Chen, Jinfeng Yi, and Cho-Jui Hsieh. Show-and-fool: Crafting adversarial examples for neural image captioning. arXiv preprint arXiv:1712.02051, 2017a.",
            "arxiv_url": "https://arxiv.org/pdf/1712.02051"
        },
        {
            "id": "Chen_et+al_0000_b",
            "entry": "Pin-Yu Chen, Yash Sharma, Huan Zhang, Jinfeng Yi, and Cho-Jui Hsieh. Ead: elastic-net attacks to deep neural networks via adversarial examples. arXiv preprint arXiv:1709.04114, 2017b.",
            "arxiv_url": "https://arxiv.org/pdf/1709.04114"
        },
        {
            "id": "Cisse_et+al_2017_a",
            "entry": "Moustapha Cisse, Yossi Adi, Natalia Neverova, and Joseph Keshet. Houdini: Fooling deep structured prediction models. arXiv preprint arXiv:1707.05373, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1707.05373"
        },
        {
            "id": "Dziugaite_et+al_2016_a",
            "entry": "Gintare Karolina Dziugaite, Zoubin Ghahramani, and Daniel M Roy. A study of the effect of jpg compression on adversarial images. arXiv preprint arXiv:1608.00853, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1608.00853"
        },
        {
            "id": "Goodfellow_et+al_2015_a",
            "entry": "Ian Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. In ICLR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Shlens%2C%20Jonathon%20Szegedy%2C%20Christian%20Explaining%20and%20harnessing%20adversarial%20examples%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Shlens%2C%20Jonathon%20Szegedy%2C%20Christian%20Explaining%20and%20harnessing%20adversarial%20examples%202015"
        },
        {
            "id": "Rd_1986_a",
            "entry": "RD Graetz, Roger P Pech, MR Gentle, and JF O\u2019Callaghan. The application of landsat image data to rangeland assessment and monitoring: the development and demonstration of a land image-based resource information system (libris). Rangeland Journal, 1986.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=RD%20Graetz%2C%20Roger%20P%20Pech%2C%20MR%20Gentle%20O%E2%80%99Callaghan%2C%20JF%20The%20application%20of%20landsat%20image%20data%20to%20rangeland%20assessment%20and%20monitoring%3A%20the%20development%20and%20demonstration%20of%20a%20land%20image-based%20resource%20information%20system%20%28libris%29%201986",
            "oa_query": "https://api.scholarcy.com/oa_version?query=RD%20Graetz%2C%20Roger%20P%20Pech%2C%20MR%20Gentle%20O%E2%80%99Callaghan%2C%20JF%20The%20application%20of%20landsat%20image%20data%20to%20rangeland%20assessment%20and%20monitoring%3A%20the%20development%20and%20demonstration%20of%20a%20land%20image-based%20resource%20information%20system%20%28libris%29%201986"
        },
        {
            "id": "Guo_et+al_2017_a",
            "entry": "Chuan Guo, Mayank Rana, Moustapha Cisse, and Laurens van der Maaten. Countering adversarial images using input transformations. arXiv preprint arXiv:1711.00117, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.00117"
        },
        {
            "id": "He_et+al_2017_a",
            "entry": "Warren He, James Wei, Xinyun Chen, Nicholas Carlini, and Dawn Song. Adversarial example defenses: Ensembles of weak defenses are not strong. arXiv preprint arXiv:1706.04701, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.04701"
        },
        {
            "id": "Hinton_et+al_2012_a",
            "entry": "Geoffrey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel-rahman Mohamed, Navdeep Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara N Sainath, et al. Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. IEEE Signal Processing Magazine, 29(6):82\u201397, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hinton%2C%20Geoffrey%20Deng%2C%20Li%20Yu%2C%20Dong%20Dahl%2C%20George%20E.%20Deep%20neural%20networks%20for%20acoustic%20modeling%20in%20speech%20recognition%3A%20The%20shared%20views%20of%20four%20research%20groups%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hinton%2C%20Geoffrey%20Deng%2C%20Li%20Yu%2C%20Dong%20Dahl%2C%20George%20E.%20Deep%20neural%20networks%20for%20acoustic%20modeling%20in%20speech%20recognition%3A%20The%20shared%20views%20of%20four%20research%20groups%202012"
        },
        {
            "id": "Hsu_et+al_2017_a",
            "entry": "Wei Ning Hsu, Yu Zhang, and James Glass. Unsupervised domain adaptation for robust speech recognition via variational autoencoder-based data augmentation. arXiv preprint arXiv:1707.06265, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1707.06265"
        },
        {
            "id": "Iter_et+al_2017_a",
            "entry": "Dan Iter, Jade Huang, and Mike Jermann. Generating adversarial examples for speech recognition. Techcical Report, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Iter%2C%20Dan%20Huang%2C%20Jade%20Jermann%2C%20Mike%20Generating%20adversarial%20examples%20for%20speech%20recognition.%20Techcical%20Report%202017"
        },
        {
            "id": "Kreuk_et+al_2018_a",
            "entry": "Felix Kreuk, Yossi Adi, Moustapha Cisse, and Joseph Keshet. Fooling end-to-end speaker verification by adversarial examples. arXiv preprint arXiv:1801.03339, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1801.03339"
        },
        {
            "id": "Krizhevsky_et+al_2012_a",
            "entry": "Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. ImageNet classification with deep convolutional neural networks. In NIPS, pp. 1097\u20131105, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Hinton%2C%20Geoffrey%20E.%20ImageNet%20classification%20with%20deep%20convolutional%20neural%20networks%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Hinton%2C%20Geoffrey%20E.%20ImageNet%20classification%20with%20deep%20convolutional%20neural%20networks%202012"
        },
        {
            "id": "Levenshtein_1966_a",
            "entry": "V. I Levenshtein. Binary codes capable of correcting deletions, insertions and reversals. Soviet Physics Doklady, 10(1):845\u2013848, 1966.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Levenshtein%2C%20V.I.%20Binary%20codes%20capable%20of%20correcting%20deletions%2C%20insertions%20and%20reversals%201966",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Levenshtein%2C%20V.I.%20Binary%20codes%20capable%20of%20correcting%20deletions%2C%20insertions%20and%20reversals%201966"
        },
        {
            "id": "Levine_et+al_2016_a",
            "entry": "Sergey Levine, Chelsea Finn, Trevor Darrell, and Pieter Abbeel. End-to-end training of deep visuomotor policies. JMLR, 17(39):1\u201340, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Levine%2C%20Sergey%20Finn%2C%20Chelsea%20Darrell%2C%20Trevor%20Abbeel%2C%20Pieter%20End-to-end%20training%20of%20deep%20visuomotor%20policies%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Levine%2C%20Sergey%20Finn%2C%20Chelsea%20Darrell%2C%20Trevor%20Abbeel%2C%20Pieter%20End-to-end%20training%20of%20deep%20visuomotor%20policies%202016"
        },
        {
            "id": "Liu_et+al_2017_a",
            "entry": "Yanpei Liu, Xinyun Chen, Chang Liu, and Dawn Song. Delving into transferable adversarial examples and black-box attacks. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Yanpei%20Chen%2C%20Xinyun%20Liu%2C%20Chang%20Song%2C%20Dawn%20Delving%20into%20transferable%20adversarial%20examples%20and%20black-box%20attacks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Yanpei%20Chen%2C%20Xinyun%20Liu%2C%20Chang%20Song%2C%20Dawn%20Delving%20into%20transferable%20adversarial%20examples%20and%20black-box%20attacks%202017"
        },
        {
            "id": "Lowe_1999_a",
            "entry": "David G Lowe. Object recognition from local scale-invariant features. In Computer vision, 1999. The proceedings of the seventh IEEE international conference on, volume 2, pp. 1150\u20131157.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lowe%2C%20David%20G.%20Object%20recognition%20from%20local%20scale-invariant%20features%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lowe%2C%20David%20G.%20Object%20recognition%20from%20local%20scale-invariant%20features%201999"
        },
        {
            "id": "Lu_et+al_2018_a",
            "entry": "Pei-Hsuan Lu, Pin-Yu Chen, Kang-Cheng Chen, and Chia-Mu Yu. On the limitation of MagNet defense against L1-based adversarial examples. arXiv preprint arXiv:1805.00310, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1805.00310"
        },
        {
            "id": "Luo_et+al_2015_a",
            "entry": "Yan Luo, Xavier Boix, Gemma Roig, Tomaso Poggio, and Qi Zhao. Foveation-based mechanisms alleviate adversarial examples. arXiv preprint arXiv:1511.06292, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06292"
        },
        {
            "id": "Meng_2017_a",
            "entry": "Dongyu Meng and Hao Chen. Magnet: a two-pronged defense against adversarial examples. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 135\u2013147. ACM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Meng%2C%20Dongyu%20Chen%2C%20Hao%20Magnet%3A%20a%20two-pronged%20defense%20against%20adversarial%20examples%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Meng%2C%20Dongyu%20Chen%2C%20Hao%20Magnet%3A%20a%20two-pronged%20defense%20against%20adversarial%20examples%202017"
        },
        {
            "id": "Michelsanti_2017_a",
            "entry": "Daniel Michelsanti and Zheng-Hua Tan. Conditional generative adversarial networks for speech enhancement and noise-robust speaker verification. arXiv preprint arXiv:1709.01703, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1709.01703"
        },
        {
            "id": "Panayotov_et+al_2015_a",
            "entry": "V. Panayotov, G. Chen, D. Povey, and S. Khudanpur. Librispeech: An asr corpus based on public domain audio books. In 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 5206\u20135210, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Panayotov%2C%20V.%20Chen%2C%20G.%20Povey%2C%20D.%20Khudanpur%2C%20S.%20Librispeech%3A%20An%20asr%20corpus%20based%20on%20public%20domain%20audio%20books%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Panayotov%2C%20V.%20Chen%2C%20G.%20Povey%2C%20D.%20Khudanpur%2C%20S.%20Librispeech%3A%20An%20asr%20corpus%20based%20on%20public%20domain%20audio%20books%202015"
        },
        {
            "id": "Serdyuk_et+al_2016_a",
            "entry": "Dmitriy Serdyuk, Kartik Audhkhasi, Philemon Brakel, Bhuvana Ramabhadran, Samuel Thomas, and Yoshua Bengio. Invariant representations for noisy speech recognition. arXiv preprint arXiv:1612.01928, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1612.01928"
        },
        {
            "id": "Sriram_et+al_2017_a",
            "entry": "Anuroop Sriram, Heewoo Jun, Yashesh Gaur, and Sanjeev Satheesh. Robust speech recognition using generative adversarial networks. arXiv preprint arXiv:1711.01567, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.01567"
        },
        {
            "id": "Su_et+al_2018_a",
            "entry": "Dong Su, Huan Zhang, Hongge Chen, Jinfeng Yi, Pin-Yu Chen, and Yupeng Gao. Is robustness the cost of accuracy?\u2013a comprehensive study on the robustness of 18 deep image classification models. arXiv preprint arXiv:1808.01688, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1808.01688"
        },
        {
            "id": "Sun_et+al_2018_a",
            "entry": "Sining Sun, Ching-Feng Yeh, Mari Ostendorf, Mei-Yuh Hwang, and Lei Xie. Data augmentation with adversarial examples for robust speech recognition. ResearchGate, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sun%2C%20Sining%20Yeh%2C%20Ching-Feng%20Ostendorf%2C%20Mari%20Hwang%2C%20Mei-Yuh%20Data%20augmentation%20with%20adversarial%20examples%20for%20robust%20speech%20recognition%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sun%2C%20Sining%20Yeh%2C%20Ching-Feng%20Ostendorf%2C%20Mari%20Hwang%2C%20Mei-Yuh%20Data%20augmentation%20with%20adversarial%20examples%20for%20robust%20speech%20recognition%202018"
        },
        {
            "id": "Szegedy_et+al_2014_a",
            "entry": "Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. Intriguing properties of neural networks. In ICLR, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szegedy%2C%20Christian%20Zaremba%2C%20Wojciech%20Sutskever%2C%20Ilya%20Bruna%2C%20Joan%20Intriguing%20properties%20of%20neural%20networks%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Szegedy%2C%20Christian%20Zaremba%2C%20Wojciech%20Sutskever%2C%20Ilya%20Bruna%2C%20Joan%20Intriguing%20properties%20of%20neural%20networks%202014"
        },
        {
            "id": "Qinglong_2016_a",
            "entry": "Qinglong Wang, Wenbo Guo, II Ororbia, G Alexander, Xinyu Xing, Lin Lin, C Lee Giles, Xue Liu, Peng Liu, and Gang Xiong. Using non-invertible data transformations to build adversarial-robust neural networks. arXiv preprint arXiv:1610.01934, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1610.01934"
        },
        {
            "id": "Warden_2018_a",
            "entry": "Pete Warden. Speech commands: A dataset for limited-vocabulary speech recognition. arXiv preprint arXiv:1804.03209, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.03209"
        },
        {
            "id": "Xu_et+al_2017_a",
            "entry": "Weilin Xu, David Evans, and Yanjun Qi. Feature squeezing: Detecting adversarial examples in deep neural networks. arXiv preprint arXiv:1704.01155, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.01155"
        },
        {
            "id": "Yuan_et+al_2018_a",
            "entry": "Xuejing Yuan, Yuxuan Chen, Yue Zhao, Yunhui Long, Xiaokang Liu, Kai Chen, Shengzhi Zhang, Heqing Huang, Xiaofeng Wang, and Carl A Gunter. Commandersong: A systematic approach for practical adversarial voice recognition. arXiv preprint arXiv:1801.08535, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1801.08535"
        }
    ]
}

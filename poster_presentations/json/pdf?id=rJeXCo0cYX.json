{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "BABYAI: A PLATFORM TO STUDY THE SAMPLE EFFICIENCY OF GROUNDED LANGUAGE LEARNING",
        "author": "Maxime Chevalier-Boisvert, Mila, Universit\u00e9 de Montr\u00e9al",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=rJeXCo0cYX"
        },
        "abstract": "Allowing humans to interactively train artificial agents to understand language instructions is desirable for both practical and scientific reasons. Though, given the lack of sample efficiency in current learning methods, reaching this goal may require substantial research efforts. We introduce the BabyAI research platform, with the goal of supporting investigations towards including humans in the loop for grounded language learning. The BabyAI platform comprises an extensible suite of 19 levels of increasing difficulty. Each level gradually leads the agent towards acquiring a combinatorially rich synthetic language, which is a proper subset of English. The platform also provides a hand-crafted bot agent, which simulates a human teacher. We report estimated amount of supervision required for training neural reinforcement and behavioral-cloning agents on some BabyAI levels. We put forward strong evidence that current deep learning methods are not yet sufficiently sample-efficient in the context of learning a language with compositional properties."
    },
    "keywords": [
        {
            "term": "Backus-Naur Form",
            "url": "https://en.wikipedia.org/wiki/Backus-Naur_Form"
        },
        {
            "term": "language learning",
            "url": "https://en.wikipedia.org/wiki/language_learning"
        },
        {
            "term": "natural language",
            "url": "https://en.wikipedia.org/wiki/natural_language"
        }
    ],
    "abbreviations": {
        "BNF": "Backus-Naur Form",
        "ROOM": "Room Navigation",
        "MAZE": "Maze Navigation",
        "UNBLOCK": "Unblocking the Way",
        "UNLOCK": "Unlocking Doors",
        "GOTO": "Go To Instructions",
        "OPEN": "Open Instructions",
        "PUT": "Put Instructions",
        "SEQ": "Sequences of Commands",
        "IL": "imitation learning"
    },
    "highlights": [
        "How can a human train an intelligent agent to understand natural language instructions? We believe that this research question is important from both technological and scientific perspectives",
        "Developmental psychology, cognitive science and linguistics study similar questions but applied to human children, and a synergy is possible between research in grounded language learning by computers and research in human language acquisition",
        "We present the BabyAI research platform, whose purpose is to facilitate research on grounded language learning",
        "The models were trained for 80 epochs on levels with a single room and for 20 epochs on levels with a 3x3 maze of rooms",
        "In the same table we report the number of episodes that were required for reinforcement learning to solve each of these levels, and as expected, the sample efficiency of RL is substantially worse than that of imitation learning",
        "We present the BabyAI research platform to study language learning with a human in the loop"
    ],
    "key_statements": [
        "How can a human train an intelligent agent to understand natural language instructions? We believe that this research question is important from both technological and scientific perspectives",
        "Developmental psychology, cognitive science and linguistics study similar questions but applied to human children, and a synergy is possible between research in grounded language learning by computers and research in human language acquisition",
        "We present the BabyAI research platform, whose purpose is to facilitate research on grounded language learning",
        "The usefulness of curriculum learning for training machine learning models has been demonstrated numerous times in the literature (<a class=\"ref-link\" id=\"cBengio_et+al_2009_a\" href=\"#rBengio_et+al_2009_a\">Bengio et al, 2009</a>; <a class=\"ref-link\" id=\"cKumar_et+al_2010_a\" href=\"#rKumar_et+al_2010_a\">Kumar et al, 2010</a>; Zaremba and Sutskever, 2015; <a class=\"ref-link\" id=\"cGraves_et+al_2016_a\" href=\"#rGraves_et+al_2016_a\">Graves et al, 2016</a>), and we believe that gradually increasing the difficulty of the task will likely be essential for achieving efficient humanmachine teaching, as in the case of human-human teaching",
        "Interactive teaching, i.e. teaching differently based on what the learner can currently achieve, is another key capability of human teachers",
        "Note that the GoToObj level does not require the Go To Instructions competency, as this level can be solved without any language understanding, since there is only a single object in the room",
        "The models were trained for 80 epochs on levels with a single room and for 20 epochs on levels with a 3x3 maze of rooms",
        "All of the single-room levels are solved with a success rate of 100.0%",
        "In the same table we report the number of episodes that were required for reinforcement learning to solve each of these levels, and as expected, the sample efficiency of RL is substantially worse than that of imitation learning",
        "We present the BabyAI research platform to study language learning with a human in the loop"
    ],
    "summary": [
        "How can a human train an intelligent agent to understand natural language instructions? We believe that this research question is important from both technological and scientific perspectives.",
        "To facilitate curriculum learning studies, BabyAI currently features 19 levels in which the difficulty of the environment configuration and the complexity of the instruction language are gradually increased.",
        "We estimate the number of demonstrations/episodes required to solve several levels with imitation and reinforcement learning baselines.",
        "We contribute the BabyAI research platform for learning to perform language instructions with a simulated human in the loop.",
        "We hope that BabyAI will spur further research towards improving sample efficiency of grounded language learning, allowing human-in-the-loop training.",
        "The BabyAI platform that we present in this work comprises an efficiently simulated gridworld environment (MiniGrid) and a number of instruction-following tasks that we call levels, all formulated using subsets of a synthetic language (Baby Language).",
        "To investigate how a curriculum improves sample efficiency, we created 19 levels which require understanding only a limited subset of Baby Language within environments of varying complexity.",
        "Note that the GoToObj level does not require the GOTO competency, as this level can be solved without any language understanding, since there is only a single object in the room.",
        "Solving the GoToLocal level, which instructs the agent to go to a specific object in the presence of multiple distractors, requires understanding GOTO instructions.",
        "To bootstrap such studies we have computed baseline sample efficiencies for imitation learning and reinforcement learning approaches to solving BabyAI levels.",
        "We define the sample efficiency as the minimum number of demonstrations or RL episodes required to train an agent solve a given level.",
        "In the same table we report the number of episodes that were required for reinforcement learning to solve each of these levels, and as expected, the sample efficiency of RL is substantially worse than that of IL.",
        "To demonstrate how curriculum learning research can be done using the BabyAI platform, we perform a number of basic pretraining experiments.",
        "We perform an example case study of how sample efficiency can be improved by interactively providing more informative examples to the agent based on what it has already learned.",
        "We repeat such an experiment 4 times for levels GoToRedBallGrey, GoToRedBall and GoToLocal and report the maximum and the minimum sample efficiency for this approach, which we call interactive imitation learning, in Table 5.",
        "We present the BabyAI research platform to study language learning with a human in the loop.",
        "The platform is open source and extensible, meaning new levels and language concepts can be integrated"
    ],
    "headline": "We introduce the BabyAI research platform, with the goal of supporting investigations towards including humans in the loop for grounded language learning",
    "reference_links": [
        {
            "id": "Anderson_et+al_2018_a",
            "entry": "Anderson, P., Wu, Q., Teney, D., Bruce, J., Johnson, M., S\u00fcnderhauf, N., Reid, I., Gould, S., and Hengel, A. v. d. (2018). Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments. In Proceedings of the 2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Anderson%2C%20P.%20Wu%2C%20Q.%20Teney%2C%20D.%20Bruce%2C%20J.%20Vision-and-Language%20Navigation%3A%20Interpreting%20visually-grounded%20navigation%20instructions%20in%20real%20environments%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Anderson%2C%20P.%20Wu%2C%20Q.%20Teney%2C%20D.%20Bruce%2C%20J.%20Vision-and-Language%20Navigation%3A%20Interpreting%20visually-grounded%20navigation%20instructions%20in%20real%20environments%202018"
        },
        {
            "id": "Andreas_et+al_2016_a",
            "entry": "Andreas, J., Rohrbach, M., Darrell, T., and Klein, D. (2016). Neural Module Networks. In Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Andreas%2C%20J.%20Rohrbach%2C%20M.%20Darrell%2C%20T.%20Klein%2C%20D.%20Neural%20Module%20Networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Andreas%2C%20J.%20Rohrbach%2C%20M.%20Darrell%2C%20T.%20Klein%2C%20D.%20Neural%20Module%20Networks%202016"
        },
        {
            "id": "Artzi_2013_a",
            "entry": "Artzi, Y. and Zettlemoyer, L. (2013). Weakly supervised learning of semantic parsers for mapping instructions to actions. Transactions of the Association for Computational Linguistics, 1:49\u201362.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Artzi%2C%20Y.%20Zettlemoyer%2C%20L.%20Weakly%20supervised%20learning%20of%20semantic%20parsers%20for%20mapping%20instructions%20to%20actions%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Artzi%2C%20Y.%20Zettlemoyer%2C%20L.%20Weakly%20supervised%20learning%20of%20semantic%20parsers%20for%20mapping%20instructions%20to%20actions%202013"
        },
        {
            "id": "Bahdanau_et+al_2015_a",
            "entry": "Bahdanau, D., Cho, K., and Bengio, Y. (2015). Neural Machine Translation by Jointly Learning to Align and Translate. In Proceedings of the 2015 International Conference on Learning Representations.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bahdanau%2C%20D.%20Cho%2C%20K.%20Bengio%2C%20Y.%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bahdanau%2C%20D.%20Cho%2C%20K.%20Bengio%2C%20Y.%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate%202015"
        },
        {
            "id": "Bahdanau_et+al_2018_a",
            "entry": "Bahdanau, D., Hill, F., Leike, J., Hughes, E., Kohli, P., and Grefenstette, E. (2018). Learning to Follow Language Instructions with Adversarial Reward Induction. arXiv:1806.01946 [cs]. arXiv: 1806.01946.",
            "arxiv_url": "https://arxiv.org/pdf/1806.01946"
        },
        {
            "id": "Bellemare_et+al_2013_a",
            "entry": "Bellemare, M. G., Naddaf, Y., Veness, J., and Bowling, M. (2013). The Arcade Learning Environment: An Evaluation Platform for General Agents. Journal of Artificial Intelligence Research, 47:253\u2013279. arXiv: 1207.4708.",
            "arxiv_url": "https://arxiv.org/pdf/1207.4708"
        },
        {
            "id": "Bengio_et+al_2009_a",
            "entry": "Bengio, Y., Louradour, J., Collobert, R., and Weston, J. (2009). Curriculum learning. In Proceedings of the 26th annual international conference on machine learning, pages 41\u201348.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bengio%2C%20Y.%20Louradour%2C%20J.%20Collobert%2C%20R.%20Weston%2C%20J.%20Curriculum%20learning%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bengio%2C%20Y.%20Louradour%2C%20J.%20Collobert%2C%20R.%20Weston%2C%20J.%20Curriculum%20learning%202009"
        },
        {
            "id": "Chaplot_et+al_2018_a",
            "entry": "Chaplot, D. S., Sathyendra, K. M., Pasumarthi, R. K., Rajagopal, D., and Salakhutdinov, R. (2018). Gated-Attention Architectures for Task-Oriented Language Grounding. In Proceedings of 32nd AAAI Conference on Artificial Intelligence.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chaplot%2C%20D.S.%20Sathyendra%2C%20K.M.%20Pasumarthi%2C%20R.K.%20Rajagopal%2C%20D.%20Gated-Attention%20Architectures%20for%20Task-Oriented%20Language%20Grounding%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chaplot%2C%20D.S.%20Sathyendra%2C%20K.M.%20Pasumarthi%2C%20R.K.%20Rajagopal%2C%20D.%20Gated-Attention%20Architectures%20for%20Task-Oriented%20Language%20Grounding%202018"
        },
        {
            "id": "Chen_2011_a",
            "entry": "Chen, D. L. and Mooney, R. J. (2011). Learning to Interpret Natural Language Navigation Instructions from Observations. In Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence, pages 859\u2013865.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20D.L.%20Mooney%2C%20R.J.%20Learning%20to%20Interpret%20Natural%20Language%20Navigation%20Instructions%20from%20Observations%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20D.L.%20Mooney%2C%20R.J.%20Learning%20to%20Interpret%20Natural%20Language%20Navigation%20Instructions%20from%20Observations%202011"
        },
        {
            "id": "Cho_et+al_2014_a",
            "entry": "Cho, K., van Merrienboer, B., Gulcehre, C., Bougares, F., Schwenk, H., and Bengio, Y. (2014). Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cho%2C%20K.%20van%20Merrienboer%2C%20B.%20Gulcehre%2C%20C.%20Bougares%2C%20F.%20Learning%20Phrase%20Representations%20using%20RNN%20Encoder-Decoder%20for%20Statistical%20Machine%20Translation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cho%2C%20K.%20van%20Merrienboer%2C%20B.%20Gulcehre%2C%20C.%20Bougares%2C%20F.%20Learning%20Phrase%20Representations%20using%20RNN%20Encoder-Decoder%20for%20Statistical%20Machine%20Translation%202014"
        },
        {
            "id": "Christiano_et+al_2017_a",
            "entry": "Christiano, P., Leike, J., Brown, T. B., Martic, M., Legg, S., and Amodei, D. (2017). Deep reinforcement learning from human preferences. In Advances in Neural Information Processing Systems 30. arXiv: 1706.03741.",
            "arxiv_url": "https://arxiv.org/pdf/1706.03741"
        },
        {
            "id": "Daum_et+al_2009_a",
            "entry": "Daum\u00e9 Iii, H., Langford, J., and Marcu, D. (2009). Search-based structured prediction. Machine learning, 75(3):297\u2013325.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Daum%C3%A9%20Iii%2C%20H.%20Langford%2C%20J.%20Marcu%2C%20D.%20Search-based%20structured%20prediction%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Daum%C3%A9%20Iii%2C%20H.%20Langford%2C%20J.%20Marcu%2C%20D.%20Search-based%20structured%20prediction%202009"
        },
        {
            "id": "DeepMind_2017_a",
            "entry": "DeepMind (2017). PycoLab.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=DeepMind%202017%20PycoLab"
        },
        {
            "id": "Espeholt_et+al_2018_a",
            "entry": "Espeholt, L., Soyer, H., Munos, R., Simonyan, K., Mnih, V., Ward, T., Doron, Y., Firoiu, V., Harley, T., Dunning, I., Legg, S., and Kavukcuoglu, K. (2018). IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures. In Proceedings of the 22nd international conference on Machine learning. arXiv: 1802.01561.",
            "arxiv_url": "https://arxiv.org/pdf/1802.01561"
        },
        {
            "id": "Graves_et+al_2016_a",
            "entry": "Graves, A., Wayne, G., Reynolds, M., Harley, T., Danihelka, I., Grabska-Barwinska, A., Colmenarejo, S. G., Grefenstette, E., Ramalho, T., Agapiou, J., Badia, A. P., Hermann, K. M., Zwols, Y., Ostrovski, G., Cain, A., King, H., Summerfield, C., Blunsom, P., Kavukcuoglu, K., and Hassabis, D. (2016). Hybrid computing using a neural network with dynamic external memory. Nature, 538(7626):471\u2013476.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Graves%2C%20A.%20Wayne%2C%20G.%20Reynolds%2C%20M.%20Harley%2C%20T.%20Hybrid%20computing%20using%20a%20neural%20network%20with%20dynamic%20external%20memory%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Graves%2C%20A.%20Wayne%2C%20G.%20Reynolds%2C%20M.%20Harley%2C%20T.%20Hybrid%20computing%20using%20a%20neural%20network%20with%20dynamic%20external%20memory%202016"
        },
        {
            "id": "Hermann_et+al_2017_a",
            "entry": "Hermann, K. M., Hill, F., Green, S., Wang, F., Faulkner, R., Soyer, H., Szepesvari, D., Czarnecki, W. M., Jaderberg, M., Teplyashin, D., Wainwright, M., Apps, C., Hassabis, D., and Blunsom, P. (2017). Grounded Language Learning in a Simulated 3d World. arXiv:1706.06551 [cs, stat].",
            "arxiv_url": "https://arxiv.org/pdf/1706.06551"
        },
        {
            "id": "Hochreiter_1997_a",
            "entry": "Hochreiter, S. and Schmidhuber, J. (1997). Long Short-Term Memory. Neural Computation, 9(8):1735\u20131780.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hochreiter%2C%20S.%20Schmidhuber%2C%20J.%20Long%20Short-Term%20Memory%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hochreiter%2C%20S.%20Schmidhuber%2C%20J.%20Long%20Short-Term%20Memory%201997"
        },
        {
            "id": "Ioffe_2015_a",
            "entry": "Ioffe, S. and Szegedy, C. (2015). Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. In Proceedings of the 32nd International Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015, pages 448\u2013456.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ioffe%2C%20S.%20Szegedy%2C%20C.%20Batch%20Normalization%3A%20Accelerating%20Deep%20Network%20Training%20by%20Reducing%20Internal%20Covariate%20Shift%202015-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ioffe%2C%20S.%20Szegedy%2C%20C.%20Batch%20Normalization%3A%20Accelerating%20Deep%20Network%20Training%20by%20Reducing%20Internal%20Covariate%20Shift%202015-07"
        },
        {
            "id": "Kempka_et+al_2016_a",
            "entry": "Kempka, M., Wydmuch, M., Runc, G., Toczek, J., and Jaskowski, W. (2016). ViZDoom: A Doombased AI research platform for visual reinforcement learning. In CIG, pages 1\u20138. IEEE.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kempka%2C%20M.%20Wydmuch%2C%20M.%20Runc%2C%20G.%20Toczek%2C%20J.%20ViZDoom%3A%20A%20Doombased%20AI%20research%20platform%20for%20visual%20reinforcement%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kempka%2C%20M.%20Wydmuch%2C%20M.%20Runc%2C%20G.%20Toczek%2C%20J.%20ViZDoom%3A%20A%20Doombased%20AI%20research%20platform%20for%20visual%20reinforcement%20learning%202016"
        },
        {
            "id": "Kingma_2015_a",
            "entry": "Kingma, D. P. and Ba, J. (2015). Adam: A Method for Stochastic Optimization. In Proceedings of the 2015 International Conference on Learning Representations. arXiv: 1412.6980.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6980"
        },
        {
            "id": "Koenig_2004_a",
            "entry": "Koenig, N. and Howard, A. (2004). Design and Use Paradigms for Gazebo, An Open-Source MultiRobot Simulator. In IEEE/RSJ International Conference on Intelligent Robots and Systems, pages 2149\u20132154, Sendai, Japan.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Koenig%2C%20N.%20Howard%2C%20A.%20Design%20and%20Use%20Paradigms%20for%20Gazebo%2C%20An%20Open-Source%20MultiRobot%20Simulator%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Koenig%2C%20N.%20Howard%2C%20A.%20Design%20and%20Use%20Paradigms%20for%20Gazebo%2C%20An%20Open-Source%20MultiRobot%20Simulator%202004"
        },
        {
            "id": "Kolve_et+al_2017_a",
            "entry": "Kolve, E., Mottaghi, R., Gordon, D., Zhu, Y., Gupta, A., and Farhadi, A. (2017). AI2-THOR: An Interactive 3d Environment for Visual AI. CoRR, abs/1712.05474.",
            "arxiv_url": "https://arxiv.org/pdf/1712.05474"
        },
        {
            "id": "Kumar_et+al_2010_a",
            "entry": "Kumar, M. P., Packer, B., and Koller, D. (2010). Self-Paced Learning for Latent Variable Models. In Advances in Neural Information Processing Systems 23, pages 1189\u20131197. Curran Associates, Inc.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kumar%2C%20M.P.%20Packer%2C%20B.%20Koller%2C%20D.%20Self-Paced%20Learning%20for%20Latent%20Variable%20Models%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kumar%2C%20M.P.%20Packer%2C%20B.%20Koller%2C%20D.%20Self-Paced%20Learning%20for%20Latent%20Variable%20Models%202010"
        },
        {
            "id": "Macmahon_et+al_2006_a",
            "entry": "Macmahon, M., Stankiewicz, B., and Kuipers, B. (2006). Walk the Talk: Connecting Language, Knowledge, Action in Route Instructions. In In Proc. of the Nat. Conf. on Artificial Intelligence (AAAI, pages 1475\u20131482.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Macmahon%2C%20M.%20Stankiewicz%2C%20B.%20Kuipers%2C%20B.%20Walk%20the%20Talk%3A%20Connecting%20Language%2C%20Knowledge%2C%20Action%20in%20Route%20Instructions%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Macmahon%2C%20M.%20Stankiewicz%2C%20B.%20Kuipers%2C%20B.%20Walk%20the%20Talk%3A%20Connecting%20Language%2C%20Knowledge%2C%20Action%20in%20Route%20Instructions%202006"
        },
        {
            "id": "Mei_et+al_2016_a",
            "entry": "Mei, H., Bansal, M., and Walter, M. R. (2016). Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to Action Sequences. In Proceedings of the 2016 AAAI Conference on Artificial Intelligence.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mei%20H%20Bansal%20M%20and%20Walter%20M%20R%202016%20Listen%20Attend%20and%20Walk%20Neural%20Mapping%20of%20Navigational%20Instructions%20to%20Action%20Sequences%20In%20Proceedings%20of%20the%202016%20AAAI%20Conference%20on%20Artificial%20Intelligence",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mei%20H%20Bansal%20M%20and%20Walter%20M%20R%202016%20Listen%20Attend%20and%20Walk%20Neural%20Mapping%20of%20Navigational%20Instructions%20to%20Action%20Sequences%20In%20Proceedings%20of%20the%202016%20AAAI%20Conference%20on%20Artificial%20Intelligence"
        },
        {
            "id": "Perez_et+al_2017_a",
            "entry": "Perez, E., Strub, F., de Vries, H., Dumoulin, V., and Courville, A. (2017). FiLM: Visual Reasoning with a General Conditioning Layer. In In Proceedings of the 2017 AAAI Conference on Artificial Intelligence.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Perez%2C%20E.%20Strub%2C%20F.%20de%20Vries%2C%20H.%20Dumoulin%2C%20V.%20FiLM%3A%20Visual%20Reasoning%20with%20a%20General%20Conditioning%20Layer%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Perez%2C%20E.%20Strub%2C%20F.%20de%20Vries%2C%20H.%20Dumoulin%2C%20V.%20FiLM%3A%20Visual%20Reasoning%20with%20a%20General%20Conditioning%20Layer%202017"
        },
        {
            "id": "Reed_2015_a",
            "entry": "Reed, S. and de Freitas, N. (2015). Neural Programmer-Interpreters. In 2016 International Conference on Learning Representations. arXiv: 1511.06279.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06279"
        },
        {
            "id": "Ross_et+al_2011_a",
            "entry": "Ross, S., Gordon, G., and Bagnell, D. (2011). A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning. In PMLR, pages 627\u2013635.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ross%2C%20S.%20Gordon%2C%20G.%20Bagnell%2C%20D.%20A%20Reduction%20of%20Imitation%20Learning%20and%20Structured%20Prediction%20to%20No-Regret%20Online%20Learning%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ross%2C%20S.%20Gordon%2C%20G.%20Bagnell%2C%20D.%20A%20Reduction%20of%20Imitation%20Learning%20and%20Structured%20Prediction%20to%20No-Regret%20Online%20Learning%202011"
        },
        {
            "id": "Schulman_et+al_2015_a",
            "entry": "Schulman, J., Moritz, P., Levine, S., Jordan, M., and Abbeel, P. (2015). High-Dimensional Continuous Control Using Generalized Advantage Estimation. In Advances in Neural Information Processing Systems 30.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schulman%2C%20J.%20Moritz%2C%20P.%20Levine%2C%20S.%20Jordan%2C%20M.%20High-Dimensional%20Continuous%20Control%20Using%20Generalized%20Advantage%20Estimation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schulman%2C%20J.%20Moritz%2C%20P.%20Levine%2C%20S.%20Jordan%2C%20M.%20High-Dimensional%20Continuous%20Control%20Using%20Generalized%20Advantage%20Estimation%202015"
        },
        {
            "id": "Schulman_et+al_2017_a",
            "entry": "Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O. (2017). Proximal Policy Optimization Algorithms. arXiv:1707.06347 [cs]. arXiv: 1707.06347.",
            "arxiv_url": "https://arxiv.org/pdf/1707.06347"
        },
        {
            "id": "Sukhbaatar_et+al_2015_a",
            "entry": "Sukhbaatar, S., Szlam, A., Synnaeve, G., Chintala, S., and Fergus, R. (2015). MazeBase: A Sandbox for Learning from Games. arXiv:1511.07401 [cs]. arXiv: 1511.07401.",
            "arxiv_url": "https://arxiv.org/pdf/1511.07401"
        },
        {
            "id": "Sutskever_et+al_2014_a",
            "entry": "Sutskever, I., Vinyals, O., and Le, Q. V. (2014). Sequence to Sequence Learning with Neural Networks. In Advances in Neural Information Processing Systems 27, pages 3104\u20133112.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sutskever%2C%20I.%20Vinyals%2C%20O.%20Le%2C%20Q.V.%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sutskever%2C%20I.%20Vinyals%2C%20O.%20Le%2C%20Q.V.%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks%202014"
        },
        {
            "id": "Tellex_et+al_2011_a",
            "entry": "Tellex, S., Kollar, T., Dickerson, S., Walter, M. R., Banerjee, A. G., Teller, S., and Roy, N. (2011). Understanding Natural Language Commands for Robotic Navigation and Mobile Manipulation. In Twenty-Fifth AAAI Conference on Artificial Intelligence.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tellex%2C%20S.%20Kollar%2C%20T.%20Dickerson%2C%20S.%20Walter%2C%20M.R.%20Understanding%20Natural%20Language%20Commands%20for%20Robotic%20Navigation%20and%20Mobile%20Manipulation%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tellex%2C%20S.%20Kollar%2C%20T.%20Dickerson%2C%20S.%20Walter%2C%20M.R.%20Understanding%20Natural%20Language%20Commands%20for%20Robotic%20Navigation%20and%20Mobile%20Manipulation%202011"
        },
        {
            "id": "Wang_et+al_2016_a",
            "entry": "Wang, S. I., Liang, P., and Manning, C. D. (2016). Learning Language Games through Interaction. In Proceedings Of the 54th Annual Meeting of the Association for Computational Linguistics. arXiv: 1606.02447.",
            "arxiv_url": "https://arxiv.org/pdf/1606.02447"
        },
        {
            "id": "Warnell_et+al_2017_a",
            "entry": "Warnell, G., Waytowich, N., Lawhern, V., and Stone, P. (2017). Deep TAMER: Interactive Agent Shaping in High-Dimensional State Spaces. In Proceedings of 32nd AAAI Conference on Artificial Intelligence. arXiv: 1709.10163.",
            "arxiv_url": "https://arxiv.org/pdf/1709.10163"
        },
        {
            "id": "Weston_et+al_2016_a",
            "entry": "Weston, J., Bordes, A., Chopra, S., Rush, A. M., van Merri\u00ebnboer, B., Joulin, A., and Mikolov, T. (2016). Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Weston%2C%20J.%20Bordes%2C%20A.%20Chopra%2C%20S.%20Rush%2C%20A.M.%20Towards%20AI-Complete%20Question%20Answering%3A%20A%20Set%20of%20Prerequisite%20Toy%20Tasks%202016"
        },
        {
            "id": "Williams_et+al_2018_a",
            "entry": "Williams, E. C., Gopalan, N., Rhee, M., and Tellex, S. (2018). Learning to Parse Natural Language to Grounded Reward Functions with Weak Supervision. In 2018 IEEE International Conference on Robotics and Automation, ICRA 2018, Brisbane, Australia, May 21-25, 2018, pages 1\u20137.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Williams%2C%20E.C.%20Gopalan%2C%20N.%20Rhee%2C%20M.%20Tellex%2C%20S.%20Learning%20to%20Parse%20Natural%20Language%20to%20Grounded%20Reward%20Functions%20with%20Weak%20Supervision%202018-05-21",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Williams%2C%20E.C.%20Gopalan%2C%20N.%20Rhee%2C%20M.%20Tellex%2C%20S.%20Learning%20to%20Parse%20Natural%20Language%20to%20Grounded%20Reward%20Functions%20with%20Weak%20Supervision%202018-05-21"
        },
        {
            "id": "Wilson_et+al_2012_a",
            "entry": "Wilson, A., Fern, A., and Tadepalli, P. (2012). A Bayesian Approach for Policy Learning from Trajectory Preference Queries. In Pereira, F., Burges, C. J. C., Bottou, L., and Weinberger, K. Q., editors, Advances in Neural Information Processing Systems 25, pages 1133\u20131141. Curran Associates, Inc.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wilson%2C%20A.%20Fern%2C%20A.%20Tadepalli%2C%20P.%20A%20Bayesian%20Approach%20for%20Policy%20Learning%20from%20Trajectory%20Preference%20Queries%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wilson%2C%20A.%20Fern%2C%20A.%20Tadepalli%2C%20P.%20A%20Bayesian%20Approach%20for%20Policy%20Learning%20from%20Trajectory%20Preference%20Queries%202012"
        },
        {
            "id": "Wu_et+al_2016_a",
            "entry": "Wu, Y., Schuster, M., Chen, Z., Le, Q. V., Norouzi, M., Macherey, W., Krikun, M., Cao, Y., Gao, Q., Macherey, K., and others (2016). Google\u2019s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation. arXiv preprint arXiv:1609.08144.",
            "arxiv_url": "https://arxiv.org/pdf/1609.08144"
        },
        {
            "id": "Wu_et+al_2019_a",
            "entry": "Published as a conference paper at ICLR 2019 Wu, Y., Wu, Y., Gkioxari, G., and Tian, Y. (2018). Building Generalizable Agents with a Realistic and Rich 3d Environment. arXiv:1801.02209 [cs]. arXiv: 1801.02209.",
            "arxiv_url": "https://arxiv.org/pdf/1801.02209"
        },
        {
            "id": "Yu_et+al_2018_a",
            "entry": "Yu, H., Zhang, H., and Xu, W. (2018). Interactive Grounded Language Acquisition and Generalization in 2d Environment. In ICLR. Zaremba, W. and Sutskever, I. (2015). Learning to Execute. In 2015 International Conference on",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yu%2C%20H.%20Zhang%2C%20H.%20Xu%2C%20W.%20Interactive%20Grounded%20Language%20Acquisition%20and%20Generalization%20in%202d%20Environment%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yu%2C%20H.%20Zhang%2C%20H.%20Xu%2C%20W.%20Interactive%20Grounded%20Language%20Acquisition%20and%20Generalization%20in%202d%20Environment%202018"
        },
        {
            "id": "Ziebart_et+al_2008_a",
            "entry": "Ziebart, B. D., Maas, A., Bagnell, J. A., and Dey, A. K. (2008). Maximum Entropy Inverse Reinforcement Learning. In Proc. AAAI, pages 1433\u20131438.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ziebart%2C%20B.D.%20Maas%2C%20A.%20Bagnell%2C%20J.A.%20Dey%2C%20A.K.%20Maximum%20Entropy%20Inverse%20Reinforcement%20Learning%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ziebart%2C%20B.D.%20Maas%2C%20A.%20Bagnell%2C%20J.A.%20Dey%2C%20A.K.%20Maximum%20Entropy%20Inverse%20Reinforcement%20Learning%202008"
        }
    ]
}

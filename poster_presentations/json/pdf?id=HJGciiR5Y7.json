{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "LATENT CONVOLUTIONAL MODELS",
        "author": "ShahRukh Athar",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=HJGciiR5Y7"
        },
        "abstract": "We present a new latent model of natural images that can be learned on large-scale datasets. The learning process provides a latent embedding for every image in the training dataset, as well as a deep convolutional network that maps the latent space to the image space. After training, the new model provides a strong and universal image prior for a variety of image restoration tasks such as large-hole inpainting, superresolution, and colorization. To model high-resolution natural images, our approach uses latent spaces of very high dimensionality (one to two orders of magnitude higher than previous latent image models). To tackle this high dimensionality, we use latent spaces with a special manifold structure (convolutional manifolds) parameterized by a ConvNet of a certain architecture. In the experiments, we compare the learned latent models with latent models learned by autoencoders, advanced variants of generative adversarial networks, and a strong baseline system using simpler parameterization of the latent space. Our model outperforms the competing approaches over a range of restoration tasks."
    },
    "keywords": [
        {
            "term": "high resolution",
            "url": "https://en.wikipedia.org/wiki/high_resolution"
        },
        {
            "term": "image space",
            "url": "https://en.wikipedia.org/wiki/image_space"
        },
        {
            "term": "generative adversarial networks",
            "url": "https://en.wikipedia.org/wiki/generative_adversarial_networks"
        },
        {
            "term": "mean squared error",
            "url": "https://en.wikipedia.org/wiki/mean_squared_error"
        },
        {
            "term": "learning process",
            "url": "https://en.wikipedia.org/wiki/learning_process"
        }
    ],
    "abbreviations": {
        "GANs": "generative adversarial networks",
        "PGAN": "Progressive GAN",
        "MSE": "mean squared error"
    },
    "highlights": [
        "Learning good image priors is one of the core problems of computer vision and machine learning",
        "One promising approach to obtaining such priors is to learn a deep latent model, where the set of natural images is parameterized by a certain simple-structured set or probabilistic distribution, whereas the complexity of natural images is tackled by a deep ConvNet that maps from the latent space into the space of images",
        "Given a good deep latent model, virtually any image restoration task can be solved by finding a latent representation that best corresponds to the image evidence",
        "We show that training such latent models is possible using direct optimization (<a class=\"ref-link\" id=\"cBojanowski_et+al_2018_a\" href=\"#rBojanowski_et+al_2018_a\">Bojanowski et al, 2018</a>) and that it leads to good image priors that can be used across a broad variety of reconstruction tasks",
        "The results of the comparison are summarized in Figure 3 and Table 1 with representative examples shown in Figure 4 and Figure 5. \u201cTraditional\u201d latent models performed poorly",
        "The results in this work suggest that high-dimensional latent spaces are necessary to get good image reconstructions on desired hold-out sets"
    ],
    "key_statements": [
        "Learning good image priors is one of the core problems of computer vision and machine learning",
        "One promising approach to obtaining such priors is to learn a deep latent model, where the set of natural images is parameterized by a certain simple-structured set or probabilistic distribution, whereas the complexity of natural images is tackled by a deep ConvNet that maps from the latent space into the space of images",
        "Given a good deep latent model, virtually any image restoration task can be solved by finding a latent representation that best corresponds to the image evidence",
        "We argue that it is the limited dimensionality of the latent space in generative adversarial networks and other existing latent models that precludes them from spanning the space of high-resolution natural images",
        "We show that training such latent models is possible using direct optimization (<a class=\"ref-link\" id=\"cBojanowski_et+al_2018_a\" href=\"#rBojanowski_et+al_2018_a\">Bojanowski et al, 2018</a>) and that it leads to good image priors that can be used across a broad variety of reconstruction tasks",
        "Our experiments are performed on CelebA (<a class=\"ref-link\" id=\"cLiu_et+al_2015_a\" href=\"#rLiu_et+al_2015_a\">Liu et al, 2015</a>) (128x128 resolution), SUN Bedrooms (<a class=\"ref-link\" id=\"cYu_et+al_2015_a\" href=\"#rYu_et+al_2015_a\">Yu et al, 2015</a>) (256x256 resolution), CelebA-HQ (<a class=\"ref-link\" id=\"cKarras_et+al_2018_a\" href=\"#rKarras_et+al_2018_a\">Karras et al, 2018</a>) (1024x1024 resolution) datasets, and we demonstrate that the latent models, once trained, can be applied to large hole inpainting, superresolution of very small images, and colorization tasks, outperforming other latent models in our comparisons",
        "Our approach differs from and expands (<a class=\"ref-link\" id=\"cBojanowski_et+al_2018_a\" href=\"#rBojanowski_et+al_2018_a\">Bojanowski et al, 2018</a>) in three ways: (i) we consider a much higher dimensionality of the latent space, we use an indirect parameterization of the latent space discussed further below, we demonstrate the applicability of the resulting model to a variety of image restoration tasks",
        "While not all elements of the manifold If,s,\u03b8 will correspond to natural images from the distribution X, we have found out that with few thousand dimensions, the resulting manifolds can cover the support of X rather well",
        "The results of the comparison are summarized in Figure 3 and Table 1 with representative examples shown in Figure 4 and Figure 5. \u201cTraditional\u201d latent models performed poorly",
        "In Figure 6 and Table 2, we provide qualitative and quantitative comparison between the progressive generative adversarial networks model (<a class=\"ref-link\" id=\"cKarras_et+al_2018_a\" href=\"#rKarras_et+al_2018_a\">Karras et al, 2018</a>), the LCM model, and the same LCM model applied without the convolutional manifold constraint for the task of inpainting",
        "The results in this work suggest that high-dimensional latent spaces are necessary to get good image reconstructions on desired hold-out sets"
    ],
    "summary": [
        "Learning good image priors is one of the core problems of computer vision and machine learning.",
        "We consider the training of deep latent image models with the latent dimensionality that is much higher than previous works, and demonstrate that the resulting models provide universal (w.r.t. restoration tasks) image priors.",
        "Our experiments are performed on CelebA (<a class=\"ref-link\" id=\"cLiu_et+al_2015_a\" href=\"#rLiu_et+al_2015_a\">Liu et al, 2015</a>) (128x128 resolution), SUN Bedrooms (<a class=\"ref-link\" id=\"cYu_et+al_2015_a\" href=\"#rYu_et+al_2015_a\">Yu et al, 2015</a>) (256x256 resolution), CelebA-HQ (<a class=\"ref-link\" id=\"cKarras_et+al_2018_a\" href=\"#rKarras_et+al_2018_a\"><a class=\"ref-link\" id=\"cKarras_et+al_2018_a\" href=\"#rKarras_et+al_2018_a\">Karras et al, 2018</a></a>) (1024x1024 resolution) datasets, and we demonstrate that the latent models, once trained, can be applied to large hole inpainting, superresolution of very small images, and colorization tasks, outperforming other latent models in our comparisons.",
        "The deep latent modeling of images implies learning the generator network g\u03b8 with learnable parameters \u03b8, which usually has convolutional architecture.",
        "Our approach differs from and expands (<a class=\"ref-link\" id=\"cBojanowski_et+al_2018_a\" href=\"#rBojanowski_et+al_2018_a\"><a class=\"ref-link\" id=\"cBojanowski_et+al_2018_a\" href=\"#rBojanowski_et+al_2018_a\">Bojanowski et al, 2018</a></a>) in three ways: (i) we consider a much higher dimensionality of the latent space, we use an indirect parameterization of the latent space discussed further below, we demonstrate the applicability of the resulting model to a variety of image restoration tasks.",
        "While they effectively use convolutional manifolds to model natural images directly, in our case, we use them to model the latent space of the generator networks resulting in a fully-fledged learnable latent image model cannot be learned on a dataset of images).",
        "The work (<a class=\"ref-link\" id=\"cUlyanov_et+al_2018_a\" href=\"#rUlyanov_et+al_2018_a\">Ulyanov et al, 2018</a>) demonstrates that the regularization imposed by the structure of a very high-dimensional convolutional manifold is beneficial when modeling natural images.",
        "We describe how the learned latent model can be used to perform the restoration of the unknown image x0 from the distribution X, given some evidence y.",
        "We have performed extensive comparisons with other latent models on the two datasets with smaller image size and lower training times (CelebA and Bedrooms).",
        "GLO: The baseline model discussed in the end of Section 2 and inspired by (<a class=\"ref-link\" id=\"cBojanowski_et+al_2018_a\" href=\"#rBojanowski_et+al_2018_a\"><a class=\"ref-link\" id=\"cBojanowski_et+al_2018_a\" href=\"#rBojanowski_et+al_2018_a\">Bojanowski et al, 2018</a></a>), where the generator network has the same architecture as in LCM, but the convolutional space is parameterized by a set of maps.",
        "For Bedrooms we use the pretrained Progressive GAN (PGAN) models with the latent space of dimensionality 512 published by the authors of (<a class=\"ref-link\" id=\"cKarras_et+al_2018_a\" href=\"#rKarras_et+al_2018_a\"><a class=\"ref-link\" id=\"cKarras_et+al_2018_a\" href=\"#rKarras_et+al_2018_a\">Karras et al, 2018</a></a>).",
        "Except for the Bedrooms-inpainting, the new models with very large latent space produced results that were clearly favoured by the users.",
        "The results in this work suggest that high-dimensional latent spaces are necessary to get good image reconstructions on desired hold-out sets.",
        "This method can be extended to come up with more interesting parametrizations of the latent space, e.g. by interleaving the layers with image-specific and dataset-specific parameters.",
        "The number of iterations can be drastically reduced using degradation-specific or universal feed-forward encoders from image-space to the latent space that may provide a reasonable starting point for optimization"
    ],
    "headline": "We present a new latent model of natural images that can be learned on large-scale datasets",
    "reference_links": [
        {
            "id": "Martin_2017_a",
            "entry": "Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou. Wasserstein generative adversarial networks. In Proc. ICML, pp. 214\u2013223, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Martin%20Arjovsky%2C%20Soumith%20Chintala%20Bottou%2C%20L%C3%A9on%20Wasserstein%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Martin%20Arjovsky%2C%20Soumith%20Chintala%20Bottou%2C%20L%C3%A9on%20Wasserstein%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "Bojanowski_et+al_2018_a",
            "entry": "P. Bojanowski, A. Joulin, D. Lopez-Paz, and A. Szlam. Optimizing the latent space of generative networks. In Proc. ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bojanowski%2C%20P.%20Joulin%2C%20A.%20Lopez-Paz%2C%20D.%20Szlam%2C%20A.%20Optimizing%20the%20latent%20space%20of%20generative%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bojanowski%2C%20P.%20Joulin%2C%20A.%20Lopez-Paz%2C%20D.%20Szlam%2C%20A.%20Optimizing%20the%20latent%20space%20of%20generative%20networks%202018"
        },
        {
            "id": "Burt_1983_a",
            "entry": "P. Burt and E. Adelson. The laplacian pyramid as a compact image code. IEEE Transactions on Communications, 31(4):532\u2013540, Apr 1983. ISSN 0090-6778. doi: 10.1109/TCOM.1983.1095851.",
            "crossref": "https://dx.doi.org/10.1109/TCOM.1983.1095851",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/TCOM.1983.1095851"
        },
        {
            "id": "Goodfellow_et+al_2014_a",
            "entry": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Proc. NIPS, pp. 2672\u20132680. 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "Goodfellow_et+al_2016_a",
            "entry": "Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. MIT Press, 2016. http://www.deeplearningbook.org.",
            "url": "http://www.deeplearningbook.org"
        },
        {
            "id": "Gulrajani_et+al_2017_a",
            "entry": "Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville. Improved training of wasserstein GANs. In Proc. NIPS, pp. 5767\u20135777. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gulrajani%2C%20Ishaan%20Ahmed%2C%20Faruk%20Arjovsky%2C%20Martin%20Dumoulin%2C%20Vincent%20Improved%20training%20of%20wasserstein%20GANs%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gulrajani%2C%20Ishaan%20Ahmed%2C%20Faruk%20Arjovsky%2C%20Martin%20Dumoulin%2C%20Vincent%20Improved%20training%20of%20wasserstein%20GANs%202017"
        },
        {
            "id": "Iizuka_et+al_2017_a",
            "entry": "Satoshi Iizuka, Edgar Simo-Serra, and Hiroshi Ishikawa. Globally and Locally Consistent Image Completion. Proc. SIGGRAPH, 36(4):107:1\u2013107:14, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Iizuka%2C%20Satoshi%20Simo-Serra%2C%20Edgar%20Ishikawa%2C%20Hiroshi%20Globally%20and%20Locally%20Consistent%20Image%20Completion%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Iizuka%2C%20Satoshi%20Simo-Serra%2C%20Edgar%20Ishikawa%2C%20Hiroshi%20Globally%20and%20Locally%20Consistent%20Image%20Completion%202017"
        },
        {
            "id": "Johnson_et+al_2016_a",
            "entry": "Justin Johnson, Alexandre Alahi, and Li Fei-Fei. Perceptual losses for real-time style transfer and super-resolution. In Proc. ECCV, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Justin%20Alahi%2C%20Alexandre%20Fei-Fei%2C%20Li%20Perceptual%20losses%20for%20real-time%20style%20transfer%20and%20super-resolution%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20Justin%20Alahi%2C%20Alexandre%20Fei-Fei%2C%20Li%20Perceptual%20losses%20for%20real-time%20style%20transfer%20and%20super-resolution%202016"
        },
        {
            "id": "Karklin_2009_a",
            "entry": "Yan Karklin and Michael S Lewicki. Emergence of complex cell properties by learning to generalize in natural scenes. Nature, 457(7225):83, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Karklin%2C%20Yan%20Lewicki%2C%20Michael%20S.%20Emergence%20of%20complex%20cell%20properties%20by%20learning%20to%20generalize%20in%20natural%20scenes%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Karklin%2C%20Yan%20Lewicki%2C%20Michael%20S.%20Emergence%20of%20complex%20cell%20properties%20by%20learning%20to%20generalize%20in%20natural%20scenes%202009"
        },
        {
            "id": "Karras_et+al_2018_a",
            "entry": "T. Karras, T. Aila, S. Laine, and J. Lehtinen. Progressive growing of GANs for improved quality, stability, and variation. In Proc. ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Karras%2C%20T.%20Aila%2C%20T.%20Laine%2C%20S.%20Lehtinen%2C%20J.%20Progressive%20growing%20of%20GANs%20for%20improved%20quality%2C%20stability%2C%20and%20variation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Karras%2C%20T.%20Aila%2C%20T.%20Laine%2C%20S.%20Lehtinen%2C%20J.%20Progressive%20growing%20of%20GANs%20for%20improved%20quality%2C%20stability%2C%20and%20variation%202018"
        },
        {
            "id": "Kingma_2014_a",
            "entry": "D. P Kingma and M. Welling. Auto-encoding variational bayes. In Proc. ICLR, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20D.P.%20Welling%2C%20M.%20Auto-encoding%20variational%20bayes%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20D.P.%20Welling%2C%20M.%20Auto-encoding%20variational%20bayes%202014"
        },
        {
            "id": "Liu_et+al_2015_a",
            "entry": "Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In Proc. ICCV, December 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Ziwei%20Luo%2C%20Ping%20Wang%2C%20Xiaogang%20Tang%2C%20Xiaoou%20Deep%20learning%20face%20attributes%20in%20the%20wild%202015-12",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Ziwei%20Luo%2C%20Ping%20Wang%2C%20Xiaogang%20Tang%2C%20Xiaoou%20Deep%20learning%20face%20attributes%20in%20the%20wild%202015-12"
        },
        {
            "id": "Roth_2005_a",
            "entry": "Stefan Roth and Michael J Black. Fields of experts: A framework for learning image priors. In Proc. CVPR, volume 2, pp. 860\u2013867, 2005.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Roth%2C%20Stefan%20Black%2C%20Michael%20J.%20Fields%20of%20experts%3A%20A%20framework%20for%20learning%20image%20priors%202005",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Roth%2C%20Stefan%20Black%2C%20Michael%20J.%20Fields%20of%20experts%3A%20A%20framework%20for%20learning%20image%20priors%202005"
        },
        {
            "id": "Simonyan_2015_a",
            "entry": "K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. In Proc. ICLR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Simonyan%2C%20K.%20Zisserman%2C%20A.%20Very%20deep%20convolutional%20networks%20for%20large-scale%20image%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Simonyan%2C%20K.%20Zisserman%2C%20A.%20Very%20deep%20convolutional%20networks%20for%20large-scale%20image%20recognition%202015"
        },
        {
            "id": "Sirovich_1987_a",
            "entry": "Lawrence Sirovich and Michael Kirby. Low-dimensional procedure for the characterization of human faces. Josa A, 4(3):519\u2013524, 1987.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sirovich%2C%20Lawrence%20Kirby%2C%20Michael%20Low-dimensional%20procedure%20for%20the%20characterization%20of%20human%20faces%201987",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sirovich%2C%20Lawrence%20Kirby%2C%20Michael%20Low-dimensional%20procedure%20for%20the%20characterization%20of%20human%20faces%201987"
        },
        {
            "id": "Ulyanov_et+al_2018_a",
            "entry": "D. Ulyanov, A. Vedaldi, and V. Lempitsky. Deep image prior. In Proc. CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ulyanov%2C%20D.%20Vedaldi%2C%20A.%20Lempitsky%2C%20V.%20Deep%20image%20prior%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ulyanov%2C%20D.%20Vedaldi%2C%20A.%20Lempitsky%2C%20V.%20Deep%20image%20prior%202018"
        },
        {
            "id": "Yeh_et+al_2017_a",
            "entry": "R. A. Yeh, C. Chen, T. Y. Lim, A. G. Schwing, M. Hasegawa-Johnson, and M. N. Do. Semantic image inpainting with deep generative models. In Proc. CVPR, pp. 6882\u20136890, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yeh%2C%20R.A.%20Chen%2C%20C.%20Lim%2C%20T.Y.%20Schwing%2C%20A.G.%20Semantic%20image%20inpainting%20with%20deep%20generative%20models%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yeh%2C%20R.A.%20Chen%2C%20C.%20Lim%2C%20T.Y.%20Schwing%2C%20A.G.%20Semantic%20image%20inpainting%20with%20deep%20generative%20models%202017"
        },
        {
            "id": "Yu_et+al_2015_a",
            "entry": "Fisher Yu, Yinda Zhang, Shuran Song, Ari Seff, and Jianxiong Xiao. Lsun: Construction of a largescale image dataset using deep learning with humans in the loop. arXiv preprint arXiv:1506.03365, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1506.03365"
        },
        {
            "id": "Zhang_et+al_2018_a",
            "entry": "R. Zhang, P. Isola, A. A. Efros, E. Shechtman, and O. Wang. The Unreasonable Effectiveness of Deep Features as a Perceptual Metric. ArXiv e-prints, January 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20R.%20Isola%2C%20P.%20Efros%2C%20A.A.%20Shechtman%2C%20E.%20The%20Unreasonable%20Effectiveness%20of%20Deep%20Features%20as%20a%20Perceptual%20Metric.%20ArXiv%20e-prints%202018-01"
        },
        {
            "id": "Zhu_et+al_2016_a",
            "entry": "Jun-Yan Zhu, Philipp Kr\u00e4henb\u00fchl, Eli Shechtman, and Alexei A. Efros. Generative visual manipulation on the natural image manifold. In Proc. ECCV, pp. 597\u2013613, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20Jun-Yan%20Kr%C3%A4henb%C3%BChl%2C%20Philipp%20Shechtman%2C%20Eli%20Efros%2C%20Alexei%20A.%20Generative%20visual%20manipulation%20on%20the%20natural%20image%20manifold%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20Jun-Yan%20Kr%C3%A4henb%C3%BChl%2C%20Philipp%20Shechtman%2C%20Eli%20Efros%2C%20Alexei%20A.%20Generative%20visual%20manipulation%20on%20the%20natural%20image%20manifold%202016"
        },
        {
            "id": "Zoran_2011_a",
            "entry": "Daniel Zoran and Yair Weiss. From learning models of natural image patches to whole image restoration. In Proc. ICCV, pp. 479\u2013486, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zoran%2C%20Daniel%20Weiss%2C%20Yair%20From%20learning%20models%20of%20natural%20image%20patches%20to%20whole%20image%20restoration%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zoran%2C%20Daniel%20Weiss%2C%20Yair%20From%20learning%20models%20of%20natural%20image%20patches%20to%20whole%20image%20restoration%202011"
        }
    ]
}

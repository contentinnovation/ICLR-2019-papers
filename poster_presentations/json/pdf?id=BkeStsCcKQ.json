{
    "filename": "pdf.pdf",
    "metadata": {
        "date": 2019,
        "title": "CRITICAL LEARNING PERIODS IN DEEP NETWORKS",
        "author": "Alessandro Achille \u2217 Department of Computer Science University of California, Los Angeles achille@cs.ucla.edu",
        "identifiers": {
            "url": "https://openreview.net/pdf?id=BkeStsCcKQ"
        },
        "abstract": "Similar to humans and animals, deep artificial neural networks exhibit critical periods during which a temporary stimulus deficit can impair the development of a skill. The extent of the impairment depends on the onset and length of the deficit window, as in animal models, and on the size of the neural network. Deficits that do not affect low-level statistics, such as vertical flipping of the images, have no lasting effect on performance and can be overcome with further training. To better understand this phenomenon, we use the Fisher Information of the weights to measure the effective connectivity between layers of a network during training. Counterintuitively, information rises rapidly in the early phases of training, and then decreases, preventing redistribution of information resources in a phenomenon we refer to as a loss of \u201cInformation Plasticity\u201d. Our analysis suggests that the first few epochs are critical for the creation of strong connections that are optimal relative to the input data distribution. Once such strong connections are created, they do not appear to change during additional training. These findings suggest that the initial learning transient, under-scrutinized compared to asymptotic behavior, plays a key role in determining the outcome of the training process. Our findings, combined with recent theoretical results in the literature, also suggest that forgetting (decrease of information in the weights) is critical to achieving invariance and disentanglement in representation learning. Finally, critical periods are not restricted to biological systems, but can emerge naturally in learning systems, whether biological or artificial, due to fundamental constrains arising from learning dynamics and information processing."
    },
    "keywords": [
        {
            "term": "information processing",
            "url": "https://en.wikipedia.org/wiki/information_processing"
        },
        {
            "term": "biology",
            "url": "https://en.wikipedia.org/wiki/biology"
        },
        {
            "term": "deep neural networks",
            "url": "https://en.wikipedia.org/wiki/deep_neural_networks"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "biological phenomenon",
            "url": "https://en.wikipedia.org/wiki/biological_phenomenon"
        },
        {
            "term": "amblyopia",
            "url": "https://en.wikipedia.org/wiki/amblyopia"
        },
        {
            "term": "multi-layer perceptron",
            "url": "https://en.wikipedia.org/wiki/multi-layer_perceptron"
        },
        {
            "term": "animal model",
            "url": "https://en.wikipedia.org/wiki/animal_model"
        },
        {
            "term": "visual cortex",
            "url": "https://en.wikipedia.org/wiki/visual_cortex"
        },
        {
            "term": "fisher information",
            "url": "https://en.wikipedia.org/wiki/fisher_information"
        },
        {
            "term": "critical period",
            "url": "https://en.wikipedia.org/wiki/critical_period"
        }
    ],
    "abbreviations": {
        "DNNs": "deep neural networks",
        "CNN": "convolutional network",
        "FIM": "Fisher Information Matrix",
        "MLP": "multi-layer perceptron"
    },
    "highlights": [
        "Critical periods are time windows of early post-natal development during which sensory deficits can lead to permanent skill impairment (Kandel et al, 2013)",
        "We show that deep neural networks (DNNs), while completely devoid of such regulations, respond to sensory deficits in ways similar to those observed in humans and animal models",
        "We propose using the information in the weights, measured by an efficient approximation of the Fisher Information, to study critical period phenomena in deep neural networks",
        "While traditionally well-understood mathematical models were used by neuroscientists to study biological phenomena, information processing in modern artificial networks is often just as poorly understood as in biology, so we chose to exploit well-known biological phenomena as probes to study information processing in artificial networks",
        "It would be interesting to explore ways to test whether biological networks prune connections as a consequences of a loss of Information Plasticity, rather than as a cause",
        "The mechanisms underlying network reconfiguration during learning and development might be an evolutionary outcome obtained under the pressure of fundamental information processing phenomena"
    ],
    "key_statements": [
        "Critical periods are time windows of early post-natal development during which sensory deficits can lead to permanent skill impairment (Kandel et al, 2013)",
        "We show that deep neural networks (DNNs), while completely devoid of such regulations, respond to sensory deficits in ways similar to those observed in humans and animal models",
        "This surprising result suggests that critical periods may arise from information processing, rather than biochemical, phenomena",
        "We propose using the information in the weights, measured by an efficient approximation of the Fisher Information, to study critical period phenomena in deep neural networks",
        "Critical periods are centered in the memorization phase",
        "deep neural networks exhibit critical periods: In Figure 1, we plot the final performance of a network affected by the deficit as a function of the epoch t0 at which the deficit is corrected",
        "Two phases of learning: As its name suggests, the Fisher Information Matrix can be thought as a measure of the quantity of information about the training data that is contained in the model (Fisher, 1925)",
        "To the best of our knowledge, we are the first to show that artificial neural networks exhibit critical period phenomena, and to highlight the critical role of the transient in determining the asymptotic performance of the network",
        "Inspired by the role of synaptic connectivity in modulating critical periods, we introduce the use of Fisher Information to study this initial phase",
        "We show that the initial sensitivity to deficits closely follows changes in the Fisher Information Matrix, both global, as the network first rapidly increases and decreases the amount of stored information, and layer-wise, as the network \u201creorganizes\u201d its effective connectivity in order to optimally process information",
        "Our work naturally relates to the extensive literature on critical periods in biology",
        "Despite artificial networks being an extremely reductionist approximation of neuronal networks, they exhibit behaviors that are qualitatively similar to the critical periods observed in human and animal models",
        "Our information analysis shows that the initial rapid memorization phase is followed by a loss of Information Plasticity which, counterintuitively, further improves the performance",
        "In Figure 6, we show that the covariance and norm of the gradients exhibit no clear trends during training with and without deficits, and, unlike the Fisher Information Matrix, do not correlate with the sensitivity to critical periods",
        "An insightful interpretation of critical periods in animal models was proposed by Knudsen (2004): The initial connections of neuronal networks are unstable and modified, but as more \u201csamples\u201d are observed, they change and reach a more stable configuration which is difficult to modify",
        "While traditionally well-understood mathematical models were used by neuroscientists to study biological phenomena, information processing in modern artificial networks is often just as poorly understood as in biology, so we chose to exploit well-known biological phenomena as probes to study information processing in artificial networks",
        "It would be interesting to explore ways to test whether biological networks prune connections as a consequences of a loss of Information Plasticity, rather than as a cause",
        "The mechanisms underlying network reconfiguration during learning and development might be an evolutionary outcome obtained under the pressure of fundamental information processing phenomena"
    ],
    "summary": [
        "Critical periods are time windows of early post-natal development during which sensory deficits can lead to permanent skill impairment (Kandel et al, 2013).",
        "DNNs exhibit critical periods: In Figure 1, we plot the final performance of a network affected by the deficit as a function of the epoch t0 at which the deficit is corrected.",
        "Architecture, depth, and learning rate annealing: Figure 3 shows that a fully-connected network trained on the MNIST digit classification dataset shows a critical period for the image blur deficit.",
        "Two phases of learning: As its name suggests, the FIM can be thought as a measure of the quantity of information about the training data that is contained in the model (Fisher, 1925).",
        "It is well-established how the elimination (\u201cpruning\u201d) of unnecessary synapses is a fundamental process during learning and brain development (<a class=\"ref-link\" id=\"cRakic_et+al_1986_a\" href=\"#rRakic_et+al_1986_a\">Rakic et al, 1986</a>) (Figure 4, Center); in Figure 4 (Left) an analogous phenomenon is clearly and quantitatively shown for DNNs. Strikingly, these changes in the connection strength are closely related to the sensitivity to criticalperiod-inducing deficits such as image blur, computed using the \u201csliding window\u201d method as in Figure 1.",
        "When the network is trained without deficits, the most important connections are in the intermediate layers (Figure 5, Left), which can process the input CIFAR-10 image at the most informative intermediate scale.",
        "Inspired by the role of synaptic connectivity in modulating critical periods, we introduce the use of Fisher Information to study this initial phase.",
        "We show that the initial sensitivity to deficits closely follows changes in the FIM, both global, as the network first rapidly increases and decreases the amount of stored information, and layer-wise, as the network \u201creorganizes\u201d its effective connectivity in order to optimally process information.",
        "In Figure 6, we show that the covariance and norm of the gradients exhibit no clear trends during training with and without deficits, and, unlike the FIM, do not correlate with the sensitivity to critical periods.",
        "Sensitivity to critical periods and the trace of the Fisher Information peak at the same epochs, in accord with the evidence that skill development and critical periods in neuronal networks are modulated by changes in synaptic plasticity (Knudsen, 2004; Hensch, 2004).",
        "An insightful interpretation of critical periods in animal models was proposed by Knudsen (2004): The initial connections of neuronal networks are unstable and modified, but as more \u201csamples\u201d are observed, they change and reach a more stable configuration which is difficult to modify.",
        "Supported by ONR N00014-17-1-2072, ARO W911NF-17-1-0304, AFOSR FA9550-15-1-0229 and FA8650-11-1-7156"
    ],
    "headline": "We show that deep neural networks, while completely devoid of such regulations, respond to sensory deficits in ways similar to those observed in humans and animal models",
    "reference_links": [
        {
            "id": "Achille_2018_a",
            "entry": "Alessandro Achille and Stefano Soatto. Emergence of invariance and disentanglement in deep representations. Journal of Machine Learning Research, 19(1):1947\u20131980, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Achille%2C%20Alessandro%20Soatto%2C%20Stefano%20Emergence%20of%20invariance%20and%20disentanglement%20in%20deep%20representations%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Achille%2C%20Alessandro%20Soatto%2C%20Stefano%20Emergence%20of%20invariance%20and%20disentanglement%20in%20deep%20representations%202018"
        },
        {
            "id": "Amari_2000_a",
            "entry": "Shun-ichi Amari and Hiroshi Nagaoka. Methods of information geometry, volume 191 of Translations of Mathematical Monographs. American Mathematical Society and Oxford University Press, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Amari%2C%20Shun-ichi%20Nagaoka%2C%20Hiroshi%20Methods%20of%20information%20geometry%2C%20volume%20191%20of%20Translations%20of%20Mathematical%20Monographs%202000"
        },
        {
            "id": "Banks_et+al_1975_a",
            "entry": "Martin S Banks, Richard N Aslin, and Robert D Letson. Sensitive period for the development of human binocular vision. Science, 190(4215):675\u2013677, 1975.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Banks%2C%20Martin%20S.%20Aslin%2C%20Richard%20N.%20Letson%2C%20Robert%20D.%20Sensitive%20period%20for%20the%20development%20of%20human%20binocular%20vision%201975",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Banks%2C%20Martin%20S.%20Aslin%2C%20Richard%20N.%20Letson%2C%20Robert%20D.%20Sensitive%20period%20for%20the%20development%20of%20human%20binocular%20vision%201975"
        },
        {
            "id": "Chaudhari_et+al_2017_a",
            "entry": "Pratik Chaudhari, Anna Choromanska, Stefano Soatto, Yann LeCun, Carlo Baldassi, Christian Borgs, Jennifer Chayes, Levent Sagun, and Riccardo Zecchina. Entropy-sgd: Biasing gradient descent into wide valleys. In Proceedings of the International Conference on Learning Representations, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chaudhari%2C%20Pratik%20Choromanska%2C%20Anna%20Soatto%2C%20Stefano%20LeCun%2C%20Yann%20Entropy-sgd%3A%20Biasing%20gradient%20descent%20into%20wide%20valleys%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chaudhari%2C%20Pratik%20Choromanska%2C%20Anna%20Soatto%2C%20Stefano%20LeCun%2C%20Yann%20Entropy-sgd%3A%20Biasing%20gradient%20descent%20into%20wide%20valleys%202017"
        },
        {
            "id": "Daw_2014_a",
            "entry": "Nigel W Daw. Visual Development. Springer, New York, NY, 3rd edition, 2014. Dumitru Erhan, Yoshua Bengio, Aaron Courville, Pierre-Antoine Manzagol, Pascal Vincent, and",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Daw%2C%20Nigel%20W.%20Visual%20Development%202014"
        },
        {
            "id": "Martens_2015_a",
            "entry": "James Martens and Roger Grosse. Optimizing neural networks with kronecker-factored approximate curvature. Proceedings of International Conference on Machine Learning, 37:2408\u20132417, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Martens%2C%20James%20Grosse%2C%20Roger%20Optimizing%20neural%20networks%20with%20kronecker-factored%20approximate%20curvature%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Martens%2C%20James%20Grosse%2C%20Roger%20Optimizing%20neural%20networks%20with%20kronecker-factored%20approximate%20curvature%202015"
        },
        {
            "id": "Mitchell_1988_a",
            "entry": "Donald E Mitchell. The extent of visual recovery from early monocular or binocular visual deprivation in kittens. The Journal of physiology, 395(1):639\u2013660, 1988.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mitchell%2C%20Donald%20E.%20The%20extent%20of%20visual%20recovery%20from%20early%20monocular%20or%20binocular%20visual%20deprivation%20in%20kittens%201988",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mitchell%2C%20Donald%20E.%20The%20extent%20of%20visual%20recovery%20from%20early%20monocular%20or%20binocular%20visual%20deprivation%20in%20kittens%201988"
        },
        {
            "id": "Montavon_et+al_2011_a",
            "entry": "Gregoire Montavon, Mikio L Braun, and Klaus-Robert Muller. Kernel analysis of deep networks. Journal of Machine Learning Research, 12(Sep):2563\u20132581, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Montavon%2C%20Gregoire%20Braun%2C%20Mikio%20L.%20Muller%2C%20Klaus-Robert%20Kernel%20analysis%20of%20deep%20networks%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Montavon%2C%20Gregoire%20Braun%2C%20Mikio%20L.%20Muller%2C%20Klaus-Robert%20Kernel%20analysis%20of%20deep%20networks%202011"
        },
        {
            "id": "Mower_1991_a",
            "entry": "George D Mower. The effect of dark rearing on the time course of the critical period in cat visual cortex. Developmental Brain Research, 58(2):151\u2013158, 1991.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mower%2C%20George%20D.%20The%20effect%20of%20dark%20rearing%20on%20the%20time%20course%20of%20the%20critical%20period%20in%20cat%20visual%20cortex%201991",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mower%2C%20George%20D.%20The%20effect%20of%20dark%20rearing%20on%20the%20time%20course%20of%20the%20critical%20period%20in%20cat%20visual%20cortex%201991"
        },
        {
            "id": "Olson_1980_a",
            "entry": "Carl R Olson and Ralph D Freeman. Profile of the sensitive period for monocular deprivation in kittens. Experimental Brain Research, 39(1):17\u201321, 1980.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Olson%2C%20Carl%20R.%20Freeman%2C%20Ralph%20D.%20Profile%20of%20the%20sensitive%20period%20for%20monocular%20deprivation%20in%20kittens%201980",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Olson%2C%20Carl%20R.%20Freeman%2C%20Ralph%20D.%20Profile%20of%20the%20sensitive%20period%20for%20monocular%20deprivation%20in%20kittens%201980"
        },
        {
            "id": "Rakic_et+al_1986_a",
            "entry": "Pasko Rakic, Jean-Pierre Bourgeois, Maryellen F Eckenhoff, Nada Zecevic, and Patricia S Goldman-Rakic. Concurrent overproduction of synapses in diverse regions of the primate cerebral cortex. Science, 232(4747):232\u2013235, 1986.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rakic%2C%20Pasko%20Bourgeois%2C%20Jean-Pierre%20Eckenhoff%2C%20Maryellen%20F.%20Zecevic%2C%20Nada%20Concurrent%20overproduction%20of%20synapses%20in%20diverse%20regions%20of%20the%20primate%20cerebral%20cortex%201986",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rakic%2C%20Pasko%20Bourgeois%2C%20Jean-Pierre%20Eckenhoff%2C%20Maryellen%20F.%20Zecevic%2C%20Nada%20Concurrent%20overproduction%20of%20synapses%20in%20diverse%20regions%20of%20the%20primate%20cerebral%20cortex%201986"
        },
        {
            "id": "Shwartz-Ziv_2017_a",
            "entry": "Ravid Shwartz-Ziv and Naftali Tishby. Opening the black box of deep neural networks via information. arXiv preprint arXiv:1703.00810, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.00810"
        },
        {
            "id": "Springenberg_et+al_2014_a",
            "entry": "Jost T Springenberg, Alexey Dosovitskiy, Thomas Brox, and Martin Riedmiller. Striving for simplicity: The all convolutional net. arXiv preprint arXiv:1412.6806, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6806"
        },
        {
            "id": "Stratton_0000_a",
            "entry": "George M Stratton. Some preliminary experiments on vision without inversion of the retinal image. Psychological Review, 3(6):611\u2013617, 1896.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stratton%2C%20George%20M.%20Some%20preliminary%20experiments%20on%20vision%20without%20inversion%20of%20the%20retinal%20image",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Stratton%2C%20George%20M.%20Some%20preliminary%20experiments%20on%20vision%20without%20inversion%20of%20the%20retinal%20image"
        },
        {
            "id": "Taylor_1979_a",
            "entry": "David Taylor et al. Critical period for deprivation amblyopia in children. Transactions of the ophthalmological societies of the United Kingdom, 99(3):432\u2013439, 1979.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Taylor%2C%20David%20Critical%20period%20for%20deprivation%20amblyopia%20in%20children.%20Transactions%20of%20the%20ophthalmological%20societies%20of%20the%201979",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Taylor%2C%20David%20Critical%20period%20for%20deprivation%20amblyopia%20in%20children.%20Transactions%20of%20the%20ophthalmological%20societies%20of%20the%201979"
        },
        {
            "id": "Von_1981_a",
            "entry": "Gunter K von Noorden. New clinical aspects of stimulus deprivation amblyopia. American journal of ophthalmology, 92(3):416\u2013421, 1981.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=von%20Noorden%2C%20Gunter%20K.%20New%20clinical%20aspects%20of%20stimulus%20deprivation%20amblyopia%201981",
            "oa_query": "https://api.scholarcy.com/oa_version?query=von%20Noorden%2C%20Gunter%20K.%20New%20clinical%20aspects%20of%20stimulus%20deprivation%20amblyopia%201981"
        },
        {
            "id": "Wiesel_1982_a",
            "entry": "Torsten N Wiesel. Postnatal development of the visual cortex and the influence of environment. Nature, 299(5884):583, 1982.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wiesel%2C%20Torsten%20N.%20Postnatal%20development%20of%20the%20visual%20cortex%20and%20the%20influence%20of%20environment%201982",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wiesel%2C%20Torsten%20N.%20Postnatal%20development%20of%20the%20visual%20cortex%20and%20the%20influence%20of%20environment%201982"
        },
        {
            "id": "Wiesel_0000_a",
            "entry": "Torsten N Wiesel and David H Hubel. Single-cell responses in striate cortex of kittens deprived of vision in one eye. Journal of neurophysiology, 26(6):1003\u20131017, 1963a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wiesel%2C%20Torsten%20N.%20Hubel%2C%20David%20H.%20Single-cell%20responses%20in%20striate%20cortex%20of%20kittens%20deprived%20of%20vision%20in%20one%20eye",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wiesel%2C%20Torsten%20N.%20Hubel%2C%20David%20H.%20Single-cell%20responses%20in%20striate%20cortex%20of%20kittens%20deprived%20of%20vision%20in%20one%20eye"
        },
        {
            "id": "Wiesel_0000_b",
            "entry": "Torsten N Wiesel and David H Hubel. Effects of visual deprivation on morphology and physiology of cells in the cat\u2019s lateral geniculate body. Journal of neurophysiology, 26(6):978\u2013993, 1963b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wiesel%2C%20Torsten%20N.%20Hubel%2C%20David%20H.%20Effects%20of%20visual%20deprivation%20on%20morphology%20and%20physiology%20of%20cells%20in%20the%20cat%E2%80%99s%20lateral%20geniculate%20body",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wiesel%2C%20Torsten%20N.%20Hubel%2C%20David%20H.%20Effects%20of%20visual%20deprivation%20on%20morphology%20and%20physiology%20of%20cells%20in%20the%20cat%E2%80%99s%20lateral%20geniculate%20body"
        },
        {
            "id": "-_0000_a",
            "entry": "- conv1 10 In order to avoid interferences between the annealing scheme and the architecture, in these experiments we fix the learning rate to 0.001. The Fully Connected network used for the MNIST experiments has hidden layers of size [2500, 2000, 1500, 1000, 500]. All hidden layers use batch normalization followed by ReLU activations. We fix the learning rate to 0.005. Weight decay is not used. We use data augmentation with random translations up to 4 pixels and random horizontal flipping. For MNIST, we pad the images with zeros to bring them to size 32 \u00d7 32.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=conv1%2010%20In%20order%20to%20avoid%20interferences%20between%20the%20annealing%20scheme%20and%20the%20architecture%20in%20these%20experiments%20we%20fix%20the%20learning%20rate%20to%200001%20The%20Fully%20Connected%20network%20used%20for%20the%20MNIST%20experiments%20has%20hidden%20layers%20of%20size%202500%202000%201500%201000%20500%20All%20hidden%20layers%20use%20batch%20normalization%20followed%20by%20ReLU%20activations%20We%20fix%20the%20learning%20rate%20to%200005%20Weight%20decay%20is%20not%20used%20We%20use%20data%20augmentation%20with%20random%20translations%20up%20to%204%20pixels%20and%20random%20horizontal%20flipping%20For%20MNIST%20we%20pad%20the%20images%20with%20zeros%20to%20bring%20them%20to%20size%2032%20%2032",
            "oa_query": "https://api.scholarcy.com/oa_version?query=conv1%2010%20In%20order%20to%20avoid%20interferences%20between%20the%20annealing%20scheme%20and%20the%20architecture%20in%20these%20experiments%20we%20fix%20the%20learning%20rate%20to%200001%20The%20Fully%20Connected%20network%20used%20for%20the%20MNIST%20experiments%20has%20hidden%20layers%20of%20size%202500%202000%201500%201000%20500%20All%20hidden%20layers%20use%20batch%20normalization%20followed%20by%20ReLU%20activations%20We%20fix%20the%20learning%20rate%20to%200005%20Weight%20decay%20is%20not%20used%20We%20use%20data%20augmentation%20with%20random%20translations%20up%20to%204%20pixels%20and%20random%20horizontal%20flipping%20For%20MNIST%20we%20pad%20the%20images%20with%20zeros%20to%20bring%20them%20to%20size%2032%20%2032"
        },
        {
            "id": "A.3_1975_a",
            "entry": "A.3 CURVE FITTING Fitting of sensitivity curves and synaptic density profiles from the literature was performed using: f (t) = e\u2212(t\u2212d)/\u03c41 \u2212 ke\u2212(t\u2212d)/\u03c42 as the fitting equation, where t is the age at the time of sampling and \u03c41, \u03c42, k and d are unconstrained parameters (Banks et al., 1975). The exponential fit of the sensitivity to the Fisher Information trace uses the expression",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=A3%20CURVE%20FITTING%20Fitting%20of%20sensitivity%20curves%20and%20synaptic%20density%20profiles%20from%20the%20literature%20was%20performed%20using%20f%20t%20%20etd%CF%841%20%20ketd%CF%842%20as%20the%20fitting%20equation%20where%20t%20is%20the%20age%20at%20the%20time%20of%20sampling%20and%20%CF%841%20%CF%842%20k%20and%20d%20are%20unconstrained%20parameters%20Banks%20et%20al%201975%20The%20exponential%20fit%20of%20the%20sensitivity%20to%20the%20Fisher%20Information%20trace%20uses%20the%20expression",
            "oa_query": "https://api.scholarcy.com/oa_version?query=A3%20CURVE%20FITTING%20Fitting%20of%20sensitivity%20curves%20and%20synaptic%20density%20profiles%20from%20the%20literature%20was%20performed%20using%20f%20t%20%20etd%CF%841%20%20ketd%CF%842%20as%20the%20fitting%20equation%20where%20t%20is%20the%20age%20at%20the%20time%20of%20sampling%20and%20%CF%841%20%CF%842%20k%20and%20d%20are%20unconstrained%20parameters%20Banks%20et%20al%201975%20The%20exponential%20fit%20of%20the%20sensitivity%20to%20the%20Fisher%20Information%20trace%20uses%20the%20expression"
        }
    ]
}

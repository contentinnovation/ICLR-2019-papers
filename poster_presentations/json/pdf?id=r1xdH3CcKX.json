{
    "filename": "pdf.pdf",
    "metadata": {
        "date": 2019,
        "title": "STOCHASTIC PREDICTION OF MULTI-AGENT INTERACTIONS FROM PARTIAL OBSERVATIONS",
        "author": "Chen Sun Google Research",
        "identifiers": {
            "url": "https://openreview.net/pdf?id=r1xdH3CcKX"
        },
        "abstract": "We present a method that learns to integrate temporal information, from a learned dynamics model, with ambiguous visual information, from a learned vision model, in the context of interacting agents. Our method is based on a graph-structured variational recurrent neural network (Graph-VRNN), which is trained end-to-end to infer the current state of the (partially observed) world, as well as to forecast future states. We show that our method outperforms various baselines on two sports datasets, one based on real basketball trajectories, and one generated by a soccer game engine."
    },
    "keywords": [
        {
            "term": "dynamics",
            "url": "https://en.wikipedia.org/wiki/dynamics"
        },
        {
            "term": "recurrent neural network",
            "url": "https://en.wikipedia.org/wiki/recurrent_neural_network"
        },
        {
            "term": "physics",
            "url": "https://en.wikipedia.org/wiki/physics"
        },
        {
            "term": "state space model",
            "url": "https://en.wikipedia.org/wiki/State_Space_Model"
        },
        {
            "term": "evidence lower bound",
            "url": "https://en.wikipedia.org/wiki/evidence_lower_bound"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "dynamic model",
            "url": "https://en.wikipedia.org/wiki/dynamic_model"
        }
    ],
    "abbreviations": {
        "ELBO": "evidence lower bound"
    },
    "highlights": [
        "The key issue is how to define the output decoder, p, in such a way that we properly combine the information from the current visual input, vt, with our past beliefs about the object states, ht\u22121, as well as any stochastic noise zt",
        "You can only see a subset of the players, and you may or may not be able to see the ball, yet you probably have some reasonable idea about where all the players currently are, even if they are not in the field of view. (For example, the goal keeper is probably close to the goal.) you cannot see the future, but you may still be able to predict where the \u201cagents\u201d will be, at least approximately. These problems are intertwined: we are able to predict future states by using a state dynamics model, but we can use the same dynamics model to infer the current state of the world by extrapolating from the last time we saw each agent",
        "We show that our approach can infer the current state more accurately than other methods, and can make more accurate future forecasts",
        "EXPERIMENTAL SETUP The first task we evaluate is inferring the current state of the all the objects",
        "Instead we evaluate the negative log-likelihood on the discretized predictions, which can better capture the multi-modal nature of the problem. (This is similar to the perplexity measure used to evaluate language models, except we apply it to each object separately and sum the results.) For each task, we consider the following models: Visual only: standalone visual encoder without any recurrent neural network as backbone",
        "We have presented a method that learns to integrate temporal information with partially observed visual evidence, based on graph-structured VRNNs, and shown that it outperforms various baselines on two simple datasets"
    ],
    "key_statements": [
        "The key issue is how to define the output decoder, p, in such a way that we properly combine the information from the current visual input, vt, with our past beliefs about the object states, ht\u22121, as well as any stochastic noise zt",
        "You can only see a subset of the players, and you may or may not be able to see the ball, yet you probably have some reasonable idea about where all the players currently are, even if they are not in the field of view. (For example, the goal keeper is probably close to the goal.) you cannot see the future, but you may still be able to predict where the \u201cagents\u201d will be, at least approximately. These problems are intertwined: we are able to predict future states by using a state dynamics model, but we can use the same dynamics model to infer the current state of the world by extrapolating from the last time we saw each agent",
        "We show that our approach can infer the current state more accurately than other methods, and can make more accurate future forecasts",
        "EXPERIMENTAL SETUP The first task we evaluate is inferring the current state of the all the objects",
        "Instead we evaluate the negative log-likelihood on the discretized predictions, which can better capture the multi-modal nature of the problem. (This is similar to the perplexity measure used to evaluate language models, except we apply it to each object separately and sum the results.) For each task, we consider the following models: Visual only: standalone visual encoder without any recurrent neural network as backbone",
        "Figure 6 shows the examples trajectories for five attacking players generated by Graph-VRNN and baseline methods",
        "\u00a7In the case of variational models, we report the evidence lower bound, rather than the true log likelihood",
        "We have presented a method that learns to integrate temporal information with partially observed visual evidence, based on graph-structured VRNNs, and shown that it outperforms various baselines on two simple datasets"
    ],
    "summary": [
        "The key issue is how to define the output decoder, p, in such a way that we properly combine the information from the current visual input, vt, with our past beliefs about the object states, ht\u22121, as well as any stochastic noise zt.",
        "This step would be performed with Bayes\u2019 rule, combining the dynamical prior with the visual likelihood.",
        "To encourage the model to learn to forecast future states, in addition to predicting the current state, we modify the above loss function to maximize a lower bound\u2020 on log p(s1:T +\u2206|v1:T ), computed as",
        "When the future prediction loss weight is too small, the dynamics model is not trained well.",
        "Since we are interested in inferring and forecasting the state of a system composed of multiple interacting objects, based on visual evidence, analysing sports videos is a natural choice.",
        "Specialized solutions to state estimation for basketball and soccer already exist, multiple calibrated cameras (<a class=\"ref-link\" id=\"cManafifard_et+al_2017_a\" href=\"#rManafifard_et+al_2017_a\">Manafifard et al, 2017</a>), or complex monocular vision pipelines (<a class=\"ref-link\" id=\"cRematas_et+al_2018_a\" href=\"#rRematas_et+al_2018_a\">Rematas et al, 2018</a>)), we are interested in seeing how far we can get with a pure learning based approach, since such a method will be more generally applicable.",
        "The left half of Table 1 shows the average normalized 2 distance between the true and predicted location of all the agents for the soccer data as a function of time.",
        "Since the future is multimodal, we do not use 2 error, but instead we compute the log-likelihood of the discretized ground truth locations, Figure 4: Belief states for one player in the basketball data across multiple different world state scenarios.",
        "In Figure 4, we visualize the belief state for a single agent in the basketball dataset as a function of time.",
        "We visualize the output of the decoder, ptk = \u03c6dec, as a heatmap, where zkt \u223c \u03c6prior are different stochastic samples of the latent state drawn from the dynamical prior.",
        "Figure 6 shows the examples trajectories for five attacking players generated by Graph-VRNN and baseline methods.",
        "Figure 5 shows the belief states for the soccer domain for three different kinds of agents: a regular player, the goal keeper, and the ball.",
        "We draw a single stochastic sample, and visualize the resulting belief states.",
        "We have presented a method that learns to integrate temporal information with partially observed visual evidence, based on graph-structured VRNNs, and shown that it outperforms various baselines on two simple datasets.",
        "We would like to reduce the dependence on labeled data, perhaps by using some form of self-supervised learning"
    ],
    "headline": "We present a method that learns to integrate temporal information, from a learned dynamics model, with ambiguous visual information, from a learned vision model, in the context of interacting agents",
    "reference_links": [
        {
            "id": "Alahi_et+al_2016_a",
            "entry": "Alexandre Alahi, Kratarth Goel, Vignesh Ramanathan, Alexandre Robicquet, Li Fei-Fei, and Silvio Savarese. Social LSTM: Human Trajectory Prediction in Crowded Spaces. In CVPR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Alexandre%20Alahi%20Kratarth%20Goel%20Vignesh%20Ramanathan%20Alexandre%20Robicquet%20Li%20FeiFei%20and%20Silvio%20Savarese%20Social%20LSTM%20Human%20Trajectory%20Prediction%20in%20Crowded%20Spaces%20In%20CVPR%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Alexandre%20Alahi%20Kratarth%20Goel%20Vignesh%20Ramanathan%20Alexandre%20Robicquet%20Li%20FeiFei%20and%20Silvio%20Savarese%20Social%20LSTM%20Human%20Trajectory%20Prediction%20in%20Crowded%20Spaces%20In%20CVPR%202016"
        },
        {
            "id": "Alemi_et+al_2018_a",
            "entry": "Alexander A Alemi, Ben Poole, Ian Fischer, Joshua V Dillon, Rif A Saurous, and Kevin Murphy. Fixing a broken ELBO. In ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Alemi%2C%20Alexander%20A.%20Poole%2C%20Ben%20Fischer%2C%20Ian%20Dillon%2C%20Joshua%20V.%20Rif%20A%20Saurous%2C%20and%20Kevin%20Murphy.%20Fixing%20a%20broken%20ELBO%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Alemi%2C%20Alexander%20A.%20Poole%2C%20Ben%20Fischer%2C%20Ian%20Dillon%2C%20Joshua%20V.%20Rif%20A%20Saurous%2C%20and%20Kevin%20Murphy.%20Fixing%20a%20broken%20ELBO%202018"
        },
        {
            "id": "Babaeizadeh_et+al_2018_a",
            "entry": "Mohammad Babaeizadeh, Chelsea Finn, Dumitru Erhan, Roy H Campbell, and Sergey Levine. Stochastic variational video prediction. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Babaeizadeh%2C%20Mohammad%20Finn%2C%20Chelsea%20Erhan%2C%20Dumitru%20Campbell%2C%20Roy%20H.%20Stochastic%20variational%20video%20prediction%202018"
        },
        {
            "id": "Bar-Shalom_et+al_2011_a",
            "entry": "Yaakov Bar-Shalom, Peter K Willett, and Xin Tian. Tracking and Data Fusion: A Handbook of Algorithms. Yaakov Bar-Shalom, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bar-Shalom%2C%20Yaakov%20Willett%2C%20Peter%20K.%20Tian%2C%20Xin%20Tracking%20and%20Data%20Fusion%3A%20A%20Handbook%20of%20Algorithms%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bar-Shalom%2C%20Yaakov%20Willett%2C%20Peter%20K.%20Tian%2C%20Xin%20Tracking%20and%20Data%20Fusion%3A%20A%20Handbook%20of%20Algorithms%202011"
        },
        {
            "id": "Battaglia_et+al_2016_a",
            "entry": "Peter W Battaglia, Razvan Pascanu, Matthew Lai, Danilo J Rezende, and Koray Kavukcuoglu. Interaction networks for learning about objects, relations and physics. In NeurIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Battaglia%2C%20Peter%20W.%20Pascanu%2C%20Razvan%20Lai%2C%20Matthew%20Rezende%2C%20Danilo%20J.%20Interaction%20networks%20for%20learning%20about%20objects%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Battaglia%2C%20Peter%20W.%20Pascanu%2C%20Razvan%20Lai%2C%20Matthew%20Rezende%2C%20Danilo%20J.%20Interaction%20networks%20for%20learning%20about%20objects%202016"
        },
        {
            "id": "Battaglia_et+al_2018_a",
            "entry": "Peter W Battaglia, Jessica B Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, Caglar Gulcehre, Francis Song, Andrew Ballard, Justin Gilmer, George Dahl, Ashish Vaswani, Kelsey Allen, Charles Nash, Victoria Langston, Chris Dyer, Nicolas Heess, Daan Wierstra, Pushmeet Kohli, Matt Botvinick, Oriol Vinyals, Yujia Li, and Razvan Pascanu. Relational inductive biases, deep learning, and graph networks. arXiv:1806.01261, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1806.01261"
        },
        {
            "id": "Bengio_et+al_2015_a",
            "entry": "Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and Noam Shazeer. Scheduled sampling for sequence prediction with recurrent neural networks. In NeurIPS, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bengio%2C%20Samy%20Vinyals%2C%20Oriol%20Jaitly%2C%20Navdeep%20Shazeer%2C%20Noam%20Scheduled%20sampling%20for%20sequence%20prediction%20with%20recurrent%20neural%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bengio%2C%20Samy%20Vinyals%2C%20Oriol%20Jaitly%2C%20Navdeep%20Shazeer%2C%20Noam%20Scheduled%20sampling%20for%20sequence%20prediction%20with%20recurrent%20neural%20networks%202015"
        },
        {
            "id": "Bowman_et+al_2016_a",
            "entry": "Samuel R Bowman, Luke Vilnis, Oriol Vinyals, Andrew M Dai, Rafal Jozefowicz, and Samy Bengio. Generating sentences from a continuous space. In CoNLL, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bowman%2C%20Samuel%20R.%20Vilnis%2C%20Luke%20Vinyals%2C%20Oriol%20Dai%2C%20Andrew%20M.%20Generating%20sentences%20from%20a%20continuous%20space%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bowman%2C%20Samuel%20R.%20Vilnis%2C%20Luke%20Vinyals%2C%20Oriol%20Dai%2C%20Andrew%20M.%20Generating%20sentences%20from%20a%20continuous%20space%202016"
        },
        {
            "id": "Buesing_et+al_2018_a",
            "entry": "Lars Buesing, Theophane Weber, Sebastien Racaniere, S. M. Ali Eslami, Danilo Rezende, David P. Reichert, Fabio Viola, Frederic Besse, Karol Gregor, Demis Hassabis, and Daan Wierstra. Learning and querying fast generative models for reinforcement learning. arXiv:1802.03006, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.03006"
        },
        {
            "id": "Chang_et+al_2017_a",
            "entry": "Michael B Chang, Tomer Ullman, Antonio Torralba, and Joshua B Tenenbaum. A compositional object-based approach to learning physical dynamics. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chang%2C%20Michael%20B.%20Ullman%2C%20Tomer%20Torralba%2C%20Antonio%20Tenenbaum%2C%20Joshua%20B.%20A%20compositional%20object-based%20approach%20to%20learning%20physical%20dynamics%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chang%2C%20Michael%20B.%20Ullman%2C%20Tomer%20Torralba%2C%20Antonio%20Tenenbaum%2C%20Joshua%20B.%20A%20compositional%20object-based%20approach%20to%20learning%20physical%20dynamics%202017"
        },
        {
            "id": "Chung_et+al_2015_a",
            "entry": "Junyoung Chung, Kyle Kastner, Laurent Dinh, Kratarth Goel, Aaron C Courville, and Yoshua Bengio. A recurrent latent variable model for sequential data. In NeurIPS, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chung%2C%20Junyoung%20Kastner%2C%20Kyle%20Dinh%2C%20Laurent%20Goel%2C%20Kratarth%20and%20Yoshua%20Bengio.%20A%20recurrent%20latent%20variable%20model%20for%20sequential%20data%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chung%2C%20Junyoung%20Kastner%2C%20Kyle%20Dinh%2C%20Laurent%20Goel%2C%20Kratarth%20and%20Yoshua%20Bengio.%20A%20recurrent%20latent%20variable%20model%20for%20sequential%20data%202015"
        },
        {
            "id": "Denton_2018_a",
            "entry": "Emily Denton and Rob Fergus. Stochastic video generation with a learned prior. In ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Denton%2C%20Emily%20Fergus%2C%20Rob%20Stochastic%20video%20generation%20with%20a%20learned%20prior%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Denton%2C%20Emily%20Fergus%2C%20Rob%20Stochastic%20video%20generation%20with%20a%20learned%20prior%202018"
        },
        {
            "id": "Dequaire_et+al_2018_a",
            "entry": "Julie Dequaire, Peter Ondruska, Dushyant Rao, Dominic Wang, and Ingmar Posner. Deep tracking in the wild: End-to-end tracking using recurrent neural networks. The International Journal of Robotics Research, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dequaire%2C%20Julie%20Ondruska%2C%20Peter%20Rao%2C%20Dushyant%20Wang%2C%20Dominic%20Deep%20tracking%20in%20the%20wild%3A%20End-to-end%20tracking%20using%20recurrent%20neural%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dequaire%2C%20Julie%20Ondruska%2C%20Peter%20Rao%2C%20Dushyant%20Wang%2C%20Dominic%20Deep%20tracking%20in%20the%20wild%3A%20End-to-end%20tracking%20using%20recurrent%20neural%20networks%202018"
        },
        {
            "id": "Ehrhardt_et+al_2017_a",
            "entry": "Sebastien Ehrhardt, Aron Monszpart, Niloy Mitra, and Andrea Vedaldi. Taking visual motion prediction to new heightfields. arXiv:1712.09448, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.09448"
        },
        {
            "id": "Felsen_et+al_2017_a",
            "entry": "Panna Felsen, Pulkit Agrawal, and Jitendra Malik. What will happen next? forecasting player moves in sports videos. In ICCV, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Felsen%2C%20Panna%20Agrawal%2C%20Pulkit%20Malik%2C%20Jitendra%20What%20will%20happen%20next%3F%20forecasting%20player%20moves%20in%20sports%20videos%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Felsen%2C%20Panna%20Agrawal%2C%20Pulkit%20Malik%2C%20Jitendra%20What%20will%20happen%20next%3F%20forecasting%20player%20moves%20in%20sports%20videos%202017"
        },
        {
            "id": "Fraccaro_et+al_2016_a",
            "entry": "Marco Fraccaro, S\u00f8ren Kaae S\u00f8nderby, Ulrich Paquet, and Ole Winther. Sequential neural models with stochastic layers. In NeurIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fraccaro%2C%20Marco%20S%C3%B8nderby%2C%20S%C3%B8ren%20Kaae%20Paquet%2C%20Ulrich%20Winther%2C%20Ole%20Sequential%20neural%20models%20with%20stochastic%20layers%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fraccaro%2C%20Marco%20S%C3%B8nderby%2C%20S%C3%B8ren%20Kaae%20Paquet%2C%20Ulrich%20Winther%2C%20Ole%20Sequential%20neural%20models%20with%20stochastic%20layers%202016"
        },
        {
            "id": "Fragkiadaki_et+al_2016_a",
            "entry": "Katerina Fragkiadaki, Pulkit Agrawal, Sergey Levine, and Jitendra Malik. Learning visual predictive models of physics for playing billiards. In ICLR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fragkiadaki%2C%20Katerina%20Agrawal%2C%20Pulkit%20Levine%2C%20Sergey%20Malik%2C%20Jitendra%20Learning%20visual%20predictive%20models%20of%20physics%20for%20playing%20billiards%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fragkiadaki%2C%20Katerina%20Agrawal%2C%20Pulkit%20Levine%2C%20Sergey%20Malik%2C%20Jitendra%20Learning%20visual%20predictive%20models%20of%20physics%20for%20playing%20billiards%202016"
        },
        {
            "id": "Goyal_et+al_2017_a",
            "entry": "Anirudh Goyal, Alessandro Sordoni, Marc-Alexandre Cote, Nan Rosemary Ke, and Yoshua Bengio. Z-forcing: Training stochastic recurrent networks. In NeurIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goyal%2C%20Anirudh%20Sordoni%2C%20Alessandro%20Cote%2C%20Marc-Alexandre%20Ke%2C%20Nan%20Rosemary%20Z-forcing%3A%20Training%20stochastic%20recurrent%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goyal%2C%20Anirudh%20Sordoni%2C%20Alessandro%20Cote%2C%20Marc-Alexandre%20Ke%2C%20Nan%20Rosemary%20Z-forcing%3A%20Training%20stochastic%20recurrent%20networks%202017"
        },
        {
            "id": "Gupta_et+al_2018_a",
            "entry": "Agrim Gupta, Justin Johnson, Li Fei-Fei, Silvio Savarese, and Alexandre Alahi. Social GAN: Socially acceptable trajectories with generative adversarial networks. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gupta%2C%20Agrim%20Johnson%2C%20Justin%20Fei-Fei%2C%20Li%20Savarese%2C%20Silvio%20Social%20GAN%3A%20Socially%20acceptable%20trajectories%20with%20generative%20adversarial%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gupta%2C%20Agrim%20Johnson%2C%20Justin%20Fei-Fei%2C%20Li%20Savarese%2C%20Silvio%20Social%20GAN%3A%20Socially%20acceptable%20trajectories%20with%20generative%20adversarial%20networks%202018"
        },
        {
            "id": "Haarnoja_et+al_2016_a",
            "entry": "Tuomas Haarnoja, Anurag Ajay, Sergey Levine, and Pieter Abbeel. Backprop KF: Learning discriminative deterministic state estimators. In nips, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Haarnoja%2C%20Tuomas%20Ajay%2C%20Anurag%20Levine%2C%20Sergey%20Abbeel%2C%20Pieter%20Backprop%20KF%3A%20Learning%20discriminative%20deterministic%20state%20estimators%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Haarnoja%2C%20Tuomas%20Ajay%2C%20Anurag%20Levine%2C%20Sergey%20Abbeel%2C%20Pieter%20Backprop%20KF%3A%20Learning%20discriminative%20deterministic%20state%20estimators%202016"
        },
        {
            "id": "He_et+al_2016_a",
            "entry": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "Hoshen_2017_a",
            "entry": "Yedid Hoshen. VAIN: Attentional multi-agent predictive modeling. arXiv:1706.06122, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.06122"
        },
        {
            "id": "Karl_et+al_2017_a",
            "entry": "Maximilian Karl, Maximilian Soelch, Justin Bayer, and Patrick van der Smagt. Deep variational bayes filters: Unsupervised learning of state space models from raw data. In ICLR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Karl%2C%20Maximilian%20Soelch%2C%20Maximilian%20Bayer%2C%20Justin%20van%20der%20Smagt%2C%20Patrick%20Deep%20variational%20bayes%20filters%3A%20Unsupervised%20learning%20of%20state%20space%20models%20from%20raw%20data%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Karl%2C%20Maximilian%20Soelch%2C%20Maximilian%20Bayer%2C%20Justin%20van%20der%20Smagt%2C%20Patrick%20Deep%20variational%20bayes%20filters%3A%20Unsupervised%20learning%20of%20state%20space%20models%20from%20raw%20data%202017"
        },
        {
            "id": "Kingma_2014_a",
            "entry": "Diederik Kingma and Max Welling. Auto-encoding variational bayes. In ICLR, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Diederik%20Welling%2C%20Max%20Auto-encoding%20variational%20bayes%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20Diederik%20Welling%2C%20Max%20Auto-encoding%20variational%20bayes%202014"
        },
        {
            "id": "Kipf_et+al_2018_a",
            "entry": "Thomas Kipf, Ethan Fetaya, Kuan-Chieh Wang, Max Welling, and Richard Zemel. Neural relational inference for interacting systems. In ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kipf%2C%20Thomas%20Fetaya%2C%20Ethan%20Wang%2C%20Kuan-Chieh%20Welling%2C%20Max%20Neural%20relational%20inference%20for%20interacting%20systems%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kipf%2C%20Thomas%20Fetaya%2C%20Ethan%20Wang%2C%20Kuan-Chieh%20Welling%2C%20Max%20Neural%20relational%20inference%20for%20interacting%20systems%202018"
        },
        {
            "id": "Kitani_et+al_2017_a",
            "entry": "Kris M. Kitani, De-An Huang, and Wei-Chiu Ma. Activity forecasting. In Group and Crowd Behavior for Computer Vision. Elsevier, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kitani%2C%20Kris%20M.%20Huang%2C%20De-An%20Ma%2C%20Wei-Chiu%20Activity%20forecasting.%20In%20Group%20and%20Crowd%20Behavior%20for%20Computer%20Vision%202017"
        },
        {
            "id": "Kosiorek_et+al_2018_a",
            "entry": "Adam R Kosiorek, Hyunjik Kim, Ingmar Posner, and Yee Whye Teh. Sequential attend, infer, repeat: Generative modelling of moving objects. arXiv:1806.01794, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1806.01794"
        },
        {
            "id": "Krishnan_et+al_2017_a",
            "entry": "Rahul G Krishnan, Uri Shalit, and David Sontag. Structured inference networks for nonlinear state space models. In AAAI, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krishnan%2C%20Rahul%20G.%20Shalit%2C%20Uri%20Sontag%2C%20David%20Structured%20inference%20networks%20for%20nonlinear%20state%20space%20models%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krishnan%2C%20Rahul%20G.%20Shalit%2C%20Uri%20Sontag%2C%20David%20Structured%20inference%20networks%20for%20nonlinear%20state%20space%20models%202017"
        },
        {
            "id": "Lee_et+al_2018_a",
            "entry": "Alex X Lee, Richard Zhang, Frederik Ebert, Pieter Abbeel, Chelsea Finn, and Sergey Levine. Stochastic adversarial video prediction. arXiv:1804.01523, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.01523"
        },
        {
            "id": "Lee_et+al_2017_a",
            "entry": "Namhoon Lee, Wongun Choi, Paul Vernaza, Christopher B Choy, Philip H S Torr, and Manmohan Chandraker. DESIRE: Distant future prediction in dynamic scenes with interacting agents. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lee%2C%20Namhoon%20Choi%2C%20Wongun%20Vernaza%2C%20Paul%20Choy%2C%20Christopher%20B.%20DESIRE%3A%20Distant%20future%20prediction%20in%20dynamic%20scenes%20with%20interacting%20agents%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lee%2C%20Namhoon%20Choi%2C%20Wongun%20Vernaza%2C%20Paul%20Choy%2C%20Christopher%20B.%20DESIRE%3A%20Distant%20future%20prediction%20in%20dynamic%20scenes%20with%20interacting%20agents%202017"
        },
        {
            "id": "Lerer_et+al_2016_a",
            "entry": "Adam Lerer, Sam Gross, and Rob Fergus. Learning physical intuition of block towers by example. In ICML, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lerer%2C%20Adam%20Gross%2C%20Sam%20Fergus%2C%20Rob%20Learning%20physical%20intuition%20of%20block%20towers%20by%20example%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lerer%2C%20Adam%20Gross%2C%20Sam%20Fergus%2C%20Rob%20Learning%20physical%20intuition%20of%20block%20towers%20by%20example%202016"
        },
        {
            "id": "Manafifard_et+al_2017_a",
            "entry": "M Manafifard, H Ebadi, and H Abrishami Moghaddam. A survey on player tracking in soccer videos. CVIU, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Manafifard%2C%20M.%20Ebadi%2C%20H.%20H.%20Abrishami%20Moghaddam.%20A%20survey%20on%20player%20tracking%20in%20soccer%20videos%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Manafifard%2C%20M.%20Ebadi%2C%20H.%20H.%20Abrishami%20Moghaddam.%20A%20survey%20on%20player%20tracking%20in%20soccer%20videos%202017"
        },
        {
            "id": "Mathieu_et+al_2016_a",
            "entry": "Michael Mathieu, Camille Couprie, and Yann LeCun. Deep multi-scale video prediction beyond mean square error. In ICLR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mathieu%2C%20Michael%20Couprie%2C%20Camille%20LeCun%2C%20Yann%20Deep%20multi-scale%20video%20prediction%20beyond%20mean%20square%20error%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mathieu%2C%20Michael%20Couprie%2C%20Camille%20LeCun%2C%20Yann%20Deep%20multi-scale%20video%20prediction%20beyond%20mean%20square%20error%202016"
        },
        {
            "id": "Mottaghi_et+al_2016_a",
            "entry": "Roozbeh Mottaghi, Hessam Bagherinezhad, Mohammad Rastegari, and Ali Farhadi. Newtonian scene understanding: Unfolding the dynamics of objects in static images. In CVPR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mottaghi%2C%20Roozbeh%20Bagherinezhad%2C%20Hessam%20Rastegari%2C%20Mohammad%20Farhadi%2C%20Ali%20Newtonian%20scene%20understanding%3A%20Unfolding%20the%20dynamics%20of%20objects%20in%20static%20images%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mottaghi%2C%20Roozbeh%20Bagherinezhad%2C%20Hessam%20Rastegari%2C%20Mohammad%20Farhadi%2C%20Ali%20Newtonian%20scene%20understanding%3A%20Unfolding%20the%20dynamics%20of%20objects%20in%20static%20images%202016"
        },
        {
            "id": "Rematas_et+al_2018_a",
            "entry": "Konstantinos Rematas, Ira Kemelmacher-Shlizerman, Brian Curless, and Steve Seitz. Soccer on your tabletop. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rematas%2C%20Konstantinos%20Kemelmacher-Shlizerman%2C%20Ira%20Curless%2C%20Brian%20Seitz%2C%20Steve%20Soccer%20on%20your%20tabletop%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rematas%2C%20Konstantinos%20Kemelmacher-Shlizerman%2C%20Ira%20Curless%2C%20Brian%20Seitz%2C%20Steve%20Soccer%20on%20your%20tabletop%202018"
        },
        {
            "id": "Sanchez-Gonzalez_et+al_2018_a",
            "entry": "Alvaro Sanchez-Gonzalez, Nicolas Heess, Jost Tobias Springenberg, Josh Merel, Martin Riedmiller, Raia Hadsell, and Peter Battaglia. Graph networks as learnable physics engines for inference and control. In ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sanchez-Gonzalez%2C%20Alvaro%20Heess%2C%20Nicolas%20Springenberg%2C%20Jost%20Tobias%20Merel%2C%20Josh%20Graph%20networks%20as%20learnable%20physics%20engines%20for%20inference%20and%20control%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sanchez-Gonzalez%2C%20Alvaro%20Heess%2C%20Nicolas%20Springenberg%2C%20Jost%20Tobias%20Merel%2C%20Josh%20Graph%20networks%20as%20learnable%20physics%20engines%20for%20inference%20and%20control%202018"
        },
        {
            "id": "Sanguesa_2017_a",
            "entry": "Adria Arbues Sanguesa. Identifying basketball plays from sensor data; towards a Low-Cost automatic extraction of advanced statistics. Master\u2019s thesis, Aarlborg, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sanguesa%2C%20Adria%20Arbues%20Identifying%20basketball%20plays%20from%20sensor%20data%3B%20towards%20a%20Low-Cost%20automatic%20extraction%20of%20advanced%20statistics%202017"
        },
        {
            "id": "Santoro_et+al_2017_a",
            "entry": "Adam Santoro, David Raposo, David G Barrett, Mateusz Malinowski, Razvan Pascanu, Peter Battaglia, and Tim Lillicrap. A simple neural network module for relational reasoning. In NeurIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Santoro%2C%20Adam%20Raposo%2C%20David%20Barrett%2C%20David%20G.%20Malinowski%2C%20Mateusz%20A%20simple%20neural%20network%20module%20for%20relational%20reasoning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Santoro%2C%20Adam%20Raposo%2C%20David%20Barrett%2C%20David%20G.%20Malinowski%2C%20Mateusz%20A%20simple%20neural%20network%20module%20for%20relational%20reasoning%202017"
        },
        {
            "id": "Tulyakov_et+al_2018_a",
            "entry": "Sergey Tulyakov, Ming-Yu Liu, Xiaodong Yang, and Jan Kautz. MoCoGAN: Decomposing motion and content for video generation. In CVPR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tulyakov%2C%20Sergey%20Liu%2C%20Ming-Yu%20Yang%2C%20Xiaodong%20Kautz%2C%20Jan%20MoCoGAN%3A%20Decomposing%20motion%20and%20content%20for%20video%20generation%202018"
        },
        {
            "id": "Van_et+al_2018_a",
            "entry": "Sjoerd van Steenkiste, Michael Chang, Klaus Greff, and Jurgen Schmidhuber. Relational neural expectation maximization: Unsupervised discovery of objects and their interactions. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=van%20Steenkiste%2C%20Sjoerd%20Chang%2C%20Michael%20Greff%2C%20Klaus%20Schmidhuber%2C%20Jurgen%20Relational%20neural%20expectation%20maximization%3A%20Unsupervised%20discovery%20of%20objects%20and%20their%20interactions%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=van%20Steenkiste%2C%20Sjoerd%20Chang%2C%20Michael%20Greff%2C%20Klaus%20Schmidhuber%2C%20Jurgen%20Relational%20neural%20expectation%20maximization%3A%20Unsupervised%20discovery%20of%20objects%20and%20their%20interactions%202018"
        },
        {
            "id": "Velickovic_et+al_2018_a",
            "entry": "Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. Graph attention networks. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Petar%20Velickovic%20Guillem%20Cucurull%20Arantxa%20Casanova%20Adriana%20Romero%20Pietro%20Lio%20and%20Yoshua%20Bengio%20Graph%20attention%20networks%20In%20ICLR%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Petar%20Velickovic%20Guillem%20Cucurull%20Arantxa%20Casanova%20Adriana%20Romero%20Pietro%20Lio%20and%20Yoshua%20Bengio%20Graph%20attention%20networks%20In%20ICLR%202018"
        },
        {
            "id": "Vondrick_et+al_2016_a",
            "entry": "Carl Vondrick, Hamed Pirsiavash, and Antonio Torralba. Anticipating visual representations from unlabeled video. In CVPR, 2016a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vondrick%2C%20Carl%20Pirsiavash%2C%20Hamed%20Torralba%2C%20Antonio%20Anticipating%20visual%20representations%20from%20unlabeled%20video%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vondrick%2C%20Carl%20Pirsiavash%2C%20Hamed%20Torralba%2C%20Antonio%20Anticipating%20visual%20representations%20from%20unlabeled%20video%202016"
        },
        {
            "id": "Published_2019_a",
            "entry": "Published as a conference paper at ICLR 2019 Carl Vondrick, Hamed Pirsiavash, and Antonio Torralba. Generating videos with scene dynamics. In",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Published%20as%20a%20conference%20paper%20at%20ICLR%202019%20Carl%20Vondrick%20Hamed%20Pirsiavash%20and%20Antonio%20Torralba%20Generating%20videos%20with%20scene%20dynamics%20In",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Published%20as%20a%20conference%20paper%20at%20ICLR%202019%20Carl%20Vondrick%20Hamed%20Pirsiavash%20and%20Antonio%20Torralba%20Generating%20videos%20with%20scene%20dynamics%20In"
        },
        {
            "id": "Neurips_2016_a",
            "entry": "NeurIPS, 2016b. Jacob Walker, Carl Doersch, Abhinav Gupta, and Martial Hebert. An uncertain future: Forecasting from static images using variational autoencoders. In ECCV, 2016. Nicholas Watters, Andrea Tacchetti, Theophane Weber, Razvan Pascanu, Peter Battaglia, and Daniel",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=NeurIPS%202016b%20Jacob%20Walker%20Carl%20Doersch%20Abhinav%20Gupta%20and%20Martial%20Hebert%20An%20uncertain%20future%20Forecasting%20from%20static%20images%20using%20variational%20autoencoders%20In%20ECCV%202016%20Nicholas%20Watters%20Andrea%20Tacchetti%20Theophane%20Weber%20Razvan%20Pascanu%20Peter%20Battaglia%20and%20Daniel",
            "oa_query": "https://api.scholarcy.com/oa_version?query=NeurIPS%202016b%20Jacob%20Walker%20Carl%20Doersch%20Abhinav%20Gupta%20and%20Martial%20Hebert%20An%20uncertain%20future%20Forecasting%20from%20static%20images%20using%20variational%20autoencoders%20In%20ECCV%202016%20Nicholas%20Watters%20Andrea%20Tacchetti%20Theophane%20Weber%20Razvan%20Pascanu%20Peter%20Battaglia%20and%20Daniel"
        },
        {
            "id": "Zoran_2017_a",
            "entry": "Zoran. Visual interaction networks. In NeurIPS, 2017. Jiajun Wu, Erika Lu, Pushmeet Kohli, Bill Freeman, and Josh Tenenbaum. Learning to see physics via visual de-animation. In NeurIPS, 2017. Saining Xie, Chen Sun, Jonathan Huang, Zhuowen Tu, and Kevin Murphy. Rethinking spatiotemporal feature learning: Speed-accuracy trade-offs in video classification. In ECCV, 2018. Tianfan Xue, Jiajun Wu, Katherine Bouman, and Bill Freeman. Visual dynamics: Probabilistic future frame synthesis via cross convolutional networks. In NeurIPS, 2016. Eric Zhan, Stephan Zheng, Yisong Yue, Long Sha, and Patrick Lucey. Generative multi-agent behavioral cloning. arXiv:1803.07612, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.07612"
        }
    ]
}

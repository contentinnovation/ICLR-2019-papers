{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "LEARNING EMBEDDINGS INTO ENTROPIC WASSERSTEIN SPACES",
        "author": "Charlie Frogner MIT CSAIL and MIT-IBM Watson AI Lab frogner@mit.edu",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=rJg4J3CqFm"
        },
        "abstract": "Euclidean embeddings of data are fundamentally limited in their ability to capture latent semantic structures, which need not conform to Euclidean spatial assumptions. Here we consider an alternative, which embeds data as discrete probability distributions in a Wasserstein space, endowed with an optimal transport metric. Wasserstein spaces are much larger and more flexible than Euclidean spaces, in that they can successfully embed a wider variety of metric structures. We exploit this flexibility by learning an embedding that captures semantic information in the Wasserstein distance between embedded distributions. We examine empirically the representational capacity of our learned Wasserstein embeddings, showing that they can embed a wide variety of metric structures with smaller distortion than an equivalent Euclidean embedding. We also investigate an application to word embedding, demonstrating a unique advantage of Wasserstein embeddings: We can visualize the high-dimensional embedding directly, since it is a probability distribution on a low-dimensional space. This obviates the need for dimensionality reduction techniques like t-SNE for visualization."
    },
    "keywords": [
        {
            "term": "word embedding",
            "url": "https://en.wikipedia.org/wiki/word_embedding"
        },
        {
            "term": "wasserstein distance",
            "url": "https://en.wikipedia.org/wiki/wasserstein_distance"
        },
        {
            "term": "dimensionality reduction",
            "url": "https://en.wikipedia.org/wiki/dimensionality_reduction"
        },
        {
            "term": "probability distribution",
            "url": "https://en.wikipedia.org/wiki/probability_distribution"
        },
        {
            "term": "word vector",
            "url": "https://en.wikipedia.org/wiki/word_vector"
        },
        {
            "term": "metric structure",
            "url": "https://en.wikipedia.org/wiki/metric_structure"
        },
        {
            "term": "euclidean space",
            "url": "https://en.wikipedia.org/wiki/euclidean_space"
        },
        {
            "term": "knowledge graph",
            "url": "https://en.wikipedia.org/wiki/knowledge_graph"
        },
        {
            "term": "optimal transport",
            "url": "https://en.wikipedia.org/wiki/optimal_transport"
        }
    ],
    "abbreviations": {},
    "highlights": [
        "Learned embeddings form the basis for many state-of-the-art learning systems",
        "An effective embedding should capture the semantic structure of the data with high fidelity, in a way that is amenable to downstream tasks",
        "We empirically investigate two settings for Wasserstein embeddings",
        "We learn to embed into the space of discrete probability distributions endowed with the Wasserstein distance",
        "As discussed in \u00a72.3, theory suggests that Wasserstein spaces are quite flexible, in that they can embed a wide variety of metrics with low distortion",
        "Entropy-regularized Wasserstein distances are effective for embedding a wide variety of semantic structures, while enabling direct visualization of the embedding"
    ],
    "key_statements": [
        "Learned embeddings form the basis for many state-of-the-art learning systems",
        "An effective embedding should capture the semantic structure of the data with high fidelity, in a way that is amenable to downstream tasks",
        "We empirically investigate two settings for Wasserstein embeddings",
        "Theoretical results in this domain are motivated by interest in efficient algorithms for approximating Wasserstein distances by embedding into spaces with -computed metrics",
        "In \u00a74, we empirically investigate the embedding capacity of Wasserstein spaces, by attempting to learn low-distortion embeddings for a variety of input spaces",
        "We learn to embed into the space of discrete probability distributions endowed with the Wasserstein distance",
        "Our objective is to find a map \u03c6 : C \u2192 Wp(X ) such that the relationship r(u, v) can be recovered from the Wasserstein distance between \u03c6(u) and \u03c6(v), for any u, v \u2208 C",
        "As discussed in \u00a72.3, theory suggests that Wasserstein spaces are quite flexible, in that they can embed a wide variety of metrics with low distortion",
        "The collection of vertices for each network serves as the input space C for our embedding, and our goal is to learn a map \u03c6 : C \u2192 Wp(Rk) such that the 1-Wasserstein distance W1(\u03c6(u), \u03c6(v)) matches as closely as possible the shortest path distance between vertices u and v, for all pairs of vertices",
        "We examine the performance of Wasserstein embedding using both random networks and real networks",
        "Entropy-regularized Wasserstein distances are effective for embedding a wide variety of semantic structures, while enabling direct visualization of the embedding"
    ],
    "summary": [
        "Learned embeddings form the basis for many state-of-the-art learning systems.",
        "The p-Wasserstein distance between probability distributions \u03bc and \u03bd over a metric space X is p",
        "Wp(A), for A an arbitrary metric space, embeds any product space An, for example (<a class=\"ref-link\" id=\"cKloeckner_2010_a\" href=\"#rKloeckner_2010_a\">Kloeckner, 2010</a>), via discrete distributions supported at n points.",
        "The reverse direction, embedding Wasserstein spaces into others, is well-studied in the case of discrete distributions.",
        "Theoretical results in this domain are motivated by interest in efficient algorithms for approximating Wasserstein distances by embedding into spaces with -computed metrics.",
        "The embedding capacity of Sinkhorn divergences is previously unstudied, to our knowledge, except in the weak sense that the approximation error with respect to the Wasserstein distance vanishes with the regularizer taken to zero (<a class=\"ref-link\" id=\"cCarlier_et+al_2017_a\" href=\"#rCarlier_et+al_2017_a\">Carlier et al, 2017</a>; <a class=\"ref-link\" id=\"cGenevay_et+al_2018_a\" href=\"#rGenevay_et+al_2018_a\">Genevay et al, 2018a</a>).",
        "We learn to embed into the space of discrete probability distributions endowed with the Wasserstein distance.",
        "We restrict ourselves to discrete distributions with an a priori fixed number of support points M , reducing optimal transport to the linear program in Equation 3.",
        "As discussed in \u00a72.3, theory suggests that Wasserstein spaces are quite flexible, in that they can embed a wide variety of metrics with low distortion.",
        "The collection of vertices for each network serves as the input space C for our embedding, and our goal is to learn a map \u03c6 : C \u2192 Wp(Rk) such that the 1-Wasserstein distance W1(\u03c6(u), \u03c6(v)) matches as closely as possible the shortest path distance between vertices u and v, for all pairs of vertices.",
        "We learn a minimum-distortion embedding: Given a fully-observed distance metric dC : C \u00d7C \u2192 R in the input space, we minimize the mean distortion: \u03c6\u2217 = arg min \u03c6 n 2",
        "Entropy-regularized Wasserstein distances are effective for embedding a wide variety of semantic structures, while enabling direct visualization of the embedding.",
        "Beyond simple extensions like weighting points in the point cloud, one observation is that we can lift nearly any representation space X to distributions over that space W(X ) represented as point clouds; in this paper we focused on the case X = Rn. Since X embeds within W(X ) using \u03b4-functions, this might be viewed as a general \u201clifting\u201d procedure increasing the capacity of a representation.",
        "Following recent work on computing geodesics in Wasserstein space (Seguy & Cuturi, 2015), it may be interesting to invert the learned mappings and use them for interpolation."
    ],
    "headline": "We examine empirically the representational capacity of our learned Wasserstein embeddings, showing that they can embed a wide variety of metric structures with smaller distortion than an equivalent Euclidean embedding",
    "reference_links": [
        {
            "id": "Albert_2002_a",
            "entry": "Reka Albert and Albert-Laszlo Barabasi. Statistical mechanics of complex networks. Reviews of Modern Physics, 74(1):47, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Albert%2C%20Reka%20Barabasi%2C%20Albert-Laszlo%20Statistical%20mechanics%20of%20complex%20networks%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Albert%2C%20Reka%20Barabasi%2C%20Albert-Laszlo%20Statistical%20mechanics%20of%20complex%20networks%202002"
        },
        {
            "id": "Andoni_et+al_0000_a",
            "entry": "Alexandr Andoni, Assaf Naor, and Ofer Neiman. Snowflake universality of Wasserstein spaces. arXiv:1509.08677, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1509.08677"
        },
        {
            "id": "Andoni_et+al_2016_a",
            "entry": "Alexandr Andoni, Assaf Naor, and Ofer Neiman. Impossibility of sketching of the 3d transportation metric with quadratic cost. In LIPIcs-Leibniz International Proceedings in Informatics, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Andoni%2C%20Alexandr%20Naor%2C%20Assaf%20Neiman%2C%20Ofer%20Impossibility%20of%20sketching%20of%20the%203d%20transportation%20metric%20with%20quadratic%20cost%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Andoni%2C%20Alexandr%20Naor%2C%20Assaf%20Neiman%2C%20Ofer%20Impossibility%20of%20sketching%20of%20the%203d%20transportation%20metric%20with%20quadratic%20cost%202016"
        },
        {
            "id": "Arjovsky_et+al_2017_a",
            "entry": "Martin Arjovsky, Soumith Chintala, and Leon Bottou. Wasserstein generative adversarial networks. In ICML, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arjovsky%2C%20Martin%20Chintala%2C%20Soumith%20Bottou%2C%20Leon%20Wasserstein%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arjovsky%2C%20Martin%20Chintala%2C%20Soumith%20Bottou%2C%20Leon%20Wasserstein%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "Athiwaratkun_2018_a",
            "entry": "Ben Athiwaratkun and Andrew Gordon Wilson. On modeling hierarchical data via probabilistic order embeddings. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Athiwaratkun%2C%20Ben%20Wilson%2C%20Andrew%20Gordon%20On%20modeling%20hierarchical%20data%20via%20probabilistic%20order%20embeddings%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Athiwaratkun%2C%20Ben%20Wilson%2C%20Andrew%20Gordon%20On%20modeling%20hierarchical%20data%20via%20probabilistic%20order%20embeddings%202018"
        },
        {
            "id": "Bojanowski_et+al_2017_a",
            "entry": "Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. Enriching word vectors with subword information. TACL, 5:135\u2013146, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bojanowski%2C%20Piotr%20Grave%2C%20Edouard%20Joulin%2C%20Armand%20Mikolov%2C%20Tomas%20Enriching%20word%20vectors%20with%20subword%20information%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bojanowski%2C%20Piotr%20Grave%2C%20Edouard%20Joulin%2C%20Armand%20Mikolov%2C%20Tomas%20Enriching%20word%20vectors%20with%20subword%20information%202017"
        },
        {
            "id": "Bojchevski_2018_a",
            "entry": "Aleksandar Bojchevski and Stephan Gunnemann. Deep Gaussian embedding of graphs: Unsupervised inductive learning via ranking. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bojchevski%2C%20Aleksandar%20Gunnemann%2C%20Stephan%20Deep%20Gaussian%20embedding%20of%20graphs%3A%20Unsupervised%20inductive%20learning%20via%20ranking%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bojchevski%2C%20Aleksandar%20Gunnemann%2C%20Stephan%20Deep%20Gaussian%20embedding%20of%20graphs%3A%20Unsupervised%20inductive%20learning%20via%20ranking%202018"
        },
        {
            "id": "Bourgain_1986_a",
            "entry": "Jean Bourgain. The metrical interpretation of superreflexivity in banach spaces. Israel Journal of Mathematics, 56(2):222\u2013230, 1986.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bourgain%2C%20Jean%20The%20metrical%20interpretation%20of%20superreflexivity%20in%20banach%20spaces%201986",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bourgain%2C%20Jean%20The%20metrical%20interpretation%20of%20superreflexivity%20in%20banach%20spaces%201986"
        },
        {
            "id": "Brancolini_et+al_2009_a",
            "entry": "Alessio Brancolini, Giuseppe Buttazzo, Filippo Santambrogio, and Eugene Stepanov. Long-term planning versus short-term planning in the asymptotical location problem. ESAIM: Control, Optimisation and Calculus of Variations, 15(3):509\u2013524, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Brancolini%2C%20Alessio%20Buttazzo%2C%20Giuseppe%20Santambrogio%2C%20Filippo%20Stepanov%2C%20Eugene%20Long-term%20planning%20versus%20short-term%20planning%20in%20the%20asymptotical%20location%20problem%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Brancolini%2C%20Alessio%20Buttazzo%2C%20Giuseppe%20Santambrogio%2C%20Filippo%20Stepanov%2C%20Eugene%20Long-term%20planning%20versus%20short-term%20planning%20in%20the%20asymptotical%20location%20problem%202009"
        },
        {
            "id": "Bromley_et+al_1993_a",
            "entry": "Jane Bromley, James W. Bentz, Leon Bottou, Isabelle Guyon, Yann LeCun, Cliff Moore, Eduard Sackinger, and Roopak Shah. Signature verification using A \u201cSiamese\u201d time delay neural network. In NIPS, 1993.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bromley%2C%20Jane%20Bentz%2C%20James%20W.%20Bottou%2C%20Leon%20Guyon%2C%20Isabelle%20Signature%20verification%20using%20A%20%E2%80%9CSiamese%E2%80%9D%20time%20delay%20neural%20network%201993",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bromley%2C%20Jane%20Bentz%2C%20James%20W.%20Bottou%2C%20Leon%20Guyon%2C%20Isabelle%20Signature%20verification%20using%20A%20%E2%80%9CSiamese%E2%80%9D%20time%20delay%20neural%20network%201993"
        },
        {
            "id": "Carlier_et+al_2017_a",
            "entry": "Guillaume Carlier, Vincent Duval, Gabriel Peyre, and Bernhard Schmitzer. Convergence of entropic schemes for optimal transport and gradient flows. SIAM Journal on Mathematical Analysis, 49 (2):1385\u20131418, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Carlier%2C%20Guillaume%20Duval%2C%20Vincent%20Peyre%2C%20Gabriel%20Schmitzer%2C%20Bernhard%20Convergence%20of%20entropic%20schemes%20for%20optimal%20transport%20and%20gradient%20flows%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Carlier%2C%20Guillaume%20Duval%2C%20Vincent%20Peyre%2C%20Gabriel%20Schmitzer%2C%20Bernhard%20Convergence%20of%20entropic%20schemes%20for%20optimal%20transport%20and%20gradient%20flows%202017"
        },
        {
            "id": "Claici_2018_a",
            "entry": "Sebastian Claici, Edward Chien, and Justin Solomon. Stochastic Wasserstein barycenters. In ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Claici%2C%20Sebastian%20Chien%2C%20Edward%20and%20Justin%20Solomon.%20Stochastic%20Wasserstein%20barycenters%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Claici%2C%20Sebastian%20Chien%2C%20Edward%20and%20Justin%20Solomon.%20Stochastic%20Wasserstein%20barycenters%202018"
        },
        {
            "id": "Collobert_2011_a",
            "entry": "Ronan Collobert. Deep learning for efficient discriminative parsing. In AISTATS, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Collobert%2C%20Ronan%20Deep%20learning%20for%20efficient%20discriminative%20parsing%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Collobert%2C%20Ronan%20Deep%20learning%20for%20efficient%20discriminative%20parsing%202011"
        },
        {
            "id": "Courty_et+al_2014_a",
            "entry": "Nicolas Courty, Remi Flamary, and Devis Tuia. Domain adaptation with regularized optimal transport. In ECML-PKDD, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Courty%2C%20Nicolas%20Flamary%2C%20Remi%20Tuia%2C%20Devis%20Domain%20adaptation%20with%20regularized%20optimal%20transport%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Courty%2C%20Nicolas%20Flamary%2C%20Remi%20Tuia%2C%20Devis%20Domain%20adaptation%20with%20regularized%20optimal%20transport%202014"
        },
        {
            "id": "Courty_et+al_2018_a",
            "entry": "Nicolas Courty, Remi Flamary, and Melanie Ducoffe. Learning Wasserstein embeddings. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Courty%2C%20Nicolas%20Flamary%2C%20Remi%20Ducoffe%2C%20Melanie%20Learning%20Wasserstein%20embeddings%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Courty%2C%20Nicolas%20Flamary%2C%20Remi%20Ducoffe%2C%20Melanie%20Learning%20Wasserstein%20embeddings%202018"
        },
        {
            "id": "Cuturi_2013_a",
            "entry": "Marco Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. In NIPS, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cuturi%2C%20Marco%20Sinkhorn%20distances%3A%20Lightspeed%20computation%20of%20optimal%20transport%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cuturi%2C%20Marco%20Sinkhorn%20distances%3A%20Lightspeed%20computation%20of%20optimal%20transport%202013"
        },
        {
            "id": "Faruqui_2014_a",
            "entry": "Manaal Faruqui and Chris Dyer. Community evaluation and exchange of word vectors at wordvectors.org. In Association for Computational Linguistics: System Demonstrations, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Faruqui%2C%20Manaal%20Dyer%2C%20Chris%20Community%20evaluation%20and%20exchange%20of%20word%20vectors%20at%20wordvectors.org%202014"
        },
        {
            "id": "Frogner_et+al_2015_a",
            "entry": "Charlie Frogner, Chiyuan Zhang, Hossein Mobahi, Mauricio Araya-Polo, and Tomaso A. Poggio. Learning with a Wasserstein loss. In NIPS, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Frogner%2C%20Charlie%20Zhang%2C%20Chiyuan%20Mobahi%2C%20Hossein%20Araya-Polo%2C%20Mauricio%20Learning%20with%20a%20Wasserstein%20loss%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Frogner%2C%20Charlie%20Zhang%2C%20Chiyuan%20Mobahi%2C%20Hossein%20Araya-Polo%2C%20Mauricio%20Learning%20with%20a%20Wasserstein%20loss%202015"
        },
        {
            "id": "Genevay_et+al_0000_a",
            "entry": "Aude Genevay, Lenaic Chizat, Francis Bach, Marco Cuturi, and Gabriel Peyre. Sample complexity of Sinkhorn divergences. arXiv:1810.02733, 2018a.",
            "arxiv_url": "https://arxiv.org/pdf/1810.02733"
        },
        {
            "id": "Genevay_et+al_2018_a",
            "entry": "Aude Genevay, Gabriel Peyre, and Marco Cuturi. Learning generative models with Sinkhorn divergences. In AISTATS, 2018b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Genevay%2C%20Aude%20Peyre%2C%20Gabriel%20Cuturi%2C%20Marco%20Learning%20generative%20models%20with%20Sinkhorn%20divergences%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Genevay%2C%20Aude%20Peyre%2C%20Gabriel%20Cuturi%2C%20Marco%20Learning%20generative%20models%20with%20Sinkhorn%20divergences%202018"
        },
        {
            "id": "Grover_2016_a",
            "entry": "Aditya Grover and Jure Leskovec. Node2vec: Scalable feature learning for networks. In KDD, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Grover%2C%20Aditya%20Leskovec%2C%20Jure%20Node2vec%3A%20Scalable%20feature%20learning%20for%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Grover%2C%20Aditya%20Leskovec%2C%20Jure%20Node2vec%3A%20Scalable%20feature%20learning%20for%20networks%202016"
        },
        {
            "id": "Hadsell_et+al_2006_a",
            "entry": "Raia Hadsell, Sumit Chopra, and Yann LeCun. Dimensionality reduction by learning an invariant mapping. In CVPR, 2006.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hadsell%2C%20Raia%20Chopra%2C%20Sumit%20LeCun%2C%20Yann%20Dimensionality%20reduction%20by%20learning%20an%20invariant%20mapping%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hadsell%2C%20Raia%20Chopra%2C%20Sumit%20LeCun%2C%20Yann%20Dimensionality%20reduction%20by%20learning%20an%20invariant%20mapping%202006"
        },
        {
            "id": "Holland_et+al_1983_a",
            "entry": "Paul W Holland, Kathryn Blackmond Laskey, and Samuel Leinhardt. Stochastic blockmodels: First steps. Social Networks, 5(2):109\u2013137, 1983.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Holland%2C%20Paul%20W.%20Laskey%2C%20Kathryn%20Blackmond%20Leinhardt%2C%20Samuel%20Stochastic%20blockmodels%3A%20First%20steps%201983",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Holland%2C%20Paul%20W.%20Laskey%2C%20Kathryn%20Blackmond%20Leinhardt%2C%20Samuel%20Stochastic%20blockmodels%3A%20First%20steps%201983"
        },
        {
            "id": "Huang_et+al_2012_a",
            "entry": "Eric H Huang, Richard Socher, Christopher D Manning, and Andrew Y Ng. Improving word representations via global context and multiple word prototypes. In ACL, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20Eric%20H.%20Socher%2C%20Richard%20Manning%2C%20Christopher%20D.%20and%20Andrew%20Y%20Ng.%20Improving%20word%20representations%20via%20global%20context%20and%20multiple%20word%20prototypes%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20Eric%20H.%20Socher%2C%20Richard%20Manning%2C%20Christopher%20D.%20and%20Andrew%20Y%20Ng.%20Improving%20word%20representations%20via%20global%20context%20and%20multiple%20word%20prototypes%202012"
        },
        {
            "id": "Indyk_2003_a",
            "entry": "Piotr Indyk and Nitin Thaper. Fast image retrieval via embeddings. In ICCV Workshop on Statistical and Computational Theories of Vision, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Indyk%2C%20Piotr%20Thaper%2C%20Nitin%20Fast%20image%20retrieval%20via%20embeddings%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Indyk%2C%20Piotr%20Thaper%2C%20Nitin%20Fast%20image%20retrieval%20via%20embeddings%202003"
        },
        {
            "id": "Kingma_2014_a",
            "entry": "Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv:1412.6980, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6980"
        },
        {
            "id": "Kiros_et+al_2014_a",
            "entry": "Ryan Kiros, Richard S. Zemel, and Ruslan Salakhutdinov. A multiplicative model for learning distributed text-based attribute representations. In NIPS, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kiros%2C%20Ryan%20Zemel%2C%20Richard%20S.%20Salakhutdinov%2C%20Ruslan%20A%20multiplicative%20model%20for%20learning%20distributed%20text-based%20attribute%20representations%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kiros%2C%20Ryan%20Zemel%2C%20Richard%20S.%20Salakhutdinov%2C%20Ruslan%20A%20multiplicative%20model%20for%20learning%20distributed%20text-based%20attribute%20representations%202014"
        },
        {
            "id": "Kloeckner_2010_a",
            "entry": "Benoit Kloeckner. A geometric study of Wasserstein spaces: Euclidean spaces. Annali della Scuola Normale Superiore di Pisa-Classe di Scienze-Serie V, 9(2):297, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kloeckner%2C%20Benoit%20A%20geometric%20study%20of%20Wasserstein%20spaces%3A%20Euclidean%20spaces.%20Annali%20della%20Scuola%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kloeckner%2C%20Benoit%20A%20geometric%20study%20of%20Wasserstein%20spaces%3A%20Euclidean%20spaces.%20Annali%20della%20Scuola%202010"
        },
        {
            "id": "Kloeckner_2012_a",
            "entry": "Benoit Kloeckner. Approximation by finitely supported measures. ESAIM: Control, Optimisation and Calculus of Variations, 18(2):343\u2013359, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kloeckner%2C%20Benoit%20Approximation%20by%20finitely%20supported%20measures%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kloeckner%2C%20Benoit%20Approximation%20by%20finitely%20supported%20measures%202012"
        },
        {
            "id": "Kombrink_et+al_2011_a",
            "entry": "Stefan Kombrink, Tomas Mikolov, Martin Karafiat, and Lukas Burget. Recurrent neural network based language modeling in meeting recognition. In INTERSPEECH, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kombrink%2C%20Stefan%20Mikolov%2C%20Tomas%20Karafiat%2C%20Martin%20Burget%2C%20Lukas%20Recurrent%20neural%20network%20based%20language%20modeling%20in%20meeting%20recognition%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kombrink%2C%20Stefan%20Mikolov%2C%20Tomas%20Karafiat%2C%20Martin%20Burget%2C%20Lukas%20Recurrent%20neural%20network%20based%20language%20modeling%20in%20meeting%20recognition%202011"
        },
        {
            "id": "Solomon_1951_a",
            "entry": "Solomon Kullback and Richard A Leibler. On information and sufficiency. The Annals of Mathematical Statistics, 22(1):79\u201386, 1951.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Solomon%20Kullback%20and%20Richard%20A%20Leibler%20On%20information%20and%20sufficiency%20The%20Annals%20of%20Mathematical%20Statistics%202217986%201951",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Solomon%20Kullback%20and%20Richard%20A%20Leibler%20On%20information%20and%20sufficiency%20The%20Annals%20of%20Mathematical%20Statistics%202217986%201951"
        },
        {
            "id": "Kusner_et+al_2015_a",
            "entry": "Matt Kusner, Yu Sun, Nicholas Kolkin, and Kilian Weinberger. From word embeddings to document distances. In ICML, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kusner%2C%20Matt%20Sun%2C%20Yu%20Kolkin%2C%20Nicholas%20Weinberger%2C%20Kilian%20From%20word%20embeddings%20to%20document%20distances%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kusner%2C%20Matt%20Sun%2C%20Yu%20Kolkin%2C%20Nicholas%20Weinberger%2C%20Kilian%20From%20word%20embeddings%20to%20document%20distances%202015"
        },
        {
            "id": "Leskovec_2014_a",
            "entry": "Jure Leskovec and Andrej Krevl. SNAP Datasets: Stanford large network dataset collection. http://snap.stanford.edu/data, June 2014.",
            "url": "http://snap.stanford.edu/data"
        },
        {
            "id": "Mikolov_et+al_2013_a",
            "entry": "Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. Distributed representations of words and phrases and their compositionality. In NIPS, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mikolov%2C%20Tomas%20Sutskever%2C%20Ilya%20Chen%2C%20Kai%20Corrado%2C%20Greg%20S.%20Distributed%20representations%20of%20words%20and%20phrases%20and%20their%20compositionality%202013"
        },
        {
            "id": "Mirzazadeh_2017_a",
            "entry": "Farzaneh Mirzazadeh. Solving Association Problems with Convex Co-embedding. PhD thesis, University of Alberta, 2017. Chapter 5.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mirzazadeh%2C%20Farzaneh%20Solving%20Association%20Problems%20with%20Convex%20Co-embedding%202017"
        },
        {
            "id": "Mirzazadeh_et+al_2014_a",
            "entry": "Farzaneh Mirzazadeh, Yuhong Guo, and Dale Schuurmans. Convex co-embedding. In AAAI, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mirzazadeh%2C%20Farzaneh%20Guo%2C%20Yuhong%20Schuurmans%2C%20Dale%20Convex%20co-embedding%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mirzazadeh%2C%20Farzaneh%20Guo%2C%20Yuhong%20Schuurmans%2C%20Dale%20Convex%20co-embedding%202014"
        },
        {
            "id": "Mirzazadeh_et+al_2015_a",
            "entry": "Farzaneh Mirzazadeh, Siamak Ravanbakhsh, Nan Ding, and Dale Schuurmans. Embedding inference for structured multilabel prediction. In NIPS, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mirzazadeh%2C%20Farzaneh%20Ravanbakhsh%2C%20Siamak%20Ding%2C%20Nan%20Schuurmans%2C%20Dale%20Embedding%20inference%20for%20structured%20multilabel%20prediction%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mirzazadeh%2C%20Farzaneh%20Ravanbakhsh%2C%20Siamak%20Ding%2C%20Nan%20Schuurmans%2C%20Dale%20Embedding%20inference%20for%20structured%20multilabel%20prediction%202015"
        },
        {
            "id": "Muzellec_2018_a",
            "entry": "Boris Muzellec and Marco Cuturi. Generalizing point embeddings using the Wasserstein space of elliptical distributions. In NIPS, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Muzellec%2C%20Boris%20Cuturi%2C%20Marco%20Generalizing%20point%20embeddings%20using%20the%20Wasserstein%20space%20of%20elliptical%20distributions%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Muzellec%2C%20Boris%20Cuturi%2C%20Marco%20Generalizing%20point%20embeddings%20using%20the%20Wasserstein%20space%20of%20elliptical%20distributions%202018"
        },
        {
            "id": "Neubig_et+al_2018_a",
            "entry": "Graham Neubig, Matthias Sperber, Xinyi Wang, Matthieu Felix, Austin Matthews, Sarguna Padmanabhan, Ye Qi, Devendra Singh Sachan, Philip Arthur, Pierre Godard, John Hewitt, Rachid Riad, and Liming Wang. XNMT: the extensible neural machine translation toolkit. In AMTA (1), pp. 185\u2013192, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Graham%20Neubig%20Matthias%20Sperber%20Xinyi%20Wang%20Matthieu%20Felix%20Austin%20Matthews%20Sarguna%20Padmanabhan%20Ye%20Qi%20Devendra%20Singh%20Sachan%20Philip%20Arthur%20Pierre%20Godard%20John%20Hewitt%20Rachid%20Riad%20and%20Liming%20Wang%20XNMT%20the%20extensible%20neural%20machine%20translation%20toolkit%20In%20AMTA%201%20pp%20185192%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Graham%20Neubig%20Matthias%20Sperber%20Xinyi%20Wang%20Matthieu%20Felix%20Austin%20Matthews%20Sarguna%20Padmanabhan%20Ye%20Qi%20Devendra%20Singh%20Sachan%20Philip%20Arthur%20Pierre%20Godard%20John%20Hewitt%20Rachid%20Riad%20and%20Liming%20Wang%20XNMT%20the%20extensible%20neural%20machine%20translation%20toolkit%20In%20AMTA%201%20pp%20185192%202018"
        },
        {
            "id": "Nickel_2017_a",
            "entry": "Maximilian Nickel and Douwe Kiela. Poincareembeddings for learning hierarchical representations. In NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nickel%2C%20Maximilian%20Kiela%2C%20Douwe%20Poincareembeddings%20for%20learning%20hierarchical%20representations%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nickel%2C%20Maximilian%20Kiela%2C%20Douwe%20Poincareembeddings%20for%20learning%20hierarchical%20representations%202017"
        },
        {
            "id": "Nickel_2018_a",
            "entry": "Maximilian Nickel and Douwe Kiela. Learning continuous hierarchies in the Lorentz model of hyperbolic geometry. In ICML, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nickel%2C%20Maximilian%20Kiela%2C%20Douwe%20Learning%20continuous%20hierarchies%20in%20the%20Lorentz%20model%20of%20hyperbolic%20geometry%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nickel%2C%20Maximilian%20Kiela%2C%20Douwe%20Learning%20continuous%20hierarchies%20in%20the%20Lorentz%20model%20of%20hyperbolic%20geometry%202018"
        },
        {
            "id": "Nickel_2016_a",
            "entry": "Maximilian Nickel, Kevin Murphy, Volker Tresp, and Evgeniy Gabrilovich. A review of relational machine learning for knowledge graphs. Proc. IEEE, 104(1):11\u201333, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nickel%2C%20Maximilian%20Murphy%2C%20Kevin%20Volker%20Tresp%2C%20and%20Evgeniy%20Gabrilovich.%20A%20review%20of%20relational%20machine%20learning%20for%20knowledge%20graphs%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nickel%2C%20Maximilian%20Murphy%2C%20Kevin%20Volker%20Tresp%2C%20and%20Evgeniy%20Gabrilovich.%20A%20review%20of%20relational%20machine%20learning%20for%20knowledge%20graphs%202016"
        },
        {
            "id": "Pennington_et+al_2014_a",
            "entry": "Jeffrey Pennington, Richard Socher, and Christopher Manning. Glove: Global vectors for word representation. In EMNLP, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pennington%2C%20Jeffrey%20Socher%2C%20Richard%20Manning%2C%20Christopher%20Glove%3A%20Global%20vectors%20for%20word%20representation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pennington%2C%20Jeffrey%20Socher%2C%20Richard%20Manning%2C%20Christopher%20Glove%3A%20Global%20vectors%20for%20word%20representation%202014"
        },
        {
            "id": "Peters_et+al_2018_a",
            "entry": "Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. Deep contextualized word representations. In NAACL-HLT, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Peters%2C%20Matthew%20E.%20Neumann%2C%20Mark%20Iyyer%2C%20Mohit%20Gardner%2C%20Matt%20Deep%20contextualized%20word%20representations%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Peters%2C%20Matthew%20E.%20Neumann%2C%20Mark%20Iyyer%2C%20Mohit%20Gardner%2C%20Matt%20Deep%20contextualized%20word%20representations%202018"
        },
        {
            "id": "Cuturi_2017_a",
            "entry": "Gabriel Peyreand Marco Cuturi. Computational optimal transport. Technical report, 2017. Yossi Rubner, Carlo Tomasi, and Leonidas J Guibas. A metric for distributions with applications to image databases. In ICCV, 1998. Vivien Seguy and Marco Cuturi. Principal geodesic analysis for probability measures under the optimal transport metric. In NIPS, 2015. Sameer Shirdhonkar and David W Jacobs. Approximate Earth Mover\u2019s distance in linear time. In",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cuturi%2C%20Gabriel%20Peyreand%20Marco%20Computational%20optimal%20transport%202017"
        },
        {
            "id": "Cvpr_2016_a",
            "entry": "CVPR, 2008. Marcel Simon, Erik Rodner, and Joachim Denzler. Imagenet pre-trained models with batch normalization. arXiv:1612.01452, 2016. Sidak Pal Singh, Andreas Hug, Aymeric Dieuleveut, and Martin Jaggi. Context mover\u2019s distance barycenters: Optimal transport of contexts for building representations. arXiv:1808.09663, 2018. Justin Solomon. Optimal transport on discrete domains. AMS Short Course on Discrete Differential",
            "arxiv_url": "https://arxiv.org/pdf/1612.01452"
        },
        {
            "id": "Geometry_2010_a",
            "entry": "Geometry, 2018. Joseph P. Turian, Lev-Arie Ratinov, and Yoshua Bengio. Word representations: A simple and general method for semi-supervised learning. In ACL, 2010. Ivan Vendrov, Ryan Kiros, Sanja Fidler, and Raquel Urtasun. Order-embeddings of images and language. In ICLR, 2015. Cedric Villani. Topics in Optimal Transportation. Number 58 in Graduate studies in mathematics.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Geometry%2C%202018.%20Joseph%20P.%20Turian%2C%20Lev-Arie%20Ratinov%20Bengio%2C%20Yoshua%20Word%20representations%3A%20A%20simple%20and%20general%20method%20for%20semi-supervised%20learning.%20In%20ACL%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Geometry%2C%202018.%20Joseph%20P.%20Turian%2C%20Lev-Arie%20Ratinov%20Bengio%2C%20Yoshua%20Word%20representations%3A%20A%20simple%20and%20general%20method%20for%20semi-supervised%20learning.%20In%20ACL%202010"
        },
        {
            "id": "Soc_2003_a",
            "entry": "American Mathematical Soc., 2003. Cedric Villani. Optimal Transport: Old and New, volume 338. Springer Science & Business Media, 2008. Luke Vilnis and Andrew McCallum. Word representations via Gaussian embedding. In ICLR, 2015. Duncan J Watts and Steven H Strogatz. Collective dynamics of \u2018small-world\u2019 networks. Nature, 393(6684):440, 1998. Jason Weston, Samy Bengio, and Nicolas Usunier. WSABIE: scaling up to large vocabulary image annotation. In IJCAI, 2011. Xiaohan Zhao, Alessandra Sala, Haitao Zheng, and Ben Y Zhao. Fast and scalable analysis of massive social graphs. arXiv:1107.5114, 2011. Dingyuan Zhu, Peng Cui, Daixin Wang, and Wenwu Zhu. Deep variational network embedding in",
            "arxiv_url": "https://arxiv.org/pdf/1107.5114"
        },
        {
            "id": "Space_2018_a",
            "entry": "Wasserstein space. In KDD, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wasserstein%20space%20In%20KDD%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wasserstein%20space%20In%20KDD%202018"
        }
    ]
}

{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "DISJOINT MAPPING NETWORK FOR CROSS-MODAL MATCHING OF VOICES AND FACES",
        "author": "Yandong Wen, Mahmoud Al Ismail, Weiyang Liu\u00a7, Bhiksha Raj, Rita Singh, \u2020Carnegie Mellon University \u00a7Georgia Institute of Technology yandongw@andrew.cmu.edu, mahmoudi@andrew.cmu.edu, wyliu@gatech.edu",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=B1exrnCcF7"
        },
        "abstract": "We propose a novel framework, called Disjoint Mapping Network (DIMNet), for cross-modal biometric matching, in particular of voices and faces. Different from the existing methods, DIMNet does not explicitly learn the joint relationship between the modalities. Instead, DIMNet learns a shared representation for different modalities by mapping them individually to their common covariates. These shared representations can then be used to find the correspondences between the modalities. We show empirically that DIMNet is able to achieve better performance than the current state-of-the-art methods, with the additional benefits of being conceptually simpler and less data-intensive. The code is made available at https://github.com/ydwen/DIMNet."
    },
    "keywords": [
        {
            "term": "false alarms",
            "url": "https://en.wikipedia.org/wiki/false_alarms"
        },
        {
            "term": "multi-dimensional scaling",
            "url": "https://en.wikipedia.org/wiki/multi-dimensional_scaling"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        },
        {
            "term": "mean average precision",
            "url": "https://en.wikipedia.org/wiki/mean_average_precision"
        },
        {
            "term": "stochastic gradient descent",
            "url": "https://en.wikipedia.org/wiki/stochastic_gradient_descent"
        },
        {
            "term": "area under the curve",
            "url": "https://en.wikipedia.org/wiki/area_under_the_curve"
        }
    ],
    "abbreviations": {
        "DIMNet": "Disjoint Mapping Network",
        "SGD": "stochastic gradient descent",
        "FR": "false rejections",
        "FA": "false alarms",
        "MAP": "Mean Average Precision",
        "EER": "equal error rate",
        "mAP": "mean average precision",
        "AUC": "area under the curve",
        "MDS": "multi-dimensional scaling"
    },
    "highlights": [
        "Studies indicate that neuro-cognitive pathways for voices and faces share common structure (Ellis, 1989), possibly following parallel pathways within a common recognition framework (<a class=\"ref-link\" id=\"cBelin_et+al_2004_a\" href=\"#rBelin_et+al_2004_a\">Belin et al, 2004</a>; 2011)",
        "We propose a novel framework to learn mappings between voices and faces that do not consider any direct dependence between the two, but instead explicitly exploit their individual dependence on the covariates",
        "We propose Disjoint Mapping Network, a framework that formulates the problem of cross-modal matching of voices and faces as learning common embeddings for the two through individual supervision from one or more covariates, in contrast to current approaches that attempt to map voices to faces directly",
        "We report results in terms of equal error rate, i.e.when false rejections = false alarms",
        "We have proposed that it is possible to learn common embeddings for multi-modal inputs, voices and faces, by mapping them individually to common covariates"
    ],
    "key_statements": [
        "Studies indicate that neuro-cognitive pathways for voices and faces share common structure (Ellis, 1989), possibly following parallel pathways within a common recognition framework (<a class=\"ref-link\" id=\"cBelin_et+al_2004_a\" href=\"#rBelin_et+al_2004_a\">Belin et al, 2004</a>; 2011)",
        "This paper focuses on the task of devising computational mechanisms for cross-modal matching of voice recordings and images of the speakers\u2019 faces",
        "We propose a novel framework to learn mappings between voices and faces that do not consider any direct dependence between the two, but instead explicitly exploit their individual dependence on the covariates",
        "We propose Disjoint Mapping Network, a framework that formulates the problem of cross-modal matching of voices and faces as learning common embeddings for the two through individual supervision from one or more covariates, in contrast to current approaches that attempt to map voices to faces directly",
        "We ran experiments on matching voices to faces, to evaluate the embeddings derived by Disjoint Mapping Network",
        "We report results in terms of equal error rate, i.e.when false rejections = false alarms",
        "We report the equal error rate (EER) for verification in Table 3",
        "The significant and consistent improvements over chance-level results show that the Disjoint Mapping Network models do learn some useful associations between voices and faces.\n3.4",
        "We have proposed that it is possible to learn common embeddings for multi-modal inputs, voices and faces, by mapping them individually to common covariates"
    ],
    "summary": [
        "We propose DIMNets, a framework that formulates the problem of cross-modal matching of voices and faces as learning common embeddings for the two through individual supervision from one or more covariates, in contrast to current approaches that attempt to map voices to faces directly.",
        "Our model attempts to find common representations for both face images and voice recordings by leveraging their relationship to these covariates.",
        "The training data comprise voice recordings and face images.",
        "We construct the minibatches with a mixture of speech segments and face images, as the network learns more robust cross-modal features with mixed inputs.",
        "We ran experiments on matching voices to faces, to evaluate the embeddings derived by DIMNets.",
        "As explained in Appendix B, recognizing a covariate such as gender can result in seemingly significant matching performance.",
        "Just recognizing the subjects\u2019 gender from their voice and images can result in a 33% EER for verification, and 25% error in matching for the 1 : 2 tests.",
        "It shows that mapping voices and faces to their common covariates is an effective strategy to learn representations for cross-modal matching.",
        "DIMNet-G respectively achieves 72.90% and 72.47% for voice to face and face to voice matching using only gender as a covariate.",
        "The results in Table 3 show that using both gender and ID information as covariates can further improve the performance over using ID alone, well validating the superiority of our multi-task learning framework.",
        "The significant and consistent improvements over chance-level results show that the DIMNet models do learn some useful associations between voices and faces.",
        "We have proposed that it is possible to learn common embeddings for multi-modal inputs, voices and faces, by mapping them individually to common covariates.",
        "The proposed DIMNet architecture is able to extract embeddings for both modalities that achieves consistently better performance than the methods that directly map faces to voices.",
        "The approach provides us the ability to tease out the influence of each of the covariates of voice and face data, in determining their relation.",
        "The results indicate that prior results by other researchers who have attempted to directly match voices to faces may perhaps not be learning any direct relation between the two, but implicitly learning about the common covariates, such as ID, gender, etc."
    ],
    "headline": "We propose a novel framework, called Disjoint Mapping Network, for cross-modal biometric matching, in particular of voices and faces",
    "reference_links": [
        {
            "id": "Belin_et+al_2011_a",
            "entry": "P. Belin, P.E.G. Bestelmeyer, M. Latinus, and R. Watson. Understanding voice perception. British Journal of Psychology, 108:711\u2013725, 2011. 1",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Belin%2C%20P.%20Bestelmeyer%2C%20P.E.G.%20Latinus%2C%20M.%20Watson%2C%20R.%20Understanding%20voice%20perception%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Belin%2C%20P.%20Bestelmeyer%2C%20P.E.G.%20Latinus%2C%20M.%20Watson%2C%20R.%20Understanding%20voice%20perception%202011"
        },
        {
            "id": "Belin_et+al_2004_a",
            "entry": "Pascal Belin, Shirley Fecteau, and Catherine Bedard. Thinking the voice: neural correlates of voice perception. Trends in cognitive sciences, 8(3):129\u2013135, 2004. 1",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Belin%2C%20Pascal%20Fecteau%2C%20Shirley%20Bedard%2C%20Catherine%20Thinking%20the%20voice%3A%20neural%20correlates%20of%20voice%20perception%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Belin%2C%20Pascal%20Fecteau%2C%20Shirley%20Bedard%2C%20Catherine%20Thinking%20the%20voice%3A%20neural%20correlates%20of%20voice%20perception%202004"
        },
        {
            "id": "Springer_2016_a",
            "entry": "Springer, 2016. 11",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Springer%202016%2011"
        },
        {
            "id": "Elsevier_1989_a",
            "entry": "Elsevier, 1989. 1",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Elsevier%201989%201"
        },
        {
            "id": "Ioffe_2015_a",
            "entry": "Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015. 11",
            "arxiv_url": "https://arxiv.org/pdf/1502.03167"
        },
        {
            "id": "Kamachi_et+al_2003_a",
            "entry": "Miyuki Kamachi, Harold Hill, Karen Lander, and Eric Vatikiotis-Bateson. Putting the face to the voice\u2019: Matching identity across modality. Current Biology, 13(19):1709\u20131714, 2003. 1",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kamachi%2C%20Miyuki%20Hill%2C%20Harold%20Lander%2C%20Karen%20and%20Eric%20Vatikiotis-Bateson.%20Putting%20the%20face%20to%20the%20voice%E2%80%99%3A%20Matching%20identity%20across%20modality%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kamachi%2C%20Miyuki%20Hill%2C%20Harold%20Lander%2C%20Karen%20and%20Eric%20Vatikiotis-Bateson.%20Putting%20the%20face%20to%20the%20voice%E2%80%99%3A%20Matching%20identity%20across%20modality%202003"
        },
        {
            "id": "Kim_et+al_2018_a",
            "entry": "Changil Kim, Hijung Valentina Shin, Tae-Hyun Oh, Kaspar Alexandre, Mohamed Elgharib, and Wojciech Matusik. On learning associations of faces and voices. arXiv preprint arXiv:1805.05553, 2018. 1, 2",
            "arxiv_url": "https://arxiv.org/pdf/1805.05553"
        },
        {
            "id": "Krizhevsky_et+al_2012_a",
            "entry": "Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, 2012. 11",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Hinton%2C%20Geoffrey%20E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krizhevsky%2C%20Alex%20Sutskever%2C%20Ilya%20Hinton%2C%20Geoffrey%20E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012"
        },
        {
            "id": "Lippert_et+al_2017_a",
            "entry": "Christoph Lippert, Riccardo Sabatini, M Cyrus Maher, Eun Yong Kang, Seunghak Lee, Okan Arikan, Alena Harley, Axel Bernal, Peter Garst, Victor Lavrenko, et al. Identification of individuals by trait prediction using whole-genome sequencing data. Proceedings of the National Academy of Sciences, 114(38):10166\u201310171, 2017. 3",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lippert%2C%20Christoph%20Riccardo%20Sabatini%2C%20M.Cyrus%20Maher%20Kang%2C%20Eun%20Yong%20Lee%2C%20Seunghak%20Identification%20of%20individuals%20by%20trait%20prediction%20using%20whole-genome%20sequencing%20data%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lippert%2C%20Christoph%20Riccardo%20Sabatini%2C%20M.Cyrus%20Maher%20Kang%2C%20Eun%20Yong%20Lee%2C%20Seunghak%20Identification%20of%20individuals%20by%20trait%20prediction%20using%20whole-genome%20sequencing%20data%202017"
        },
        {
            "id": "Liu_et+al_2016_a",
            "entry": "Weiyang Liu, Yandong Wen, Zhiding Yu, and Meng Yang. Large-margin softmax loss for convolutional neural networks. In ICML, 2016. 9",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Weiyang%20Wen%2C%20Yandong%20Yu%2C%20Zhiding%20Yang%2C%20Meng%20Large-margin%20softmax%20loss%20for%20convolutional%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Weiyang%20Wen%2C%20Yandong%20Yu%2C%20Zhiding%20Yang%2C%20Meng%20Large-margin%20softmax%20loss%20for%20convolutional%20neural%20networks%202016"
        },
        {
            "id": "Liu_et+al_2017_a",
            "entry": "Weiyang Liu, Yandong Wen, Zhiding Yu, Ming Li, Bhiksha Raj, and Le Song. Sphereface: Deep hypersphere embedding for face recognition. In CVPR, 2017a. 9",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Weiyang%20Wen%2C%20Yandong%20Yu%2C%20Zhiding%20Li%2C%20Ming%20Sphereface%3A%20Deep%20hypersphere%20embedding%20for%20face%20recognition%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Weiyang%20Wen%2C%20Yandong%20Yu%2C%20Zhiding%20Li%2C%20Ming%20Sphereface%3A%20Deep%20hypersphere%20embedding%20for%20face%20recognition%202017"
        },
        {
            "id": "Liu_et+al_2017_b",
            "entry": "Weiyang Liu, Yan-Ming Zhang, Xingguo Li, Zhiding Yu, Bo Dai, Tuo Zhao, and Le Song. Deep hyperspherical learning. In NIPS, 2017b. 9",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Weiyang%20Zhang%2C%20Yan-Ming%20Li%2C%20Xingguo%20Yu%2C%20Zhiding%20Deep%20hyperspherical%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Weiyang%20Zhang%2C%20Yan-Ming%20Li%2C%20Xingguo%20Yu%2C%20Zhiding%20Deep%20hyperspherical%20learning%202017"
        },
        {
            "id": "Manning_et+al_0000_a",
            "entry": "Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schutze. Evaluation in information retrieval. In Introduction to Information Retrieval, chapter 8, pp. 159\u2013160. Cambridge University Press, 2008. 6",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Christopher%20D%20Manning%20Prabhakar%20Raghavan%20and%20Hinrich%20Schutze%20Evaluation%20in%20information%20retrieval%20In%20Introduction%20to%20Information%20Retrieval%20chapter%208%20pp%20159160%20Cambridge%20University%20Press%202008%206",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Christopher%20D%20Manning%20Prabhakar%20Raghavan%20and%20Hinrich%20Schutze%20Evaluation%20in%20information%20retrieval%20In%20Introduction%20to%20Information%20Retrieval%20chapter%208%20pp%20159160%20Cambridge%20University%20Press%202008%206"
        },
        {
            "id": "Mcallister_et+al_1993_a",
            "entry": "Hunter A McAllister, Robert HI Dale, Norman J Bregman, Allyssa McCabe, and C Randy Cotton. When eyewitnesses are also earwitnesses: Effects on visual and voice identifications. Basic and Applied Social Psychology, 14(2):161\u2013170, 1993. 1",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=McAllister%2C%20Hunter%20A.%20Dale%2C%20Robert%20H.I.%20Bregman%2C%20Norman%20J.%20McCabe%2C%20Allyssa%20When%20eyewitnesses%20are%20also%20earwitnesses%3A%20Effects%20on%20visual%20and%20voice%20identifications%201993",
            "oa_query": "https://api.scholarcy.com/oa_version?query=McAllister%2C%20Hunter%20A.%20Dale%2C%20Robert%20H.I.%20Bregman%2C%20Norman%20J.%20McCabe%2C%20Allyssa%20When%20eyewitnesses%20are%20also%20earwitnesses%3A%20Effects%20on%20visual%20and%20voice%20identifications%201993"
        },
        {
            "id": "Nagrani_et+al_2017_a",
            "entry": "A. Nagrani, J. S. Chung, and A. Zisserman. Voxceleb: a large-scale speaker identification dataset. In INTERSPEECH, 2017. 1, 5",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nagrani%2C%20A.%20Chung%2C%20J.S.%20Zisserman%2C%20A.%20Voxceleb%3A%20a%20large-scale%20speaker%20identification%20dataset%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nagrani%2C%20A.%20Chung%2C%20J.S.%20Zisserman%2C%20A.%20Voxceleb%3A%20a%20large-scale%20speaker%20identification%20dataset%202017"
        },
        {
            "id": "Nagrani_et+al_2018_a",
            "entry": "Arsha Nagrani, Samuel Albanie, and Andrew Zisserman. Learnable pins: Cross-modal embeddings for person identity. arXiv preprint arXiv:1805.00833, 2018a. 1, 2, 8, 11",
            "arxiv_url": "https://arxiv.org/pdf/1805.00833"
        },
        {
            "id": "Nagrani_et+al_2018_b",
            "entry": "Arsha Nagrani, Samuel Albanie, and Andrew Zisserman. Seeing voices and hearing faces: Crossmodal biometric matching. arXiv preprint arXiv:1804.00326, 2018b. 1, 2, 5, 6, 7, 11",
            "arxiv_url": "https://arxiv.org/pdf/1804.00326"
        },
        {
            "id": "Parkhi_et+al_2015_a",
            "entry": "Omkar M Parkhi, Andrea Vedaldi, Andrew Zisserman, et al. Deep face recognition. In BMVC, 2015. 5",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Parkhi%2C%20Omkar%20M.%20Vedaldi%2C%20Andrea%20Zisserman%2C%20Andrew%20Deep%20face%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Parkhi%2C%20Omkar%20M.%20Vedaldi%2C%20Andrea%20Zisserman%2C%20Andrew%20Deep%20face%20recognition%202015"
        },
        {
            "id": "Povey_et+al_2011_a",
            "entry": "Daniel Povey, Arnab Ghoshal, Gilles Boulianne, Lukas Burget, Ondrej Glembek, Nagendra Goel, Mirko Hannemann, Petr Motlicek, Yanmin Qian, Petr Schwarz, et al. The kaldi speech recognition toolkit. In IEEE 2011 workshop on automatic speech recognition and understanding. IEEE Signal Processing Society, 2011. 11",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Povey%2C%20Daniel%20Ghoshal%2C%20Arnab%20Boulianne%2C%20Gilles%20Burget%2C%20Lukas%20The%20kaldi%20speech%20recognition%20toolkit%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Povey%2C%20Daniel%20Ghoshal%2C%20Arnab%20Boulianne%2C%20Gilles%20Burget%2C%20Lukas%20The%20kaldi%20speech%20recognition%20toolkit%202011"
        },
        {
            "id": "Schweinberger_et+al_2007_a",
            "entry": "Stefan R Schweinberger, David Robertson, and Jurgen M Kaufmann. Hearing facial identities. Quarterly Journal of Experimental Psychology, 60(10):1446\u20131456, 2007. 1",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schweinberger%2C%20Stefan%20R.%20Robertson%2C%20David%20Kaufmann%2C%20Jurgen%20M.%20Hearing%20facial%20identities%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schweinberger%2C%20Stefan%20R.%20Robertson%2C%20David%20Kaufmann%2C%20Jurgen%20M.%20Hearing%20facial%20identities%202007"
        },
        {
            "id": "Schweinberger_et+al_2011_a",
            "entry": "Stefan R Schweinberger, Nadine Kloth, and David MC Robertson. Hearing facial identities: Brain correlates of face\u2013voice integration in person identification. Cortex, 47(9):1026\u20131037, 2011. 1",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schweinberger%2C%20Stefan%20R.%20Kloth%2C%20Nadine%20Robertson%2C%20David%20M.C.%20Hearing%20facial%20identities%3A%20Brain%20correlates%20of%20face%E2%80%93voice%20integration%20in%20person%20identification%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schweinberger%2C%20Stefan%20R.%20Kloth%2C%20Nadine%20Robertson%2C%20David%20M.C.%20Hearing%20facial%20identities%3A%20Brain%20correlates%20of%20face%E2%80%93voice%20integration%20in%20person%20identification%202011"
        },
        {
            "id": "Van_2008_a",
            "entry": "Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine learning research, 9(Nov):2579\u20132605, 2008. 9",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=van%20der%20Maaten%2C%20Laurens%20Hinton%2C%20Geoffrey%20Visualizing%20data%20using%20t-sne%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=van%20der%20Maaten%2C%20Laurens%20Hinton%2C%20Geoffrey%20Visualizing%20data%20using%20t-sne%202008"
        },
        {
            "id": "Wen_et+al_2016_a",
            "entry": "Yandong Wen, Kaipeng Zhang, Zhifeng Li, and Yu Qiao. A discriminative feature learning approach for deep face recognition. In ECCV, 2016. 9",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wen%2C%20Yandong%20Zhang%2C%20Kaipeng%20Li%2C%20Zhifeng%20Qiao%2C%20Yu%20A%20discriminative%20feature%20learning%20approach%20for%20deep%20face%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wen%2C%20Yandong%20Zhang%2C%20Kaipeng%20Li%2C%20Zhifeng%20Qiao%2C%20Yu%20A%20discriminative%20feature%20learning%20approach%20for%20deep%20face%20recognition%202016"
        },
        {
            "id": "Wen_et+al_2018_a",
            "entry": "Yandong Wen, Mahmoud Al Ismail, Bhiksha Raj, and Rita Singh. Optimal strategies for matching and retrieval problems by comparing covariates. arXiv preprint arXiv:1807.04834, 2018. 12",
            "arxiv_url": "https://arxiv.org/pdf/1807.04834"
        },
        {
            "id": "Wickelmaier_2003_a",
            "entry": "Florian Wickelmaier. An introduction to mds. Sound Quality Research Unit, Aalborg University, Denmark, 46(5), 2003. 8, 9",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wickelmaier%2C%20Florian%20An%20introduction%20to%20mds.%20Sound%20Quality%20Research%202003"
        },
        {
            "id": "Zhang_et+al_2016_a",
            "entry": "Kaipeng Zhang, Zhanpeng Zhang, Zhifeng Li, and Yu Qiao. Joint face detection and alignment using multitask cascaded convolutional networks. IEEE Signal Processing Letters, 23(10):1499\u20131503, 2016. 11",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Kaipeng%20Zhang%2C%20Zhanpeng%20Li%2C%20Zhifeng%20Qiao%2C%20Yu%20Joint%20face%20detection%20and%20alignment%20using%20multitask%20cascaded%20convolutional%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Kaipeng%20Zhang%2C%20Zhanpeng%20Li%2C%20Zhifeng%20Qiao%2C%20Yu%20Joint%20face%20detection%20and%20alignment%20using%20multitask%20cascaded%20convolutional%20networks%202016"
        }
    ]
}

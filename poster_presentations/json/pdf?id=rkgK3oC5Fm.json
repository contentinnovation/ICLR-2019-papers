{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "BAYESIAN PREDICTION OF FUTURE STREET SCENES USING SYNTHETIC LIKELIHOODS.",
        "author": "Apratim Bhattacharyya, Mario Fritz, Bernt Schiele Max Planck Institute for Informatics, Saarland Informatics Campus, Saarbrucken, Germany {abhattac, mfritz, schiele}@mpi-inf.mpg.de",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=rkgK3oC5Fm"
        },
        "abstract": "For autonomous agents to successfully operate in the real world, the ability to anticipate future scene states is a key competence. In real-world scenarios, future states become increasingly uncertain and multi-modal, particularly on long time horizons. Dropout based Bayesian inference provides a computationally tractable, theoretically well grounded approach to learn likely hypotheses/models to deal with uncertain futures and make predictions that correspond well to observations \u2013 are well calibrated. However, it turns out that such approaches fall short to capture complex real-world scenes, even falling behind in accuracy when compared to the plain deterministic approaches. This is because the used log-likelihood estimate discourages diversity. In this work, we propose a novel Bayesian formulation for anticipating future scene states which leverages synthetic likelihoods that encourage the learning of diverse models to accurately capture the multi-modal nature of future scene states. We show that our approach achieves accurate state-of-the-art predictions and calibrated probabilities through extensive experiments for scene anticipation on Cityscapes dataset. Moreover, we show that our approach generalizes across diverse tasks such as digit generation and precipitation forecasting."
    },
    "keywords": [
        {
            "term": "street scene",
            "url": "https://en.wikipedia.org/wiki/street_scene"
        },
        {
            "term": "real world",
            "url": "https://en.wikipedia.org/wiki/real_world"
        },
        {
            "term": "autonomous agent",
            "url": "https://en.wikipedia.org/wiki/autonomous_agent"
        },
        {
            "term": "bayesian inference",
            "url": "https://en.wikipedia.org/wiki/bayesian_inference"
        }
    ],
    "abbreviations": {
        "SFNN": "Stochastic feedforward neural networks",
        "CVAE": "Conditional Variational Autoencoder",
        "mIoU": "mean Intersection-over-Union",
        "CLL": "conditional log-likelihood"
    },
    "highlights": [
        "The ability to anticipate future scene states which involves mapping one scene state to likely future states under uncertainty is key for autonomous agents to successfully operate in the real world e.g., to anticipate the movements of pedestrians and vehicles for autonomous vehicles",
        "The main cause is the data log-likelihood maximization step during optimization \u2013 for every data point the average likelihood assigned by all models is maximized. This forces every model to explain every data point well, pushing every model in the distribution to the mean. We address this problem through an objective leveraging synthetic likelihoods (Wood, 2010; <a class=\"ref-link\" id=\"cRosca_et+al_2017_a\" href=\"#rRosca_et+al_2017_a\">Rosca et al, 2017</a>) which relaxes the constraint on every model to explain every data point, encouraging diversity in the learned models to deal with multi-modality",
        "We develop the first Bayesian approach to anticipate the multi-modal future of street scenes and demonstrate state-of-the-art accuracy on the diverse Cityscapes dataset without compromising on calibrated probabilities, 2",
        "We propose a novel approach for predicting real-world semantic segmentations into the future that casts a convolutional deep learning approach into a Bayesian formulation",
        "We show that the developed methodology goes beyond just street scene anticipation and creates new opportunities to enhance high performance deep learning architectures with principled formulations of Bayesian inference"
    ],
    "key_statements": [
        "The ability to anticipate future scene states which involves mapping one scene state to likely future states under uncertainty is key for autonomous agents to successfully operate in the real world e.g., to anticipate the movements of pedestrians and vehicles for autonomous vehicles",
        "The main cause is the data log-likelihood maximization step during optimization \u2013 for every data point the average likelihood assigned by all models is maximized. This forces every model to explain every data point well, pushing every model in the distribution to the mean. We address this problem through an objective leveraging synthetic likelihoods (Wood, 2010; <a class=\"ref-link\" id=\"cRosca_et+al_2017_a\" href=\"#rRosca_et+al_2017_a\">Rosca et al, 2017</a>) which relaxes the constraint on every model to explain every data point, encouraging diversity in the learned models to deal with multi-modality",
        "We develop the first Bayesian approach to anticipate the multi-modal future of street scenes and demonstrate state-of-the-art accuracy on the diverse Cityscapes dataset without compromising on calibrated probabilities, 2",
        "We propose a novel optimization scheme for dropout based Bayesian inference using synthetic likelihoods to encourage diversity and accurately capture model uncertainty, 3",
        "We propose a novel approach for predicting real-world semantic segmentations into the future that casts a convolutional deep learning approach into a Bayesian formulation",
        "We show that the developed methodology goes beyond just street scene anticipation and creates new opportunities to enhance high performance deep learning architectures with principled formulations of Bayesian inference"
    ],
    "summary": [
        "The ability to anticipate future scene states which involves mapping one scene state to likely future states under uncertainty is key for autonomous agents to successfully operate in the real world e.g., to anticipate the movements of pedestrians and vehicles for autonomous vehicles.",
        "We propose a novel optimization scheme for dropout based Bayesian inference using synthetic likelihoods to encourage diversity and accurately capture model uncertainty, 3.",
        "Consider f : x \u2192 y, we capture model uncertainty by learning the distribution p(f |X, Y) of generative models f , likely to have generated our data {X, Y}.",
        "The classifier estimates the likelihood based on whether the models \u03c9 \u223c q(\u03c9) explain data samples likely under the true data distribution p(y|x).",
        "That can distinguish between samples of the true data distribution and samples (x, \u02c6y) generated by the model \u03c9, which provides a synthetic estimate of the likelihood, and equivalently integrating directly over (x, y),",
        "The encoder contains three resid- Figure 2: The architecture of our ResNet based generual blocks with max-pooling in between and the ative models for street scene prediction in our model decoder consists of a residual and a convolua- distribution q(\u03c9).",
        "We consider the following baselines for comparison to our Resnet based Bayesian (BayesWD-SL) model with weight dropout and trained using synthetic likelihoods: 1.",
        "We use the mIoU metric and for a fair comparison consider the mean prediction of our Bayesian models.",
        "We evaluate whether our Bayesian models are able to accurately capture uncertainity and deal with multi-modal futures, upto t + 10 frames (0.6 seconds) in Table 3.",
        "We consider the mean of best 5% of predictions (<a class=\"ref-link\" id=\"cLee_et+al_2017_a\" href=\"#rLee_et+al_2017_a\">Lee et al (2017</a>)) of our Bayesian models to evaluate whether the learned model distribution q(\u03c9) contains likely models corresponding to the groundtruth.",
        "We see that the best predictions considerably improve over the mean predictions \u2013 showing that our Bayesian models learns to capture uncertainity and deal with multi-modal futures.",
        "It is the only Bayesian model whose performance exceeds that of the ResG-Mean model, demonstrating the effectiveness of synthetic likelihoods during training.",
        "In Figure 5 we show examples comparing the best prediction of our Bayes-WD-SL model and ResG-Mean at t + 9.",
        "We see that our Bayes-WD-SL model performs the best, demonstrating that the learned model and observation uncertainty corresponds to the variation in the data.",
        "As there exists no CVAE (Sohn et al, 2015) based model for future segmentation prediction, we construct a baseline as close as possible to our Bayesian models",
        "We propose a novel approach for predicting real-world semantic segmentations into the future that casts a convolutional deep learning approach into a Bayesian formulation.",
        "We show that the developed methodology goes beyond just street scene anticipation and creates new opportunities to enhance high performance deep learning architectures with principled formulations of Bayesian inference"
    ],
    "headline": "We propose a novel Bayesian formulation for anticipating future scene states which leverages synthetic likelihoods that encourage the learning of diverse models to accurately capture the multi-modal nature of future scene states",
    "reference_links": [
        {
            "id": "Babaeizadeh_et+al_2018_a",
            "entry": "Mohammad Babaeizadeh, Chelsea Finn, Dumitru Erhan, Roy H Campbell, and Sergey Levine. Stochastic variational video prediction. In ICLR, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Babaeizadeh%2C%20Mohammad%20Finn%2C%20Chelsea%20Erhan%2C%20Dumitru%20Campbell%2C%20Roy%20H.%20Stochastic%20variational%20video%20prediction%202018"
        },
        {
            "id": "Bao_et+al_2017_a",
            "entry": "Jianmin Bao, Dong Chen, Fang Wen, Houqiang Li, and Gang Hua. Cvae-gan: fine-grained image generation through asymmetric training. In ICCV, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bao%2C%20Jianmin%20Chen%2C%20Dong%20Wen%2C%20Fang%20Li%2C%20Houqiang%20Cvae-gan%3A%20fine-grained%20image%20generation%20through%20asymmetric%20training%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bao%2C%20Jianmin%20Chen%2C%20Dong%20Wen%2C%20Fang%20Li%2C%20Houqiang%20Cvae-gan%3A%20fine-grained%20image%20generation%20through%20asymmetric%20training%202017"
        },
        {
            "id": "Bhattacharyya_et+al_2018_a",
            "entry": "Apratim Bhattacharyya, Mario Fritz, and Bernt Schiele. Long-term on-board prediction of people in traffic scenes under uncertainty. In CVPR, 2018a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bhattacharyya%2C%20Apratim%20Fritz%2C%20Mario%20Schiele%2C%20Bernt%20Long-term%20on-board%20prediction%20of%20people%20in%20traffic%20scenes%20under%20uncertainty%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bhattacharyya%2C%20Apratim%20Fritz%2C%20Mario%20Schiele%2C%20Bernt%20Long-term%20on-board%20prediction%20of%20people%20in%20traffic%20scenes%20under%20uncertainty%202018"
        },
        {
            "id": "Bhattacharyya_et+al_2018_b",
            "entry": "Apratim Bhattacharyya, Mario Fritz, and Bernt Schiele. Accurate and diverse sampling of sequences based on a \u201cbest of many\u201d sample objective. In CVPR, 2018b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bhattacharyya%2C%20Apratim%20Fritz%2C%20Mario%20Schiele%2C%20Bernt%20Accurate%20and%20diverse%20sampling%20of%20sequences%20based%20on%20a%20%E2%80%9Cbest%20of%20many%E2%80%9D%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bhattacharyya%2C%20Apratim%20Fritz%2C%20Mario%20Schiele%2C%20Bernt%20Accurate%20and%20diverse%20sampling%20of%20sequences%20based%20on%20a%20%E2%80%9Cbest%20of%20many%E2%80%9D%202018"
        },
        {
            "id": "Denton_2018_a",
            "entry": "Emily Denton and Rob Fergus. Stochastic video generation with a learned prior. arXiv preprint arXiv:1802.07687, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.07687"
        },
        {
            "id": "Gal_2016_a",
            "entry": "Yarin Gal and Zoubin Ghahramani. Bayesian convolutional neural networks with Bernoulli approximate variational inference. In ICLR workshop track, 2016a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gal%2C%20Yarin%20Ghahramani%2C%20Zoubin%20Bayesian%20convolutional%20neural%20networks%20with%20Bernoulli%20approximate%20variational%20inference%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gal%2C%20Yarin%20Ghahramani%2C%20Zoubin%20Bayesian%20convolutional%20neural%20networks%20with%20Bernoulli%20approximate%20variational%20inference%202016"
        },
        {
            "id": "Gal_2016_b",
            "entry": "Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model uncertainty in deep learning. In ICML, 2016b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gal%2C%20Yarin%20Ghahramani%2C%20Zoubin%20Dropout%20as%20a%20bayesian%20approximation%3A%20Representing%20model%20uncertainty%20in%20deep%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gal%2C%20Yarin%20Ghahramani%2C%20Zoubin%20Dropout%20as%20a%20bayesian%20approximation%3A%20Representing%20model%20uncertainty%20in%20deep%20learning%202016"
        },
        {
            "id": "Gu_et+al_2016_a",
            "entry": "Shixiang Gu, Sergey Levine, Ilya Sutskever, and Andriy Mnih. Muprop: Unbiased backpropagation for stochastic neural networks. In ICLR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gu%2C%20Shixiang%20Levine%2C%20Sergey%20Sutskever%2C%20Ilya%20Mnih%2C%20Andriy%20Muprop%3A%20Unbiased%20backpropagation%20for%20stochastic%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gu%2C%20Shixiang%20Levine%2C%20Sergey%20Sutskever%2C%20Ilya%20Mnih%2C%20Andriy%20Muprop%3A%20Unbiased%20backpropagation%20for%20stochastic%20neural%20networks%202016"
        },
        {
            "id": "He_et+al_2016_a",
            "entry": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "Jin_et+al_2017_a",
            "entry": "Xiaojie Jin, Huaxin Xiao, Xiaohui Shen, Jimei Yang, Zhe Lin, Yunpeng Chen, Zequn Jie, Jiashi Feng, and Shuicheng Yan. Predicting scene parsing and motion dynamics in the future. In NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xiaojie%20Jin%20Huaxin%20Xiao%20Xiaohui%20Shen%20Jimei%20Yang%20Zhe%20Lin%20Yunpeng%20Chen%20Zequn%20Jie%20Jiashi%20Feng%20and%20Shuicheng%20Yan%20Predicting%20scene%20parsing%20and%20motion%20dynamics%20in%20the%20future%20In%20NIPS%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xiaojie%20Jin%20Huaxin%20Xiao%20Xiaohui%20Shen%20Jimei%20Yang%20Zhe%20Lin%20Yunpeng%20Chen%20Zequn%20Jie%20Jiashi%20Feng%20and%20Shuicheng%20Yan%20Predicting%20scene%20parsing%20and%20motion%20dynamics%20in%20the%20future%20In%20NIPS%202017"
        },
        {
            "id": "Kendall_2017_a",
            "entry": "Alex Kendall and Yarin Gal. What uncertainties do we need in bayesian deep learning for computer vision? In NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kendall%2C%20Alex%20Gal%2C%20Yarin%20What%20uncertainties%20do%20we%20need%20in%20bayesian%20deep%20learning%20for%20computer%20vision%3F%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kendall%2C%20Alex%20Gal%2C%20Yarin%20What%20uncertainties%20do%20we%20need%20in%20bayesian%20deep%20learning%20for%20computer%20vision%3F%202017"
        },
        {
            "id": "Kingma_2015_a",
            "entry": "Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Diederik%20P.%20Ba%2C%20Jimmy%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20Diederik%20P.%20Ba%2C%20Jimmy%20Adam%3A%20A%20method%20for%20stochastic%20optimization%202015"
        },
        {
            "id": "Lee_et+al_2017_a",
            "entry": "Namhoon Lee, Wongun Choi, Paul Vernaza, Christopher B Choy, Philip HS Torr, and Manmohan Chandraker. Desire: Distant future prediction in dynamic scenes with interacting agents. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lee%2C%20Namhoon%20Choi%2C%20Wongun%20Vernaza%2C%20Paul%20Choy%2C%20Christopher%20B.%20Desire%3A%20Distant%20future%20prediction%20in%20dynamic%20scenes%20with%20interacting%20agents%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lee%2C%20Namhoon%20Choi%2C%20Wongun%20Vernaza%2C%20Paul%20Choy%2C%20Christopher%20B.%20Desire%3A%20Distant%20future%20prediction%20in%20dynamic%20scenes%20with%20interacting%20agents%202017"
        },
        {
            "id": "Luc_et+al_2017_a",
            "entry": "Pauline Luc, Natalia Neverova, Camille Couprie, Jakob Verbeek, and Yann LeCun. Predicting deeper into the future of semantic segmentation. In ICCV, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Luc%2C%20Pauline%20Neverova%2C%20Natalia%20Couprie%2C%20Camille%20Verbeek%2C%20Jakob%20Predicting%20deeper%20into%20the%20future%20of%20semantic%20segmentation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Luc%2C%20Pauline%20Neverova%2C%20Natalia%20Couprie%2C%20Camille%20Verbeek%2C%20Jakob%20Predicting%20deeper%20into%20the%20future%20of%20semantic%20segmentation%202017"
        },
        {
            "id": "Luc_et+al_2018_a",
            "entry": "Pauline Luc, Camille Couprie, Yann Lecun, and Jakob Verbeek. Predicting future instance segmentations by forecasting convolutional features. arXiv preprint arXiv:1803.11496, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.11496"
        },
        {
            "id": "Mackay_1992_a",
            "entry": "David JC MacKay. A practical bayesian framework for backpropagation networks. Neural computation, 4(3), 1992.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=MacKay%2C%20David%20J.C.%20A%20practical%20bayesian%20framework%20for%20backpropagation%20networks%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=MacKay%2C%20David%20J.C.%20A%20practical%20bayesian%20framework%20for%20backpropagation%20networks%201992"
        },
        {
            "id": "Mathieu_et+al_2016_a",
            "entry": "Michael Mathieu, Camille Couprie, and Yann LeCun. Deep multi-scale video prediction beyond mean square error. In ICLR, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mathieu%2C%20Michael%20Couprie%2C%20Camille%20LeCun%2C%20Yann%20Deep%20multi-scale%20video%20prediction%20beyond%20mean%20square%20error%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mathieu%2C%20Michael%20Couprie%2C%20Camille%20LeCun%2C%20Yann%20Deep%20multi-scale%20video%20prediction%20beyond%20mean%20square%20error%202016"
        },
        {
            "id": "Mirza_2014_a",
            "entry": "Mehdi Mirza and Simon Osindero. Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1411.1784"
        },
        {
            "id": "Neal_2012_a",
            "entry": "Radford M Neal. Bayesian learning for neural networks, volume 118. Springer Science & Business Media, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Neal%2C%20Radford%20M.%20Bayesian%20learning%20for%20neural%20networks%2C%20volume%20118%202012"
        },
        {
            "id": "Osband_2016_a",
            "entry": "Ian Osband. Risk versus uncertainty in deep learning: Bayes, bootstrap and the dangers of dropout. NIPS Workshop on Bayesian Deep Learning, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Osband%2C%20Ian%20Risk%20versus%20uncertainty%20in%20deep%20learning%3A%20Bayes%2C%20bootstrap%20and%20the%20dangers%20of%20dropout%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Osband%2C%20Ian%20Risk%20versus%20uncertainty%20in%20deep%20learning%3A%20Bayes%2C%20bootstrap%20and%20the%20dangers%20of%20dropout%202016"
        },
        {
            "id": "Rezende_et+al_2014_a",
            "entry": "Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models. In ICML, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rezende%2C%20Danilo%20Jimenez%20Mohamed%2C%20Shakir%20Wierstra%2C%20Daan%20Stochastic%20backpropagation%20and%20approximate%20inference%20in%20deep%20generative%20models%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rezende%2C%20Danilo%20Jimenez%20Mohamed%2C%20Shakir%20Wierstra%2C%20Daan%20Stochastic%20backpropagation%20and%20approximate%20inference%20in%20deep%20generative%20models%202014"
        },
        {
            "id": "Rosca_et+al_2017_a",
            "entry": "Mihaela Rosca, Balaji Lakshminarayanan, David Warde-Farley, and Shakir Mohamed. Variational approaches for auto-encoding generative adversarial networks. arXiv preprint arXiv:1706.04987, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.04987"
        },
        {
            "id": "Saatci_2017_a",
            "entry": "Yunus Saatci and Andrew G Wilson. Bayesian gan. In NIPS, 2017. Shahabeddin Nabavi Seyed, Mrigank Rochan, and Wang Yang. Future semantic segmentation with convolutional lstm. In BMVC, 2018. Kihyuk Sohn, Honglak Lee, and Xinchen Yan. Learning structured output representation using deep conditional generative models. In NIPS, 2015. Yichuan Tang and Ruslan R Salakhutdinov. Learning stochastic feedforward neural networks. In",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Saatci%2C%20Yunus%20gan.%20In%20NIPS%2C%20Andrew%20G.Wilson%20Bayesian%20Future%20semantic%20segmentation%20with%20convolutional%20lstm%202017"
        },
        {
            "id": "N_2013_a",
            "entry": "NIPS, 2013. Simon N Wood. Statistical inference for noisy nonlinear ecological dynamic systems. Nature, 466 (7310):1102, 2010. Shi Xingjian, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-Kin Wong, and Wang-chun Woo.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=N.I.P.S.%20Simon%20N%20Wood.%20Statistical%20inference%20for%20noisy%20nonlinear%20ecological%20dynamic%20systems%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=N.I.P.S.%20Simon%20N%20Wood.%20Statistical%20inference%20for%20noisy%20nonlinear%20ecological%20dynamic%20systems%202013"
        },
        {
            "id": "Xue_et+al_2015_a",
            "entry": "Convolutional lstm network: A machine learning approach for precipitation nowcasting. NIPS, 2015. Tianfan Xue, Jiajun Wu, Katherine Bouman, and Bill Freeman. Visual dynamics: Probabilistic future frame synthesis via cross convolutional networks. In NIPS, pp. 91\u201399, 2016. Fisher Yu and Vladlen Koltun. Multi-scale context aggregation by dilated convolutions. In ICLR, 2016. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xue%2C%20Jiajun%20Wu%20Bouman%2C%20Katherine%20Freeman%2C%20Bill%20Convolutional%20lstm%20network%3A%20A%20machine%20learning%20approach%20for%20precipitation%20nowcasting%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xue%2C%20Jiajun%20Wu%20Bouman%2C%20Katherine%20Freeman%2C%20Bill%20Convolutional%20lstm%20network%3A%20A%20machine%20learning%20approach%20for%20precipitation%20nowcasting%202015"
        }
    ]
}

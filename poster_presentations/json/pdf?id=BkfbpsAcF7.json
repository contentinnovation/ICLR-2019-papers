{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "EXCESSIVE INVARIANCE CAUSES ADVERSARIAL VULNERABILITY",
        "author": "Jorn-Henrik Jacobsen 1\u2217, Jens Behrmann, Richard Zemel, Matthias Bethge, 1Vector Institute and University of Toronto 2University of Bremen, Center for Industrial Mathematics 3University of Tubingen \u2217j.jacobsen@vectorinstitute.ai",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=BkfbpsAcF7"
        },
        "journal": "Yet",
        "abstract": "Despite their impressive performance, deep neural networks exhibit striking failures on out-of-distribution inputs. One core idea of adversarial example research is to reveal neural network errors under such distribution shifts. We decompose these errors into two complementary sources: sensitivity and invariance. We show deep networks are not only too sensitive to task-irrelevant changes of their input, as is well-known from -adversarial examples, but are also too invariant to a wide range of task-relevant changes, thus making vast regions in input space vulnerable to adversarial attacks. We show such excessive invariance occurs across various tasks and architecture types. On MNIST and ImageNet one can manipulate the class-specific content of almost any image without changing the hidden activations. We identify an insufficiency of the standard cross-entropy loss as a reason for these failures. Further, we extend this objective based on an informationtheoretic analysis so it encourages the model to consider all task-dependent features in its decision. This provides the first approach tailored explicitly to overcome excessive invariance and resulting vulnerabilities."
    },
    "keywords": [
        {
            "term": "machine learning",
            "url": "https://en.wikipedia.org/wiki/machine_learning"
        },
        {
            "term": "deep network",
            "url": "https://en.wikipedia.org/wiki/deep_network"
        },
        {
            "term": "deep neural network",
            "url": "https://en.wikipedia.org/wiki/deep_neural_network"
        },
        {
            "term": "mutual information",
            "url": "https://en.wikipedia.org/wiki/mutual_information"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        }
    ],
    "abbreviations": {},
    "highlights": [
        "Adversarial vulnerability is one of the most iconic failure cases of modern machine learning models (<a class=\"ref-link\" id=\"cSzegedy_et+al_2013_a\" href=\"#rSzegedy_et+al_2013_a\"><a class=\"ref-link\" id=\"cSzegedy_et+al_2013_a\" href=\"#rSzegedy_et+al_2013_a\">Szegedy et al, 2013</a></a>) and a prime example of their weakness in out-of-distribution generalization",
        "Instead of focusing on transformations erroneously crossing the decision-boundary of classifiers, we focus on excessive invariance as a major cause for adversarial vulnerability",
        "We identify excessive invariance underlying striking failures in deep networks and formalize the connection to adversarial examples",
        "We show invariance-based adversarial examples can be observed across various tasks and types of deep network architectures",
        "The field of adversarial example research aims to close this gap from a robustness point of view",
        "We introduce a reverse view on the problem to: (1) show that a major cause for adversarial vulnerability is excessive invariance to semantically meaningful variations, (2) demonstrate that this issue persists across tasks and architectures; and (3) make the control of invariance tractable via fully-invertible networks"
    ],
    "key_statements": [
        "Adversarial vulnerability is one of the most iconic failure cases of modern machine learning models (<a class=\"ref-link\" id=\"cSzegedy_et+al_2013_a\" href=\"#rSzegedy_et+al_2013_a\"><a class=\"ref-link\" id=\"cSzegedy_et+al_2013_a\" href=\"#rSzegedy_et+al_2013_a\">Szegedy et al, 2013</a></a>) and a prime example of their weakness in out-of-distribution generalization",
        "Instead of focusing on transformations erroneously crossing the decision-boundary of classifiers, we focus on excessive invariance as a major cause for adversarial vulnerability",
        "We identify excessive invariance underlying striking failures in deep networks and formalize the connection to adversarial examples",
        "We show invariance-based adversarial examples can be observed across various tasks and types of deep network architectures",
        "We show that our proposed independence cross-entropy loss is effective in reducing invariance-based vulnerability in practice by comparing it to vanilla cross-entropy training in four aspects: (1) error on train and test set, (2) effect under distribution shift, perturbing nuisances via metameric sampling, (3) evaluate accuracy of a classifier on the nuisance variables to quantify the class-specific information in them and (4) on our newly introduced shiftMNIST, an augmented version of MNIST to benchmark adversarial distribution shifts according to Theorem 6",
        "The field of adversarial example research aims to close this gap from a robustness point of view",
        "We introduce a reverse view on the problem to: (1) show that a major cause for adversarial vulnerability is excessive invariance to semantically meaningful variations, (2) demonstrate that this issue persists across tasks and architectures; and (3) make the control of invariance tractable via fully-invertible networks"
    ],
    "summary": [
        "Adversarial vulnerability is one of the most iconic failure cases of modern machine learning models (<a class=\"ref-link\" id=\"cSzegedy_et+al_2013_a\" href=\"#rSzegedy_et+al_2013_a\"><a class=\"ref-link\" id=\"cSzegedy_et+al_2013_a\" href=\"#rSzegedy_et+al_2013_a\">Szegedy et al, 2013</a></a>) and a prime example of their weakness in out-of-distribution generalization.",
        "We identify excessive invariance underlying striking failures in deep networks and formalize the connection to adversarial examples.",
        "We show invariance-based adversarial examples can be observed across various tasks and types of deep network architectures.",
        "As invariance-based adversarial examples manifest themselves in changes which do not affect the output of the network F , we need zs zn a generic approach that gives us access to the discarded nuisance variability.",
        "We find that logit metamers are revealing adversarial subspaces and are visually close to natural images on ImageNet. metameric sampling gives us an analytic tool to inspect dependencies between semantic and nuisance variables without the need for expensive and approximate optimization procedures.",
        "Incorporating the nuisance classifier allows for the discussed indirect increase of IDAdv (y; zs) under an adversarial distribution shift, visualized in Figure 6.",
        "We show that our proposed independence cross-entropy loss is effective in reducing invariance-based vulnerability in practice by comparing it to vanilla cross-entropy training in four aspects: (1) error on train and test set, (2) effect under distribution shift, perturbing nuisances via metameric sampling, (3) evaluate accuracy of a classifier on the nuisance variables to quantify the class-specific information in them and (4) on our newly introduced shiftMNIST, an augmented version of MNIST to benchmark adversarial distribution shifts according to Theorem 6.",
        "To further test the efficacy of our proposed independence cross-entropy, we introduce a simple, but challenging new dataset termed shiftMNIST to test classifiers under adversarial distribution shifts DAdv. The dataset is based on vanilla MNIST, augmented by introducing additional, highly predictive features at train time that are randomized or removed at test time.",
        "There is ample evidence that RevNet-type networks are closely related to ResNets, while providing a principled framework to study widely observed issues related to excessive invariance in deep learning in general and adversarial robustness in particular.",
        "We introduce a reverse view on the problem to: (1) show that a major cause for adversarial vulnerability is excessive invariance to semantically meaningful variations, (2) demonstrate that this issue persists across tasks and architectures; and (3) make the control of invariance tractable via fully-invertible networks.",
        "We demonstrated how a bijective network architecture enables us to identify large adversarial subspaces on multiple datasets like the adversarial spheres, MNIST and ImageNet. Afterwards, we formalized the distribution shifts causing such undesirable behavior via information theory."
    ],
    "headline": "We show deep networks are not only too sensitive to task-irrelevant changes of their input, as is well-known from -adversarial examples, but are too invariant to a wide range of task-relevant changes, making vast regions in input space vulnerable to adversarial attacks",
    "reference_links": [
        {
            "id": "Abadi_et+al_2016_a",
            "entry": "Mart\u0131n Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al. Tensorflow: a system for largescale machine learning. In OSDI, volume 16, pp. 265\u2013283, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abadi%2C%20Mart%C4%B1n%20Barham%2C%20Paul%20Chen%2C%20Jianmin%20Chen%2C%20Zhifeng%20Tensorflow%3A%20a%20system%20for%20largescale%20machine%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Abadi%2C%20Mart%C4%B1n%20Barham%2C%20Paul%20Chen%2C%20Jianmin%20Chen%2C%20Zhifeng%20Tensorflow%3A%20a%20system%20for%20largescale%20machine%20learning%202016"
        },
        {
            "id": "Achille_2018_a",
            "entry": "Alessandro Achille and Stefano Soatto. Emergence of invariance and disentanglement in deep representations. Journal of Machine Learning Research, 18, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Achille%2C%20Alessandro%20Soatto%2C%20Stefano%20Emergence%20of%20invariance%20and%20disentanglement%20in%20deep%20representations%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Achille%2C%20Alessandro%20Soatto%2C%20Stefano%20Emergence%20of%20invariance%20and%20disentanglement%20in%20deep%20representations%202018"
        },
        {
            "id": "Alemi_et+al_2017_a",
            "entry": "Alexander A. Alemi, Ian Fischer, Joshua V. Dillon, and Kevin Murphy. Deep variational information bottleneck. International Conference on Lerning Representations, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Alemi%2C%20Alexander%20A.%20Fischer%2C%20Ian%20Dillon%2C%20Joshua%20V.%20Murphy%2C%20Kevin%20Deep%20variational%20information%20bottleneck%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Alemi%2C%20Alexander%20A.%20Fischer%2C%20Ian%20Dillon%2C%20Joshua%20V.%20Murphy%2C%20Kevin%20Deep%20variational%20information%20bottleneck%202017"
        },
        {
            "id": "Alemi_et+al_2018_a",
            "entry": "Alexander A. Alemi, Ben Poole, Ian Fischer, Joshua V. Dillon, Rif A. Saurous, and Kevin Murphy. An information-theoretic analysis of deep latent-variable models. Proceedings of the 35th International Conference on Machine Learning, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Alemi%2C%20Alexander%20A.%20Poole%2C%20Ben%20Fischer%2C%20Ian%20Dillon%2C%20Joshua%20V.%20An%20information-theoretic%20analysis%20of%20deep%20latent-variable%20models%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Alemi%2C%20Alexander%20A.%20Poole%2C%20Ben%20Fischer%2C%20Ian%20Dillon%2C%20Joshua%20V.%20An%20information-theoretic%20analysis%20of%20deep%20latent-variable%20models%202018"
        },
        {
            "id": "Ardizzone_et+al_2019_a",
            "entry": "Lynton Ardizzone, Jakob Kruse, Carsten Rother, and Ullrich Kthe. Analyzing inverse problems with invertible neural networks. In International Conference on Learning Representations, 2019.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ardizzone%2C%20Lynton%20Kruse%2C%20Jakob%20Rother%2C%20Carsten%20Kthe%2C%20Ullrich%20Analyzing%20inverse%20problems%20with%20invertible%20neural%20networks%202019",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ardizzone%2C%20Lynton%20Kruse%2C%20Jakob%20Rother%2C%20Carsten%20Kthe%2C%20Ullrich%20Analyzing%20inverse%20problems%20with%20invertible%20neural%20networks%202019"
        },
        {
            "id": "Barber_2003_a",
            "entry": "David Barber and Felix Agakov. The im algorithm: A variational approach to information maximization. In Advances in Neural Information Processing Systemss, 2003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Barber%2C%20David%20Agakov%2C%20Felix%20The%20im%20algorithm%3A%20A%20variational%20approach%20to%20information%20maximization%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Barber%2C%20David%20Agakov%2C%20Felix%20The%20im%20algorithm%3A%20A%20variational%20approach%20to%20information%20maximization%202003"
        },
        {
            "id": "Behrmann_et+al_0000_a",
            "entry": "Jens Behrmann, Soren Dittmer, Pascal Fernsel, and Peter Maa\u00df. Analysis of invariance and robustness via invertibility of relu-networks. arXiv preprint arXiv:1806.09730, 2018a.",
            "arxiv_url": "https://arxiv.org/pdf/1806.09730"
        },
        {
            "id": "Behrmann_et+al_2018_a",
            "entry": "Jens Behrmann, David Duvenaud, and Jorn-Henrik Jacobsen. Invertible residual networks. arXiv preprint arXiv:1811.00995, 2018b.",
            "arxiv_url": "https://arxiv.org/pdf/1811.00995"
        },
        {
            "id": "Belghazi_et+al_2018_a",
            "entry": "Mohamed Ishmael Belghazi, Aristide Baratin, Sai Rajeshwar, Sherjil Ozair, Yoshua Bengio, Devon Hjelm, and Aaron Courville. Mutual information neural estimation. In Proceedings of the 35th International Conference on Machine Learning, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Belghazi%2C%20Mohamed%20Ishmael%20Baratin%2C%20Aristide%20Rajeshwar%2C%20Sai%20Ozair%2C%20Sherjil%20Mutual%20information%20neural%20estimation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Belghazi%2C%20Mohamed%20Ishmael%20Baratin%2C%20Aristide%20Rajeshwar%2C%20Sai%20Ozair%2C%20Sherjil%20Mutual%20information%20neural%20estimation%202018"
        },
        {
            "id": "Brendel_et+al_2018_a",
            "entry": "Wieland Brendel, Jonas Rauber, Alexey Kurakin, Nicolas Papernot, Behar Veliqi, Marcel Salathe, Sharada P Mohanty, and Matthias Bethge. Adversarial vision challenge. arXiv preprint arXiv:1808.01976, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1808.01976"
        },
        {
            "id": "Brown_et+al_2018_a",
            "entry": "Tom B. Brown, Nicholas Carlini, Chiyuan Zhang, Catherine Olsson, Paul Christiano, and Ian Goodfellow. Unrestricted adversarial examples. arXiv preprint arXiv:1809.08352, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1809.08352"
        },
        {
            "id": "Bubeck_2018_a",
            "entry": "Sebastien Bubeck, Eric Price, and Ilya Razenshteyn. Adversarial examples from computational constraints. arXiv preprint arXiv:1805.10204, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1805.10204"
        },
        {
            "id": "Chen_et+al_2016_a",
            "entry": "Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. Infogan: Interpretable representation learning by information maximizing generative adversarial nets. In Advances in Neural Information Processing Systems. 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Xi%20Duan%2C%20Yan%20Houthooft%2C%20Rein%20Schulman%2C%20John%20Infogan%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Xi%20Duan%2C%20Yan%20Houthooft%2C%20Rein%20Schulman%2C%20John%20Infogan%3A%20Interpretable%20representation%20learning%20by%20information%20maximizing%20generative%20adversarial%20nets%202016"
        },
        {
            "id": "M_2014_a",
            "entry": "M. Cimpoi, S. Maji, I. Kokkinos, S. Mohamed,, and A. Vedaldi. Describing textures in the wild. In Proceedings of the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=M%20Cimpoi%20S%20Maji%20I%20Kokkinos%20S%20Mohamed%20and%20A%20Vedaldi%20Describing%20textures%20in%20the%20wild%20In%20Proceedings%20of%20the%20IEEE%20Conf%20on%20Computer%20Vision%20and%20Pattern%20Recognition%20CVPR%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=M%20Cimpoi%20S%20Maji%20I%20Kokkinos%20S%20Mohamed%20and%20A%20Vedaldi%20Describing%20textures%20in%20the%20wild%20In%20Proceedings%20of%20the%20IEEE%20Conf%20on%20Computer%20Vision%20and%20Pattern%20Recognition%20CVPR%202014"
        },
        {
            "id": "Cover_2006_a",
            "entry": "Thomas M. Cover and Joy A. Thomas. Elements of Information Theory (Wiley Series in Telecommunications and Signal Processing). Wiley-Interscience, New York, NY, USA, 2006. ISBN 0471241954.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cover%2C%20Thomas%20M.%20Thomas%2C%20Joy%20A.%20Elements%20of%20Information%20Theory%20%28Wiley%20Series%20in%20Telecommunications%20and%20Signal%20Processing%29%202006"
        },
        {
            "id": "Dinh_et+al_2017_a",
            "entry": "Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using real nvp. International Conference on Learning Representations, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dinh%2C%20Laurent%20Sohl-Dickstein%2C%20Jascha%20Bengio%2C%20Samy%20Density%20estimation%20using%20real%20nvp%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dinh%2C%20Laurent%20Sohl-Dickstein%2C%20Jascha%20Bengio%2C%20Samy%20Density%20estimation%20using%20real%20nvp%202017"
        },
        {
            "id": "Fawzi_et+al_2018_a",
            "entry": "Alhussein Fawzi, Hamza Fawzi, and Omar Fawzi. Adversarial vulnerability for any classifier. In Advances in Neural Information Processing Systems 31. 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fawzi%2C%20Alhussein%20Fawzi%2C%20Hamza%20Fawzi%2C%20Omar%20Adversarial%20vulnerability%20for%20any%20classifier%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fawzi%2C%20Alhussein%20Fawzi%2C%20Hamza%20Fawzi%2C%20Omar%20Adversarial%20vulnerability%20for%20any%20classifier%202018"
        },
        {
            "id": "Gatys_et+al_2017_a",
            "entry": "Leon A Gatys, Alexander S Ecker, and Matthias Bethge. Texture and art with deep neural networks. Current opinion in neurobiology, 46:178\u2013186, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gatys%2C%20Leon%20A.%20Ecker%2C%20Alexander%20S.%20Bethge%2C%20Matthias%20Texture%20and%20art%20with%20deep%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gatys%2C%20Leon%20A.%20Ecker%2C%20Alexander%20S.%20Bethge%2C%20Matthias%20Texture%20and%20art%20with%20deep%20neural%20networks%202017"
        },
        {
            "id": "Ghassami_2017_a",
            "entry": "AmirEmad Ghassami and Negar Kiyavash. Interaction information for causal inference: The case of directed triangle. arXiv preprint arXiv:abs/1701.08868, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ghassami%2C%20AmirEmad%20Kiyavash%2C%20Negar%20Interaction%20information%20for%20causal%20inference%3A%20The%20case%20of%20directed%20triangle%202017"
        },
        {
            "id": "Gilmer_et+al_0000_a",
            "entry": "Justin Gilmer, Ryan P. Adams, Ian Goodfellow, David Andersen, and George E. Dahl. Motivating the rules of the game for adversarial example research. arXiv preprint arXiv:1807.06732, 2018a.",
            "arxiv_url": "https://arxiv.org/pdf/1807.06732"
        },
        {
            "id": "Gilmer_et+al_0000_b",
            "entry": "Justin Gilmer, Luke Metz, Fartash Faghri, Samuel S Schoenholz, Maithra Raghu, Martin Wattenberg, and Ian Goodfellow. Adversarial spheres. arXiv preprint arXiv:1801.02774, 2018b.",
            "arxiv_url": "https://arxiv.org/pdf/1801.02774"
        },
        {
            "id": "Gomez_et+al_2017_a",
            "entry": "Aidan N Gomez, Mengye Ren, Raquel Urtasun, and Roger B Grosse. The reversible residual network: Backpropagation without storing activations. Advances in Neural Information Processing Systems, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gomez%2C%20Aidan%20N.%20Ren%2C%20Mengye%20Urtasun%2C%20Raquel%20Grosse%2C%20Roger%20B.%20The%20reversible%20residual%20network%3A%20Backpropagation%20without%20storing%20activations%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gomez%2C%20Aidan%20N.%20Ren%2C%20Mengye%20Urtasun%2C%20Raquel%20Grosse%2C%20Roger%20B.%20The%20reversible%20residual%20network%3A%20Backpropagation%20without%20storing%20activations%202017"
        },
        {
            "id": "Goodfellow_et+al_2014_a",
            "entry": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in Neural Information Processing Systems, pp. 2672\u20132680, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "Goodfellow_et+al_2015_a",
            "entry": "Ian Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. International Conference on Learning Representations, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Shlens%2C%20Jonathon%20Szegedy%2C%20Christian%20Explaining%20and%20harnessing%20adversarial%20examples%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Shlens%2C%20Jonathon%20Szegedy%2C%20Christian%20Explaining%20and%20harnessing%20adversarial%20examples%202015"
        },
        {
            "id": "Grathwohl_et+al_2019_a",
            "entry": "Will Grathwohl, Ricky T. Q. Chen, Jesse Bettencourt, and David Duvenaud. Scalable reversible generative models with free-form continuous dynamics. In International Conference on Learning Representations, 2019.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Grathwohl%2C%20Will%20Chen%2C%20Ricky%20T.Q.%20Bettencourt%2C%20Jesse%20Duvenaud%2C%20David%20Scalable%20reversible%20generative%20models%20with%20free-form%20continuous%20dynamics%202019",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Grathwohl%2C%20Will%20Chen%2C%20Ricky%20T.Q.%20Bettencourt%2C%20Jesse%20Duvenaud%2C%20David%20Scalable%20reversible%20generative%20models%20with%20free-form%20continuous%20dynamics%202019"
        },
        {
            "id": "He_et+al_2016_a",
            "entry": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770\u2013778, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "Hjelm_et+al_2019_a",
            "entry": "Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil Bachman, Adam Trischler, and Yoshua Bengio. Learning deep representations by mutual information estimation and maximization. In International Conference on Learning Representations, 2019.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hjelm%2C%20Devon%20Fedorov%2C%20Alex%20Lavoie-Marchildon%2C%20Samuel%20Grewal%2C%20Karan%20Learning%20deep%20representations%20by%20mutual%20information%20estimation%20and%20maximization%202019",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hjelm%2C%20Devon%20Fedorov%2C%20Alex%20Lavoie-Marchildon%2C%20Samuel%20Grewal%2C%20Karan%20Learning%20deep%20representations%20by%20mutual%20information%20estimation%20and%20maximization%202019"
        },
        {
            "id": "Hyvarinen_2000_a",
            "entry": "Aapo Hyvarinen and Patrik Hoyer. Emergence of phase-and shift-invariant features by decomposition of natural images into independent feature subspaces. Neural computation, 12(7):1705\u20131720, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hyvarinen%2C%20Aapo%20Hoyer%2C%20Patrik%20Emergence%20of%20phase-and%20shift-invariant%20features%20by%20decomposition%20of%20natural%20images%20into%20independent%20feature%20subspaces%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hyvarinen%2C%20Aapo%20Hoyer%2C%20Patrik%20Emergence%20of%20phase-and%20shift-invariant%20features%20by%20decomposition%20of%20natural%20images%20into%20independent%20feature%20subspaces%202000"
        },
        {
            "id": "Jacobsen_et+al_2018_a",
            "entry": "Jorn-Henrik Jacobsen, Arnold W.M. Smeulders, and Edouard Oyallon. i-revnet: Deep invertible networks. In International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jacobsen%2C%20Jorn-Henrik%20Smeulders%2C%20Arnold%20W.M.%20Oyallon%2C%20Edouard%20i-revnet%3A%20Deep%20invertible%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jacobsen%2C%20Jorn-Henrik%20Smeulders%2C%20Arnold%20W.M.%20Oyallon%2C%20Edouard%20i-revnet%3A%20Deep%20invertible%20networks%202018"
        },
        {
            "id": "Jo_2017_a",
            "entry": "Jason Jo and Yoshua Bengio. Measuring the tendency of cnns to learn surface statistical regularities. arXiv preprint arXiv:1711.11561, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.11561"
        },
        {
            "id": "Kingma_2014_a",
            "entry": "Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6980"
        },
        {
            "id": "Kingma_2018_a",
            "entry": "Durk P Kingma and Prafulla Dhariwal. Glow: Generative flow with invertible 1x1 convolutions. In Advances in Neural Information Processing Systems 31. 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kingma%2C%20Durk%20P.%20Dhariwal%2C%20Prafulla%20Glow%3A%20Generative%20flow%20with%20invertible%201x1%20convolutions%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kingma%2C%20Durk%20P.%20Dhariwal%2C%20Prafulla%20Glow%3A%20Generative%20flow%20with%20invertible%201x1%20convolutions%202018"
        },
        {
            "id": "Kraskov_et+al_2004_a",
            "entry": "Alexander Kraskov, Harald Stogbauer, and Peter Grassberger. Estimating mutual information. Physical Review E, 69, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kraskov%2C%20Alexander%20Stogbauer%2C%20Harald%20Grassberger%2C%20Peter%20Estimating%20mutual%20information%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kraskov%2C%20Alexander%20Stogbauer%2C%20Harald%20Grassberger%2C%20Peter%20Estimating%20mutual%20information%202004"
        },
        {
            "id": "Lecun_et+al_2015_a",
            "entry": "Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 521(7553):436\u2013444, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=LeCun%2C%20Yann%20Bengio%2C%20Yoshua%20Hinton%2C%20Geoffrey%20Deep%20learning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=LeCun%2C%20Yann%20Bengio%2C%20Yoshua%20Hinton%2C%20Geoffrey%20Deep%20learning%202015"
        },
        {
            "id": "Louizos_et+al_2015_a",
            "entry": "Christos Louizos, Kevin Swersky, Yujia Li, Max Welling, and Richard S. Zemel. The variational fair autoencoder. arXiv preprint arXiv:abs/1511.00830, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Louizos%2C%20Christos%20Swersky%2C%20Kevin%20Li%2C%20Yujia%20Welling%2C%20Max%20The%20variational%20fair%20autoencoder%202015"
        },
        {
            "id": "Madry_et+al_2017_a",
            "entry": "Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. International Conference on Learning Representations, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Madry%2C%20Aleksander%20Makelov%2C%20Aleksandar%20Schmidt%2C%20Ludwig%20Tsipras%2C%20Dimitris%20Towards%20deep%20learning%20models%20resistant%20to%20adversarial%20attacks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Madry%2C%20Aleksander%20Makelov%2C%20Aleksandar%20Schmidt%2C%20Ludwig%20Tsipras%2C%20Dimitris%20Towards%20deep%20learning%20models%20resistant%20to%20adversarial%20attacks%202017"
        },
        {
            "id": "Paszke_et+al_2017_a",
            "entry": "Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Paszke%2C%20Adam%20Gross%2C%20Sam%20Chintala%2C%20Soumith%20Chanan%2C%20Gregory%20Automatic%20differentiation%20in%20pytorch%202017"
        },
        {
            "id": "Pereyra_et+al_2017_a",
            "entry": "Gabriel Pereyra, George Tucker, Jan Chorowski, Lukasz Kaiser, and Geoffrey E. Hinton. Regularizing neural networks by penalizing confident output distributions. International Conference on Lerning Representations (workshop), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pereyra%2C%20Gabriel%20Tucker%2C%20George%20Chorowski%2C%20Jan%20Kaiser%2C%20Lukasz%20Regularizing%20neural%20networks%20by%20penalizing%20confident%20output%20distributions%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pereyra%2C%20Gabriel%20Tucker%2C%20George%20Chorowski%2C%20Jan%20Kaiser%2C%20Lukasz%20Regularizing%20neural%20networks%20by%20penalizing%20confident%20output%20distributions%202017"
        },
        {
            "id": "Raghunathan_et+al_2018_a",
            "entry": "Aditi Raghunathan, Jacob Steinhardt, and Percy Liang. Certified defenses against adversarial examples. International Conference on Learning Representations, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Raghunathan%2C%20Aditi%20Steinhardt%2C%20Jacob%20Liang%2C%20Percy%20Certified%20defenses%20against%20adversarial%20examples%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Raghunathan%2C%20Aditi%20Steinhardt%2C%20Jacob%20Liang%2C%20Percy%20Certified%20defenses%20against%20adversarial%20examples%202018"
        },
        {
            "id": "Sabour_et+al_2016_a",
            "entry": "Sara Sabour, Yanshuai Cao, Fartash Faghri, and David J Fleet. Adversarial manipulation of deep representations. International Conference on Learning Representations, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sabour%2C%20Sara%20Cao%2C%20Yanshuai%20Faghri%2C%20Fartash%20Fleet%2C%20David%20J.%20Adversarial%20manipulation%20of%20deep%20representations%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sabour%2C%20Sara%20Cao%2C%20Yanshuai%20Faghri%2C%20Fartash%20Fleet%2C%20David%20J.%20Adversarial%20manipulation%20of%20deep%20representations%202016"
        },
        {
            "id": "Schmidhuber_1991_a",
            "entry": "Jurgen Schmidhuber. Learning factorial codes by predictability minimization. Technical report, Dept. of Comp. Sci., University of Colorado at Boulder, 1991.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schmidhuber%2C%20Jurgen%20Learning%20factorial%20codes%20by%20predictability%20minimization%201991"
        },
        {
            "id": "Schmidt_et+al_2018_a",
            "entry": "Ludwig Schmidt, Shibani Santurkar, Dimitris Tsipras, Kunal Talwar, and Aleksander Madry. Adversarially robust generalization requires more data. In Advances in Neural Information Processing Systems 31. 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schmidt%2C%20Ludwig%20Santurkar%2C%20Shibani%20Tsipras%2C%20Dimitris%20Talwar%2C%20Kunal%20Adversarially%20robust%20generalization%20requires%20more%20data%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schmidt%2C%20Ludwig%20Santurkar%2C%20Shibani%20Tsipras%2C%20Dimitris%20Talwar%2C%20Kunal%20Adversarially%20robust%20generalization%20requires%20more%20data%202018"
        },
        {
            "id": "Shwartz-Ziv_2017_a",
            "entry": "Ravid Shwartz-Ziv and Naftali Tishby. Opening the black box of deep neural networks via information. arXiv preprint arXiv:1703.00810, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.00810"
        },
        {
            "id": "Simonyan_2014_a",
            "entry": "Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1409.1556"
        },
        {
            "id": "Song_et+al_2018_a",
            "entry": "Yang Song, Rui Shu, Nate Kushman, and Stefano Ermon. Constructing unrestricted adversarial examples with generative models. In Advances in Neural Information Processing Systems 31. 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Song%2C%20Yang%20Shu%2C%20Rui%20Kushman%2C%20Nate%20Ermon%2C%20Stefano%20Constructing%20unrestricted%20adversarial%20examples%20with%20generative%20models%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Song%2C%20Yang%20Shu%2C%20Rui%20Kushman%2C%20Nate%20Ermon%2C%20Stefano%20Constructing%20unrestricted%20adversarial%20examples%20with%20generative%20models%202018"
        },
        {
            "id": "Szegedy_et+al_2013_a",
            "entry": "Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013.",
            "arxiv_url": "https://arxiv.org/pdf/1312.6199"
        },
        {
            "id": "Tishby_2015_a",
            "entry": "Naftali Tishby and Noga Zaslavsky. Deep learning and the information bottleneck principle. In Information Theory Workshop (ITW), 2015 IEEE, pp. 1\u20135. IEEE, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tishby%2C%20Naftali%20Zaslavsky%2C%20Noga%20Deep%20learning%20and%20the%20information%20bottleneck%20principle%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tishby%2C%20Naftali%20Zaslavsky%2C%20Noga%20Deep%20learning%20and%20the%20information%20bottleneck%20principle%202015"
        },
        {
            "id": "Tsipras_et+al_2019_a",
            "entry": "Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and Aleksander Madry. Robustness may be at odds with accuracy. In International Conference on Learning Representations, 2019.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tsipras%2C%20Dimitris%20Santurkar%2C%20Shibani%20Engstrom%2C%20Logan%20Turner%2C%20Alexander%20and%20Aleksander%20Madry.%20Robustness%20may%20be%20at%20odds%20with%20accuracy%202019",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tsipras%2C%20Dimitris%20Santurkar%2C%20Shibani%20Engstrom%2C%20Logan%20Turner%2C%20Alexander%20and%20Aleksander%20Madry.%20Robustness%20may%20be%20at%20odds%20with%20accuracy%202019"
        },
        {
            "id": "Example_2018_a",
            "entry": "Example 7 (Semantic and nuisance on Adversarial Spheres (Gilmer et al., 2018b)). Consider classifying inputs x from two classes given by radii R1 or R2. Further, let (r, \u03c6) denote the spherical coordinates of x. Then, any perturbation \u2206x, x\u2217 = x + \u2206x with r\u2217 = r is semantic. On the other hand, if r\u2217 = r the perturbation is a nuisance with respect to the task of discriminating two spheres.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Example%207%20Semantic%20and%20nuisance%20on%20Adversarial%20Spheres%20Gilmer%20et%20al%202018b%20Consider%20classifying%20inputs%20x%20from%20two%20classes%20given%20by%20radii%20R1%20or%20R2%20Further%20let%20r%20%CF%86%20denote%20the%20spherical%20coordinates%20of%20x%20Then%20any%20perturbation%20x%20x%20%20x%20%20x%20with%20r%20%20r%20is%20semantic%20On%20the%20other%20hand%20if%20r%20%20r%20the%20perturbation%20is%20a%20nuisance%20with%20respect%20to%20the%20task%20of%20discriminating%20two%20spheres",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Example%207%20Semantic%20and%20nuisance%20on%20Adversarial%20Spheres%20Gilmer%20et%20al%202018b%20Consider%20classifying%20inputs%20x%20from%20two%20classes%20given%20by%20radii%20R1%20or%20R2%20Further%20let%20r%20%CF%86%20denote%20the%20spherical%20coordinates%20of%20x%20Then%20any%20perturbation%20x%20x%20%20x%20%20x%20with%20r%20%20r%20is%20semantic%20On%20the%20other%20hand%20if%20r%20%20r%20the%20perturbation%20is%20a%20nuisance%20with%20respect%20to%20the%20task%20of%20discriminating%20two%20spheres"
        },
        {
            "id": "2",
            "entry": "2. Perturbation \u2206x is semantic, as o(x) = o(x + \u2206x). We empirically evaluate the classifier in equation 7 on the spheres problem (10M/2M samples setting (Gilmer et al., 2018b)) and validate that it can reach perfect classification accuracy. However, by construction, perturbing the invariant dimension xd\u2217 = xd + \u2206xd allows us to move all samples from the inner sphere to the outer sphere. Thus, the accuracy of the classifier drops to chance level when evaluating its performance under such a distributional shift. To conclude, this underlines how classifiers with optimal performance on finite samples can exhibit non-intuitive failure modes due to excessive invariance with respect to semantic variations.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Perturbation%20x%20is%20semantic%20as%20ox%20%20ox%20%20x%20We%20empirically%20evaluate%20the%20classifier%20in%20equation%207%20on%20the%20spheres%20problem%2010M2M%20samples%20setting%20Gilmer%20et%20al%202018b%20and%20validate%20that%20it%20can%20reach%20perfect%20classification%20accuracy%20However%20by%20construction%20perturbing%20the%20invariant%20dimension%20xd%20%20xd%20%20xd%20allows%20us%20to%20move%20all%20samples%20from%20the%20inner%20sphere%20to%20the%20outer%20sphere%20Thus%20the%20accuracy%20of%20the%20classifier%20drops%20to%20chance%20level%20when%20evaluating%20its%20performance%20under%20such%20a%20distributional%20shift%20To%20conclude%20this%20underlines%20how%20classifiers%20with%20optimal%20performance%20on%20finite%20samples%20can%20exhibit%20nonintuitive%20failure%20modes%20due%20to%20excessive%20invariance%20with%20respect%20to%20semantic%20variations"
        },
        {
            "id": "We_2017_b",
            "entry": "We use a standard Imagenet pre-trained Resnet-154 as provided by the torchvision package (Paszke et al., 2017) and choose a logit percept y = G(x) that can be based on any seed image. Then we optimize various images xto be metameric to x by simply minimizing a mean squared error loss of the form: 1 LMSE(G(x), G(x)) = K",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=We%20use%20a%20standard%20Imagenet%20pretrained%20Resnet154%20as%20provided%20by%20the%20torchvision%20package%20Paszke%20et%20al%202017%20and%20choose%20a%20logit%20percept%20y%20%20Gx%20that%20can%20be%20based%20on%20any%20seed%20image%20Then%20we%20optimize%20various%20images%20xto%20be%20metameric%20to%20x%20by%20simply%20minimizing%20a%20mean%20squared%20error%20loss%20of%20the%20form%201%20LMSEGx%20Gx%20%20K",
            "oa_query": "https://api.scholarcy.com/oa_version?query=We%20use%20a%20standard%20Imagenet%20pretrained%20Resnet154%20as%20provided%20by%20the%20torchvision%20package%20Paszke%20et%20al%202017%20and%20choose%20a%20logit%20percept%20y%20%20Gx%20that%20can%20be%20based%20on%20any%20seed%20image%20Then%20we%20optimize%20various%20images%20xto%20be%20metameric%20to%20x%20by%20simply%20minimizing%20a%20mean%20squared%20error%20loss%20of%20the%20form%201%20LMSEGx%20Gx%20%20K"
        }
    ]
}

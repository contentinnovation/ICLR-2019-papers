{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "ROBUST CONDITIONAL GENERATIVE ADVERSARIAL NETWORKS",
        "author": "Grigorios G. Chrysos, Jean Kossaifi, Stefanos Zafeiriou, 1 Department of Computing, Imperial College London, UK {g.chrysos, jean.kossaifi, s.zafeiriou}@imperial.ac.uk",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=Byg0DsCqYQ"
        },
        "abstract": "Conditional generative adversarial networks (cGAN) have led to large improvements in the task of conditional image generation, which lies at the heart of computer vision. The major focus so far has been on performance improvement, while there has been little effort in making cGAN more robust to noise. The regression (of the generator) might lead to arbitrarily large errors in the output, which makes cGAN unreliable for real-world applications. In this work, we introduce a novel conditional GAN model, called RoCGAN, which leverages structure in the target space of the model to address the issue. Our model augments the generator with an unsupervised pathway, which promotes the outputs of the generator to span the target manifold even in the presence of intense noise. We prove that RoCGAN share similar theoretical properties as GAN and experimentally verify that our model outperforms existing state-of-the-art cGAN architectures by a large margin in a variety of domains including images from natural scenes and faces."
    },
    "keywords": [
        {
            "term": "generative adversarial network",
            "url": "https://en.wikipedia.org/wiki/generative_adversarial_network"
        },
        {
            "term": "computer vision",
            "url": "https://en.wikipedia.org/wiki/computer_vision"
        },
        {
            "term": "target manifold",
            "url": "https://en.wikipedia.org/wiki/target_manifold"
        },
        {
            "term": "image translation",
            "url": "https://en.wikipedia.org/wiki/image_translation"
        }
    ],
    "abbreviations": {
        "cGAN": "Conditional GAN",
        "RoCGAN": "Robust Conditional GAN"
    },
    "highlights": [
        "Image-to-image translation and more generally conditional image generation lie at the heart of computer vision",
        "The mapping of Conditional GAN does not constrain the output to the target manifold, the output can be arbitrarily off the target manifold (<a class=\"ref-link\" id=\"cVidal_et+al_2017_a\" href=\"#rVidal_et+al_2017_a\">Vidal et al, 2017</a>)",
        "We prove that Robust Conditional GAN share similar theoretical properties with the original GAN, i.e. convergence and optimal discriminator",
        "We introduce the Robust Conditional GAN (RoCGAN) model, a new conditional GAN capable of leveraging unsupervised data to learn better latent representations, even in the face of large amount of noise",
        "The linear analogy along with the synthetic experiment demonstrate how Robust Conditional GAN can create more robust results, while we prove that our model shares similar convergence properties with generative adversarial networks",
        "The ablation study dictates that our model is more resilient to intense noise and more robust to adversarial examples than the baseline"
    ],
    "key_statements": [
        "Image-to-image translation and more generally conditional image generation lie at the heart of computer vision",
        "The mapping of Conditional GAN does not constrain the output to the target manifold, the output can be arbitrarily off the target manifold (<a class=\"ref-link\" id=\"cVidal_et+al_2017_a\" href=\"#rVidal_et+al_2017_a\">Vidal et al, 2017</a>)",
        "We prove that Robust Conditional GAN share similar theoretical properties with the original GAN, i.e. convergence and optimal discriminator",
        "We introduce Robust Conditional GAN that leverages structure in the target space",
        "We introduce the Robust Conditional GAN (RoCGAN) model, a new conditional GAN capable of leveraging unsupervised data to learn better latent representations, even in the face of large amount of noise",
        "The linear analogy along with the synthetic experiment demonstrate how Robust Conditional GAN can create more robust results, while we prove that our model shares similar convergence properties with generative adversarial networks",
        "The ablation study dictates that our model is more resilient to intense noise and more robust to adversarial examples than the baseline"
    ],
    "summary": [
        "Image-to-image translation and more generally conditional image generation lie at the heart of computer vision.",
        "The unsupervised pathway enables the network to explore the structure that is not present in the labelled training set, while implicitly constraining the output.",
        "We constrain the decoder to generate samples that span only the target manifold.",
        "The first pathway, to the cGAN generator, performs regression while the second is an autoencoder in the target domain.",
        "Pix2pix includes three modifications over the baseline cGAN: i) lateral skip connections between the encoder and the decoder network are added in the generator, ii) the discriminator accepts pairs of source/gt and source/model output images, iii) additional content loss terms are added.",
        "During training they utilize the augmented network as two pathways: i) labelled input samples are fed to the initial bottom-up module, ii) input samples are corrupted with noise and fed to the encoder-decoder with the lateral connections.",
        "If we denote s the conditioning label and y a sample from the target distribution, the adversarial loss is expressed as: Ladv(G, D) = Es,y\u223cpd(s,y)[log D(y|s)]+",
        "The first pathway, referred as reg pathway performs a similar regression as its counterpart in cGAN; it accepts a sample from the source domain and maps it to the target domain.",
        "To obtain RoCGAN, we augment a vanilla cGAN model as follows: i) we duplicate the encoder/decoder; ii) we share the decoder\u2019s weights in z z y x y x",
        "An ablation study on the significance and the sensitivity of the hyper-parameters is conducted; additional architectures are implemented, while we evaluate our model under more intense noise.",
        "The results demonstrate that our model accepts a range of hyper-parameter values, while it is robust to additional sources of noise.",
        "Each module of the AAE shares the same architecture as its cGAN counterpart, while the AAE is trained with images in the target space.",
        "We introduce the Robust Conditional GAN (RoCGAN) model, a new conditional GAN capable of leveraging unsupervised data to learn better latent representations, even in the face of large amount of noise.",
        "By adding weight sharing between the two decoders, we implicitly constrain the reg pathway to output images that span the target manifold.",
        "The linear analogy along with the synthetic experiment demonstrate how RoCGAN can create more robust results, while we prove that our model shares similar convergence properties with generative adversarial networks.",
        "The experimental results with images showcase that RoCGAN outperform existing, state-of-the-art conditional GAN models."
    ],
    "headline": "We introduce a novel conditional GAN model, called Robust Conditional GAN, which leverages structure in the target space of the model to address the issue",
    "reference_links": [
        {
            "id": "Bengio_et+al_2013_a",
            "entry": "Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new perspectives. IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI), 35(8): 1798\u20131828, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bengio%2C%20Yoshua%20Courville%2C%20Aaron%20Vincent%2C%20Pascal%20Representation%20learning%3A%20A%20review%20and%20new%20perspectives%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bengio%2C%20Yoshua%20Courville%2C%20Aaron%20Vincent%2C%20Pascal%20Representation%20learning%3A%20A%20review%20and%20new%20perspectives%202013"
        },
        {
            "id": "Bousmalis_et+al_2016_a",
            "entry": "Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman, Dilip Krishnan, and Dumitru Erhan. Domain separation networks. In Advances in neural information processing systems (NIPS), pp. 343\u2013351, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bousmalis%2C%20Konstantinos%20Trigeorgis%2C%20George%20Silberman%2C%20Nathan%20Krishnan%2C%20Dilip%20Domain%20separation%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bousmalis%2C%20Konstantinos%20Trigeorgis%2C%20George%20Silberman%2C%20Nathan%20Krishnan%2C%20Dilip%20Domain%20separation%20networks%202016"
        },
        {
            "id": "Cogswell_et+al_2016_a",
            "entry": "Michael Cogswell, Faruk Ahmed, Ross Girshick, Larry Zitnick, and Dhruv Batra. Reducing overfitting in deep networks by decorrelating representations. In International Conference on Learning Representations (ICLR), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cogswell%2C%20Michael%20Ahmed%2C%20Faruk%20Girshick%2C%20Ross%20Zitnick%2C%20Larry%20Reducing%20overfitting%20in%20deep%20networks%20by%20decorrelating%20representations%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cogswell%2C%20Michael%20Ahmed%2C%20Faruk%20Girshick%2C%20Ross%20Zitnick%2C%20Larry%20Reducing%20overfitting%20in%20deep%20networks%20by%20decorrelating%20representations%202016"
        },
        {
            "id": "Deng_et+al_2009_a",
            "entry": "Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In IEEE Proceedings of International Conference on Computer Vision and Pattern Recognition (CVPR), pp. 248\u2013255, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Deng%2C%20Jia%20Dong%2C%20Wei%20Socher%2C%20Richard%20Li%2C%20Li-Jia%20Imagenet%3A%20A%20large-scale%20hierarchical%20image%20database%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Deng%2C%20Jia%20Dong%2C%20Wei%20Socher%2C%20Richard%20Li%2C%20Li-Jia%20Imagenet%3A%20A%20large-scale%20hierarchical%20image%20database%202009"
        },
        {
            "id": "Everingham_et+al_2010_a",
            "entry": "Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, and Andrew Zisserman. The pascal visual object classes (voc) challenge. International Journal of Computer Vision (IJCV), 88 (2):303\u2013338, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Everingham%2C%20Mark%20Gool%2C%20Luc%20Van%20Williams%2C%20Christopher%20K.I.%20Winn%2C%20John%20The%20pascal%20visual%20object%20classes%20%28voc%29%20challenge%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Everingham%2C%20Mark%20Gool%2C%20Luc%20Van%20Williams%2C%20Christopher%20K.I.%20Winn%2C%20John%20The%20pascal%20visual%20object%20classes%20%28voc%29%20challenge%202010"
        },
        {
            "id": "Goodfellow_et+al_2014_a",
            "entry": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems (NIPS), 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "Goodfellow_et+al_2014_b",
            "entry": "Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples (2014). In International Conference on Learning Representations (ICLR), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20J.%20Shlens%2C%20Jonathon%20Szegedy%2C%20Christian%20Explaining%20and%20harnessing%20adversarial%20examples%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20J.%20Shlens%2C%20Jonathon%20Szegedy%2C%20Christian%20Explaining%20and%20harnessing%20adversarial%20examples%202014"
        },
        {
            "id": "Gretton_et+al_2007_a",
            "entry": "Arthur Gretton, Karsten M Borgwardt, Malte Rasch, Bernhard Sch\u00f6lkopf, and Alex J Smola. A kernel method for the two-sample-problem. In Advances in neural information processing systems (NIPS), pp. 513\u2013520, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gretton%2C%20Arthur%20Borgwardt%2C%20Karsten%20M.%20Rasch%2C%20Malte%20Sch%C3%B6lkopf%2C%20Bernhard%20A%20kernel%20method%20for%20the%20two-sample-problem%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gretton%2C%20Arthur%20Borgwardt%2C%20Karsten%20M.%20Rasch%2C%20Malte%20Sch%C3%B6lkopf%2C%20Bernhard%20A%20kernel%20method%20for%20the%20two-sample-problem%202007"
        },
        {
            "id": "Guo_2016_a",
            "entry": "Y. Guo et al. Ms-celeb-1m: A dataset and benchmark for large-scale face recognition. In Proceedings of European Conference on Computer Vision (ECCV), pp. 87\u2013102, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Guo%2C%20Y.%20Ms-celeb-%201m%3A%20A%20dataset%20and%20benchmark%20for%20large-scale%20face%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Guo%2C%20Y.%20Ms-celeb-%201m%3A%20A%20dataset%20and%20benchmark%20for%20large-scale%20face%20recognition%202016"
        },
        {
            "id": "He_et+al_2016_a",
            "entry": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In IEEE Proceedings of International Conference on Computer Vision and Pattern Recognition (CVPR), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "Hotelling_1936_a",
            "entry": "Harold Hotelling. Relations between two sets of variates. Biometrika, 28(3/4):321\u2013377, 1936.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hotelling%2C%20Harold%20Relations%20between%20two%20sets%20of%20variates%201936",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hotelling%2C%20Harold%20Relations%20between%20two%20sets%20of%20variates%201936"
        },
        {
            "id": "Ioffe_2015_a",
            "entry": "Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International Conference on Machine Learning (ICML), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ioffe%2C%20Sergey%20Szegedy%2C%20Christian%20Batch%20normalization%3A%20Accelerating%20deep%20network%20training%20by%20reducing%20internal%20covariate%20shift%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ioffe%2C%20Sergey%20Szegedy%2C%20Christian%20Batch%20normalization%3A%20Accelerating%20deep%20network%20training%20by%20reducing%20internal%20covariate%20shift%202015"
        },
        {
            "id": "Isola_et+al_2017_a",
            "entry": "Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with conditional adversarial networks. In IEEE Proceedings of International Conference on Computer Vision and Pattern Recognition (CVPR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Isola%2C%20Phillip%20Zhu%2C%20Jun-Yan%20Zhou%2C%20Tinghui%20and%20Alexei%20A%20Efros.%20Image-to-image%20translation%20with%20conditional%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Isola%2C%20Phillip%20Zhu%2C%20Jun-Yan%20Zhou%2C%20Tinghui%20and%20Alexei%20A%20Efros.%20Image-to-image%20translation%20with%20conditional%20adversarial%20networks%202017"
        },
        {
            "id": "Johnson_et+al_2016_a",
            "entry": "Justin Johnson, Alexandre Alahi, and Li Fei-Fei. Perceptual losses for real-time style transfer and super-resolution. In Proceedings of European Conference on Computer Vision (ECCV), pp. 694\u2013711, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Justin%20Alahi%2C%20Alexandre%20Fei-Fei%2C%20Li%20Perceptual%20losses%20for%20real-time%20style%20transfer%20and%20super-resolution%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20Justin%20Alahi%2C%20Alexandre%20Fei-Fei%2C%20Li%20Perceptual%20losses%20for%20real-time%20style%20transfer%20and%20super-resolution%202016"
        },
        {
            "id": "Kumar_et+al_2017_a",
            "entry": "Abhishek Kumar, Prasanna Sattigeri, and Tom Fletcher. Semi-supervised learning with gans: manifold invariance with improved inference. In Advances in neural information processing systems (NIPS), pp. 5534\u20135544, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kumar%2C%20Abhishek%20Sattigeri%2C%20Prasanna%20Fletcher%2C%20Tom%20Semi-supervised%20learning%20with%20gans%3A%20manifold%20invariance%20with%20improved%20inference%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kumar%2C%20Abhishek%20Sattigeri%2C%20Prasanna%20Fletcher%2C%20Tom%20Semi-supervised%20learning%20with%20gans%3A%20manifold%20invariance%20with%20improved%20inference%202017"
        },
        {
            "id": "Lamb_et+al_2018_a",
            "entry": "Alex Lamb, Jonathan Binas, Anirudh Goyal, Dmitriy Serdyuk, Sandeep Subramanian, Ioannis Mitliagkas, and Yoshua Bengio. Fortified networks: Improving the robustness of deep networks by modeling the manifold of hidden representations. arXiv preprint arXiv:1804.02485, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.02485"
        },
        {
            "id": "Ledig_et+al_2017_a",
            "entry": "Christian Ledig, Lucas Theis, Ferenc Husz\u00e1r, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, et al. Photo-realistic single image super-resolution using a generative adversarial network. In IEEE Proceedings of International Conference on Computer Vision and Pattern Recognition (CVPR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ledig%2C%20Christian%20Theis%2C%20Lucas%20Husz%C3%A1r%2C%20Ferenc%20Caballero%2C%20Jose%20Photo-realistic%20single%20image%20super-resolution%20using%20a%20generative%20adversarial%20network%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ledig%2C%20Christian%20Theis%2C%20Lucas%20Husz%C3%A1r%2C%20Ferenc%20Caballero%2C%20Jose%20Photo-realistic%20single%20image%20super-resolution%20using%20a%20generative%20adversarial%20network%202017"
        },
        {
            "id": "Liu_et+al_2017_a",
            "entry": "Ming-Yu Liu, Thomas Breuel, and Jan Kautz. Unsupervised image-to-image translation networks. In Advances in neural information processing systems (NIPS), pp. 700\u2013708, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Ming-Yu%20Breuel%2C%20Thomas%20Kautz%2C%20Jan%20Unsupervised%20image-to-image%20translation%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Ming-Yu%20Breuel%2C%20Thomas%20Kautz%2C%20Jan%20Unsupervised%20image-to-image%20translation%20networks%202017"
        },
        {
            "id": "Liu_et+al_2015_a",
            "entry": "Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In IEEE Proceedings of International Conference on Computer Vision (ICCV), pp. 3730\u20133738, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liu%2C%20Ziwei%20Luo%2C%20Ping%20Wang%2C%20Xiaogang%20Tang%2C%20Xiaoou%20Deep%20learning%20face%20attributes%20in%20the%20wild%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Liu%2C%20Ziwei%20Luo%2C%20Ping%20Wang%2C%20Xiaogang%20Tang%2C%20Xiaoou%20Deep%20learning%20face%20attributes%20in%20the%20wild%202015"
        },
        {
            "id": "Ma_et+al_2018_a",
            "entry": "Liqian Ma, Qianru Sun, Stamatios Georgoulis, Luc Van Gool, Bernt Schiele, and Mario Fritz. Disentangled person image generation. In IEEE Proceedings of International Conference on Computer Vision and Pattern Recognition (CVPR), pp. 99\u2013108, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ma%2C%20Liqian%20Sun%2C%20Qianru%20Georgoulis%2C%20Stamatios%20Gool%2C%20Luc%20Van%20Disentangled%20person%20image%20generation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ma%2C%20Liqian%20Sun%2C%20Qianru%20Georgoulis%2C%20Stamatios%20Gool%2C%20Luc%20Van%20Disentangled%20person%20image%20generation%202018"
        },
        {
            "id": "Makhzani_et+al_2015_a",
            "entry": "Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, and Brendan Frey. Adversarial autoencoders. arXiv preprint arXiv:1511.05644, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.05644"
        },
        {
            "id": "Mirza_2014_a",
            "entry": "Mehdi Mirza and Simon Osindero. Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1411.1784"
        },
        {
            "id": "Miyato_2018_a",
            "entry": "Takeru Miyato and Masanori Koyama. cgans with projection discriminator. In International Conference on Learning Representations (ICLR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Miyato%2C%20Takeru%20Koyama%2C%20Masanori%20cgans%20with%20projection%20discriminator%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Miyato%2C%20Takeru%20Koyama%2C%20Masanori%20cgans%20with%20projection%20discriminator%202018"
        },
        {
            "id": "Murdock_et+al_2018_a",
            "entry": "Calvin Murdock, Ming-Fang Chang, and Simon Lucey. Deep component analysis via alternating direction neural networks. arXiv preprint arXiv:1803.06407, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.06407"
        },
        {
            "id": "Panagakis_et+al_2016_a",
            "entry": "Yannis Panagakis, Mihalis A Nicolaou, Stefanos Zafeiriou, and Maja Pantic. Robust correlated and individual component analysis. IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI), 38(8):1665\u20131678, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Panagakis%2C%20Yannis%20Nicolaou%2C%20Mihalis%20A.%20Zafeiriou%2C%20Stefanos%20Pantic%2C%20Maja%20Robust%20correlated%20and%20individual%20component%20analysis%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Panagakis%2C%20Yannis%20Nicolaou%2C%20Mihalis%20A.%20Zafeiriou%2C%20Stefanos%20Pantic%2C%20Maja%20Robust%20correlated%20and%20individual%20component%20analysis%202016"
        },
        {
            "id": "Pathak_et+al_2016_a",
            "entry": "Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and Alexei A Efros. Context encoders: Feature learning by inpainting. In IEEE Proceedings of International Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2536\u20132544, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pathak%2C%20Deepak%20Krahenbuhl%2C%20Philipp%20Donahue%2C%20Jeff%20Darrell%2C%20Trevor%20and%20Alexei%20A%20Efros.%20Context%20encoders%3A%20Feature%20learning%20by%20inpainting%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pathak%2C%20Deepak%20Krahenbuhl%2C%20Philipp%20Donahue%2C%20Jeff%20Darrell%2C%20Trevor%20and%20Alexei%20A%20Efros.%20Context%20encoders%3A%20Feature%20learning%20by%20inpainting%202016"
        },
        {
            "id": "Rasmus_et+al_2015_a",
            "entry": "Antti Rasmus, Mathias Berglund, Mikko Honkala, Harri Valpola, and Tapani Raiko. Semi-supervised learning with ladder networks. In Advances in neural information processing systems (NIPS), pp. 3546\u20133554, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rasmus%2C%20Antti%20Berglund%2C%20Mathias%20Honkala%2C%20Mikko%20Valpola%2C%20Harri%20Semi-supervised%20learning%20with%20ladder%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rasmus%2C%20Antti%20Berglund%2C%20Mathias%20Honkala%2C%20Mikko%20Valpola%2C%20Harri%20Semi-supervised%20learning%20with%20ladder%20networks%202015"
        },
        {
            "id": "Chang_et+al_2017_a",
            "entry": "JH Rick Chang, Chun-Liang Li, Barnabas Poczos, BVK Vijaya Kumar, and Aswin C Sankaranarayanan. One network to solve them all\u2013solving linear inverse problems using deep projection models. In IEEE Proceedings of International Conference on Computer Vision (ICCV), pp. 5888\u20135897, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chang%2C%20J.H.Rick%20Li%2C%20Chun-Liang%20Barnabas%20Poczos%2C%20B.V.K.Vijaya%20Kumar%20Sankaranarayanan%2C%20Aswin%20C.%20One%20network%20to%20solve%20them%20all%E2%80%93solving%20linear%20inverse%20problems%20using%20deep%20projection%20models%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chang%2C%20J.H.Rick%20Li%2C%20Chun-Liang%20Barnabas%20Poczos%2C%20B.V.K.Vijaya%20Kumar%20Sankaranarayanan%2C%20Aswin%20C.%20One%20network%20to%20solve%20them%20all%E2%80%93solving%20linear%20inverse%20problems%20using%20deep%20projection%20models%202017"
        },
        {
            "id": "Russakovsky_et+al_2015_a",
            "entry": "Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual recognition challenge. International Journal of Computer Vision (IJCV), 115(3):211\u2013252, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Russakovsky%2C%20Olga%20Deng%2C%20Jia%20Su%2C%20Hao%20Krause%2C%20Jonathan%20Imagenet%20large%20scale%20visual%20recognition%20challenge%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Russakovsky%2C%20Olga%20Deng%2C%20Jia%20Su%2C%20Hao%20Krause%2C%20Jonathan%20Imagenet%20large%20scale%20visual%20recognition%20challenge%202015"
        },
        {
            "id": "Salimans_et+al_2016_a",
            "entry": "Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. In Advances in neural information processing systems (NIPS), pp. 2234\u20132242, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Salimans%2C%20Tim%20Goodfellow%2C%20Ian%20Zaremba%2C%20Wojciech%20Cheung%2C%20Vicki%20Improved%20techniques%20for%20training%20gans%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Salimans%2C%20Tim%20Goodfellow%2C%20Ian%20Zaremba%2C%20Wojciech%20Cheung%2C%20Vicki%20Improved%20techniques%20for%20training%20gans%202016"
        },
        {
            "id": "Samangouei_et+al_2018_a",
            "entry": "Pouya Samangouei, Maya Kabkab, and Rama Chellappa. Defense-gan: Protecting classifiers against adversarial attacks using generative models. In International Conference on Learning Representations (ICLR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Samangouei%2C%20Pouya%20Kabkab%2C%20Maya%20Chellappa%2C%20Rama%20Defense-gan%3A%20Protecting%20classifiers%20against%20adversarial%20attacks%20using%20generative%20models%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Samangouei%2C%20Pouya%20Kabkab%2C%20Maya%20Chellappa%2C%20Rama%20Defense-gan%3A%20Protecting%20classifiers%20against%20adversarial%20attacks%20using%20generative%20models%202018"
        },
        {
            "id": "Schroff_et+al_2015_a",
            "entry": "Florian Schroff, Dmitry Kalenichenko, and James Philbin. Facenet: A unified embedding for face recognition and clustering. In IEEE Proceedings of International Conference on Computer Vision and Pattern Recognition (CVPR), pp. 815\u2013823, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Schroff%2C%20Florian%20Kalenichenko%2C%20Dmitry%20Philbin%2C%20James%20Facenet%3A%20A%20unified%20embedding%20for%20face%20recognition%20and%20clustering%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Schroff%2C%20Florian%20Kalenichenko%2C%20Dmitry%20Philbin%2C%20James%20Facenet%3A%20A%20unified%20embedding%20for%20face%20recognition%20and%20clustering%202015"
        },
        {
            "id": "Szegedy_et+al_2014_a",
            "entry": "Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. Intriguing properties of neural networks. In International Conference on Learning Representations (ICLR), 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Szegedy%2C%20Christian%20Zaremba%2C%20Wojciech%20Sutskever%2C%20Ilya%20Bruna%2C%20Joan%20Intriguing%20properties%20of%20neural%20networks%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Szegedy%2C%20Christian%20Zaremba%2C%20Wojciech%20Sutskever%2C%20Ilya%20Bruna%2C%20Joan%20Intriguing%20properties%20of%20neural%20networks%202014"
        },
        {
            "id": "Tulyakov_et+al_2018_a",
            "entry": "Sergey Tulyakov, Ming-Yu Liu, Xiaodong Yang, and Jan Kautz. Mocogan: Decomposing motion and content for video generation. In IEEE Proceedings of International Conference on Computer Vision and Pattern Recognition (CVPR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tulyakov%2C%20Sergey%20Liu%2C%20Ming-Yu%20Yang%2C%20Xiaodong%20Kautz%2C%20Jan%20Mocogan%3A%20Decomposing%20motion%20and%20content%20for%20video%20generation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tulyakov%2C%20Sergey%20Liu%2C%20Ming-Yu%20Yang%2C%20Xiaodong%20Kautz%2C%20Jan%20Mocogan%3A%20Decomposing%20motion%20and%20content%20for%20video%20generation%202018"
        },
        {
            "id": "Valpola_2015_a",
            "entry": "Harri Valpola. From neural pca to deep unsupervised learning. In Advances in Independent Component Analysis and Learning Machines, pp. 143\u2013171. 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Valpola%2C%20Harri%20From%20neural%20pca%20to%20deep%20unsupervised%20learning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Valpola%2C%20Harri%20From%20neural%20pca%20to%20deep%20unsupervised%20learning%202015"
        },
        {
            "id": "Vidal_et+al_2017_a",
            "entry": "Rene Vidal, Joan Bruna, Raja Giryes, and Stefano Soatto. Mathematics of deep learning. arXiv preprint arXiv:1712.04741, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.04741"
        },
        {
            "id": "Vincent_et+al_2008_a",
            "entry": "Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol. Extracting and composing robust features with denoising autoencoders. In International Conference on Machine Learning (ICML), pp. 1096\u20131103, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vincent%2C%20Pascal%20Larochelle%2C%20Hugo%20Bengio%2C%20Yoshua%20Manzagol%2C%20Pierre-Antoine%20Extracting%20and%20composing%20robust%20features%20with%20denoising%20autoencoders%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vincent%2C%20Pascal%20Larochelle%2C%20Hugo%20Bengio%2C%20Yoshua%20Manzagol%2C%20Pierre-Antoine%20Extracting%20and%20composing%20robust%20features%20with%20denoising%20autoencoders%202008"
        },
        {
            "id": "Wang_et+al_2004_a",
            "entry": "Zhou Wang, Alan C Bovik, Hamid R Sheikh, and Eero P Simoncelli. Image quality assessment: from error visibility to structural similarity. IEEE Transactions in Image Processing (TIP), 13(4): 600\u2013612, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Zhou%20Bovik%2C%20Alan%20C.%20Sheikh%2C%20Hamid%20R.%20Simoncelli%2C%20Eero%20P.%20Image%20quality%20assessment%3A%20from%20error%20visibility%20to%20structural%20similarity%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Zhou%20Bovik%2C%20Alan%20C.%20Sheikh%2C%20Hamid%20R.%20Simoncelli%2C%20Eero%20P.%20Image%20quality%20assessment%3A%20from%20error%20visibility%20to%20structural%20similarity%202004"
        },
        {
            "id": "Wang_et+al_2017_a",
            "entry": "Ziyu Wang, Josh S Merel, Scott E Reed, Nando de Freitas, Gregory Wayne, and Nicolas Heess. Robust imitation of diverse behaviors. In Advances in neural information processing systems (NIPS), pp. 5320\u20135329, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Ziyu%20Merel%2C%20Josh%20S.%20Reed%2C%20Scott%20E.%20de%20Freitas%2C%20Nando%20Robust%20imitation%20of%20diverse%20behaviors%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Ziyu%20Merel%2C%20Josh%20S.%20Reed%2C%20Scott%20E.%20de%20Freitas%2C%20Nando%20Robust%20imitation%20of%20diverse%20behaviors%202017"
        },
        {
            "id": "Yu_et+al_2018_a",
            "entry": "Jiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, and Thomas S Huang. Generative image inpainting with contextual attention. In IEEE Proceedings of International Conference on Computer Vision and Pattern Recognition (CVPR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yu%2C%20Jiahui%20Lin%2C%20Zhe%20Yang%2C%20Jimei%20Shen%2C%20Xiaohui%20Generative%20image%20inpainting%20with%20contextual%20attention%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yu%2C%20Jiahui%20Lin%2C%20Zhe%20Yang%2C%20Jimei%20Shen%2C%20Xiaohui%20Generative%20image%20inpainting%20with%20contextual%20attention%202018"
        },
        {
            "id": "Yuan_et+al_2017_a",
            "entry": "Xiaoyong Yuan, Pan He, Qile Zhu, Rajendra Rana Bhat, and Xiaolin Li. Adversarial examples: Attacks and defenses for deep learning. arXiv preprint arXiv:1712.07107, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.07107"
        },
        {
            "id": "Zhang_2016_a",
            "entry": "Published as a conference paper at ICLR 2019 Yuting Zhang, Kibok Lee, and Honglak Lee. Augmenting supervised neural networks with unsupervised objectives for large-scale image classification. In International Conference on Machine Learning (ICML), pp. 612\u2013621, 2016. Jun-Yan Zhu, Richard Zhang, Deepak Pathak, Trevor Darrell, Alexei A Efros, Oliver Wang, and Eli Shechtman. Toward multimodal image-to-image translation. In Advances in neural information processing systems (NIPS), pp. 465\u2013476, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Published%20as%20a%20conference%20paper%20at%20ICLR%202019%20Yuting%20Zhang%20Kibok%20Lee%20and%20Honglak%20Lee%20Augmenting%20supervised%20neural%20networks%20with%20unsupervised%20objectives%20for%20largescale%20image%20classification%20In%20International%20Conference%20on%20Machine%20Learning%20ICML%20pp%20612621%202016%20JunYan%20Zhu%20Richard%20Zhang%20Deepak%20Pathak%20Trevor%20Darrell%20Alexei%20A%20Efros%20Oliver%20Wang%20and%20Eli%20Shechtman%20Toward%20multimodal%20imagetoimage%20translation%20In%20Advances%20in%20neural%20information%20processing%20systems%20NIPS%20pp%20465476%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Published%20as%20a%20conference%20paper%20at%20ICLR%202019%20Yuting%20Zhang%20Kibok%20Lee%20and%20Honglak%20Lee%20Augmenting%20supervised%20neural%20networks%20with%20unsupervised%20objectives%20for%20largescale%20image%20classification%20In%20International%20Conference%20on%20Machine%20Learning%20ICML%20pp%20612621%202016%20JunYan%20Zhu%20Richard%20Zhang%20Deepak%20Pathak%20Trevor%20Darrell%20Alexei%20A%20Efros%20Oliver%20Wang%20and%20Eli%20Shechtman%20Toward%20multimodal%20imagetoimage%20translation%20In%20Advances%20in%20neural%20information%20processing%20systems%20NIPS%20pp%20465476%202017"
        }
    ]
}

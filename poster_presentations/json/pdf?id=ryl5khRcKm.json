{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "HUMAN-LEVEL PROTEIN LOCALIZATION WITH CONVOLUTIONAL NEURAL NETWORKS",
        "author": "Elisabeth Rumetshofer, Markus Hofmarcher, Clemens R\u00f6hrl, Sepp Hochreiter, G\u00fcnter Klambauer, 1 LIT AI Lab, Johannes Kepler University Linz 2 Institute for Machine Learning, Johannes Kepler University Linz {rumetshofer,hofmarcher,hochreit,klambauer}@ml.jku.at 3Department of Medical Chemistry, Center for Pathobiochemistry and Genetics, Medical University of Vienna clemens.roehrl@meduniwien.ac.at",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=ryl5khRcKm"
        },
        "abstract": "Localizing a specific protein in a human cell is essential for understanding cellular functions and biological processes of underlying diseases. A promising, low-cost, and time-efficient biotechnology for localizing proteins is high-throughput fluorescence microscopy imaging (HTI). This imaging technique stains the protein of interest in a cell with fluorescent antibodies and subsequently takes a microscopic image. Together with images of other stained proteins or cell organelles and the annotation by the Human Protein Atlas project, these images provide a rich source of information on the protein location which can be utilized by computational methods. It is yet unclear how precise such methods are and whether they can compete with human experts. We here focus on deep learning image analysis methods and, in particular, on Convolutional Neural Networks (CNNs) since they showed overwhelming success across different imaging tasks. We propose a novel CNN architecture \u201cGapNet-PL\u201d that has been designed to tackle the characteristics of HTI data and uses global averages of filters at different abstraction levels. We present the largest comparison of CNN architectures including GapNet-PL for protein localization in HTI images of human cells. GapNet-PL outperforms all other competing methods and reaches close to perfect localization in all 13 tasks with an average AUC of 98% and F1 score of 78%. On a separate test set the performance of GapNet-PL was compared with three human experts and 25 scholars. GapNet-PL achieved an accuracy of 91%, significantly (p-value 1.1e\u22126) outperforming the best human expert with an accuracy of 72%.1"
    },
    "keywords": [
        {
            "term": "human cell",
            "url": "https://en.wikipedia.org/wiki/human_cell"
        },
        {
            "term": "image analysis",
            "url": "https://en.wikipedia.org/wiki/image_analysis"
        },
        {
            "term": "cell organelle",
            "url": "https://en.wikipedia.org/wiki/cell_organelle"
        },
        {
            "term": "convolutional neural networks",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_networks"
        },
        {
            "term": "protein localization",
            "url": "https://en.wikipedia.org/wiki/protein_localization"
        },
        {
            "term": "multiple instance learning",
            "url": "https://en.wikipedia.org/wiki/multiple_instance_learning"
        },
        {
            "term": "biological process",
            "url": "https://en.wikipedia.org/wiki/biological_process"
        },
        {
            "term": "Microscopy",
            "url": "https://en.wikipedia.org/wiki/Microscopy"
        }
    ],
    "abbreviations": {
        "HTI": "high-throughput fluorescence microscopy imaging",
        "CNNs": "Convolutional Neural Networks",
        "HPA": "Human Protein Atlas project",
        "ReLU": "Rectified Linear Unit",
        "MIL": "multiple instance learning",
        "FCN": "fully convolutional approach",
        "M-CNN": "Multi-scale Convolutional Neural Network",
        "SGD": "Stochastic Gradient Descent",
        "AUC": "area under ROC"
    },
    "highlights": [
        "Proteins perform their function at specific times and locations within a cell",
        "We found that the average performance across the 13 tasks of the compared methods ranges from an area under ROC (AUC) of 91% to 98%, with a mean area under ROC of 95%",
        "We introduced a new neural network architecture GapNet-PL that was designed to overcome the challenges introduced by the nature of high-throughput fluorescence microscopy imaging data such as high resolution and weak labels",
        "Where human experts fail, but GapNet-PL classifies correctly, the staining can be variable across cells (Appendix Figure 12) or the staining is weak (Appendix Figure 13)",
        "Based on our investigation of failures, we hypothesize that GapNet-PL is better for classes that have similar staining patterns, such as cytosol and vesicles, and in cases where there is some variability across cells, and when the staining is weak",
        "With respect to our comparison with the human experts, we are aware that our estimate of human performance at this task could suffer from potential biases such as the following: a) Anchoring effect: The human experts investigated only a subset of the training data points and could be biased towards those; b) Confirmation bias: The human experts knew they would compete against an AI and probably thought the AI would be better, which could have decreased their motivation and thereby their performance; c) Response bias: There was interaction between human experts and the experimenter in an interactive session, such that the human experts knew that the experimenter\u2019s goal was to show that the AI can outperform humans and might have subconsciously supported this effort or \u2013 vice versa \u2013 may have motivated the human experts to perform even better than routinely; d) The human experts could be performing better than usual since they knew they were in a testing situation; e) Limited sample size and selection bias: we only tested the performance of three human experts and the human experts were selected to be familiar with protein localization in microscopic images, but it is unclear how representative their performance is for possible human performance"
    ],
    "key_statements": [
        "Proteins perform their function at specific times and locations within a cell",
        "We found that the average performance across the 13 tasks of the compared methods ranges from an area under ROC (AUC) of 91% to 98%, with a mean area under ROC of 95%",
        "In our comparison of the best performing Convolutional Neural Networks against human experts and scholars, we found that the computational method could reach an accuracy of 91%",
        "We introduced a new neural network architecture GapNet-PL that was designed to overcome the challenges introduced by the nature of high-throughput fluorescence microscopy imaging data such as high resolution and weak labels",
        "Where human experts fail, but GapNet-PL classifies correctly, the staining can be variable across cells (Appendix Figure 12) or the staining is weak (Appendix Figure 13)",
        "Based on our investigation of failures, we hypothesize that GapNet-PL is better for classes that have similar staining patterns, such as cytosol and vesicles, and in cases where there is some variability across cells, and when the staining is weak",
        "With respect to our comparison with the human experts, we are aware that our estimate of human performance at this task could suffer from potential biases such as the following: a) Anchoring effect: The human experts investigated only a subset of the training data points and could be biased towards those; b) Confirmation bias: The human experts knew they would compete against an AI and probably thought the AI would be better, which could have decreased their motivation and thereby their performance; c) Response bias: There was interaction between human experts and the experimenter in an interactive session, such that the human experts knew that the experimenter\u2019s goal was to show that the AI can outperform humans and might have subconsciously supported this effort or \u2013 vice versa \u2013 may have motivated the human experts to perform even better than routinely; d) The human experts could be performing better than usual since they knew they were in a testing situation; e) Limited sample size and selection bias: we only tested the performance of three human experts and the human experts were selected to be familiar with protein localization in microscopic images, but it is unclear how representative their performance is for possible human performance",
        "We have shown that GapNet-PL could be used to automatically annotate protein locations in immunostained high-throughput fluorescence microscopy imaging data and envision that it could be developed into a routine clinical application"
    ],
    "summary": [
        "Proteins perform their function at specific times and locations within a cell.",
        "Multi-scale Convolutional Neural Network (M-CNN) The M-CNN model (<a class=\"ref-link\" id=\"cGodinez_et+al_2017_a\" href=\"#rGodinez_et+al_2017_a\">Godinez et al, 2017</a>) is designed for phenotype classification of human HTI data and was benchmarked on 8 separate datasets, half of them dealing with protein localization for different cell types (HeLa, CHO, A-531 and MCF-7).",
        "To determine the practical applicability of our model, we conducted a comparison of the GapNetPL performance with a) 3 human experts in pathobiology who frequently work with fluorescence microscopy images and b) 25 scholars, i.e. graduate and undergraduate students with a life science background that were given special training.",
        "In a large study comparing convolutional neural networks for protein localization in human cells, GapNet-PL performs almost perfectly, achieving an average AUC of 98% and an F1 score of 78%, outperforming all compared computational methods while requiring less computational resources.",
        "With respect to our comparison with the human experts, we are aware that our estimate of human performance at this task could suffer from potential biases such as the following: a) Anchoring effect: The human experts investigated only a subset of the training data points and could be biased towards those; b) Confirmation bias: The human experts knew they would compete against an AI and probably thought the AI would be better, which could have decreased their motivation and thereby their performance; c) Response bias: There was interaction between human experts and the experimenter in an interactive session, such that the human experts knew that the experimenter\u2019s goal was to show that the AI can outperform humans and might have subconsciously supported this effort or \u2013 vice versa \u2013 may have motivated the human experts to perform even better than routinely; d) The human experts could be performing better than usual since they knew they were in a testing situation; e) Limited sample size and selection bias: we only tested the performance of three human experts and the human experts were selected to be familiar with protein localization in microscopic images, but it is unclear how representative their performance is for possible human performance.",
        "It already exhibits a high predictive performance on a large and diverse dataset setting the state-of-the-art from 0.51 to 0.78 and could get even better with more data from different stainings and additional cell lines produced by other biotechnological devices from various labs."
    ],
    "headline": "We propose a novel Convolutional Neural Networks architecture \u201cGapNet-PL\u201d that has been designed to tackle the characteristics of high-throughput fluorescence microscopy imaging data and uses global averages of filters at different abstraction levels",
    "reference_links": [
        {
            "id": "Carpenter_et+al_2006_a",
            "entry": "Carpenter, A. E., Jones, T. R., Lamprecht, M. R., Clarke, C., Kang, I., Friman, O., Guertin, D. A., Chang, J., Lindquist, R. A., Moffat, J., Golland, P., and Sabatini, D. M. (2006). CellProfiler: image analysis software for identifying and quantifying cell phenotypes. Genome Biology, 7(10):R100.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Carpenter%2C%20A.E.%20Jones%2C%20T.R.%20Lamprecht%2C%20M.R.%20Clarke%2C%20C.%20CellProfiler%3A%20image%20analysis%20software%20for%20identifying%20and%20quantifying%20cell%20phenotypes%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Carpenter%2C%20A.E.%20Jones%2C%20T.R.%20Lamprecht%2C%20M.R.%20Clarke%2C%20C.%20CellProfiler%3A%20image%20analysis%20software%20for%20identifying%20and%20quantifying%20cell%20phenotypes%202006"
        },
        {
            "id": "Duerr_2016_a",
            "entry": "D\u00fcrr, O. and Sick, B. (2016). Single-Cell Phenotype Classification Using Deep Convolutional Neural Networks. Journal of Biomolecular Screening, 21(9):998\u20131003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=D%C3%BCrr%2C%20O.%20Sick%2C%20B.%20Single-Cell%20Phenotype%20Classification%20Using%20Deep%20Convolutional%20Neural%20Networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=D%C3%BCrr%2C%20O.%20Sick%2C%20B.%20Single-Cell%20Phenotype%20Classification%20Using%20Deep%20Convolutional%20Neural%20Networks%202016"
        },
        {
            "id": "Esteva_et+al_2017_a",
            "entry": "Esteva, A., Kuprel, B., Novoa, R. A., Ko, J., Swetter, S. M., Blau, H. M., and Thrun, S. (2017). Dermatologist-level classification of skin cancer with deep neural networks. Nature, 542(7639):115\u2013118.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Esteva%2C%20A.%20Kuprel%2C%20B.%20Novoa%2C%20R.A.%20Ko%2C%20J.%20Dermatologist-level%20classification%20of%20skin%20cancer%20with%20deep%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Esteva%2C%20A.%20Kuprel%2C%20B.%20Novoa%2C%20R.A.%20Ko%2C%20J.%20Dermatologist-level%20classification%20of%20skin%20cancer%20with%20deep%20neural%20networks%202017"
        },
        {
            "id": "Godinez_et+al_2017_a",
            "entry": "Godinez, W. J., Hossain, I., Lazic, S. E., Davies, J. W., and Zhang, X. (2017). A multi-scale convolutional neural network for phenotyping high-content cellular images. Bioinformatics, 33(13):2010\u2013 2019.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Godinez%2C%20W.J.%20Hossain%2C%20I.%20Lazic%2C%20S.E.%20Davies%2C%20J.W.%20A%20multi-scale%20convolutional%20neural%20network%20for%20phenotyping%20high-content%20cellular%20images%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Godinez%2C%20W.J.%20Hossain%2C%20I.%20Lazic%2C%20S.E.%20Davies%2C%20J.W.%20A%20multi-scale%20convolutional%20neural%20network%20for%20phenotyping%20high-content%20cellular%20images%202017"
        },
        {
            "id": "He_et+al_2015_a",
            "entry": "He, K., Zhang, X., Ren, S., and Sun, J. (2015). Deep residual learning for image recognition. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202015"
        },
        {
            "id": "Huang_et+al_2017_a",
            "entry": "Huang, G., Liu, Z., van der Maaten, L., and Weinberger, K. Q. (2017). Densely connected convolutional networks. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2261\u20132269. IEEE.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20G.%20Liu%2C%20Z.%20van%20der%20Maaten%2C%20L.%20Weinberger%2C%20K.Q.%20Densely%20connected%20convolutional%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20G.%20Liu%2C%20Z.%20van%20der%20Maaten%2C%20L.%20Weinberger%2C%20K.Q.%20Densely%20connected%20convolutional%20networks%202017"
        },
        {
            "id": "Klambauer_et+al_2017_a",
            "entry": "Klambauer, G., Unterthiner, T., Mayr, A., and Hochreiter, S. (2017). Self-normalizing neural networks. In Guyon, I., Luxburg, U. V., Bengio, S., Wallach, H., Fergus, R., Vishwanathan, S., and Garnett, R., editors, Advances in Neural Information Processing Systems 30, pages 971\u2013980. Curran Associates, Inc.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Klambauer%2C%20G.%20Unterthiner%2C%20T.%20Mayr%2C%20A.%20Hochreiter%2C%20S.%20Self-normalizing%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Klambauer%2C%20G.%20Unterthiner%2C%20T.%20Mayr%2C%20A.%20Hochreiter%2C%20S.%20Self-normalizing%20neural%20networks%202017"
        },
        {
            "id": "Kraus_et+al_2016_a",
            "entry": "Kraus, O. Z., Ba, J. L., and Frey, B. J. (2016). Classifying and segmenting microscopy images with deep multiple instance learning. Bioinformatics, 32(12):i52\u2013i59.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kraus%2C%20O.Z.%20Ba%2C%20J.L.%20Frey%2C%20B.J.%20Classifying%20and%20segmenting%20microscopy%20images%20with%20deep%20multiple%20instance%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kraus%2C%20O.Z.%20Ba%2C%20J.L.%20Frey%2C%20B.J.%20Classifying%20and%20segmenting%20microscopy%20images%20with%20deep%20multiple%20instance%20learning%202016"
        },
        {
            "id": "Kraus_et+al_2017_a",
            "entry": "Kraus, O. Z., Grys, B. T., Ba, J., Chong, Y., Frey, B. J., Boone, C., and Andrews, B. J. (2017). Automated analysis of high-content microscopy data with deep learning. Molecular Systems Biology, 13(4):924.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kraus%2C%20O.Z.%20Grys%2C%20B.T.%20Ba%2C%20J.%20Chong%2C%20Y.%20Automated%20analysis%20of%20high-content%20microscopy%20data%20with%20deep%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kraus%2C%20O.Z.%20Grys%2C%20B.T.%20Ba%2C%20J.%20Chong%2C%20Y.%20Automated%20analysis%20of%20high-content%20microscopy%20data%20with%20deep%20learning%202017"
        },
        {
            "id": "Krizhevsky_et+al_2012_a",
            "entry": "Krizhevsky, A., Sutskever, I., and Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. In Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1, NIPS\u201912, pages 1097\u20131105, USA. Curran Associates Inc.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20A.%20Sutskever%2C%20I.%20Hinton%2C%20G.E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krizhevsky%2C%20A.%20Sutskever%2C%20I.%20Hinton%2C%20G.E.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks%202012"
        },
        {
            "id": "Liimatainen_et+al_2018_a",
            "entry": "Liimatainen, K., Valkonen, M., Latonen, L., and Ruusuvuori, P. (2018). Cell organelle classification with fully convolutional neural networks. Technical report.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Liimatainen%2C%20K.%20Valkonen%2C%20M.%20Latonen%2C%20L.%20Ruusuvuori%2C%20P.%20Cell%20organelle%20classification%20with%20fully%20convolutional%20neural%20networks.%20Technical%20report%202018"
        },
        {
            "id": "Long_et+al_2015_a",
            "entry": "Long, J., Shelhamer, E., and Darrell, T. (2015). Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3431\u20133440.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Long%2C%20J.%20Shelhamer%2C%20E.%20Darrell%2C%20T.%20Fully%20convolutional%20networks%20for%20semantic%20segmentation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Long%2C%20J.%20Shelhamer%2C%20E.%20Darrell%2C%20T.%20Fully%20convolutional%20networks%20for%20semantic%20segmentation%202015"
        },
        {
            "id": "Paernamaa_2017_a",
            "entry": "P\u00e4rnamaa, T. and Parts, L. (2017). Accurate Classification of Protein Subcellular Localization from High-Throughput Microscopy Images Using Deep Learning. G3: Genes, Genomes, Genetics, 7(5):1385\u20131392.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=P%C3%A4rnamaa%2C%20T.%20Parts%2C%20L.%20Accurate%20Classification%20of%20Protein%20Subcellular%20Localization%20from%20High-Throughput%20Microscopy%20Images%20Using%20Deep%20Learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=P%C3%A4rnamaa%2C%20T.%20Parts%2C%20L.%20Accurate%20Classification%20of%20Protein%20Subcellular%20Localization%20from%20High-Throughput%20Microscopy%20Images%20Using%20Deep%20Learning%202017"
        },
        {
            "id": "Pepperkok_2006_a",
            "entry": "Pepperkok, R. and Ellenberg, J. (2006). High-throughput fluorescence microscopy for systems biology. Nature Reviews Molecular Cell Biology, 7(9):690.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pepperkok%2C%20R.%20Ellenberg%2C%20J.%20High-throughput%20fluorescence%20microscopy%20for%20systems%20biology%202006",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pepperkok%2C%20R.%20Ellenberg%2C%20J.%20High-throughput%20fluorescence%20microscopy%20for%20systems%20biology%202006"
        },
        {
            "id": "Poostchi_et+al_2018_a",
            "entry": "Poostchi, M., Silamut, K., Maude, R. J., Jaeger, S., and Thoma, G. (2018). Image analysis and machine learning for detecting malaria. Translational Research, 194:36\u201355.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Poostchi%2C%20M.%20Silamut%2C%20K.%20Maude%2C%20R.J.%20Jaeger%2C%20S.%20Image%20analysis%20and%20machine%20learning%20for%20detecting%20malaria%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Poostchi%2C%20M.%20Silamut%2C%20K.%20Maude%2C%20R.J.%20Jaeger%2C%20S.%20Image%20analysis%20and%20machine%20learning%20for%20detecting%20malaria%202018"
        },
        {
            "id": "Stadler_et+al_2013_a",
            "entry": "Stadler, C., Rexhepaj, E., Singan, V. R., Murphy, R. F., Pepperkok, R., Uhl\u00e9n, M., Simpson, J. C., and Lundberg, E. (2013). Immunofluorescence and fluorescent-protein tagging show high correlation for protein localization in mammalian cells. Nature Methods, 10(4):315.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stadler%2C%20C.%20Rexhepaj%2C%20E.%20Singan%2C%20V.R.%20Murphy%2C%20R.F.%20Immunofluorescence%20and%20fluorescent-protein%20tagging%20show%20high%20correlation%20for%20protein%20localization%20in%20mammalian%20cells%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Stadler%2C%20C.%20Rexhepaj%2C%20E.%20Singan%2C%20V.R.%20Murphy%2C%20R.F.%20Immunofluorescence%20and%20fluorescent-protein%20tagging%20show%20high%20correlation%20for%20protein%20localization%20in%20mammalian%20cells%202013"
        },
        {
            "id": "Swamidoss_et+al_2013_a",
            "entry": "Swamidoss, I. N., K\u00e5rsn\u00e4s, A., Uhlmann, V., Ponnusamy, P., Kampf, C., Simonsson, M., W\u00e4hlby, C., and Strand, R. (2013). Automated classification of immunostaining patterns in breast tissue from the human protein atlas. Journal of Pathology Informatics, 4(Suppl).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Swamidoss%2C%20I.N.%20K%C3%A5rsn%C3%A4s%2C%20A.%20Uhlmann%2C%20V.%20Ponnusamy%2C%20P.%20Automated%20classification%20of%20immunostaining%20patterns%20in%20breast%20tissue%20from%20the%20human%20protein%20atlas%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Swamidoss%2C%20I.N.%20K%C3%A5rsn%C3%A4s%2C%20A.%20Uhlmann%2C%20V.%20Ponnusamy%2C%20P.%20Automated%20classification%20of%20immunostaining%20patterns%20in%20breast%20tissue%20from%20the%20human%20protein%20atlas%202013"
        },
        {
            "id": "Thul_et+al_2017_a",
            "entry": "Thul, P. J., \u00c5kesson, L., Wiking, M., Mahdessian, D., Geladaki, A., Ait Blal, H., Alm, T., Asplund, A., Bj\u00f6rk, L., Breckels, L. M., B\u00e4ckstr\u00f6m, A., Danielsson, F., Fagerberg, L., Fall, J., Gatto, L., Gnann, C., Hober, S., Hjelmare, M., Johansson, F., Lee, S., Lindskog, C., Mulder, J., Mulvey, C. M., Nilsson, P., Oksvold, P., Rockberg, J., Schutten, R., Schwenk, J. M., Sivertsson, \u00c5., Sj\u00f6stedt, E., Skogs, M., Stadler, C., Sullivan, D. P., Tegel, H., Winsnes, C., Zhang, C., Zwahlen, M., Mardinoglu, A., Pont\u00e9n, F., von Feilitzen, K., Lilley, K. S., Uhl\u00e9n, M., and Lundberg, E. (2017). A subcellular map of the human proteome. Science, 356(6340).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Thul%2C%20P.J.%20%C3%85kesson%2C%20L.%20Wiking%2C%20M.%20Mahdessian%2C%20D.%20A%20subcellular%20map%20of%20the%20human%20proteome%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Thul%2C%20P.J.%20%C3%85kesson%2C%20L.%20Wiking%2C%20M.%20Mahdessian%2C%20D.%20A%20subcellular%20map%20of%20the%20human%20proteome%202017"
        },
        {
            "id": "Uhlen_et+al_2010_a",
            "entry": "Uhlen, M., Oksvold, P., Fagerberg, L., Lundberg, E., Jonasson, K., Forsberg, M., Zwahlen, M., Kampf, C., Wester, K., Hober, S., et al. (2010). Towards a knowledge-based human protein atlas. Nature Biotechnology, 28(12):1248.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Uhlen%2C%20M.%20Oksvold%2C%20P.%20Fagerberg%2C%20L.%20Lundberg%2C%20E.%20Towards%20a%20knowledge-based%20human%20protein%20atlas%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Uhlen%2C%20M.%20Oksvold%2C%20P.%20Fagerberg%2C%20L.%20Lundberg%2C%20E.%20Towards%20a%20knowledge-based%20human%20protein%20atlas%202010"
        }
    ]
}

{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "CONDITIONAL NETWORK EMBEDDINGS",
        "author": "Bo Kang, Jefrey Lijffijt & Tijl De Bie Department of Electronics and Information Systems (ELIS), IDLab Ghent University Ghent, Belgium {firstname.lastname}@ugent.be",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=ryepUj0qtX"
        },
        "abstract": "Network Embeddings (NEs) map the nodes of a given network into d-dimensional Euclidean space Rd. Ideally, this mapping is such that \u2018similar\u2019 nodes are mapped onto nearby points, such that the NE can be used for purposes such as link prediction (if \u2018similar\u2019 means being \u2018more likely to be connected\u2019 or \u2018having similar neighborhoods\u2019) or classification (if \u2018similar\u2019 means \u2018being more likely to have the same label\u2019). In recent years various methods for NE have been introduced, all following a similar strategy: defining a notion of similarity between nodes, a distance measure in the embedding space, and a loss function that penalizes large distances for similar nodes and small distances for dissimilar nodes. A difficulty faced by existing methods is that certain networks are fundamentally hard to embed due to their structural properties: (approximate) multipartiteness, certain degree distributions, assortativity, etc. To overcome this, we introduce a conceptual innovation to the NE literature and propose to create Conditional Network Embeddings (CNEs); embeddings that maximally add information with respect to given structural properties (e.g. node degrees, block densities, etc.). We use a simple Bayesian approach to achieve this, and propose a block stochastic gradient descent algorithm for fitting it efficiently. We demonstrate that CNEs are superior for link prediction and multi-label classification when compared to state-ofthe-art methods, and this without adding significant mathematical or computational complexity. Finally, we illustrate the potential of CNE for network visualization."
    },
    "keywords": [
        {
            "term": "euclidean space",
            "url": "https://en.wikipedia.org/wiki/euclidean_space"
        },
        {
            "term": "loss function",
            "url": "https://en.wikipedia.org/wiki/loss_function"
        },
        {
            "term": "logistic regression",
            "url": "https://en.wikipedia.org/wiki/logistic_regression"
        },
        {
            "term": "Maximum A Posteriori",
            "url": "https://en.wikipedia.org/wiki/Maximum_A_Posteriori"
        },
        {
            "term": "degree distribution",
            "url": "https://en.wikipedia.org/wiki/degree_distribution"
        },
        {
            "term": "Maximum Likelihood",
            "url": "https://en.wikipedia.org/wiki/Maximum_Likelihood"
        }
    ],
    "abbreviations": {
        "NEs": "Network Embeddings",
        "CNEs": "Conditional Network Embeddings",
        "CNE": "Conditional Network Embedding",
        "ML": "Maximum Likelihood",
        "MAP": "Maximum A Posteriori",
        "AUC": "area under the ROC curve",
        "LR": "logistic regression",
        "ELIS": "Electronics and Information Systems",
        "PPI": "Protein-Protein Interactions"
    },
    "highlights": [
        "Network Embeddings (NEs) map nodes into d-dimensional Euclidean space Rd such that an ordinary distance measure allows for meaningful comparisons between nodes",
        "Even with a uniform prior, Conditional Network Embeddings performs better than all baselines on 5 of the 7 networks",
        "Conditional Network Embeddings outperforms all baselines on all networks",
        "Conditional Network Embeddings is capable of encoding the knowledge of the block structure of this multi-relational network as a prior, with each block corresponding to one node type",
        "We proposed the notion of Conditional Network Embeddings (CNEs), which seeks an embedding of a network that maximally adds information with respect to certain given prior knowledge about the network",
        "The empirical evaluation of this algorithm confirms our intuition that the combination of structural prior knowledge and a Euclidean embedding is extremely powerful. This is confirmed empirically for both the tasks of link prediction and multi-label classification, where Conditional Network Embeddings outperforms a range of state-of-the-art baselines on a wide range of networks"
    ],
    "key_statements": [
        "Network Embeddings (NEs) map nodes into d-dimensional Euclidean space Rd such that an ordinary distance measure allows for meaningful comparisons between nodes",
        "Conditional Network Embeddings: the idea To address these limitations of Network Embeddings, we propose a principled probabilistic approach\u2014 dubbed Conditional Network Embedding (CNE)\u2014that allows optimizing embeddings w.r.t. certain prior knowledge about the network, formalized as a prior distribution over the links",
        "Contributions and outline Our contributions can be summarized as follows: This paper introduces the concept of Network Embeddings conditional on certain prior knowledge about the network. Section 2 presents Conditional Network Embeddings (\u2018Conditional Network Embedding\u2019), which realizes this idea by using",
        "We first evaluate the network representation obtained by Conditional Network Embeddings on downstream tasks typically used for evaluating Network Embeddings methods: link prediction for links and multi-label classification for nodes",
        "For the Network Embeddings baselines, we perform link prediction using logistic regression based on the link representation derived from the node embedding Xtrain",
        "Even with a uniform prior, Conditional Network Embeddings performs better than all baselines on 5 of the 7 networks",
        "Conditional Network Embeddings outperforms all baselines on all networks",
        "For the multi-relational dataset studentdb, metapath2vec++, which is designed for heterogeneous data, outperforms other baselines but not Conditional Network Embeddings",
        "Conditional Network Embeddings is capable of encoding the knowledge of the block structure of this multi-relational network as a prior, with each block corresponding to one node type",
        "Over the seven datasets Conditional Network Embeddings is fastest in two cases, 12% slower than the fastest in one case, and takes approximately twice as long in the four other cases",
        "We proposed the notion of Conditional Network Embeddings (CNEs), which seeks an embedding of a network that maximally adds information with respect to certain given prior knowledge about the network",
        "This prior knowledge can encode information about the network that cannot be represented well by means of an embedding. We implemented this conceptually novel idea in a new algorithm based on a simple probabilistic model for the joint of the data and the network, which scales to state-of-the-art Network Embeddings approaches",
        "The empirical evaluation of this algorithm confirms our intuition that the combination of structural prior knowledge and a Euclidean embedding is extremely powerful. This is confirmed empirically for both the tasks of link prediction and multi-label classification, where Conditional Network Embeddings outperforms a range of state-of-the-art baselines on a wide range of networks",
        "In our future work we intend to investigate other models implementing the idea of conditional Network Embeddings, alternative and more scalable optimization strategies, as well as the use of other types of structural information as prior knowledge on the network",
        "We train Conditional Network Embeddings and baselines based on the full network",
        "We note that while the benefit of this link prediction approach to multi-label classification is clear for Conditional Network Embeddings, there is no consistent benefit to other methods. This shows that the superior performance of Conditional Network Embeddings-LP for multi-label classification is not thanks to the link prediction approach, but at least in part thanks to a more informative embedding when considered in combination with the prior.\n7 RUNTIME EXPERIMENT"
    ],
    "summary": [
        "Network Embeddings (NEs) map nodes into d-dimensional Euclidean space Rd such that an ordinary distance measure allows for meaningful comparisons between nodes.",
        "We first evaluate the network representation obtained by CNE on downstream tasks typically used for evaluating NE methods: link prediction for links and multi-label classification for nodes.",
        "To calculate AUC, we first compute the posterior P of the test links based on the embedding Xtrain learned on the training network.",
        "For the NE baselines, we perform link prediction using logistic regression based on the link representation derived from the node embedding Xtrain.",
        "CNE is capable of encoding the knowledge of the block structure of this multi-relational network as a prior, with each block corresponding to one node type.",
        "NE methods such as Laplacian Eigenmaps (<a class=\"ref-link\" id=\"cBelkin_2002_a\" href=\"#rBelkin_2002_a\">Belkin & Niyogi, 2002</a>), Graph factorization (<a class=\"ref-link\" id=\"cAhmed_et+al_2013_a\" href=\"#rAhmed_et+al_2013_a\">Ahmed et al, 2013</a>), GraRep (<a class=\"ref-link\" id=\"cCao_et+al_2015_a\" href=\"#rCao_et+al_2015_a\">Cao et al, 2015</a>), and HOPE (Ou et al, 2016) optimize mean-squared-error loss between Euclidean distance or inner product based proximity and link based similarity in the network.",
        "This is confirmed empirically for both the tasks of link prediction and multi-label classification, where CNE outperforms a range of state-of-the-art baselines on a wide range of networks.",
        "In our future work we intend to investigate other models implementing the idea of conditional NEs, alternative and more scalable optimization strategies, as well as the use of other types of structural information as prior knowledge on the network.",
        "LINE (Tang et al, 2015): Instead of random walks, this algorithm defines similarity between nodes based on first and second order adjacencies of the given network.",
        "Struc2vec (Ribeiro et al, 2017): The method first measures the structural information by computing pairwise similarity between nodes using a range of neighborhood sizes.",
        "ArXiv ASTRO-PH (<a class=\"ref-link\" id=\"cLeskovec_2015_a\" href=\"#rLeskovec_2015_a\">Leskovec & Krevl, 2015</a>): In this network nodes represent authors of papers submitted to arXiv. The links represents the collaborations: two authors are connected if they co-authored at least one paper.",
        "This is surprising, given the fact that CNE yields embeddings that, by design, do not reflect certain information about the nodes that may be useful in classifying.",
        "Note that this approach means that neighborhood-based link prediction methods can be used for multi-label classification.",
        "We note that while the benefit of this link prediction approach to multi-label classification is clear for CNE, there is no consistent benefit to other methods.",
        "This shows that the superior performance of CNE-LP for multi-label classification is not thanks to the link prediction approach, but at least in part thanks to a more informative embedding when considered in combination with the prior.",
        "G091017N, G0F9816N), and from the European Union\u2019s Horizon 2020 research and innovation programme and the FWO under the Marie Sklodowska-Curie Grant Agreement no. 665501"
    ],
    "headline": "We introduce a conceptual innovation to the Network Embeddings literature and propose to create Conditional Network Embeddings; embeddings that maximally add information with respect to given structural properties",
    "reference_links": [
        {
            "id": "Ahmed_et+al_2013_a",
            "entry": "Amr Ahmed, Nino Shervashidze, Shravan Narayanamurthy, Vanja Josifovski, and Alexander J Smola. Distributed large-scale natural graph factorization. In Proceedings of the 22nd international conference on World Wide Web, pp. 37\u201348. ACM, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ahmed%2C%20Amr%20Shervashidze%2C%20Nino%20Narayanamurthy%2C%20Shravan%20Josifovski%2C%20Vanja%20Distributed%20large-scale%20natural%20graph%20factorization%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ahmed%2C%20Amr%20Shervashidze%2C%20Nino%20Narayanamurthy%2C%20Shravan%20Josifovski%2C%20Vanja%20Distributed%20large-scale%20natural%20graph%20factorization%202013"
        },
        {
            "id": "Belkin_2002_a",
            "entry": "Mikhail Belkin and Partha Niyogi. Laplacian eigenmaps and spectral techniques for embedding and clustering. In Advances in neural information processing systems, pp. 585\u2013591, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Belkin%2C%20Mikhail%20Niyogi%2C%20Partha%20Laplacian%20eigenmaps%20and%20spectral%20techniques%20for%20embedding%20and%20clustering%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Belkin%2C%20Mikhail%20Niyogi%2C%20Partha%20Laplacian%20eigenmaps%20and%20spectral%20techniques%20for%20embedding%20and%20clustering%202002"
        },
        {
            "id": "Breitkreutz_et+al_2007_a",
            "entry": "Bobby-Joe Breitkreutz, Chris Stark, Teresa Reguly, Lorrie Boucher, Ashton Breitkreutz, Michael Livstone, Rose Oughtred, Daniel H Lackner, Jurg Bahler, Valerie Wood, et al. The biogrid interaction database: 2008 update. Nucleic acids research, 36:D637\u2013D640, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=BobbyJoe%20Breitkreutz%20Chris%20Stark%20Teresa%20Reguly%20Lorrie%20Boucher%20Ashton%20Breitkreutz%20Michael%20Livstone%20Rose%20Oughtred%20Daniel%20H%20Lackner%20Jurg%20Bahler%20Valerie%20Wood%20et%20al%20The%20biogrid%20interaction%20database%202008%20update%20Nucleic%20acids%20research%2036D637D640%202007"
        },
        {
            "id": "Cao_et+al_2015_a",
            "entry": "Shaosheng Cao, Wei Lu, and Qiongkai Xu. Grarep: Learning graph representations with global structural information. In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, pp. 891\u2013900. ACM, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cao%2C%20Shaosheng%20Lu%2C%20Wei%20Xu%2C%20Qiongkai%20Grarep%3A%20Learning%20graph%20representations%20with%20global%20structural%20information%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cao%2C%20Shaosheng%20Lu%2C%20Wei%20Xu%2C%20Qiongkai%20Grarep%3A%20Learning%20graph%20representations%20with%20global%20structural%20information%202015"
        },
        {
            "id": "Cho_et+al_2011_a",
            "entry": "Eunjoon Cho, Seth A Myers, and Jure Leskovec. Friendship and mobility: user movement in locationbased social networks. In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 1082\u20131090. ACM, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cho%2C%20Eunjoon%20Myers%2C%20Seth%20A.%20Leskovec%2C%20Jure%20Friendship%20and%20mobility%3A%20user%20movement%20in%20locationbased%20social%20networks%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cho%2C%20Eunjoon%20Myers%2C%20Seth%20A.%20Leskovec%2C%20Jure%20Friendship%20and%20mobility%3A%20user%20movement%20in%20locationbased%20social%20networks%202011"
        },
        {
            "id": "Dong_et+al_2017_a",
            "entry": "Yuxiao Dong, Nitesh V Chawla, and Ananthram Swami. metapath2vec: Scalable representation learning for heterogeneous networks. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 135\u2013144. ACM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dong%2C%20Yuxiao%20Chawla%2C%20Nitesh%20V.%20Swami%2C%20Ananthram%20metapath2vec%3A%20Scalable%20representation%20learning%20for%20heterogeneous%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dong%2C%20Yuxiao%20Chawla%2C%20Nitesh%20V.%20Swami%2C%20Ananthram%20metapath2vec%3A%20Scalable%20representation%20learning%20for%20heterogeneous%20networks%202017"
        },
        {
            "id": "Goethals_et+al_2010_a",
            "entry": "Bart Goethals, Wim Le Page, and Michael Mampaey. Mining interesting sets and rules in relational databases. In Proceedings of the 2010 ACM Symposium on Applied Computing, SAC \u201910, pp. 997\u20131001, New York, NY, USA, 2010. ACM. ISBN 978-1-60558-639-7. doi: 10.1145/1774088. 1774299. URL http://doi.acm.org/10.1145/1774088.1774299.",
            "crossref": "https://dx.doi.org/10.1145/1774088.1774299",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1145/1774088.1774299"
        },
        {
            "id": "Grover_2016_a",
            "entry": "Aditya Grover and Jure Leskovec. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 855\u2013864. ACM, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Grover%2C%20Aditya%20Leskovec%2C%20Jure%20node2vec%3A%20Scalable%20feature%20learning%20for%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Grover%2C%20Aditya%20Leskovec%2C%20Jure%20node2vec%3A%20Scalable%20feature%20learning%20for%20networks%202016"
        },
        {
            "id": "Hamilton_et+al_2017_a",
            "entry": "William L Hamilton, Rex Ying, and Jure Leskovec. Representation learning on graphs: Methods and applications. arXiv preprint arXiv:1709.05584, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1709.05584"
        },
        {
            "id": "Leone_et+al_1961_a",
            "entry": "FC Leone, LS Nelson, and RB Nottingham. The folded normal distribution. Technometrics, 3(4): 543\u2013550, 1961.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Leone%2C%20F.C.%20Nelson%2C%20L.S.%20Nottingham%2C%20R.B.%20The%20folded%20normal%20distribution%201961",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Leone%2C%20F.C.%20Nelson%2C%20L.S.%20Nottingham%2C%20R.B.%20The%20folded%20normal%20distribution%201961"
        },
        {
            "id": "Leskovec_2015_a",
            "entry": "Jure Leskovec and Andrej Krevl. SNAP Datasets: Stanford large network dataset collection, 2015. Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-SNE. Journal of machine learning research, 9(Nov):2579\u20132605, 2008. Matt Mahoney. Large text compression benchmark. URL: http://www.mattmahoney.net/text/text.",
            "url": "http://www.mattmahoney.net/text/text",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Leskovec%2C%20Jure%20Krevl%2C%20Andrej%20SNAP%20Datasets%3A%20Stanford%20large%20network%20dataset%20collection%202015"
        }
    ]
}

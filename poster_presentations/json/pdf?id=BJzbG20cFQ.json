{
    "filename": "pdf.pdf",
    "metadata": {
        "date": 2018,
        "title": "Towards Metamerism via Foveated Style Transfer",
        "author": "Arturo Deza, Aditya Jonnalagadda, Miguel P. Eckstein, 1 Dynamical Neuroscience, 2Psychological and Brain Sciences, 3Electric and Computer Engineering, 4 Institute for Collaborative Biotechnologies UC Santa Barbara, CA, USA deza@dyns.ucsb.edu,aditya_jonnalagada@ece.ucsb.edu,eckstein@psych.ucsb.edu",
        "identifiers": {
            "url": "https://openreview.net/pdf?id=BJzbG20cFQ"
        },
        "abstract": "The problem of visual metamerism is defined as finding a family of perceptually indistinguishable, yet physically different images. In this paper, we propose our NeuroFovea metamer model, a foveated generative model that is based on a mixture of peripheral representations and style transfer forward-pass algorithms. Our gradient-descent free model is parametrized by a foveated VGG19 encoder-decoder which allows us to encode images in high dimensional space and interpolate between the content and texture information with adaptive instance normalization anywhere in the visual field. Our contributions include: 1) A framework for computing metamers that resembles a noisy communication system via a foveated feed-forward encoder-decoder network \u2013 We observe that metamerism arises as a byproduct of noisy perturbations that partially lie in the perceptual null space; 2) A perceptual optimization scheme as a solution to the hyperparametric nature of our metamer model that requires tuning of the image-texture tradeoff coefficients everywhere in the visual field which are a consequence of internal noise; 3) An ABX psychophysical evaluation of our metamers where we also find that the rate of growth of the receptive fields in our model match V1 for reference metamers and V2 between synthesized samples. Our model also renders metamers at roughly a second, presenting a \u00d71000 speed-up compared to the previous work, which allows for tractable data-driven metamer experiments."
    },
    "keywords": [
        {
            "term": "locally linear embedding",
            "url": "https://en.wikipedia.org/wiki/locally_linear_embedding"
        },
        {
            "term": "light source",
            "url": "https://en.wikipedia.org/wiki/light_source"
        },
        {
            "term": "International Conference on Learning Representations",
            "url": "https://en.wikipedia.org/wiki/International_Conference_on_Learning_Representations"
        },
        {
            "term": "synthesis",
            "url": "https://en.wikipedia.org/wiki/synthesis"
        },
        {
            "term": "gradient descent",
            "url": "https://en.wikipedia.org/wiki/gradient_descent"
        },
        {
            "term": "metamerism",
            "url": "https://en.wikipedia.org/wiki/metamerism"
        },
        {
            "term": "visual field",
            "url": "https://en.wikipedia.org/wiki/visual_field"
        },
        {
            "term": "International Conference on Computer Vision",
            "url": "https://en.wikipedia.org/wiki/International_Conference_on_Computer_Vision"
        },
        {
            "term": "receptive field",
            "url": "https://en.wikipedia.org/wiki/receptive_field"
        },
        {
            "term": "peripheral vision",
            "url": "https://en.wikipedia.org/wiki/peripheral_vision"
        },
        {
            "term": "statistics",
            "url": "https://en.wikipedia.org/wiki/statistics"
        }
    ],
    "abbreviations": {
        "AdaIN": "Adaptive Instance Normalization",
        "NF": "NeuroFovea metamers",
        "R.F.": "receptive field",
        "PC": "Proportion Correct",
        "FCN": "fully convolutional network",
        "TTM": "Texture Tiling Model",
        "LLE": "locally linear embedding",
        "ICLR": "International Conference on Learning Representations",
        "CVPR": "Computer Vision and Pattern Recognition",
        "ICCV": "International Conference on Computer Vision"
    },
    "highlights": [
        "The history of metamers originally started through color matching theory, where two light sources were used to match a test light\u2019s wavelength, until both light sources are indistinguishable from each other producing what is called a color metamer",
        "Within the framework of metamerism where distortions lie on the perceptual null space as proposed initially in color matching theory, and in <a class=\"ref-link\" id=\"cFreeman_2011_a\" href=\"#rFreeman_2011_a\">Freeman & Simoncelli (2011</a>) for images, we can think of our model as a direct transform that is maximizing how much information to discard depending on the texture-like properties of the image and the size of the receptive fields",
        "The motivation of \u03b1 seems uncertain and perhaps un-necessary from the Occam\u2019s razor perspective of model simplicity. This raises the question: Why does the FS model not require any additional hyperparameters, requiring only a single scale (s) parameter? The answer lies in the nature of their model which is gradient descent based and where local texture statistics are matched for every pooling region in the visual field, while preserving global image structural information",
        "We computed the SSIM score for each FS and NeuroFovea metamers image paired with their reference image across each receptive field (R.F.) and averaged those that belonged to the same retinal eccentricity",
        "Analogous to <a class=\"ref-link\" id=\"cFreeman_2011_a\" href=\"#rFreeman_2011_a\">Freeman & Simoncelli (2011</a>), we find that the critical scaling factor is 0.51 when doing the Synth vs Synth experiment which match V2, a critical region in the brain that has been identified to respond to texture as in <a class=\"ref-link\" id=\"cLong_et+al_2018_a\" href=\"#rLong_et+al_2018_a\">Long et al (2018</a>); <a class=\"ref-link\" id=\"cZiemba_et+al_2016_a\" href=\"#rZiemba_et+al_2016_a\">Ziemba et al (2016</a>). This suggests that the parameters we use to capture and transfer texture statistics which are different from the correlations of a steerable pyramid decomposition as proposed in <a class=\"ref-link\" id=\"cPortilla_2000_a\" href=\"#rPortilla_2000_a\">Portilla & Simoncelli (2000</a>), might the match perceptual discrimination rates of the FS metamers. This does not imply that the models are perceptually equivalent, but it aligns with the results of <a class=\"ref-link\" id=\"cUstyuzhaninov_et+al_2017_a\" href=\"#rUstyuzhaninov_et+al_2017_a\">Ustyuzhaninov et al (2017</a>) which shows that even a basis of random filters can capture texture statistics, different flavors of metamer models can be created with different statistics",
        "The CNN synthesis model is gradient-descent based and is closest in flavor to the FS model, with the difference that their texture statistics are provided by a gramian matrix of filter activations of multiple layers of a VGGNet, rather than those used in <a class=\"ref-link\" id=\"cPortilla_2000_a\" href=\"#rPortilla_2000_a\">Portilla & Simoncelli (2000</a>)"
    ],
    "key_statements": [
        "The history of metamers originally started through color matching theory, where two light sources were used to match a test light\u2019s wavelength, until both light sources are indistinguishable from each other producing what is called a color metamer",
        "Motivated by <a class=\"ref-link\" id=\"cBalas_et+al_2009_a\" href=\"#rBalas_et+al_2009_a\">Balas et al (2009</a>)\u2019s work of local texture matching in the periphery as a mechanism that explains visual crowding, <a class=\"ref-link\" id=\"cFreeman_2011_a\" href=\"#rFreeman_2011_a\">Freeman & Simoncelli (2011</a>) were the first to create such point-of-fixation driven metamers through such local texture matching models that tile the entire visual field given log-polar pooling regions that simulate the V1 and V2 receptive field sizes, as well as having global image statistics that match the metamer with the original image",
        "Within the framework of metamerism where distortions lie on the perceptual null space as proposed initially in color matching theory, and in <a class=\"ref-link\" id=\"cFreeman_2011_a\" href=\"#rFreeman_2011_a\">Freeman & Simoncelli (2011</a>) for images, we can think of our model as a direct transform that is maximizing how much information to discard depending on the texture-like properties of the image and the size of the receptive fields",
        "The motivation of \u03b1 seems uncertain and perhaps un-necessary from the Occam\u2019s razor perspective of model simplicity. This raises the question: Why does the FS model not require any additional hyperparameters, requiring only a single scale (s) parameter? The answer lies in the nature of their model which is gradient descent based and where local texture statistics are matched for every pooling region in the visual field, while preserving global image structural information",
        "Results: A collection of 10 images were used in our experiments",
        "We computed the SSIM score for each FS and NeuroFovea metamers image paired with their reference image across each receptive field (R.F.) and averaged those that belonged to the same retinal eccentricity",
        "Computing an average should approximate the maximal distortion for the receptive field size on that eccentricity in the perceptual space for the human observer i.e. the metameric boundary",
        "Results: Absorbing gain factors \u03b20 and critical scales s0 per observer are shown in Figure 12, where the fits were made using a least squares curve fitting model and bootstrap sampling n = 10000 times to produce the 68% confidence intervals",
        "Analogous to <a class=\"ref-link\" id=\"cFreeman_2011_a\" href=\"#rFreeman_2011_a\">Freeman & Simoncelli (2011</a>), we find that the critical scaling factor is 0.51 when doing the Synth vs Synth experiment which match V2, a critical region in the brain that has been identified to respond to texture as in <a class=\"ref-link\" id=\"cLong_et+al_2018_a\" href=\"#rLong_et+al_2018_a\">Long et al (2018</a>); <a class=\"ref-link\" id=\"cZiemba_et+al_2016_a\" href=\"#rZiemba_et+al_2016_a\">Ziemba et al (2016</a>). This suggests that the parameters we use to capture and transfer texture statistics which are different from the correlations of a steerable pyramid decomposition as proposed in <a class=\"ref-link\" id=\"cPortilla_2000_a\" href=\"#rPortilla_2000_a\">Portilla & Simoncelli (2000</a>), might the match perceptual discrimination rates of the FS metamers",
        "Analogous to <a class=\"ref-link\" id=\"cFreeman_2011_a\" href=\"#rFreeman_2011_a\">Freeman & Simoncelli (2011</a>), we find that the critical scaling factor is 0.51 when doing the Synth vs Synth experiment which match V2, a critical region in the brain that has been identified to respond to texture as in <a class=\"ref-link\" id=\"cLong_et+al_2018_a\" href=\"#rLong_et+al_2018_a\">Long et al (2018</a>); <a class=\"ref-link\" id=\"cZiemba_et+al_2016_a\" href=\"#rZiemba_et+al_2016_a\">Ziemba et al (2016</a>). This suggests that the parameters we use to capture and transfer texture statistics which are different from the correlations of a steerable pyramid decomposition as proposed in <a class=\"ref-link\" id=\"cPortilla_2000_a\" href=\"#rPortilla_2000_a\">Portilla & Simoncelli (2000</a>), might the match perceptual discrimination rates of the FS metamers. This does not imply that the models are perceptually equivalent, but it aligns with the results of <a class=\"ref-link\" id=\"cUstyuzhaninov_et+al_2017_a\" href=\"#rUstyuzhaninov_et+al_2017_a\">Ustyuzhaninov et al (2017</a>) which shows that even a basis of random filters can capture texture statistics, different flavors of metamer models can be created with different statistics",
        "There has been a recent surge in interest with regards to developing and testing new metamer models: The SideEye model developed by <a class=\"ref-link\" id=\"cFridman_et+al_2017_a\" href=\"#rFridman_et+al_2017_a\">Fridman et al (2017</a>), uses a fully convolutional network (FCN) as in <a class=\"ref-link\" id=\"cLong_et+al_2015_a\" href=\"#rLong_et+al_2015_a\">Long et al (2015</a>) and learns to map an input image into a Texture Tiling Model (TTM) mongrel (<a class=\"ref-link\" id=\"cRosenholtz_et+al_2012_a\" href=\"#rRosenholtz_et+al_2012_a\">Rosenholtz et al (2012</a>))",
        "The CNN synthesis model is gradient-descent based and is closest in flavor to the FS model, with the difference that their texture statistics are provided by a gramian matrix of filter activations of multiple layers of a VGGNet, rather than those used in <a class=\"ref-link\" id=\"cPortilla_2000_a\" href=\"#rPortilla_2000_a\">Portilla & Simoncelli (2000</a>)"
    ],
    "summary": [
        "The history of metamers originally started through color matching theory, where two light sources were used to match a test light\u2019s wavelength, until both light sources are indistinguishable from each other producing what is called a color metamer.",
        "We know that the original model of <a class=\"ref-link\" id=\"cFreeman_2011_a\" href=\"#rFreeman_2011_a\"><a class=\"ref-link\" id=\"cFreeman_2011_a\" href=\"#rFreeman_2011_a\"><a class=\"ref-link\" id=\"cFreeman_2011_a\" href=\"#rFreeman_2011_a\">Freeman & Simoncelli (2011</a></a></a>) consists of a local texture matching procedure for multiple pooling regions in the visual field as well as global image content matching.",
        "Within the framework of metamerism where distortions lie on the perceptual null space as proposed initially in color matching theory, and in <a class=\"ref-link\" id=\"cFreeman_2011_a\" href=\"#rFreeman_2011_a\"><a class=\"ref-link\" id=\"cFreeman_2011_a\" href=\"#rFreeman_2011_a\"><a class=\"ref-link\" id=\"cFreeman_2011_a\" href=\"#rFreeman_2011_a\">Freeman & Simoncelli (2011</a></a></a>) for images, we can think of our model as a direct transform that is maximizing how much information to discard depending on the texture-like properties of the image and the size of the receptive fields.",
        "The answer lies in the nature of their model which is gradient descent based and where local texture statistics are matched for every pooling region in the visual field, while preserving global image structural information.",
        "Estimation of \u03b3: To numerically estimate the amount of \u03b1-noise distortion for each receptive field in our metamer model we need to find a way to simulate the perceptual loss made by a human observer when trying to discriminate between metamers and original images.",
        "Computing an average should approximate the maximal distortion for the receptive field size on that eccentricity in the perceptual space for the human observer i.e. the metameric boundary.",
        "4.2 Experiment 2: Psychophysical Evaluation of Metamerism with human observers Given that we have estimated the value of \u03b1 anywhere in the visual field via the \u03b3 function, we can render our metamers as a function of the single scaling parameter (s), as the receptive field size z is a function of s as shown in Figure 10.",
        "This suggests that the parameters we use to capture and transfer texture statistics which are different from the correlations of a steerable pyramid decomposition as proposed in <a class=\"ref-link\" id=\"cPortilla_2000_a\" href=\"#rPortilla_2000_a\">Portilla & Simoncelli (2000</a>), might the match perceptual discrimination rates of the FS metamers.",
        "Foveated representations when perturbed with texture-like noise seem to finely tile the perceptual space, and might act as a type of biological regularizer for human observers who are consistently making eye-movements when processing visual information.",
        "Via a psychophysical experiment we empirically find that the critical scaling factor matches the rate of growth of the receptive fields in V2 (s = 0.5) as in <a class=\"ref-link\" id=\"cFreeman_2011_a\" href=\"#rFreeman_2011_a\"><a class=\"ref-link\" id=\"cFreeman_2011_a\" href=\"#rFreeman_2011_a\"><a class=\"ref-link\" id=\"cFreeman_2011_a\" href=\"#rFreeman_2011_a\">Freeman & Simoncelli (2011</a></a></a>) when performing visual discrimination between synthesized metamers, and match V1 (0.25) for reference metamers similar to <a class=\"ref-link\" id=\"cWallis_et+al_2018_a\" href=\"#rWallis_et+al_2018_a\">Wallis et al (2018</a>)."
    ],
    "headline": "We propose our NeuroFovea metamer model, a foveated generative model that is based on a mixture of peripheral representations and style transfer forward-pass algorithms",
    "reference_links": [
        {
            "id": "Akbas_2017_a",
            "entry": "Emre Akbas and Miguel P Eckstein. Object detection through search with a foveated visual system. PLoS computational biology, 13(10):e1005743, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Akbas%2C%20Emre%20Eckstein%2C%20Miguel%20P.%20Object%20detection%20through%20search%20with%20a%20foveated%20visual%20system%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Akbas%2C%20Emre%20Eckstein%2C%20Miguel%20P.%20Object%20detection%20through%20search%20with%20a%20foveated%20visual%20system%202017"
        },
        {
            "id": "Balas_et+al_2009_a",
            "entry": "Benjamin Balas, Lisa Nakano, and Ruth Rosenholtz. A summary-statistic representation in peripheral vision explains visual crowding. Journal of vision, 9(12):13\u201313, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Balas%2C%20Benjamin%20Nakano%2C%20Lisa%20Rosenholtz%2C%20Ruth%20A%20summary-statistic%20representation%20in%20peripheral%20vision%20explains%20visual%20crowding%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Balas%2C%20Benjamin%20Nakano%2C%20Lisa%20Rosenholtz%2C%20Ruth%20A%20summary-statistic%20representation%20in%20peripheral%20vision%20explains%20visual%20crowding%202009"
        },
        {
            "id": "Ball_et+al_2017_a",
            "entry": "Johannes Ball\u00e9, Valero Laparra, and Eero P Simoncelli. End-to-end optimized image compression. International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ball%C3%A9%2C%20Johannes%20Laparra%2C%20Valero%20Simoncelli%2C%20Eero%20P.%20End-to-end%20optimized%20image%20compression%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ball%C3%A9%2C%20Johannes%20Laparra%2C%20Valero%20Simoncelli%2C%20Eero%20P.%20End-to-end%20optimized%20image%20compression%202017"
        },
        {
            "id": "Bell_1995_a",
            "entry": "Anthony J Bell and Terrence J Sejnowski. An information-maximization approach to blind separation and blind deconvolution. Neural computation, 7(6):1129\u20131159, 1995.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bell%2C%20Anthony%20J.%20Sejnowski%2C%20Terrence%20J.%20An%20information-maximization%20approach%20to%20blind%20separation%20and%20blind%20deconvolution%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bell%2C%20Anthony%20J.%20Sejnowski%2C%20Terrence%20J.%20An%20information-maximization%20approach%20to%20blind%20separation%20and%20blind%20deconvolution%201995"
        },
        {
            "id": "Berardino_et+al_2017_a",
            "entry": "Alexander Berardino, Valero Laparra, Johannes Ball\u00e9, and Eero Simoncelli. Eigen-distortions of hierarchical representations. In Advances in neural information processing systems, pp. 3530\u20133539, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Berardino%2C%20Alexander%20Laparra%2C%20Valero%20Ball%C3%A9%2C%20Johannes%20Simoncelli%2C%20Eero%20Eigen-distortions%20of%20hierarchical%20representations%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Berardino%2C%20Alexander%20Laparra%2C%20Valero%20Ball%C3%A9%2C%20Johannes%20Simoncelli%2C%20Eero%20Eigen-distortions%20of%20hierarchical%20representations%202017"
        },
        {
            "id": "Daly_1992_a",
            "entry": "Scott J Daly. Visible differences predictor: an algorithm for the assessment of image fidelity. In SPIE/IS&T 1992 Symposium on Electronic Imaging: Science and Technology, pp. 2\u201315. International Society for Optics and Photonics, 1992.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Daly%2C%20Scott%20J.%20Visible%20differences%20predictor%3A%20an%20algorithm%20for%20the%20assessment%20of%20image%20fidelity%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Daly%2C%20Scott%20J.%20Visible%20differences%20predictor%3A%20an%20algorithm%20for%20the%20assessment%20of%20image%20fidelity%201992"
        },
        {
            "id": "Deza_2016_a",
            "entry": "Arturo Deza and Miguel Eckstein. Can peripheral representations improve clutter metrics on complex scenes? In Advances In Neural Information Processing Systems, pp. 2847\u20132855, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Deza%2C%20Arturo%20Eckstein%2C%20Miguel%20Can%20peripheral%20representations%20improve%20clutter%20metrics%20on%20complex%20scenes%3F%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Deza%2C%20Arturo%20Eckstein%2C%20Miguel%20Can%20peripheral%20representations%20improve%20clutter%20metrics%20on%20complex%20scenes%3F%202016"
        },
        {
            "id": "Freeman_2011_a",
            "entry": "Jeremy Freeman and Eero P Simoncelli. Metamers of the ventral stream. Nature neuroscience, 14(9):1195\u20131201, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Freeman%2C%20Jeremy%20Simoncelli%2C%20Eero%20P.%20Metamers%20of%20the%20ventral%20stream%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Freeman%2C%20Jeremy%20Simoncelli%2C%20Eero%20P.%20Metamers%20of%20the%20ventral%20stream%202011"
        },
        {
            "id": "Fridman_et+al_2017_a",
            "entry": "Lex Fridman, Benedikt Jenik, Shaiyan Keshvari, Bryan Reimer, Christoph Zetzsche, and Ruth Rosenholtz. Sideeye: A generative neural network based simulator of human peripheral vision. arXiv preprint arXiv:1706.04568, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.04568"
        },
        {
            "id": "Gatys_et+al_2017_a",
            "entry": "Leon A Gatys, Alexander S Ecker, Matthias Bethge, Aaron Hertzmann, and Eli Shechtman. Controlling perceptual factors in neural style transfer. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gatys%2C%20Leon%20A.%20Ecker%2C%20Alexander%20S.%20Bethge%2C%20Matthias%20Hertzmann%2C%20Aaron%20Controlling%20perceptual%20factors%20in%20neural%20style%20transfer%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gatys%2C%20Leon%20A.%20Ecker%2C%20Alexander%20S.%20Bethge%2C%20Matthias%20Hertzmann%2C%20Aaron%20Controlling%20perceptual%20factors%20in%20neural%20style%20transfer%202017"
        },
        {
            "id": "Goodfellow_et+al_2015_a",
            "entry": "Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. International Conference on Learning Representations (ICLR), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20J.%20Shlens%2C%20Jonathon%20Szegedy%2C%20Christian%20Explaining%20and%20harnessing%20adversarial%20examples%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20J.%20Shlens%2C%20Jonathon%20Szegedy%2C%20Christian%20Explaining%20and%20harnessing%20adversarial%20examples%202015"
        },
        {
            "id": "Green_1966_a",
            "entry": "DM Green and JA Swets. Signal detection theory and psychophysics. 1966. New York, 888:889, 1966.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=DM%20Green%20and%20JA%20Swets%20Signal%20detection%20theory%20and%20psychophysics%201966%20New%20York%20888889%201966"
        },
        {
            "id": "H_2018_a",
            "entry": "Olivier J H\u00e9naff. Testing a mechanism for temporal prediction in perceptual, neural, and machine representations. PhD thesis, Center for Neural Science, New York University, New York, NY, Sept 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=H%C3%A9naff%2C%20Olivier%20J.%20Testing%20a%20mechanism%20for%20temporal%20prediction%20in%20perceptual%2C%20neural%2C%20and%20machine%20representations%202018-09"
        },
        {
            "id": "H_2016_a",
            "entry": "Olivier J H\u00e9naff and Eero P Simoncelli. Geodesics of learned representations. International Conference on Learning Representations (ICLR), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=H%C3%A9naff%2C%20Olivier%20J.%20Simoncelli%2C%20Eero%20P.%20Geodesics%20of%20learned%20representations%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=H%C3%A9naff%2C%20Olivier%20J.%20Simoncelli%2C%20Eero%20P.%20Geodesics%20of%20learned%20representations%202016"
        },
        {
            "id": "Huang_2017_a",
            "entry": "Xun Huang and Serge Belongie. Arbitrary style transfer in real-time with adaptive instance normalization. International Conference on Computer Vision (ICCV), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Huang%2C%20Xun%20Belongie%2C%20Serge%20Arbitrary%20style%20transfer%20in%20real-time%20with%20adaptive%20instance%20normalization%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Huang%2C%20Xun%20Belongie%2C%20Serge%20Arbitrary%20style%20transfer%20in%20real-time%20with%20adaptive%20instance%20normalization%202017"
        },
        {
            "id": "Isola_et+al_2017_a",
            "entry": "Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with conditional adversarial networks. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Isola%2C%20Phillip%20Zhu%2C%20Jun-Yan%20Zhou%2C%20Tinghui%20and%20Alexei%20A%20Efros.%20Image-to-image%20translation%20with%20conditional%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Isola%2C%20Phillip%20Zhu%2C%20Jun-Yan%20Zhou%2C%20Tinghui%20and%20Alexei%20A%20Efros.%20Image-to-image%20translation%20with%20conditional%20adversarial%20networks%202017"
        },
        {
            "id": "Keshvari_2016_a",
            "entry": "Shaiyan Keshvari and Ruth Rosenholtz. Pooling of continuous features provides a unifying account of crowding. Journal of Vision, 16(39), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Keshvari%2C%20Shaiyan%20Rosenholtz%2C%20Ruth%20Pooling%20of%20continuous%20features%20provides%20a%20unifying%20account%20of%20crowding%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Keshvari%2C%20Shaiyan%20Rosenholtz%2C%20Ruth%20Pooling%20of%20continuous%20features%20provides%20a%20unifying%20account%20of%20crowding%202016"
        },
        {
            "id": "Laparra_et+al_2017_a",
            "entry": "V Laparra, A Berardino, J Ball\u00e9, and EP Simoncelli. Perceptually optimized image rendering. Journal of the Optical Society of America. A, Optics, image science, and vision, 34(9):1511, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Laparra%2C%20V.%20Berardino%2C%20A.%20Ball%C3%A9%2C%20J.%20Simoncelli%2C%20E.P.%20Perceptually%20optimized%20image%20rendering%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Laparra%2C%20V.%20Berardino%2C%20A.%20Ball%C3%A9%2C%20J.%20Simoncelli%2C%20E.P.%20Perceptually%20optimized%20image%20rendering%202017"
        },
        {
            "id": "Long_et+al_2018_a",
            "entry": "Bria Long, Chen-Ping Yu, and Talia Konkle. Mid-level visual features underlie the high-level categorical organization of the ventral stream. Proceedings of the National Academy of Sciences, 2018. ISSN 00278424. doi: 10.1073/pnas.1719616115. URL http://www.pnas.org/content/early/2018/08/30/1719616115.",
            "crossref": "https://dx.doi.org/10.1073/pnas.1719616115",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1073/pnas.1719616115"
        },
        {
            "id": "Long_et+al_2015_a",
            "entry": "Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431\u20133440, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Long%2C%20Jonathan%20Shelhamer%2C%20Evan%20Darrell%2C%20Trevor%20Fully%20convolutional%20networks%20for%20semantic%20segmentation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Long%2C%20Jonathan%20Shelhamer%2C%20Evan%20Darrell%2C%20Trevor%20Fully%20convolutional%20networks%20for%20semantic%20segmentation%202015"
        },
        {
            "id": "Lubin_1997_a",
            "entry": "Jeffrey Lubin. A human vision system model for objective picture quality measurements. In Broadcasting Convention, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lubin%2C%20Jeffrey%20A%20human%20vision%20system%20model%20for%20objective%20picture%20quality%20measurements%201997",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lubin%2C%20Jeffrey%20A%20human%20vision%20system%20model%20for%20objective%20picture%20quality%20measurements%201997"
        },
        {
            "id": "International_1997_a",
            "entry": "International, pp. 498\u2013503. IET, 1997.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=International%20pp%20498503%20IET%201997"
        },
        {
            "id": "Portilla_2000_a",
            "entry": "Javier Portilla and Eero P Simoncelli. A parametric texture model based on joint statistics of complex wavelet coefficients. International Journal of Computer Vision, 40(1):49\u201370, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Portilla%2C%20Javier%20Simoncelli%2C%20Eero%20P.%20A%20parametric%20texture%20model%20based%20on%20joint%20statistics%20of%20complex%20wavelet%20coefficients%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Portilla%2C%20Javier%20Simoncelli%2C%20Eero%20P.%20A%20parametric%20texture%20model%20based%20on%20joint%20statistics%20of%20complex%20wavelet%20coefficients%202000"
        },
        {
            "id": "Rosenholtz_et+al_2012_a",
            "entry": "Ruth Rosenholtz, Jie Huang, Alvin Raj, Benjamin J Balas, and Livia Ilie. A summary statistic representation in peripheral vision explains visual search. Journal of vision, 12(4):14\u201314, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rosenholtz%2C%20Ruth%20Huang%2C%20Jie%20Raj%2C%20Alvin%20Balas%2C%20Benjamin%20J.%20A%20summary%20statistic%20representation%20in%20peripheral%20vision%20explains%20visual%20search%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rosenholtz%2C%20Ruth%20Huang%2C%20Jie%20Raj%2C%20Alvin%20Balas%2C%20Benjamin%20J.%20A%20summary%20statistic%20representation%20in%20peripheral%20vision%20explains%20visual%20search%202012"
        },
        {
            "id": "Roweis_2000_a",
            "entry": "Sam T Roweis and Lawrence K Saul. Nonlinear dimensionality reduction by locally linear embedding. science, 290(5500):2323\u20132326, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Roweis%2C%20Sam%20T.%20Saul%2C%20Lawrence%20K.%20Nonlinear%20dimensionality%20reduction%20by%20locally%20linear%20embedding%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Roweis%2C%20Sam%20T.%20Saul%2C%20Lawrence%20K.%20Nonlinear%20dimensionality%20reduction%20by%20locally%20linear%20embedding%202000"
        },
        {
            "id": "Simonyan_2015_a",
            "entry": "Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. International Conference on Learning Representations (ICLR), 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Simonyan%2C%20Karen%20Zisserman%2C%20Andrew%20Very%20deep%20convolutional%20networks%20for%20large-scale%20image%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Simonyan%2C%20Karen%20Zisserman%2C%20Andrew%20Very%20deep%20convolutional%20networks%20for%20large-scale%20image%20recognition%202015"
        },
        {
            "id": "Tabacof_2016_a",
            "entry": "Pedro Tabacof and Eduardo Valle. Exploring the space of adversarial images. In 2016 International Joint Conference on Neural Networks (IJCNN), pp. 426\u2013433. IEEE, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tabacof%2C%20Pedro%20Valle%2C%20Eduardo%20Exploring%20the%20space%20of%20adversarial%20images%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tabacof%2C%20Pedro%20Valle%2C%20Eduardo%20Exploring%20the%20space%20of%20adversarial%20images%202016"
        },
        {
            "id": "Ulyanov_et+al_2016_a",
            "entry": "Dmitry Ulyanov, Vadim Lebedev, Victor Lempitsky, et al. Texture networks: Feed-forward synthesis of textures and stylized images. In Proceedings of The 33rd International Conference on Machine Learning, pp. 1349\u20131357, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ulyanov%2C%20Dmitry%20Lebedev%2C%20Vadim%20Lempitsky%2C%20Victor%20Texture%20networks%3A%20Feed-forward%20synthesis%20of%20textures%20and%20stylized%20images%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ulyanov%2C%20Dmitry%20Lebedev%2C%20Vadim%20Lempitsky%2C%20Victor%20Texture%20networks%3A%20Feed-forward%20synthesis%20of%20textures%20and%20stylized%20images%202016"
        },
        {
            "id": "Ustyuzhaninov_et+al_2017_a",
            "entry": "Ivan Ustyuzhaninov, Wieland Brendel, Leon A Gatys, and Matthias Bethge. What does it take to generate natural textures? International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ustyuzhaninov%2C%20Ivan%20Brendel%2C%20Wieland%20Gatys%2C%20Leon%20A.%20Bethge%2C%20Matthias%20What%20does%20it%20take%20to%20generate%20natural%20textures%3F%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ustyuzhaninov%2C%20Ivan%20Brendel%2C%20Wieland%20Gatys%2C%20Leon%20A.%20Bethge%2C%20Matthias%20What%20does%20it%20take%20to%20generate%20natural%20textures%3F%202017"
        },
        {
            "id": "Wallis_et+al_2018_a",
            "entry": "Thomas S. A. Wallis, Christina M Funke, Alexander S Ecker, Leon A. Gatys, Felix A. Wichmann, and Matthias Bethge. Image content is more important than bouma\u2019s law for scene metamers. bioRxiv, 2018. doi: 10.1101/378521. URL https://www.biorxiv.org/content/early/2018/07/30/378521.",
            "crossref": "https://dx.doi.org/10.1101/378521"
        },
        {
            "id": "Wallis_et+al_2016_a",
            "entry": "Thomas SA Wallis, Matthias Bethge, and Felix A Wichmann. Testing models of peripheral encoding using metamerism in an oddity paradigm. Journal of vision, 16(2):4\u20134, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wallis%2C%20Thomas%20S.A.%20Bethge%2C%20Matthias%20Wichmann%2C%20Felix%20A.%20Testing%20models%20of%20peripheral%20encoding%20using%20metamerism%20in%20an%20oddity%20paradigm%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wallis%2C%20Thomas%20S.A.%20Bethge%2C%20Matthias%20Wichmann%2C%20Felix%20A.%20Testing%20models%20of%20peripheral%20encoding%20using%20metamerism%20in%20an%20oddity%20paradigm%202016"
        },
        {
            "id": "Wang_2011_a",
            "entry": "Z Wang and Q Li. Information content weighting for perceptual image quality assessment. IEEE transactions on image processing: a publication of the IEEE Signal Processing Society, 20(5):1185\u20131198, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Z.%20Li%2C%20Q.%20Information%20content%20weighting%20for%20perceptual%20image%20quality%20assessment.%20IEEE%20transactions%20on%20image%20processing%3A%20a%20publication%20of%20the%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Z.%20Li%2C%20Q.%20Information%20content%20weighting%20for%20perceptual%20image%20quality%20assessment.%20IEEE%20transactions%20on%20image%20processing%3A%20a%20publication%20of%20the%202011"
        },
        {
            "id": "Wang_et+al_2003_a",
            "entry": "Zhou Wang, Eero P Simoncelli, and Alan C Bovik. Multiscale structural similarity for image quality assessment. In The Thrity-Seventh Asilomar Conference on Signals, Systems & Computers, 2003, volume 2, pp. 1398\u20131402.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Zhou%20Simoncelli%2C%20Eero%20P.%20Bovik%2C%20Alan%20C.%20Multiscale%20structural%20similarity%20for%20image%20quality%20assessment%202003",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Zhou%20Simoncelli%2C%20Eero%20P.%20Bovik%2C%20Alan%20C.%20Multiscale%20structural%20similarity%20for%20image%20quality%20assessment%202003"
        },
        {
            "id": "Wichmann_2001_a",
            "entry": "Felix A Wichmann and N Jeremy Hill. The psychometric function: I. fitting, sampling, and goodness of fit. Perception & psychophysics, 63(8):1293\u20131313, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wichmann%2C%20Felix%20A.%20Hill%2C%20N.Jeremy%20The%20psychometric%20function%3A%20I.%20fitting%2C%20sampling%2C%20and%20goodness%20of%20fit%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wichmann%2C%20Felix%20A.%20Hill%2C%20N.Jeremy%20The%20psychometric%20function%3A%20I.%20fitting%2C%20sampling%2C%20and%20goodness%20of%20fit%202001"
        },
        {
            "id": "Ziemba_et+al_2016_a",
            "entry": "Corey M Ziemba, Jeremy Freeman, J Anthony Movshon, and Eero P Simoncelli. Selectivity and tolerance for visual texture in macaque v2. Proceedings of the National Academy of Sciences, 113(22):E3140\u2013E3149, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ziemba%2C%20Corey%20M.%20Jeremy%20Freeman%2C%20J.Anthony%20Movshon%20Simoncelli%2C%20Eero%20P.%20Selectivity%20and%20tolerance%20for%20visual%20texture%20in%20macaque%20v2%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ziemba%2C%20Corey%20M.%20Jeremy%20Freeman%2C%20J.Anthony%20Movshon%20Simoncelli%2C%20Eero%20P.%20Selectivity%20and%20tolerance%20for%20visual%20texture%20in%20macaque%20v2%202016"
        }
    ]
}

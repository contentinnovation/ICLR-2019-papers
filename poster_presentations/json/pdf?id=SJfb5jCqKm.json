{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "BIAS-REDUCED UNCERTAINTY ESTIMATION FOR DEEP NEURAL CLASSIFIERS",
        "author": "Yonatan Geifman Computer Science Department Technion \u2013 Israel Institute of Technology yonatan.g@cs.technion.ac.il",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=SJfb5jCqKm"
        },
        "abstract": "We consider the problem of uncertainty estimation in the context of (non-Bayesian) deep neural classification. In this context, all known methods are based on extracting uncertainty signals from a trained network optimized to solve the classification problem at hand. We demonstrate that such techniques tend to introduce biased estimates for instances whose predictions are supposed to be highly confident. We argue that this deficiency is an artifact of the dynamics of training with SGD-like optimizers, and it has some properties similar to overfitting. Based on this observation, we develop an uncertainty estimation algorithm that selectively estimates the uncertainty of highly confident points, using earlier snapshots of the trained model, before their estimates are jittered (and way before they are ready for actual classification). We present extensive experiments indicating that the proposed algorithm provides uncertainty estimates that are consistently better than all known methods."
    },
    "keywords": [
        {
            "term": "logistic regression",
            "url": "https://en.wikipedia.org/wiki/logistic_regression"
        },
        {
            "term": "image classification",
            "url": "https://en.wikipedia.org/wiki/image_classification"
        },
        {
            "term": "deep learning",
            "url": "https://en.wikipedia.org/wiki/deep_learning"
        },
        {
            "term": "deep neural network",
            "url": "https://en.wikipedia.org/wiki/deep_neural_network"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "stochastic gradient descent",
            "url": "https://en.wikipedia.org/wiki/stochastic_gradient_descent"
        }
    ],
    "abbreviations": {
        "SGD": "stochastic gradient descent",
        "DNNs": "deep neural networks",
        "AURC": "area under the (empirical) RC-curve",
        "PES": "Pointwise Early Stopping",
        "AES": "approximated version",
        "NLL": "negative log-likelihood",
        "SR": "softmax response method"
    },
    "highlights": [
        "The deployment of deep learning models in applications with demanding decision-making components such as autonomous driving or medical diagnosis hinges on our ability to monitor and control their statistical uncertainties",
        "The most common signals used for uncertainty estimation are the raw softmax response (<a class=\"ref-link\" id=\"cCordella_et+al_1995_a\" href=\"#rCordella_et+al_1995_a\">Cordella et al, 1995</a>), some functions of softmax values, signals emerging from embedding layers (<a class=\"ref-link\" id=\"cMandelbaum_2017_a\" href=\"#rMandelbaum_2017_a\">Mandelbaum & Weinshall, 2017</a>), and the MC-dropout method (<a class=\"ref-link\" id=\"cGal_2016_a\" href=\"#rGal_2016_a\">Gal & Ghahramani, 2016</a>) that proxies a Bayesian inference using dropout sampling applied at test time",
        "We present results of our approximated version algorithm applied over the four known confidence scores: softmax response, NN-distance (<a class=\"ref-link\" id=\"cMandelbaum_2017_a\" href=\"#rMandelbaum_2017_a\">Mandelbaum & Weinshall, 2017</a>), MC-dropout (<a class=\"ref-link\" id=\"cGal_2016_a\" href=\"#rGal_2016_a\">Gal & Ghahramani, 2016</a>) ans Ensemble (<a class=\"ref-link\" id=\"cLakshminarayanan_et+al_2017_a\" href=\"#rLakshminarayanan_et+al_2017_a\">Lakshminarayanan et al, 2017</a>)",
        "We evaluate the performance of these methods and our approximated version algorithm that uses them as its core \u03ba",
        "We presented novel uncertainty estimation algorithms, which are motivated by an observation regarding the training process of deep neural networks using stochastic gradient descent",
        "The Pointwise Early Stopping algorithm we presented requires an additional labeled set and expensive computational resources for training"
    ],
    "key_statements": [
        "The deployment of deep learning models in applications with demanding decision-making components such as autonomous driving or medical diagnosis hinges on our ability to monitor and control their statistical uncertainties",
        "Practically feasible uncertainty estimation methods for deep learning are based on signals emerging from standard networks that were trained in a standard manner",
        "The most common signals used for uncertainty estimation are the raw softmax response (<a class=\"ref-link\" id=\"cCordella_et+al_1995_a\" href=\"#rCordella_et+al_1995_a\">Cordella et al, 1995</a>), some functions of softmax values, signals emerging from embedding layers (<a class=\"ref-link\" id=\"cMandelbaum_2017_a\" href=\"#rMandelbaum_2017_a\">Mandelbaum & Weinshall, 2017</a>), and the MC-dropout method (<a class=\"ref-link\" id=\"cGal_2016_a\" href=\"#rGal_2016_a\">Gal & Ghahramani, 2016</a>) that proxies a Bayesian inference using dropout sampling applied at test time",
        "A recent NIPS paper provides documentation that an ensemble of softmax response values of several networks performs better than the other approaches (<a class=\"ref-link\" id=\"cLakshminarayanan_et+al_2017_a\" href=\"#rLakshminarayanan_et+al_2017_a\">Lakshminarayanan et al, 2017</a>)",
        "We propose two methods that can boost known confidence scoring functions for deep neural networks (DNNs)",
        "We propose to measure the performance of a \u03ba function as the area under the risk-coverage curve (AURC) of a selective classifier induced by \u03ba",
        "Since the area under the RC-curve of all RC-curves for f induced by any confidence scoring function will be larger than the area under the RC-curve of \u03ba\u2217, we normalize by area under the RC-curve(\u03ba\u2217) to obtain a unitless performance measure",
        "Their ensemble consists of several trained deep neural networks models, and confidence estimates were obtained by averaging softmax responses of ensemble members",
        "For each layer we find the best performing \u03ba function based on models from F",
        "We present results of our approximated version algorithm applied over the four known confidence scores: softmax response, NN-distance (<a class=\"ref-link\" id=\"cMandelbaum_2017_a\" href=\"#rMandelbaum_2017_a\">Mandelbaum & Weinshall, 2017</a>), MC-dropout (<a class=\"ref-link\" id=\"cGal_2016_a\" href=\"#rGal_2016_a\">Gal & Ghahramani, 2016</a>) ans Ensemble (<a class=\"ref-link\" id=\"cLakshminarayanan_et+al_2017_a\" href=\"#rLakshminarayanan_et+al_2017_a\">Lakshminarayanan et al, 2017</a>)",
        "We evaluate the performance of these methods and our approximated version algorithm that uses them as its core \u03ba",
        "Before considering the relative performance of the baseline methods compares to ours, it is interesting to see that the E-area under the RC-curve measure nicely quantifies the difficulty level of the learning problems",
        "We presented novel uncertainty estimation algorithms, which are motivated by an observation regarding the training process of deep neural networks using stochastic gradient descent",
        "Reliable estimates generated in early epochs are later on deformed",
        "The Pointwise Early Stopping algorithm we presented requires an additional labeled set and expensive computational resources for training"
    ],
    "summary": [
        "The deployment of deep learning models in applications with demanding decision-making components such as autonomous driving or medical diagnosis hinges on our ability to monitor and control their statistical uncertainties.",
        "We propose to measure the performance of a \u03ba function as the area under the risk-coverage curve (AURC) of a selective classifier induced by \u03ba.",
        "Given a classifier f and confidence score function \u03ba defined for f , we define an empirical performance measure for \u03ba using an independent set Vn of n labeled points.",
        "Since the AURC of all RC-curves for f induced by any confidence scoring function will be larger than the AURC of \u03ba\u2217, we normalize by AURC(\u03ba\u2217) to obtain a unitless performance measure.",
        "Their ensemble consists of several trained DNN models, and confidence estimates were obtained by averaging softmax responses of ensemble members.",
        "Recall from Section 3 that a useful method for assessing the quality of a confidence function is the E-AURC measure.",
        "The above dynamics indicates that the learning of uncertainty estimators for easy instances conceptually resembles overfitting in the sense that the assessment of higher confidence points in the test set degrades as training continues after a certain point.",
        "First we present a supervised algorithm that learns an improved scoring function for a given pair (f, \u03ba), where f is a trained deep neural classifier, and \u03ba is a confidence scoring function for f \u2019s predictions.",
        "The Averaged Early Stopping (AES) is a simple approximation of the PES motivated by the observation that \u201ceasy\u201d points are learned earlier during training as shown in Figure 2(a).",
        "We present results of our AES algorithm applied over the four known confidence scores: softmax response, NN-distance (<a class=\"ref-link\" id=\"cMandelbaum_2017_a\" href=\"#rMandelbaum_2017_a\">Mandelbaum & Weinshall, 2017</a>), MC-dropout (<a class=\"ref-link\" id=\"cGal_2016_a\" href=\"#rGal_2016_a\">Gal & Ghahramani, 2016</a>) ans Ensemble (<a class=\"ref-link\" id=\"cLakshminarayanan_et+al_2017_a\" href=\"#rLakshminarayanan_et+al_2017_a\">Lakshminarayanan et al, 2017</a>).",
        "Before considering the relative performance of the baseline methods compares to ours, it is interesting to see that the E-AURC measure nicely quantifies the difficulty level of the learning problems.",
        "In CIFAR-10, the best method is softmax response, whose E-AURC is improved 6% by AES.",
        "Our difficulties when applying the PES algorithm on many of the underlying confidence methods, and the outstanding results of the AES motivate further research that should lead to improving the algorithm and making it more efficient.",
        "This phenomenon somewhat resembles the well-known overfitting effect in DNNs. The PES algorithm we presented requires an additional labeled set and expensive computational resources for training.",
        "The resulting confidence scores our methods generate systematically improve all existing estimation techniques on all the evaluated datasets.",
        "Both PES and AES overcome confidence score deformations by utilizing available snapshot models that are generated anyway during training."
    ],
    "headline": "We demonstrate that such techniques tend to introduce biased estimates for instances whose predictions are supposed to be highly confident",
    "reference_links": [
        {
            "id": "Bartlett_2008_a",
            "entry": "Peter L Bartlett and Marten H Wegkamp. Classification with a reject option using a hinge loss. Journal of Machine Learning Research, 9(Aug):1823\u20131840, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bartlett%2C%20Peter%20L.%20Wegkamp%2C%20Marten%20H.%20Classification%20with%20a%20reject%20option%20using%20a%20hinge%20loss%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bartlett%2C%20Peter%20L.%20Wegkamp%2C%20Marten%20H.%20Classification%20with%20a%20reject%20option%20using%20a%20hinge%20loss%202008"
        },
        {
            "id": "Breiman_1996_a",
            "entry": "Leo Breiman. Bagging predictors. Machine learning, 24(2):123\u2013140, 1996.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Breiman%2C%20Leo%20Bagging%20predictors%201996",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Breiman%2C%20Leo%20Bagging%20predictors%201996"
        },
        {
            "id": "Brier_1950_a",
            "entry": "Glenn W Brier. Verification of forecasts expressed in terms of probability. Monthey Weather Review, 78(1):1\u20133, 1950.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Brier%2C%20Glenn%20W.%20Verification%20of%20forecasts%20expressed%20in%20terms%20of%20probability%201950",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Brier%2C%20Glenn%20W.%20Verification%20of%20forecasts%20expressed%20in%20terms%20of%20probability%201950"
        },
        {
            "id": "Chow_1970_a",
            "entry": "C Chow. On optimum recognition error and reject tradeoff. IEEE Transactions on information theory, 16(1):41\u201346, 1970.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chow%2C%20C.%20On%20optimum%20recognition%20error%20and%20reject%20tradeoff%201970",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chow%2C%20C.%20On%20optimum%20recognition%20error%20and%20reject%20tradeoff%201970"
        },
        {
            "id": "Cordella_et+al_1995_a",
            "entry": "Luigi Pietro Cordella, Claudio De Stefano, Francesco Tortorella, and Mario Vento. A method for improving classification reliability of multilayer perceptrons. IEEE Transactions on Neural Networks, 6(5):1140\u20131147, 1995.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cordella%2C%20Luigi%20Pietro%20Stefano%2C%20Claudio%20De%20Tortorella%2C%20Francesco%20Vento%2C%20Mario%20A%20method%20for%20improving%20classification%20reliability%20of%20multilayer%20perceptrons%201995",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cordella%2C%20Luigi%20Pietro%20Stefano%2C%20Claudio%20De%20Tortorella%2C%20Francesco%20Vento%2C%20Mario%20A%20method%20for%20improving%20classification%20reliability%20of%20multilayer%20perceptrons%201995"
        },
        {
            "id": "Stefano_et+al_2000_a",
            "entry": "Claudio De Stefano, Carlo Sansone, and Mario Vento. To reject or not to reject: that is the question-an answer in case of neural classifiers. IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews), 30(1):84\u201394, 2000.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Stefano%2C%20Claudio%20De%20Sansone%2C%20Carlo%20Vento%2C%20Mario%20To%20reject%20or%20not%20to%20reject%3A%20that%20is%20the%20question-an%20answer%20in%20case%20of%20neural%20classifiers%202000",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Stefano%2C%20Claudio%20De%20Sansone%2C%20Carlo%20Vento%2C%20Mario%20To%20reject%20or%20not%20to%20reject%3A%20that%20is%20the%20question-an%20answer%20in%20case%20of%20neural%20classifiers%202000"
        },
        {
            "id": "Deng_et+al_2009_a",
            "entry": "Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp. 248\u2013255. IEEE, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Deng%2C%20Jia%20Dong%2C%20Wei%20Socher%2C%20Richard%20Li%2C%20Li-Jia%20Imagenet%3A%20A%20large-scale%20hierarchical%20image%20database%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Deng%2C%20Jia%20Dong%2C%20Wei%20Socher%2C%20Richard%20Li%2C%20Li-Jia%20Imagenet%3A%20A%20large-scale%20hierarchical%20image%20database%202009"
        },
        {
            "id": "El-Yaniv_2010_a",
            "entry": "Ran El-Yaniv and Yair Wiener. On the foundations of noise-free selective classification. Journal of Machine Learning Research, 11(May):1605\u20131641, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=El-Yaniv%2C%20Ran%20Wiener%2C%20Yair%20On%20the%20foundations%20of%20noise-free%20selective%20classification%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=El-Yaniv%2C%20Ran%20Wiener%2C%20Yair%20On%20the%20foundations%20of%20noise-free%20selective%20classification%202010"
        },
        {
            "id": "Gal_2016_a",
            "entry": "Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model uncertainty in deep learning. In international conference on machine learning, pp. 1050\u20131059, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gal%2C%20Yarin%20Ghahramani%2C%20Zoubin%20Dropout%20as%20a%20bayesian%20approximation%3A%20Representing%20model%20uncertainty%20in%20deep%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gal%2C%20Yarin%20Ghahramani%2C%20Zoubin%20Dropout%20as%20a%20bayesian%20approximation%3A%20Representing%20model%20uncertainty%20in%20deep%20learning%202016"
        },
        {
            "id": "Geifman_2017_a",
            "entry": "Yonatan Geifman and Ran El-Yaniv. Selective classification for deep neural networks. In Advances in neural information processing systems, pp. 4885\u20134894, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Geifman%2C%20Yonatan%20El-Yaniv%2C%20Ran%20Selective%20classification%20for%20deep%20neural%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Geifman%2C%20Yonatan%20El-Yaniv%2C%20Ran%20Selective%20classification%20for%20deep%20neural%20networks%202017"
        },
        {
            "id": "Guo_et+al_2017_a",
            "entry": "Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural networks. arXiv preprint arXiv:1706.04599, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.04599"
        },
        {
            "id": "He_et+al_2016_a",
            "entry": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770\u2013778, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "Hinton_et+al_2015_a",
            "entry": "Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1503.02531"
        },
        {
            "id": "Huang_et+al_2017_a",
            "entry": "Gao Huang, Yixuan Li, Geoff Pleiss, Zhuang Liu, John E Hopcroft, and Kilian Q Weinberger. Snapshot ensembles: Train 1, get m for free. arXiv preprint arXiv:1704.00109, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.00109"
        },
        {
            "id": "Izmailov_et+al_2018_a",
            "entry": "Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, and Andrew Gordon Wilson. Averaging weights leads to wider optima and better generalization. arXiv preprint arXiv:1803.05407, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.05407"
        },
        {
            "id": "Krizhevsky_2009_a",
            "entry": "Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images. 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Hinton%2C%20Geoffrey%20Learning%20multiple%20layers%20of%20features%20from%20tiny%20images%202009"
        },
        {
            "id": "Lakshminarayanan_et+al_2017_a",
            "entry": "Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncertainty estimation using deep ensembles. In Advances in Neural Information Processing Systems, pp. 6402\u20136413, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lakshminarayanan%2C%20Balaji%20Pritzel%2C%20Alexander%20Blundell%2C%20Charles%20Simple%20and%20scalable%20predictive%20uncertainty%20estimation%20using%20deep%20ensembles%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lakshminarayanan%2C%20Balaji%20Pritzel%2C%20Alexander%20Blundell%2C%20Charles%20Simple%20and%20scalable%20predictive%20uncertainty%20estimation%20using%20deep%20ensembles%202017"
        },
        {
            "id": "Shuying_2015_a",
            "entry": "Shuying Liu and Weihong Deng. Very deep convolutional neural network based image classification using small training sample size. In Pattern Recognition (ACPR), 2015 3rd IAPR Asian Conference on, pp. 730\u2013734. IEEE, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shuying%20Liu%20and%20Weihong%20Deng%20Very%20deep%20convolutional%20neural%20network%20based%20image%20classification%20using%20small%20training%20sample%20size%20In%20Pattern%20Recognition%20ACPR%202015%203rd%20IAPR%20Asian%20Conference%20on%20pp%20730734%20IEEE%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shuying%20Liu%20and%20Weihong%20Deng%20Very%20deep%20convolutional%20neural%20network%20based%20image%20classification%20using%20small%20training%20sample%20size%20In%20Pattern%20Recognition%20ACPR%202015%203rd%20IAPR%20Asian%20Conference%20on%20pp%20730734%20IEEE%202015"
        },
        {
            "id": "Mahsereci_et+al_2017_a",
            "entry": "Maren Mahsereci, Lukas Balles, Christoph Lassner, and Philipp Hennig. Early stopping without a validation set. arXiv preprint arXiv:1703.09580, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.09580"
        },
        {
            "id": "Mandelbaum_2017_a",
            "entry": "Amit Mandelbaum and Daphna Weinshall. Distance-based confidence score for neural network classifiers. arXiv preprint arXiv:1709.09844, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1709.09844"
        },
        {
            "id": "Naeini_et+al_2015_a",
            "entry": "Mahdi Pakdaman Naeini, Gregory F Cooper, and Milos Hauskrecht. Obtaining well calibrated probabilities using bayesian binning. In AAAI, pp. 2901\u20132907, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Naeini%2C%20Mahdi%20Pakdaman%20Cooper%2C%20Gregory%20F.%20Hauskrecht%2C%20Milos%20Obtaining%20well%20calibrated%20probabilities%20using%20bayesian%20binning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Naeini%2C%20Mahdi%20Pakdaman%20Cooper%2C%20Gregory%20F.%20Hauskrecht%2C%20Milos%20Obtaining%20well%20calibrated%20probabilities%20using%20bayesian%20binning%202015"
        },
        {
            "id": "Netzer_et+al_2011_a",
            "entry": "Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading digits in natural images with unsupervised feature learning. In NIPS workshop on deep learning and unsupervised feature learning, volume 2011, pp. 5, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Netzer%2C%20Yuval%20Wang%2C%20Tao%20Coates%2C%20Adam%20Bissacco%2C%20Alessandro%20Reading%20digits%20in%20natural%20images%20with%20unsupervised%20feature%20learning%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Netzer%2C%20Yuval%20Wang%2C%20Tao%20Coates%2C%20Adam%20Bissacco%2C%20Alessandro%20Reading%20digits%20in%20natural%20images%20with%20unsupervised%20feature%20learning%202011"
        },
        {
            "id": "Platt_1999_a",
            "entry": "John Platt et al. Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods. Advances in large margin classifiers, 10(3):61\u201374, 1999.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Platt%2C%20John%20Probabilistic%20outputs%20for%20support%20vector%20machines%20and%20comparisons%20to%20regularized%20likelihood%20methods%201999",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Platt%2C%20John%20Probabilistic%20outputs%20for%20support%20vector%20machines%20and%20comparisons%20to%20regularized%20likelihood%20methods%201999"
        },
        {
            "id": "Simonyan_2014_a",
            "entry": "Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1409.1556"
        },
        {
            "id": "Wiener_2011_a",
            "entry": "Yair Wiener and Ran El-Yaniv. Agnostic selective classification. In Advances in neural information processing systems, pp. 1665\u20131673, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wiener%2C%20Yair%20El-Yaniv%2C%20Ran%20Agnostic%20selective%20classification%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wiener%2C%20Yair%20El-Yaniv%2C%20Ran%20Agnostic%20selective%20classification%202011"
        },
        {
            "id": "Wiener_2015_a",
            "entry": "Yair Wiener and Ran El-Yaniv. Agnostic pointwise-competitive selective classification. Journal of Artificial Intelligence Research, 52:171\u2013201, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wiener%2C%20Yair%20El-Yaniv%2C%20Ran%20Agnostic%20pointwise-competitive%20selective%20classification%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wiener%2C%20Yair%20El-Yaniv%2C%20Ran%20Agnostic%20pointwise-competitive%20selective%20classification%202015"
        },
        {
            "id": "Zadrozny_2002_a",
            "entry": "Bianca Zadrozny and Charles Elkan. Transforming classifier scores into accurate multiclass probability estimates. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 694\u2013699. ACM, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zadrozny%2C%20Bianca%20Elkan%2C%20Charles%20Transforming%20classifier%20scores%20into%20accurate%20multiclass%20probability%20estimates%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zadrozny%2C%20Bianca%20Elkan%2C%20Charles%20Transforming%20classifier%20scores%20into%20accurate%20multiclass%20probability%20estimates%202002"
        },
        {
            "id": "Platt_1999_b",
            "entry": "Platt scaling (Platt et al., 1999): The Platt scaling is applied as follows. Given a confidence measure \u03ba and a validation set V, the scaling is the solution of the logistic regression from \u03ba(x, yf (x)|f ) to \u03ba\u2217(x, yf (x)|f ), where \u03ba\u2217(x, yf (x)|f ) is defined as 0 when x = yf (x) and 1 otherwise. We train the logistic regression models based on all points in V. To validate the training of this calibration we randomly split (50-50) the original test set to a training and test subsets. The calibration is learned over the training subset and evaluated on the test subset. The performance of the resulting scaled probabilities has been evaluated using both negative log likelihood (NLL) and the Brier score (Brier, 1950), which is simply the average L2 distance between the predicted and the true probabilities.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Platt%20scaling%20Platt%20et%20al%201999%20The%20Platt%20scaling%20is%20applied%20as%20follows%20Given%20a%20confidence%20measure%20%CE%BA%20and%20a%20validation%20set%20V%20the%20scaling%20is%20the%20solution%20of%20the%20logistic%20regression%20from%20%CE%BAx%20yf%20xf%20%20to%20%CE%BAx%20yf%20xf%20%20where%20%CE%BAx%20yf%20xf%20%20is%20defined%20as%200%20when%20x%20%20yf%20x%20and%201%20otherwise%20We%20train%20the%20logistic%20regression%20models%20based%20on%20all%20points%20in%20V%20To%20validate%20the%20training%20of%20this%20calibration%20we%20randomly%20split%205050%20the%20original%20test%20set%20to%20a%20training%20and%20test%20subsets%20The%20calibration%20is%20learned%20over%20the%20training%20subset%20and%20evaluated%20on%20the%20test%20subset%20The%20performance%20of%20the%20resulting%20scaled%20probabilities%20has%20been%20evaluated%20using%20both%20negative%20log%20likelihood%20NLL%20and%20the%20Brier%20score%20Brier%201950%20which%20is%20simply%20the%20average%20L2%20distance%20between%20the%20predicted%20and%20the%20true%20probabilities"
        }
    ]
}

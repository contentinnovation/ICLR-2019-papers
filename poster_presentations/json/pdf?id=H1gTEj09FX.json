{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "Artificial Neural Networks and Machine Learning \u2013 ICANN 2011",
        "date": 2011,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=H1gTEj09FX",
            "doi": "10.1007/978-3-642-21735-7"
        },
        "journal": "Lecture Notes in Computer Science",
        "abstract": "Explicit encoding of group actions in deep features makes it possible for convolutional neural networks (CNNs) to handle global deformations of images, which is critical to success in many vision tasks. This paper proposes to decompose the convolutional filters over joint steerable bases across the space and the group geometry simultaneously, namely a rotation-equivariant CNN with decomposed convolutional filters (RotDCF). This decomposition facilitates computing the joint convolution, which is proved to be necessary for the group equivariance. It significantly reduces the model size and computational complexity while preserving performance, and truncation of the bases expansion serves implicitly to regularize the filters. On datasets involving in-plane and out-of-plane object rotations, RotDCF deep features demonstrate greater robustness and interpretability than regular CNNs. The stability of the equivariant representation to input variations is also proved theoretically. The RotDCF framework can be extended to groups other than rotations, providing a general approach which achieves both group equivariance and representation stability at a reduced model size."
    },
    "keywords": [
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        },
        {
            "term": "computational complexity",
            "url": "https://en.wikipedia.org/wiki/computational_complexity"
        },
        {
            "term": "group action",
            "url": "https://en.wikipedia.org/wiki/group_action"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        }
    ],
    "abbreviations": {
        "CNNs": "convolutional neural networks",
        "CNN": "convolutional neural networks",
        "CAM": "Class Activation Maps"
    },
    "highlights": [
        "While deep convolutional neural networks (CNN) have been widely used in computer vision and image processing applications, they are not designed to handle large group actions like rotations, which degrade the performance of convolutional neural networks in many tasks (<a class=\"ref-link\" id=\"cCheng_et+al_2016_a\" href=\"#rCheng_et+al_2016_a\">Cheng et al, 2016</a>; Hallman & Fowlkes, 2015; Jaderberg et al, 2015b; Laptev et al, 2016; Maninis et al, 2016)",
        "For the important case of 2D rotations, group-equivariant convolutional neural networks have been constructed in several recent works, e.g., (Weiler et al, 2017), Harmonic Net (Worrall et al, 2017) and Oriented Response Net (Zhou et al, 2017)",
        "This paper proposes a truncated bases decomposition of the filters in group-equivariant convolutional neural networks, which we call the rotation-equivariant convolutional neural networks with decomposed convolutional filters (RotDCF)",
        "This work introduces a decomposition of the filters in rotation-equivariant convolutional neural networks under joint steerable bases over space and rotations simultaneously, obtaining equivariant deep representations with significantly reduced model size and an implicit filter regularization"
    ],
    "key_statements": [
        "While deep convolutional neural networks (CNN) have been widely used in computer vision and image processing applications, they are not designed to handle large group actions like rotations, which degrade the performance of convolutional neural networks in many tasks (<a class=\"ref-link\" id=\"cCheng_et+al_2016_a\" href=\"#rCheng_et+al_2016_a\">Cheng et al, 2016</a>; Hallman & Fowlkes, 2015; Jaderberg et al, 2015b; Laptev et al, 2016; Maninis et al, 2016)",
        "For the important case of 2D rotations, group-equivariant convolutional neural networks have been constructed in several recent works, e.g., (Weiler et al, 2017), Harmonic Net (Worrall et al, 2017) and Oriented Response Net (Zhou et al, 2017)",
        "This paper proposes a truncated bases decomposition of the filters in group-equivariant convolutional neural networks, which we call the rotation-equivariant convolutional neural networks with decomposed convolutional filters (RotDCF)",
        "This work introduces a decomposition of the filters in rotation-equivariant convolutional neural networks under joint steerable bases over space and rotations simultaneously, obtaining equivariant deep representations with significantly reduced model size and an implicit filter regularization"
    ],
    "summary": [
        "While deep convolutional neural networks (CNN) have been widely used in computer vision and image processing applications, they are not designed to handle large group actions like rotations, which degrade the performance of CNN in many tasks (<a class=\"ref-link\" id=\"cCheng_et+al_2016_a\" href=\"#rCheng_et+al_2016_a\"><a class=\"ref-link\" id=\"cCheng_et+al_2016_a\" href=\"#rCheng_et+al_2016_a\">Cheng et al, 2016</a></a>; Hallman & Fowlkes, 2015; Jaderberg et al, 2015b; Laptev et al, 2016; Maninis et al, 2016).",
        "The benefits of bases decomposition are three-fold: (1) Reduction of the number of parameters and computational complexity of rotation-equivariant CNNs, c.f. Section 2.3; Figure 1: Decomposition of the convolutional filter across the 2D space and the SO(2) rotation group geometry simultaneously.",
        "Qiu et al (2018) studied decomposed-filter CNN with prefixed bases and trainable expansion coefficients, showing that the truncated bases decomposition incurs almost no decrease in classification accuracy while significantly reducing the model size and improving the robustness of the deep features.",
        "The visibly smoother trained filters in RotDCF are shown in Figure A.1, demonstrating the same regularization effects as in Qiu et al (2018), the latter being without the rotation-equivariant setting.",
        "This means that RotDCF Net achieves a significant parameter reduction from the non-bases equivariant CNN, and even reduces parameters from a regular",
        "The above result guarantees that in such cases the RotDCF representation undergoes approximately an equivariant action of T\u03c1, which implies consistency of the learned deep features up to a rotation.",
        "A CNN with 6 convolutional layers (Table A.2), and we compare with DCF (Qiu et al, 2018), which is non-rotation-equivariant but uses bases truncation, and SFCNN (Weiler et al, 2017), which is rotation-equivariant but does not use bases decompostion.",
        "We see that RotDCF net obtains improved classification accuracy from CNN with significantly reduced number of parameters, e.g., with 12K training, Rot-",
        "As shown in Table 3, RotDCF Net obtains better testing accuracy with reduced model size from the regular CNN baseline model.",
        "We train a regular CNN and a RotDCF Net on 10,000 up-right MNIST data samples, and directly test on 50,000 randomly rotated MNIST samples where the maximum rotation angle MaxRot=30 or 60 degrees.",
        "4.2 IMAGE RECONSTRUCTION To illustrate the explicit encoding of group actions in the RotDCF Net features, we train a convolutional auto-encoder on the rotated MNIST dataset, where encoder consists of stacked RotDCF layers, and the decoder consists of stacked transposed-convolutional layers (Table A.5).",
        "This is due to the rotation-equivariant property of the RotDCF Net, which means that the face representation is consistent regardless of its orientations after the group alignment.",
        "This work introduces a decomposition of the filters in rotation-equivariant CNNs under joint steerable bases over space and rotations simultaneously, obtaining equivariant deep representations with significantly reduced model size and an implicit filter regularization.",
        "RotDCF demonstrates improved recognition accuracy and better feature interpretability and stability on synthetic and realworld datasets involving object rotations, in the transfer learning setting.",
        "The framework should extend to other groups and joint geometrical domains"
    ],
    "headline": "This paper proposes to decompose the convolutional filters over joint steerable bases across the space and the group geometry simultaneously, namely a rotation-equivariant convolutional neural networks with decomposed convolutional filters",
    "reference_links": [
        {
            "id": "Abramowitz_1964_a",
            "entry": "Milton Abramowitz and Irene A Stegun. Handbook of mathematical functions: with formulas, graphs, and mathematical tables, volume 55. Courier Corporation, 1964.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Abramowitz%2C%20Milton%20Stegun%2C%20Irene%20A.%20Handbook%20of%20mathematical%20functions%3A%20with%20formulas%2C%20graphs%2C%20and%20mathematical%20tables%2C%20volume%2055%201964"
        },
        {
            "id": "Chen_et+al_2015_a",
            "entry": "Wenlin Chen, James Wilson, Stephen Tyree, Kilian Weinberger, and Yixin Chen. Compressing neural networks with the hashing trick. In International Conference on Machine Learning, pp. 2285\u20132294, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Wenlin%20Wilson%2C%20James%20Tyree%2C%20Stephen%20Weinberger%2C%20Kilian%20Compressing%20neural%20networks%20with%20the%20hashing%20trick%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Wenlin%20Wilson%2C%20James%20Tyree%2C%20Stephen%20Weinberger%2C%20Kilian%20Compressing%20neural%20networks%20with%20the%20hashing%20trick%202015"
        },
        {
            "id": "Cheng_et+al_2016_a",
            "entry": "Gong Cheng, Peicheng Zhou, and Junwei Han. Rifd-cnn: Rotation-invariant and fisher discriminative convolutional neural networks for object detection. In Computer Vision and Pattern Recognition (CVPR), 2016 IEEE Conference on, pp. 2884\u20132893. IEEE, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cheng%2C%20Gong%20Zhou%2C%20Peicheng%20Han%2C%20Junwei%20Rifd-cnn%3A%20Rotation-invariant%20and%20fisher%20discriminative%20convolutional%20neural%20networks%20for%20object%20detection%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cheng%2C%20Gong%20Zhou%2C%20Peicheng%20Han%2C%20Junwei%20Rifd-cnn%3A%20Rotation-invariant%20and%20fisher%20discriminative%20convolutional%20neural%20networks%20for%20object%20detection%202016"
        },
        {
            "id": "Cohen_2016_a",
            "entry": "Taco Cohen and Max Welling. Group equivariant convolutional networks. In ICML, pp. 2990\u20132999, 2016a. URL http://jmlr.org/proceedings/papers/v48/cohenc16.html.",
            "url": "http://jmlr.org/proceedings/papers/v48/cohenc16.html",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cohen%2C%20Taco%20Welling%2C%20Max%20Group%20equivariant%20convolutional%20networks%202016"
        },
        {
            "id": "Cohen_2016_b",
            "entry": "Taco S. Cohen and Max Welling. Steerable cnns. arXiv preprint arXiv:1612.08498, 2016b. Taco S Cohen, Mario Geiger, Jonas Koehler, and Max Welling. Spherical cnns. arXiv preprint arXiv:1801.10130, 2018. Emily L. Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, and Rob Fergus. Exploiting linear structure within convolutional networks for efficient evaluation. In NIPS, pp. 1269\u20131277, 2014. William T Freeman, Edward H Adelson, et al. The design and use of filters. IEEE Transactions on Pattern analysis and machine intelligence, 13(9):891\u2013906, 1991. Diego Marcos Gonzalez, Michele Volpi, and Devis Tuia. Learning rotation invariant convolutional filters for texture classification. CoRR, abs/1604.06720, 2016. URL http://arxiv.org/abs/1604.06720. Sam Hallman and Charless C Fowlkes. Oriented edge forests for boundary detection. In Proceedings of the",
            "url": "http://arxiv.org/abs/1604.06720",
            "arxiv_url": "https://arxiv.org/pdf/1612.08498"
        },
        {
            "id": "Han_et+al_2015_a",
            "entry": "IEEE Conference on Computer Vision and Pattern Recognition, pp. 1732\u20131740, 2015. Song Han, Jeff Pool, John Tran, and William Dally. Learning both weights and connections for efficient neural network. In Advances in Neural Information Processing Systems, pp. 1135\u20131143, 2015. Song Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. International Conference on Learning Representations (ICLR), 2016. Geoffrey E Hinton, Alex Krizhevsky, and Sida D Wang. Transforming auto-encoders. In International Conference on Artificial Neural Networks, pp. 44\u201351.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Han%2C%20Jeff%20Pool%20Tran%2C%20John%20Dally%2C%20William%20Learning%20both%20weights%20and%20connections%20for%20efficient%20neural%20network%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Han%2C%20Jeff%20Pool%20Tran%2C%20John%20Dally%2C%20William%20Learning%20both%20weights%20and%20connections%20for%20efficient%20neural%20network%202015"
        },
        {
            "id": "Springer_2017_a",
            "entry": "Springer, 2011. Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.04861"
        },
        {
            "id": "Iandola_et+al_2016_a",
            "entry": "Forrest N. Iandola, Song Han, Matthew W. Moskewicz, Khalid Ashraf, William J. Dally, and Kurt Keutzer. Squeezenet: Alexnet-level accuracy with 50x fewer parameters and <0.5mb model size. arXiv:1602.07360, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1602.07360"
        },
        {
            "id": "Jaderberg_et+al_2014_a",
            "entry": "Max Jaderberg, Andrea Vedaldi, and Andrew Zisserman. Speeding up convolutional neural networks with low rank expansions. arXiv preprint arXiv:1405.3866, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1405.3866"
        },
        {
            "id": "Jaderberg_et+al_2017_a",
            "entry": "Max Jaderberg, Karen Simonyan, Andrew Zisserman, and Koray Kavukcuoglu. Spatial transformer networks. In NIPS, pp. 2017\u20132025, 2015a. URL http://papers.nips.cc/paper/5854-spatial-transformer-networks.",
            "url": "http://papers.nips.cc/paper/5854-spatial-transformer-networks",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jaderberg%2C%20Max%20Simonyan%2C%20Karen%20Zisserman%2C%20Andrew%20Kavukcuoglu%2C%20Koray%20Spatial%20transformer%20networks%202017"
        },
        {
            "id": "Jaderberg_et+al_2017_b",
            "entry": "Max Jaderberg, Karen Simonyan, Andrew Zisserman, et al. Spatial transformer networks. In Advances in neural information processing systems, pp. 2017\u20132025, 2015b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jaderberg%2C%20Max%20Simonyan%2C%20Karen%20Zisserman%2C%20Andrew%20Spatial%20transformer%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jaderberg%2C%20Max%20Simonyan%2C%20Karen%20Zisserman%2C%20Andrew%20Spatial%20transformer%20networks%202017"
        },
        {
            "id": "Kazemi_2014_a",
            "entry": "Vahid Kazemi and Josephine Sullivan. One millisecond face alignment with an ensemble of regression trees. In Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition, CVPR, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kazemi%2C%20Vahid%20Sullivan%2C%20Josephine%20One%20millisecond%20face%20alignment%20with%20an%20ensemble%20of%20regression%20trees%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kazemi%2C%20Vahid%20Sullivan%2C%20Josephine%20One%20millisecond%20face%20alignment%20with%20an%20ensemble%20of%20regression%20trees%202014"
        },
        {
            "id": "Kivinen_2011_a",
            "entry": "Jyri J. Kivinen and Christopher K. I. Williams. Transformation equivariant boltzmann machines. In ICANN, pp. 1\u20139, 2011. doi: 10.1007/978-3-642-21735-7 1. URL http://dx.doi.org/10.1007/978-3-642-21735-7_1.",
            "crossref": "https://dx.doi.org/10.1007/978-3-642-21735-7",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1007/978-3-642-21735-7"
        },
        {
            "id": "Krizhevsky_2009_a",
            "entry": "Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, 2009. Dmitry Laptev, Nikolay Savinov, Joachim M Buhmann, and Marc Pollefeys. Ti-pooling: transformationinvariant pooling for feature learning in convolutional neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 289\u2013297, 2016. Vadim Lebedev, Yaroslav Ganin, Maksim Rakhuba, Ivan Oseledets, and Victor Lempitsky. Speeding-up convolutional neural networks using fine-tuned cp-decomposition. arXiv preprint arXiv:1412.6553, 2014. Kevis-Kokitsi Maninis, Jordi Pont-Tuset, Pablo Arbelaez, and Luc Van Gool. Convolutional oriented boundaries. In European Conference on Computer Vision, pp. 580\u2013596.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6553"
        },
        {
            "id": "Springer_2016_a",
            "entry": "Springer, 2016. Hong-Wei Ng and Stefan Winkler. A data-driven approach to cleaning large face datasets. In Image Processing (ICIP), 2014 IEEE International Conference on, pp. 343\u2013347. IEEE, 2014. Edouard Oyallon and Stephane Mallat. Deep roto-translation scattering for object classification. In CVPR, volume 3, pp. 6, 2015. Vardan Papyan, Yaniv Romano, and Michael Elad. Convolutional neural networks analyzed via convolutional sparse coding. The Journal of Machine Learning Research, 18(1):2887\u20132938, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Springer%20Hong-Wei%20Ng%20and%20Stefan%20Winkler.%20A%20data-driven%20approach%20to%20cleaning%20large%20face%20datasets%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Springer%20Hong-Wei%20Ng%20and%20Stefan%20Winkler.%20A%20data-driven%20approach%20to%20cleaning%20large%20face%20datasets%202016"
        },
        {
            "id": "Tai_et+al_2019_a",
            "entry": "Published as a conference paper at ICLR 2019 Cheng Tai, Tong Xiao, Yi Zhang, Xiaogang Wang, et al. Convolutional neural networks with low-rank regularization. arXiv preprint arXiv:1511.06067, 2015. Maurice Weiler, Fred A Hamprecht, and Martin Storath. Learning steerable filters for rotation equivariant cnns.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06067"
        },
        {
            "id": "Wu_et+al_2017_a",
            "entry": "arXiv preprint arXiv:1711.07289, 2017. Daniel E Worrall, Stephan J Garbin, Daniyar Turmukhambetov, and Gabriel J Brostow. Harmonic networks: Deep translation and rotation equivariance. In Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), volume 2, 2017. Fa Wu, Peijun Hu, and Dexing Kong. Flip-rotate-pooling convolution and split dropout on convolution neural networks for image classification. CoRR, abs/1507.08754, 2015. URL http://arxiv.org/abs/1507.08754. Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. Learning deep features for discriminative localization. In Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition, CVPR, 2016. Yanzhao Zhou, Qixiang Ye, Qiang Qiu, and Jianbin Jiao. Oriented response networks. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp.4961\u20134970. IEEE, 2017.",
            "url": "http://arxiv.org/abs/1507.08754",
            "arxiv_url": "https://arxiv.org/pdf/1711.07289"
        }
    ]
}

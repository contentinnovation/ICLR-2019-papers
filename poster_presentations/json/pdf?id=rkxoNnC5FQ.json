{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "SPIGAN: PRIVILEGED ADVERSARIAL LEARNING FROM SIMULATION",
        "author": "Kuan-Hui Lee, Jie Li, Adrien Gaidon",
        "date": 2018,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=rkxoNnC5FQ"
        },
        "abstract": "Deep Learning for Computer Vision depends mainly on the source of supervision. Photo-realistic simulators can generate large-scale automatically labeled synthetic data, but introduce a domain gap negatively impacting performance. We propose a new unsupervised domain adaptation algorithm, called SPIGAN, relying on Simulator Privileged Information (PI) and Generative Adversarial Networks (GAN). We use internal data from the simulator as PI during the training of a target task network. We experimentally evaluate our approach on semantic segmentation. We train the networks on real-world Cityscapes and Vistas datasets, using only unlabeled real-world images and synthetic labeled data with z-buffer (depth) PI from the SYNTHIA dataset. Our method improves over no adaptation and state-of-theart unsupervised domain adaptation techniques."
    },
    "keywords": [
        {
            "term": "domain adaptation",
            "url": "https://en.wikipedia.org/wiki/domain_adaptation"
        },
        {
            "term": "Generative Adversarial Networks",
            "url": "https://en.wikipedia.org/wiki/Generative_Adversarial_Networks"
        },
        {
            "term": "synthetic datum",
            "url": "https://en.wikipedia.org/wiki/synthetic_datum"
        },
        {
            "term": "real world",
            "url": "https://en.wikipedia.org/wiki/real_world"
        },
        {
            "term": "computer vision",
            "url": "https://en.wikipedia.org/wiki/computer_vision"
        },
        {
            "term": "action recognition",
            "url": "https://en.wikipedia.org/wiki/action_recognition"
        }
    ],
    "abbreviations": {
        "PI": "Privileged Information",
        "GAN": "Generative Adversarial Networks",
        "GANs": "Generative Adversarial Networks",
        "DANN": "Domain Adversarial Neural Network",
        "VAEs": "Variational Auto-Encoders",
        "LUPI": "Learning Using Privileged Information",
        "mIoU": "mean intersection-over-union",
        "CDA": "Curriculum DA",
        "LSD": "Learning from synthetic data",
        "CBST": "Class-balanced Self-Training"
    },
    "highlights": [
        "We propose a novel adversarial learning algorithm, called SPIGAN, to leverage Simulator Privileged Information for Generative Adversarial Networks-based unsupervised learning of a target task network from unpaired unlabeled real-world data",
        "We provide our algorithm performance without the Privileged Information for comparison (i.e., \u03b3 = 0 in Eq 1, named \u201dSPIGAN-no-Privileged Information\u201d)",
        "SPIGAN achieves an improvement of 3% in 320 \u00d7 640, 1.0% in 512 \u00d7 1024, in mean IoU with respect to the non-Privileged Information method",
        "We present SPIGAN, a novel method for leveraging synthetic data and Privileged Information (PI) available in simulated environments to perform unsupervised domain adaptation of deep networks",
        "We showed that our approach is able to address large domain gaps between synthetic data and target real-world domains, including for challenging realworld tasks like semantic segmentation of urban scenes",
        "We plan to investigate SPIGAN applied to additional tasks, with different types of Privileged Information that can be obtained from simulation"
    ],
    "key_statements": [
        "We propose a novel adversarial learning algorithm, called SPIGAN, to leverage Simulator Privileged Information for Generative Adversarial Networks-based unsupervised learning of a target task network from unpaired unlabeled real-world data",
        "We show that SPIGAN can successfully learn a semantic segmentation network T using no real-world labels, partially bridging the sim-to-real gap",
        "We show that for the challenging task of semantic segmentation of urban scenes, our approach significantly improves by augmenting the learning objective with our auxiliary privileged task, especially in the presence of a large sim-to-real domain gap, the main problem in challenging real-world conditions",
        "We describe our approach assuming a unified treatment of the Privileged Information, but our method trivially extends to multiple separate types of Privileged Information",
        "We evaluate our unsupervised domain adaptation method on the task of semantic segmentation in a challenging real-world domain for which training labels are not available",
        "Depth maps from SYNTHIA are used as Privileged Information in the proposed algorithm",
        "Quantitative results for these methods are shown in Table 1 for the semantic segmentation task on the target domain of Cityscapes",
        "We provide our algorithm performance without the Privileged Information for comparison (i.e., \u03b3 = 0 in Eq 1, named \u201dSPIGAN-no-Privileged Information\u201d)",
        "A finer analysis of the results attending to individual classes suggests that the use of Privileged Information helps to estimate layout-related classes such as road and sidewalk and object-related classes such as person, rider, car, bus and motorcycle",
        "SPIGAN achieves an improvement of 3% in 320 \u00d7 640, 1.0% in 512 \u00d7 1024, in mean IoU with respect to the non-Privileged Information method",
        "We present SPIGAN, a novel method for leveraging synthetic data and Privileged Information (PI) available in simulated environments to perform unsupervised domain adaptation of deep networks",
        "We showed that our approach is able to address large domain gaps between synthetic data and target real-world domains, including for challenging realworld tasks like semantic segmentation of urban scenes",
        "We plan to investigate SPIGAN applied to additional tasks, with different types of Privileged Information that can be obtained from simulation",
        "For a set of real images (a) we show examples of predicted semantic segmentation masks"
    ],
    "summary": [
        "We propose a novel adversarial learning algorithm, called SPIGAN, to leverage Simulator PI for GAN-based unsupervised learning of a target task network from unpaired unlabeled real-world data.",
        "We jointly learn four different networks: (i) a generator G, a discriminator D, a task network T, and a privileged network P trained on both synthetic images x and adapted ones G(x) to predict their associated privileged information z.",
        "Several related works propose GAN-based unsupervised domain adaptation methods to address the specific domain gap between synthetic and real-world images.",
        "Related to our work, PixelDA (<a class=\"ref-link\" id=\"cBousmalis_et+al_2017_a\" href=\"#rBousmalis_et+al_2017_a\">Bousmalis et al, 2017</a>) is a pixel-level domain adaptation method that jointly trains a task classifier along with a GAN using simulation as its source domain but no privileged information.",
        "The main challenge we address in this work is how to overcome the gap between this synthetic source domain and the target domain to ensure generalization of the task network in the real-world without target supervision.",
        "The main learning goal is to train a model \u03b8T that can correctly perform a perception task T in the target real-world domain.",
        "We evaluate our unsupervised domain adaptation method on the task of semantic segmentation in a challenging real-world domain for which training labels are not available.",
        "We use the standard FCN8s architecture <a class=\"ref-link\" id=\"cLong_et+al_2015_a\" href=\"#rLong_et+al_2015_a\">Long et al (2015</a>) for both the task predictor T and the privileged network P , given its ease of training and its acceptance in domain adaptation works Hoffman et al (2016b).",
        "We compare our results to several state-of-art domain adaptation algorithms, including FCNs in the wild (FCNs wild) (Hoffman et al, 2016b), Curriculum DA (CDA) (<a class=\"ref-link\" id=\"cZhang_et+al_2017_a\" href=\"#rZhang_et+al_2017_a\">Zhang et al, 2017</a>), Learning from synthetic data (LSD) (<a class=\"ref-link\" id=\"cSankaranarayanan_et+al_2018_a\" href=\"#rSankaranarayanan_et+al_2018_a\">Sankaranarayanan et al, 2018</a>), and Class-balanced Self-Training (CBST) Zou et al (2018).",
        "To better understand the proposed algorithm, and the impact of PI, we conduct further experiments comparing SPIGAN, SPIGAN-no-PI, and SPIGAN-base, the task network of SPIGAN trained only on the source domain (FCN source, lower bound, no adaptation), and on the target domain (FCN target, upper bound), all at 320 \u00d7 640 resolution.",
        "We present SPIGAN, a novel method for leveraging synthetic data and Privileged Information (PI) available in simulated environments to perform unsupervised domain adaptation of deep networks.",
        "Our approach jointly learns a generative pixel-level adaptation network together with a target task network and privileged information models.",
        "We showed that our approach is able to address large domain gaps between synthetic data and target real-world domains, including for challenging realworld tasks like semantic segmentation of urban scenes.",
        "We plan to investigate SPIGAN applied to additional tasks, with different types of PI that can be obtained from simulation"
    ],
    "headline": "We propose a new unsupervised domain adaptation algorithm, called SPIGAN, relying on Simulator Privileged Information and Generative Adversarial Networks",
    "reference_links": [
        {
            "id": "Bousmalis_et+al_2016_a",
            "entry": "Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman, Dilip Krishnan, and Dumitru Erhan. Domain separation networks. In NIPS, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Konstantinos%20Bousmalis%20George%20Trigeorgis%20Nathan%20Silberman%20Dilip%20Krishnan%20and%20Dumitru%20Erhan%20Domain%20separation%20networks%20In%20NIPS%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Konstantinos%20Bousmalis%20George%20Trigeorgis%20Nathan%20Silberman%20Dilip%20Krishnan%20and%20Dumitru%20Erhan%20Domain%20separation%20networks%20In%20NIPS%202016"
        },
        {
            "id": "Bousmalis_et+al_2017_a",
            "entry": "Konstantinos Bousmalis, Nathan Silberman, David Dohan, Dumitru Erhan, and Dilip Krishnan. Unsupervised pixel-level domain adaptation with generative adversarial networks. In Computer Vision and Pattern Recognition, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bousmalis%2C%20Konstantinos%20Silberman%2C%20Nathan%20Dohan%2C%20David%20Erhan%2C%20Dumitru%20Unsupervised%20pixel-level%20domain%20adaptation%20with%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bousmalis%2C%20Konstantinos%20Silberman%2C%20Nathan%20Dohan%2C%20David%20Erhan%2C%20Dumitru%20Unsupervised%20pixel-level%20domain%20adaptation%20with%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "Chen_et+al_2014_a",
            "entry": "Lin Chen, Wen Li, and Dong Xu. Recognizing rgb images by learning from rgb-d data. In Computer Vision and Pattern Recognition, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Lin%20Li%2C%20Wen%20Xu%2C%20Dong%20Recognizing%20rgb%20images%20by%20learning%20from%20rgb-d%20data%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Lin%20Li%2C%20Wen%20Xu%2C%20Dong%20Recognizing%20rgb%20images%20by%20learning%20from%20rgb-d%20data%202014"
        },
        {
            "id": "Chen_2017_a",
            "entry": "Qifeng Chen and Vladlen Koltun. Photographic image synthesis with cascaded refinement networks. In International Conference on Computer Vision, Oct 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Qifeng%20Koltun%2C%20Vladlen%20Photographic%20image%20synthesis%20with%20cascaded%20refinement%20networks%202017-10",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Qifeng%20Koltun%2C%20Vladlen%20Photographic%20image%20synthesis%20with%20cascaded%20refinement%20networks%202017-10"
        },
        {
            "id": "Chen_et+al_2017_b",
            "entry": "Yi-Hsin Chen, Wei-Yu Chen, Yu-Ting Chen, Bo-Cheng Tsai, Yu-Chiang Frank Wang, and Min Sun. No more discrimination: Cross city adaptation of road scene segmenters. In International Conference on Computer Vision, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Yi-Hsin%20Chen%2C%20Wei-Yu%20Chen%2C%20Yu-Ting%20Tsai%2C%20Bo-Cheng%20No%20more%20discrimination%3A%20Cross%20city%20adaptation%20of%20road%20scene%20segmenters%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Yi-Hsin%20Chen%2C%20Wei-Yu%20Chen%2C%20Yu-Ting%20Tsai%2C%20Bo-Cheng%20No%20more%20discrimination%3A%20Cross%20city%20adaptation%20of%20road%20scene%20segmenters%202017"
        },
        {
            "id": "Chen_et+al_2018_a",
            "entry": "Yuhua Chen, Wen Li, and Luc Van Gool. Road: Reality oriented adaptation for semantic segmentation of urban scenes. In Computer Vision and Pattern Recognition, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Yuhua%20Li%2C%20Wen%20Gool%2C%20Luc%20Van%20Road%3A%20Reality%20oriented%20adaptation%20for%20semantic%20segmentation%20of%20urban%20scenes%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Yuhua%20Li%2C%20Wen%20Gool%2C%20Luc%20Van%20Road%3A%20Reality%20oriented%20adaptation%20for%20semantic%20segmentation%20of%20urban%20scenes%202018"
        },
        {
            "id": "Cordts_et+al_2016_a",
            "entry": "Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The Cityscapes dataset for semantic urban scene understanding. In Computer Vision and Pattern Recognition, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cordts%2C%20Marius%20Omran%2C%20Mohamed%20Ramos%2C%20Sebastian%20Rehfeld%2C%20Timo%20The%20Cityscapes%20dataset%20for%20semantic%20urban%20scene%20understanding%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Cordts%2C%20Marius%20Omran%2C%20Mohamed%20Ramos%2C%20Sebastian%20Rehfeld%2C%20Timo%20The%20Cityscapes%20dataset%20for%20semantic%20urban%20scene%20understanding%202016"
        },
        {
            "id": "Csurka_2017_a",
            "entry": "Gabriela Csurka. Domain Adaptation in Computer Vision Applications. Springer, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Csurka%2C%20Gabriela%20Domain%20Adaptation%20in%20Computer%20Vision%20Applications%202017"
        },
        {
            "id": "Dai_et+al_2017_a",
            "entry": "Zihang Dai, Zhilin Yang, Fan Yang, William W. Cohen, and Ruslan Salakhutdinov. Good semisupervised learning that requires a bad GAN. NIPS, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dai%2C%20Zihang%20Yang%2C%20Zhilin%20Yang%2C%20Fan%20Cohen%2C%20William%20W.%20and%20Ruslan%20Salakhutdinov%202017"
        },
        {
            "id": "De_et+al_2017_a",
            "entry": "Cesar Roberto de Souza, Adrien Gaidon, Yohann Cabon, and Antonio Manuel Lopez Pena. Procedural generation of videos to train deep action recognition networks. In Computer Vision and Pattern Recognition, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=de%20Souza%2C%20Cesar%20Roberto%20Gaidon%2C%20Adrien%20Cabon%2C%20Yohann%20Pena%2C%20Antonio%20Manuel%20Lopez%20Procedural%20generation%20of%20videos%20to%20train%20deep%20action%20recognition%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=de%20Souza%2C%20Cesar%20Roberto%20Gaidon%2C%20Adrien%20Cabon%2C%20Yohann%20Pena%2C%20Antonio%20Manuel%20Lopez%20Procedural%20generation%20of%20videos%20to%20train%20deep%20action%20recognition%20networks%202017"
        },
        {
            "id": "Gaidon_et+al_2016_a",
            "entry": "Adrien Gaidon, Qiao Wang, Yohann Cabon, and Eleonora Vig. Virtual worlds as proxy for multiobject tracking analysis. In Computer Vision and Pattern Recognition, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gaidon%2C%20Adrien%20Wang%2C%20Qiao%20Cabon%2C%20Yohann%20Vig%2C%20Eleonora%20Virtual%20worlds%20as%20proxy%20for%20multiobject%20tracking%20analysis%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gaidon%2C%20Adrien%20Wang%2C%20Qiao%20Cabon%2C%20Yohann%20Vig%2C%20Eleonora%20Virtual%20worlds%20as%20proxy%20for%20multiobject%20tracking%20analysis%202016"
        },
        {
            "id": "Ganin_2015_a",
            "entry": "Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In International Conference on Machine Learning, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ganin%2C%20Yaroslav%20Lempitsky%2C%20Victor%20Unsupervised%20domain%20adaptation%20by%20backpropagation%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ganin%2C%20Yaroslav%20Lempitsky%2C%20Victor%20Unsupervised%20domain%20adaptation%20by%20backpropagation%202015"
        },
        {
            "id": "Ganin_et+al_2016_a",
            "entry": "Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Francois Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks. Journal of Machine Learning Research, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ganin%2C%20Yaroslav%20Ustinova%2C%20Evgeniya%20Ajakan%2C%20Hana%20Germain%2C%20Pascal%20Domain-adversarial%20training%20of%20neural%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ganin%2C%20Yaroslav%20Ustinova%2C%20Evgeniya%20Ajakan%2C%20Hana%20Germain%2C%20Pascal%20Domain-adversarial%20training%20of%20neural%20networks%202016"
        },
        {
            "id": "Garcia_et+al_2018_a",
            "entry": "Nuno Garcia, Pietro Morerio, and Vittorio Murino. Modality distillation with multiple stream networks for action recognition. In European Conference on Computer Vision, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Garcia%2C%20Nuno%20Morerio%2C%20Pietro%20Murino%2C%20Vittorio%20Modality%20distillation%20with%20multiple%20stream%20networks%20for%20action%20recognition%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Garcia%2C%20Nuno%20Morerio%2C%20Pietro%20Murino%2C%20Vittorio%20Modality%20distillation%20with%20multiple%20stream%20networks%20for%20action%20recognition%202018"
        },
        {
            "id": "Goodfellow_et+al_2014_a",
            "entry": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in Neural Information Processing Systems, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "Handa_et+al_2016_a",
            "entry": "Ankur Handa, Viorica Patraucean, Vijay Badrinarayanan, Simon Stent, and Roberto Cipolla. Understanding real world indoor scenes with synthetic data. In Computer Vision and Pattern Recognition, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Handa%2C%20Ankur%20Patraucean%2C%20Viorica%20Badrinarayanan%2C%20Vijay%20Stent%2C%20Simon%20Understanding%20real%20world%20indoor%20scenes%20with%20synthetic%20data%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Handa%2C%20Ankur%20Patraucean%2C%20Viorica%20Badrinarayanan%2C%20Vijay%20Stent%2C%20Simon%20Understanding%20real%20world%20indoor%20scenes%20with%20synthetic%20data%202016"
        },
        {
            "id": "He_et+al_2016_a",
            "entry": "K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Computer Vision and Pattern Recognition, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20K.%20Zhang%2C%20X.%20Ren%2C%20S.%20Sun%2C%20J.%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "Herath_et+al_2017_a",
            "entry": "Samitha Herath, Mehrtash Harandi, and Fatih Porikli. Learning an invariant hilbert space for domain adaptation. In Computer Vision and Pattern Recognition, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Herath%2C%20Samitha%20Harandi%2C%20Mehrtash%20Porikli%2C%20Fatih%20Learning%20an%20invariant%20hilbert%20space%20for%20domain%20adaptation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Herath%2C%20Samitha%20Harandi%2C%20Mehrtash%20Porikli%2C%20Fatih%20Learning%20an%20invariant%20hilbert%20space%20for%20domain%20adaptation%202017"
        },
        {
            "id": "Hinton_et+al_2015_a",
            "entry": "Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1503.02531"
        },
        {
            "id": "Hoffman_et+al_2013_a",
            "entry": "Judy Hoffman, Erik Rodner, Jeff Donahue, Kate Saenko, and Trevor Darrell. Efficient learning of domain-invariant image representations. In International Conference on Learning Representations, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hoffman%2C%20Judy%20Rodner%2C%20Erik%20Donahue%2C%20Jeff%20Saenko%2C%20Kate%20Efficient%20learning%20of%20domain-invariant%20image%20representations%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hoffman%2C%20Judy%20Rodner%2C%20Erik%20Donahue%2C%20Jeff%20Saenko%2C%20Kate%20Efficient%20learning%20of%20domain-invariant%20image%20representations%202013"
        },
        {
            "id": "Hoffman_et+al_2016_a",
            "entry": "Judy Hoffman, Saurabh Gupta, and Trevor Darrell. Learning with side information through modality hallucination. In Computer Vision and Pattern Recognition, 2016a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hoffman%2C%20Judy%20Gupta%2C%20Saurabh%20Darrell%2C%20Trevor%20Learning%20with%20side%20information%20through%20modality%20hallucination%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hoffman%2C%20Judy%20Gupta%2C%20Saurabh%20Darrell%2C%20Trevor%20Learning%20with%20side%20information%20through%20modality%20hallucination%202016"
        },
        {
            "id": "Hoffman_0000_a",
            "entry": "Judy Hoffman, Dequan Wang, Fisher Yu, and Trevor Darrell. Fcns in the wild: Pixel-level adversarial and constraint-based adaptation. arXiv preprint arXiv:1612.02649, 2016b.",
            "arxiv_url": "https://arxiv.org/pdf/1612.02649"
        },
        {
            "id": "Isola_et+al_2017_a",
            "entry": "Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A. Efros. Image-to-image translation with conditional adversarial networks. In Computer Vision and Pattern Recognition, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Isola%2C%20Phillip%20Zhu%2C%20Jun-Yan%20Zhou%2C%20Tinghui%20Efros%2C%20Alexei%20A.%20Image-to-image%20translation%20with%20conditional%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Isola%2C%20Phillip%20Zhu%2C%20Jun-Yan%20Zhou%2C%20Tinghui%20Efros%2C%20Alexei%20A.%20Image-to-image%20translation%20with%20conditional%20adversarial%20networks%202017"
        },
        {
            "id": "Johnson_et+al_2016_a",
            "entry": "Justin Johnson, Alexandre Alahi, and Li Fei-Fei. Perceptual losses for real-time style transfer and super-resolution. In European Conference on Computer Vision. Springer, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnson%2C%20Justin%20Alahi%2C%20Alexandre%20Fei-Fei%2C%20Li%20Perceptual%20losses%20for%20real-time%20style%20transfer%20and%20super-resolution%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnson%2C%20Justin%20Alahi%2C%20Alexandre%20Fei-Fei%2C%20Li%20Perceptual%20losses%20for%20real-time%20style%20transfer%20and%20super-resolution%202016"
        },
        {
            "id": "Kim_et+al_2017_a",
            "entry": "Taeksoo Kim, Moonsu Cha, Hyunsoo Kim, Jung Kwon Lee, and Jiwon Kim. Learning to discover cross-domain relations with generative adversarial networks. In International Conference on Machine Learning, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Kim%2C%20Taeksoo%20Cha%2C%20Moonsu%20Kim%2C%20Hyunsoo%20Lee%2C%20Jung%20Kwon%20Learning%20to%20discover%20cross-domain%20relations%20with%20generative%20adversarial%20networks%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Kim%2C%20Taeksoo%20Cha%2C%20Moonsu%20Kim%2C%20Hyunsoo%20Lee%2C%20Jung%20Kwon%20Learning%20to%20discover%20cross-domain%20relations%20with%20generative%20adversarial%20networks%202017"
        },
        {
            "id": "Kingma_2014_a",
            "entry": "Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.6980"
        },
        {
            "id": "Li_et+al_2014_a",
            "entry": "Wen Li, Li Niu, and Dong Xu. Exploiting privileged information from web data for image categorization. In European Conference on Computer Vision, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Li%2C%20Wen%20Niu%2C%20Li%20Xu%2C%20Dong%20Exploiting%20privileged%20information%20from%20web%20data%20for%20image%20categorization%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Li%2C%20Wen%20Niu%2C%20Li%20Xu%2C%20Dong%20Exploiting%20privileged%20information%20from%20web%20data%20for%20image%20categorization%202014"
        },
        {
            "id": "Liu_et+al_2017_a",
            "entry": "Ming-Yu Liu, Thomas Breuel, and Jan Kautz. Unsupervised image-to-image translation networks. arXiv preprint arXiv:1703.00848, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.00848"
        },
        {
            "id": "Long_et+al_2015_a",
            "entry": "Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features with deep adaptation networks. In International Conference on Machine Learning, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Long%2C%20Mingsheng%20Cao%2C%20Yue%20Wang%2C%20Jianmin%20Jordan%2C%20Michael%20Learning%20transferable%20features%20with%20deep%20adaptation%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Long%2C%20Mingsheng%20Cao%2C%20Yue%20Wang%2C%20Jianmin%20Jordan%2C%20Michael%20Learning%20transferable%20features%20with%20deep%20adaptation%20networks%202015"
        },
        {
            "id": "Lopez-Paz_et+al_2015_a",
            "entry": "David Lopez-Paz, Lon Bottou, Bernhard Schlkopf, and Vladimir Vapnik. Unifying distillation and privileged information. arXiv preprint arXiv:1511.03643, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.03643"
        },
        {
            "id": "Mao_et+al_2016_a",
            "entry": "Xudong Mao, Qing Li, Haoran Xie, Raymond YK Lau, and Zhen Wang. Multi-class generative adversarial networks with the l2 loss function. arXiv preprint arXiv:1611.04076, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.04076"
        },
        {
            "id": "Mar_et+al_2010_a",
            "entry": "Javier Mar\u0131n, David Vazquez, David Geronimo, and Antonio M. Lopez. Learning appearance in virtual scenarios for pedestrian detection. In Computer Vision and Pattern Recognition, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mar%C4%B1n%2C%20Javier%20Vazquez%2C%20David%20Geronimo%2C%20David%20Lopez%2C%20Antonio%20M.%20Learning%20appearance%20in%20virtual%20scenarios%20for%20pedestrian%20detection%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mar%C4%B1n%2C%20Javier%20Vazquez%2C%20David%20Geronimo%2C%20David%20Lopez%2C%20Antonio%20M.%20Learning%20appearance%20in%20virtual%20scenarios%20for%20pedestrian%20detection%202010"
        },
        {
            "id": "Mayer_et+al_2016_a",
            "entry": "Nikolaus Mayer, Eddy Ilg, Philip Hausser, Philipp Fischer, Daniel Cremers, Alexey Dosovitskiy, and Thomas Brox. A large dataset to train convolutional networks for disparity, optical flow, and scene flow estimation. In Computer Vision and Pattern Recognition, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mayer%2C%20Nikolaus%20Ilg%2C%20Eddy%20Hausser%2C%20Philip%20Fischer%2C%20Philipp%20A%20large%20dataset%20to%20train%20convolutional%20networks%20for%20disparity%2C%20optical%20flow%2C%20and%20scene%20flow%20estimation%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mayer%2C%20Nikolaus%20Ilg%2C%20Eddy%20Hausser%2C%20Philip%20Fischer%2C%20Philipp%20A%20large%20dataset%20to%20train%20convolutional%20networks%20for%20disparity%2C%20optical%20flow%2C%20and%20scene%20flow%20estimation%202016"
        },
        {
            "id": "Neuhold_et+al_2017_a",
            "entry": "Gerhard Neuhold, Tobias Ollmann, Samuel Rota Bulo, and Peter Kontschieder. The mapillary vistas dataset for semantic understanding of street scenes. In International Conference on Computer Vision, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Neuhold%2C%20Gerhard%20Ollmann%2C%20Tobias%20Bulo%2C%20Samuel%20Rota%20Kontschieder%2C%20Peter%20The%20mapillary%20vistas%20dataset%20for%20semantic%20understanding%20of%20street%20scenes%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Neuhold%2C%20Gerhard%20Ollmann%2C%20Tobias%20Bulo%2C%20Samuel%20Rota%20Kontschieder%2C%20Peter%20The%20mapillary%20vistas%20dataset%20for%20semantic%20understanding%20of%20street%20scenes%202017"
        },
        {
            "id": "Papon_2015_a",
            "entry": "Jeremie Papon and Markus Schoeler. Semantic pose using deep networks trained on synthetic RGBD. In International Conference on Computer Vision, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Papon%2C%20Jeremie%20Schoeler%2C%20Markus%20Semantic%20pose%20using%20deep%20networks%20trained%20on%20synthetic%20RGBD%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Papon%2C%20Jeremie%20Schoeler%2C%20Markus%20Semantic%20pose%20using%20deep%20networks%20trained%20on%20synthetic%20RGBD%202015"
        },
        {
            "id": "Paszke_2017_a",
            "entry": "Adam Paszke, Sam Gross, Soumith Chintala, et al. Pytorch, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Paszke%2C%20Adam%20Gross%2C%20Sam%20Soumith%20Chintala%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Paszke%2C%20Adam%20Gross%2C%20Sam%20Soumith%20Chintala%202017"
        },
        {
            "id": "Peng_et+al_2015_a",
            "entry": "Xingchao Peng, Baochen Sun, Karim Ali, and Kate Saenko. Learning deep object detectors from 3D models. In International Conference on Computer Vision, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Peng%2C%20Xingchao%20Sun%2C%20Baochen%20Ali%2C%20Karim%20Saenko%2C%20Kate%20Learning%20deep%20object%20detectors%20from%203D%20models%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Peng%2C%20Xingchao%20Sun%2C%20Baochen%20Ali%2C%20Karim%20Saenko%2C%20Kate%20Learning%20deep%20object%20detectors%20from%203D%20models%202015"
        },
        {
            "id": "Purushotham_et+al_2017_a",
            "entry": "Sanjay Purushotham, Wilka Carvalho, Tanachat Nilanon, and Yan Liu. Variational recurrent adversarial deep domain adaptation. In International Conference on Learning Representations, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Purushotham%2C%20Sanjay%20Carvalho%2C%20Wilka%20Nilanon%2C%20Tanachat%20Liu%2C%20Yan%20Variational%20recurrent%20adversarial%20deep%20domain%20adaptation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Purushotham%2C%20Sanjay%20Carvalho%2C%20Wilka%20Nilanon%2C%20Tanachat%20Liu%2C%20Yan%20Variational%20recurrent%20adversarial%20deep%20domain%20adaptation%202017"
        },
        {
            "id": "Richter_et+al_2016_a",
            "entry": "Stephan R. Richter, Vibhav Vineet, Stefan Roth, and Koltun Vladlen. Playing for data: Ground truth from computer games. In European Conference on Computer Vision, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Richter%2C%20Stephan%20R.%20Vineet%2C%20Vibhav%20Roth%2C%20Stefan%20Vladlen%2C%20Koltun%20Playing%20for%20data%3A%20Ground%20truth%20from%20computer%20games%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Richter%2C%20Stephan%20R.%20Vineet%2C%20Vibhav%20Roth%2C%20Stefan%20Vladlen%2C%20Koltun%20Playing%20for%20data%3A%20Ground%20truth%20from%20computer%20games%202016"
        },
        {
            "id": "Ros_et+al_2016_a",
            "entry": "German Ros, Laura Sellart, Joanna Materzyska, David Vazquez, and Antonio M. Lopez. The SYNTHIA dataset: a large collection of synthetic images for semantic segmentation of urban scenes. In Computer Vision and Pattern Recognition, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ros%2C%20German%20Sellart%2C%20Laura%20Materzyska%2C%20Joanna%20Vazquez%2C%20David%20The%20SYNTHIA%20dataset%3A%20a%20large%20collection%20of%20synthetic%20images%20for%20semantic%20segmentation%20of%20urban%20scenes%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ros%2C%20German%20Sellart%2C%20Laura%20Materzyska%2C%20Joanna%20Vazquez%2C%20David%20The%20SYNTHIA%20dataset%3A%20a%20large%20collection%20of%20synthetic%20images%20for%20semantic%20segmentation%20of%20urban%20scenes%202016"
        },
        {
            "id": "Saleh_et+al_2018_a",
            "entry": "Fatemeh Sadat Saleh, Mohammad Sadegh Aliakbarian, Mathieu Salzmann, Lars Petersson, and Jose M. Alvarez. Effective use of synthetic data for urban scene semantic segmentation. In European Conference on Computer Vision, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Saleh%2C%20Fatemeh%20Sadat%20Aliakbarian%2C%20Mohammad%20Sadegh%20Salzmann%2C%20Mathieu%20Petersson%2C%20Lars%20Effective%20use%20of%20synthetic%20data%20for%20urban%20scene%20semantic%20segmentation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Saleh%2C%20Fatemeh%20Sadat%20Aliakbarian%2C%20Mohammad%20Sadegh%20Salzmann%2C%20Mathieu%20Petersson%2C%20Lars%20Effective%20use%20of%20synthetic%20data%20for%20urban%20scene%20semantic%20segmentation%202018"
        },
        {
            "id": "Saito_et+al_2017_a",
            "entry": "Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tatsuya Harada. Maximum classifier discrepancy for unsupervised domain adaptation. arXiv preprint arXiv:1712.02560, 3, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.02560"
        },
        {
            "id": "Sankaranarayanan_et+al_2018_a",
            "entry": "Swami Sankaranarayanan, Yogesh Balaji, Arpit Jain, Ser Nam Lim, and Rama Chellappa. Learning from synthetic data: Addressing domain shift for semantic segmentation. In Computer Vision and Pattern Recognition, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sankaranarayanan%2C%20Swami%20Balaji%2C%20Yogesh%20Jain%2C%20Arpit%20Lim%2C%20Ser%20Nam%20Learning%20from%20synthetic%20data%3A%20Addressing%20domain%20shift%20for%20semantic%20segmentation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sankaranarayanan%2C%20Swami%20Balaji%2C%20Yogesh%20Jain%2C%20Arpit%20Lim%2C%20Ser%20Nam%20Learning%20from%20synthetic%20data%3A%20Addressing%20domain%20shift%20for%20semantic%20segmentation%202018"
        },
        {
            "id": "Sarafianos_2017_a",
            "entry": "Nikolaos Sarafianos, Michalis Vrigkas, and Ioannis A Kakadiaris. Adaptive svm+: Learning with privileged information for domain adaptation. arXiv preprint arXiv:1708.09083, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1708.09083"
        },
        {
            "id": "Shotton_et+al_2011_a",
            "entry": "Jamie Shotton, Andrew Fitzgibbon, Mat Cook, Toby Sharp, Mark Finocchio, Richard Moore, Alex Kipmanand, and Andrew Blake. Real-time human pose recognition in parts from a single depth image. In Computer Vision and Pattern Recognition, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shotton%2C%20Jamie%20Fitzgibbon%2C%20Andrew%20Cook%2C%20Mat%20Sharp%2C%20Toby%20Real-time%20human%20pose%20recognition%20in%20parts%20from%20a%20single%20depth%20image%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shotton%2C%20Jamie%20Fitzgibbon%2C%20Andrew%20Cook%2C%20Mat%20Sharp%2C%20Toby%20Real-time%20human%20pose%20recognition%20in%20parts%20from%20a%20single%20depth%20image%202011"
        },
        {
            "id": "Shrivastava_et+al_2016_a",
            "entry": "Ashish Shrivastava, Tomas Pfister, Oncel Tuzel, Josh Susskind, Wenda Wang, and Russ Webb. Learning from simulated and unsupervised images through adversarial training. arXiv preprint arXiv:1612.07828, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1612.07828"
        },
        {
            "id": "Su_et+al_2015_a",
            "entry": "Hao Su, Charles R. Qi, Yangyan Yi, and Leonidas Guibas. Render for CNN: viewpoint estimation in images using CNNs trained with rendered 3D model views. In International Conference on Computer Vision, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Su%2C%20Hao%20Qi%2C%20Charles%20R.%20Yi%2C%20Yangyan%20Guibas%2C%20Leonidas%20Render%20for%20CNN%3A%20viewpoint%20estimation%20in%20images%20using%20CNNs%20trained%20with%20rendered%203D%20model%20views%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Su%2C%20Hao%20Qi%2C%20Charles%20R.%20Yi%2C%20Yangyan%20Guibas%2C%20Leonidas%20Render%20for%20CNN%3A%20viewpoint%20estimation%20in%20images%20using%20CNNs%20trained%20with%20rendered%203D%20model%20views%202015"
        },
        {
            "id": "Baochen_2014_a",
            "entry": "Baochen Sun and Kate Saenko. From virtual to reality: Fast adaptation of virtual object detectors to real domains. In British Machine Vision Conference, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Baochen%20Sun%20and%20Kate%20Saenko%20From%20virtual%20to%20reality%20Fast%20adaptation%20of%20virtual%20object%20detectors%20to%20real%20domains%20In%20British%20Machine%20Vision%20Conference%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Baochen%20Sun%20and%20Kate%20Saenko%20From%20virtual%20to%20reality%20Fast%20adaptation%20of%20virtual%20object%20detectors%20to%20real%20domains%20In%20British%20Machine%20Vision%20Conference%202014"
        },
        {
            "id": "Taigman_et+al_2016_a",
            "entry": "Yaniv Taigman, Adam Polyak, and Lior Wolf. Unsupervised cross-domain image generation. arXiv preprint arXiv:1611.02200, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.02200"
        },
        {
            "id": "Tsai_et+al_2018_a",
            "entry": "Yi-Hsuan Tsai, Wei-Chih Hung, Samuel Schulter, Kihyuk Sohn, Ming-Hsuan Yang, and Manmohan Chandraker. Learning to adapt structured output space for semantic segmentation. In Computer Vision and Pattern Recognition, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tsai%2C%20Yi-Hsuan%20Hung%2C%20Wei-Chih%20Schulter%2C%20Samuel%20Sohn%2C%20Kihyuk%20Learning%20to%20adapt%20structured%20output%20space%20for%20semantic%20segmentation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tsai%2C%20Yi-Hsuan%20Hung%2C%20Wei-Chih%20Schulter%2C%20Samuel%20Sohn%2C%20Kihyuk%20Learning%20to%20adapt%20structured%20output%20space%20for%20semantic%20segmentation%202018"
        },
        {
            "id": "Tzeng_et+al_2014_a",
            "entry": "Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and Trevor Darrell. Deep domain confusion: Maximizing for domain invariance. arXiv preprint arXiv:1412.3474, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.3474"
        },
        {
            "id": "Vapnik_2009_a",
            "entry": "Vladimir Vapnik and Akshay Vashist. A new learning paradigm: Learning using privileged information. Neural Networks, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vapnik%2C%20Vladimir%20Vashist%2C%20Akshay%20A%20new%20learning%20paradigm%3A%20Learning%20using%20privileged%20information%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vapnik%2C%20Vladimir%20Vashist%2C%20Akshay%20A%20new%20learning%20paradigm%3A%20Learning%20using%20privileged%20information%202009"
        },
        {
            "id": "Vazquez_et+al_2014_a",
            "entry": "David Vazquez, Antonio M. Lopez, Javier Mar\u0131n, Daniel Ponsa, and David Geronimo. Virtual and real world adaptation for pedestrian detection. Transactions on Pattern Analysis and Machine Intelligence, 36(4):797 \u2013 809, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vazquez%2C%20David%20Lopez%2C%20Antonio%20M.%20Mar%C4%B1n%2C%20Javier%20Ponsa%2C%20Daniel%20Virtual%20and%20real%20world%20adaptation%20for%20pedestrian%20detection%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vazquez%2C%20David%20Lopez%2C%20Antonio%20M.%20Mar%C4%B1n%2C%20Javier%20Ponsa%2C%20Daniel%20Virtual%20and%20real%20world%20adaptation%20for%20pedestrian%20detection%202014"
        },
        {
            "id": "Witten_et+al_2016_a",
            "entry": "Ian H Witten, Eibe Frank, Mark A Hall, and Christopher J Pal. Data Mining: Practical machine learning tools and techniques. Morgan Kaufmann, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Witten%2C%20Ian%20H.%20Frank%2C%20Eibe%20Hall%2C%20Mark%20A.%20Pal%2C%20Christopher%20J.%20Data%20Mining%3A%20Practical%20machine%20learning%20tools%20and%20techniques%202016"
        },
        {
            "id": "Xu_et+al_2014_a",
            "entry": "Jiaolong Xu, David Vazquez, Antonio M. Lopez, Javier Mar\u0131n, and Daniel Ponsa. Learning a partbased pedestrian detector in a virtual world. Transaction on Intelligent Transportation Systems, 15(5):2121\u20132131, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xu%2C%20Jiaolong%20Vazquez%2C%20David%20Lopez%2C%20Antonio%20M.%20Mar%C4%B1n%2C%20Javier%20Learning%20a%20partbased%20pedestrian%20detector%20in%20a%20virtual%20world%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xu%2C%20Jiaolong%20Vazquez%2C%20David%20Lopez%2C%20Antonio%20M.%20Mar%C4%B1n%2C%20Javier%20Learning%20a%20partbased%20pedestrian%20detector%20in%20a%20virtual%20world%202014"
        },
        {
            "id": "Yan_et+al_2017_a",
            "entry": "Ke Yan, Lu Kou, and David Zhang. Learning domain-invariant subspace using domain features and independence maximization. Transactions on Cybernetics, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yan%2C%20Ke%20Kou%2C%20Lu%20Zhang%2C%20David%20Learning%20domain-invariant%20subspace%20using%20domain%20features%20and%20independence%20maximization%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yan%2C%20Ke%20Kou%2C%20Lu%20Zhang%2C%20David%20Learning%20domain-invariant%20subspace%20using%20domain%20features%20and%20independence%20maximization%202017"
        },
        {
            "id": "Zhang_et+al_2017_a",
            "entry": "Yang Zhang, Philip David, and Boqing Gong. Curriculum domain adaptation for semantic segmentation of urban scenes. In International Conference on Computer Vision, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Yang%20David%2C%20Philip%20Gong%2C%20Boqing%20Curriculum%20domain%20adaptation%20for%20semantic%20segmentation%20of%20urban%20scenes%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Yang%20David%2C%20Philip%20Gong%2C%20Boqing%20Curriculum%20domain%20adaptation%20for%20semantic%20segmentation%20of%20urban%20scenes%202017"
        },
        {
            "id": "Zhang_et+al_2018_a",
            "entry": "Yiheng Zhang, Zhaofan Qiu, Ting Yao, Dong Liu, and Tao Mei. Fully convolutional adaptation networks for semantic segmentation. In Computer Vision and Pattern Recognition, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Yiheng%20Qiu%2C%20Zhaofan%20Yao%2C%20Ting%20Liu%2C%20Dong%20Fully%20convolutional%20adaptation%20networks%20for%20semantic%20segmentation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Yiheng%20Qiu%2C%20Zhaofan%20Yao%2C%20Ting%20Liu%2C%20Dong%20Fully%20convolutional%20adaptation%20networks%20for%20semantic%20segmentation%202018"
        },
        {
            "id": "Zhu_et+al_2019_a",
            "entry": "Published as a conference paper at ICLR 2019 Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A. Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. In International Conference on Computer Vision, 2017. Yang Zou, Zhiding Yu, BVK Vijaya Kumar, and Jinsong Wang. Unsupervised domain adaptation for semantic segmentation via class-balanced self-training. In European Conference on Computer Vision, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhu%2C%20Jun-Yan%20Park%2C%20Taesung%20Isola%2C%20Phillip%20Efros%2C%20Alexei%20A.%20Published%20as%20a%20conference%20paper%20at%20ICLR%202019",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhu%2C%20Jun-Yan%20Park%2C%20Taesung%20Isola%2C%20Phillip%20Efros%2C%20Alexei%20A.%20Published%20as%20a%20conference%20paper%20at%20ICLR%202019"
        }
    ]
}

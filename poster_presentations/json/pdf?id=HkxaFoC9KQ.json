{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "DEEP REINFORCEMENT LEARNING WITH RELATIONAL",
        "author": "INDUCTIVE BIASES",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=HkxaFoC9KQ"
        },
        "abstract": "We introduce an approach for augmenting model-free deep reinforcement learning agents with a mechanism for relational reasoning over structured representations, which improves performance, learning efficiency, generalization, and interpretability. Our architecture encodes an image as a set of vectors, and applies an iterative message-passing procedure to discover and reason about relevant entities and relations in a scene. In six of seven StarCraft II Learning Environment mini-games, our agent achieved state-of-the-art performance, and surpassed human grandmasterlevel on four. In a novel navigation and planning task, our agent\u2019s performance and learning efficiency far exceeded non-relational baselines, it was able to generalize to more complex scenes than it had experienced during training. Moreover, when we examined its learned internal representations, they reflected important structure about the problem and the agent\u2019s intentions. The main contribution of this work is to introduce techniques for representing and reasoning about states in model-free deep reinforcement learning agents via relational inductive biases. Our experiments show this approach can offer advantages in efficiency, generalization, and interpretability, and can scale up to meet some of the most challenging test environments in modern artificial intelligence."
    },
    "keywords": [
        {
            "term": "physics",
            "url": "https://en.wikipedia.org/wiki/physics"
        },
        {
            "term": "convolutional neural network",
            "url": "https://en.wikipedia.org/wiki/convolutional_neural_network"
        },
        {
            "term": "multilayer perceptron",
            "url": "https://en.wikipedia.org/wiki/multilayer_perceptron"
        },
        {
            "term": "internal representation",
            "url": "https://en.wikipedia.org/wiki/internal_representation"
        },
        {
            "term": "reinforcement learning",
            "url": "https://en.wikipedia.org/wiki/reinforcement_learning"
        },
        {
            "term": "inductive bias",
            "url": "https://en.wikipedia.org/wiki/inductive_bias"
        }
    ],
    "abbreviations": {
        "RL": "reinforcement learning",
        "CNN": "convolutional neural network",
        "MHDPA": "multi-head dotproduct attention",
        "MLP": "multilayer perceptron",
        "CMS": "Collect Mineral Shards",
        "DR": "Defeat Roaches",
        "DZB": "Defeat Zerglings and Banelings"
    },
    "highlights": [
        "Recent deep reinforcement learning (RL) systems have achieved remarkable performance in very challenging problem domains (<a class=\"ref-link\" id=\"cMnih_et+al_2015_a\" href=\"#rMnih_et+al_2015_a\"><a class=\"ref-link\" id=\"cMnih_et+al_2015_a\" href=\"#rMnih_et+al_2015_a\">Mnih et al, 2015</a></a>; <a class=\"ref-link\" id=\"cSilver_et+al_2016_a\" href=\"#rSilver_et+al_2016_a\"><a class=\"ref-link\" id=\"cSilver_et+al_2016_a\" href=\"#rSilver_et+al_2016_a\">Silver et al, 2016</a></a>), in large part because of their flexibility in how they learn and exploit the statistical structure underlying observations and reward signals",
        "Drawing on several lines of work, we introduce an approach for incorporating relational inductive biases for entity- and relation-centric state representations, and iterated relational reasoning, into a deep reinforcement learning agent",
        "For Collect Mineral Shards, Defeat Roaches and Defeat Zerglings and Banelings, the relational agent improved relative to the control agent by 9, 8 and 134 points, with a standard error of 1.5, 6.4 and 18.2, respectively",
        "We focus on differences afforded by relational inductive biases and turn to particular generalization tests to determine the behavioural traits of the control and relational agents",
        "Our approach may interface well with approaches for hierarchical reinforcement learning (<a class=\"ref-link\" id=\"cVezhnevets_et+al_2017_a\" href=\"#rVezhnevets_et+al_2017_a\">Vezhnevets et al, 2017</a>), planning (<a class=\"ref-link\" id=\"cGuez_et+al_2018_a\" href=\"#rGuez_et+al_2018_a\">Guez et al, 2018</a>), and structured behavior representation (<a class=\"ref-link\" id=\"cHuang_et+al_2018_a\" href=\"#rHuang_et+al_2018_a\">Huang et al, 2018</a>), so that the structured internal representations and patterns of reasoning can translate into more structured behaviors"
    ],
    "key_statements": [
        "Recent deep reinforcement learning (RL) systems have achieved remarkable performance in very challenging problem domains (<a class=\"ref-link\" id=\"cMnih_et+al_2015_a\" href=\"#rMnih_et+al_2015_a\"><a class=\"ref-link\" id=\"cMnih_et+al_2015_a\" href=\"#rMnih_et+al_2015_a\">Mnih et al, 2015</a></a>; <a class=\"ref-link\" id=\"cSilver_et+al_2016_a\" href=\"#rSilver_et+al_2016_a\"><a class=\"ref-link\" id=\"cSilver_et+al_2016_a\" href=\"#rSilver_et+al_2016_a\">Silver et al, 2016</a></a>), in large part because of their flexibility in how they learn and exploit the statistical structure underlying observations and reward signals",
        "Drawing on several lines of work, we introduce an approach for incorporating relational inductive biases for entity- and relation-centric state representations, and iterated relational reasoning, into a deep reinforcement learning agent",
        "For Collect Mineral Shards, Defeat Roaches and Defeat Zerglings and Banelings, the relational agent improved relative to the control agent by 9, 8 and 134 points, with a standard error of 1.5, 6.4 and 18.2, respectively",
        "We focus on differences afforded by relational inductive biases and turn to particular generalization tests to determine the behavioural traits of the control and relational agents",
        "Our approach may interface well with approaches for hierarchical reinforcement learning (<a class=\"ref-link\" id=\"cVezhnevets_et+al_2017_a\" href=\"#rVezhnevets_et+al_2017_a\">Vezhnevets et al, 2017</a>), planning (<a class=\"ref-link\" id=\"cGuez_et+al_2018_a\" href=\"#rGuez_et+al_2018_a\">Guez et al, 2018</a>), and structured behavior representation (<a class=\"ref-link\" id=\"cHuang_et+al_2018_a\" href=\"#rHuang_et+al_2018_a\">Huang et al, 2018</a>), so that the structured internal representations and patterns of reasoning can translate into more structured behaviors"
    ],
    "summary": [
        "Recent deep reinforcement learning (RL) systems have achieved remarkable performance in very challenging problem domains (<a class=\"ref-link\" id=\"cMnih_et+al_2015_a\" href=\"#rMnih_et+al_2015_a\"><a class=\"ref-link\" id=\"cMnih_et+al_2015_a\" href=\"#rMnih_et+al_2015_a\">Mnih et al, 2015</a></a>; <a class=\"ref-link\" id=\"cSilver_et+al_2016_a\" href=\"#rSilver_et+al_2016_a\"><a class=\"ref-link\" id=\"cSilver_et+al_2016_a\" href=\"#rSilver_et+al_2016_a\">Silver et al, 2016</a></a>), in large part because of their flexibility in how they learn and exploit the statistical structure underlying observations and reward signals.",
        "Our agent reaches higher ceiling performance, more efficiently, than non-relational baseline, and is able to generalize to solve problems with more complex solutions than it had been trained on within this task.",
        "A key can only be used once, so the agent must be able to reason about whether a particular box is along a distractor branch or along the solution path.",
        "Agents augmented with our relational module achieved close to optimal performance in the two variants of this task, solving more than 98% of the levels.",
        "In the task variant with short distractor branches, an agent with a single relational block was able to achieve top performance.",
        "GENERALIZATION CAPABILITY: TESTING ON WITHHELD ENVIRONMENTS As we observed, the attention weights captured a link between a key and its corresponding lock, using a shared computation across entities.",
        "If the function used to compute the weights has learned to represent some general, abstract notion of what it means to \u201cunlock\u201d \u2013 e.g., unlocks \u2013 this function should be able to generalize to key-lock combinations that it has never observed during training.",
        "We tested the model under two conditions, without further training: 1) on levels that required opening a longer sequence of boxes than it had ever observed (6, 8 and 10), and 2) on levels that required using a key-lock combination that was never required for reaching the gem during training, instead only being placed on distractor paths.",
        "The performance of the agent trained without the relational module collapsed to 5% when tested on sequences of 6 boxes, and to 0% on sequences of 8 and 10.",
        "The agent augmented with a relational module achieved state-of-the-art results in six mini-games and its performance surpassed that of the human grandmaster in four of them3.",
        "As observed in Box-World, a capacity to better understand underlying relational structure \u2013 rather than latch onto superficial statistics \u2013 may manifest in better generalization to never-before-seen situations.",
        "Qualitative analysis of the policies revealed distinct behaviours for the best performing control and relational agents: while the former adopted a \"land sweep strategy\", controlling many units as a group to cover the space, the latter managed to independently control several units simultaneously, suggesting a finer grained understanding of the game dynamics.",
        "By introducing structured perception and relational reasoning into deep RL architectures, our agents can learn interpretable representations, and exceed baseline agents in terms of sample complexity, ability to generalize, and overall performance.",
        "Our work opens new directions for RL via a principled hybrid of flexible statistical learning and more structured approaches"
    ],
    "headline": "We introduce an approach for augmenting model-free deep reinforcement learning agents with a mechanism for relational reasoning over structured representations, which improves performance, learning efficiency, generalization, and interpretability",
    "reference_links": [
        {
            "id": "Allamanis_et+al_2017_a",
            "entry": "Miltiadis Allamanis, Pankajan Chanthirasegaran, Pushmeet Kohli, and Charles Sutton. Learning continuous semantic representations of symbolic expressions. In Proceedings of the International Conference on Machine Learning (ICML), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Allamanis%2C%20Miltiadis%20Chanthirasegaran%2C%20Pankajan%20Kohli%2C%20Pushmeet%20Sutton%2C%20Charles%20Learning%20continuous%20semantic%20representations%20of%20symbolic%20expressions%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Allamanis%2C%20Miltiadis%20Chanthirasegaran%2C%20Pankajan%20Kohli%2C%20Pushmeet%20Sutton%2C%20Charles%20Learning%20continuous%20semantic%20representations%20of%20symbolic%20expressions%202017"
        },
        {
            "id": "Ba_et+al_2016_a",
            "entry": "Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint arXiv:1607.06450, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1607.06450"
        },
        {
            "id": "Battaglia_et+al_2016_a",
            "entry": "Peter Battaglia, Razvan Pascanu, Matthew Lai, Danilo Jimenez Rezende, et al. Interaction networks for learning about objects, relations and physics. In Advances in neural information processing systems, pp. 4502\u20134510, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Battaglia%2C%20Peter%20Pascanu%2C%20Razvan%20Lai%2C%20Matthew%20Rezende%2C%20Danilo%20Jimenez%20Interaction%20networks%20for%20learning%20about%20objects%2C%20relations%20and%20physics%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Battaglia%2C%20Peter%20Pascanu%2C%20Razvan%20Lai%2C%20Matthew%20Rezende%2C%20Danilo%20Jimenez%20Interaction%20networks%20for%20learning%20about%20objects%2C%20relations%20and%20physics%202016"
        },
        {
            "id": "Battaglia_et+al_2018_a",
            "entry": "Peter W Battaglia, Jessica B Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, et al. Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1806.01261"
        },
        {
            "id": "Chen_et+al_2018_a",
            "entry": "Xinlei Chen, Li-Jia Li, Li Fei-Fei, and Abhinav Gupta. Iterative visual reasoning beyond convolutions. arXiv preprint arXiv:1803.11189, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.11189"
        },
        {
            "id": "Dai_et+al_2017_a",
            "entry": "Hanjun Dai, Elias Khalil, Yuyu Zhang, Bistra Dilkina, and Le Song. Learning combinatorial optimization algorithms over graphs. In Advances in Neural Information Processing Systems, pp. 6351\u20136361, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dai%2C%20Hanjun%20Khalil%2C%20Elias%20Zhang%2C%20Yuyu%20Dilkina%2C%20Bistra%20Learning%20combinatorial%20optimization%20algorithms%20over%20graphs%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dai%2C%20Hanjun%20Khalil%2C%20Elias%20Zhang%2C%20Yuyu%20Dilkina%2C%20Bistra%20Learning%20combinatorial%20optimization%20algorithms%20over%20graphs%202017"
        },
        {
            "id": "Devlin_et+al_2017_a",
            "entry": "Jacob Devlin, Jonathan Uesato, Rishabh Singh, and Pushmeet Kohli. Semantic code repair using neuro-symbolic transformation networks. arXiv preprint arXiv:1710.11054, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.11054"
        },
        {
            "id": "Diuk_et+al_2008_a",
            "entry": "Carlos Diuk, Andre Cohen, and Michael L Littman. An object-oriented representation for efficient reinforcement learning. In Proceedings of the 25th international conference on Machine learning, pp. 240\u2013247. ACM, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Diuk%2C%20Carlos%20Cohen%2C%20Andre%20Littman%2C%20Michael%20L.%20An%20object-oriented%20representation%20for%20efficient%20reinforcement%20learning%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Diuk%2C%20Carlos%20Cohen%2C%20Andre%20Littman%2C%20Michael%20L.%20An%20object-oriented%20representation%20for%20efficient%20reinforcement%20learning%202008"
        },
        {
            "id": "Driessens_2004_a",
            "entry": "Kurt Driessens and Saso Dzeroski. Integrating guidance into relational reinforcement learning. Machine Learning, 57(3):271\u2013304, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Driessens%2C%20Kurt%20Dzeroski%2C%20Saso%20Integrating%20guidance%20into%20relational%20reinforcement%20learning%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Driessens%2C%20Kurt%20Dzeroski%2C%20Saso%20Integrating%20guidance%20into%20relational%20reinforcement%20learning%202004"
        },
        {
            "id": "Dzeroski_et+al_2001_a",
            "entry": "Saso Dzeroski, Luc De Raedt, and Kurt Driessens. Relational reinforcement learning. Machine Learning, 43(1/2):7\u201352, 2001.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dzeroski%2C%20Saso%20Raedt%2C%20Luc%20De%20Driessens%2C%20Kurt%20Relational%20reinforcement%20learning%202001",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dzeroski%2C%20Saso%20Raedt%2C%20Luc%20De%20Driessens%2C%20Kurt%20Relational%20reinforcement%20learning%202001"
        },
        {
            "id": "Espeholt_et+al_2018_a",
            "entry": "Lasse Espeholt, Hubert Soyer, Remi Munos, Karen Simonyan, Volodymir Mnih, Tom Ward, Yotam Doron, Vlad Firoiu, Tim Harley, Iain Dunning, et al. Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures. arXiv preprint arXiv:1802.01561, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.01561"
        },
        {
            "id": "Evans_et+al_2018_a",
            "entry": "Richard Evans, David Saxton, David Amos, Pushmeet Kohli, and Edward Grefenstette. Can neural networks understand logical entailment? In Proceedings of the International Conference on Learning Representations (ICLR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Evans%2C%20Richard%20Saxton%2C%20David%20Amos%2C%20David%20Kohli%2C%20Pushmeet%20Can%20neural%20networks%20understand%20logical%20entailment%3F%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Evans%2C%20Richard%20Saxton%2C%20David%20Amos%2C%20David%20Kohli%2C%20Pushmeet%20Can%20neural%20networks%20understand%20logical%20entailment%3F%202018"
        },
        {
            "id": "Garnelo_et+al_2016_a",
            "entry": "Marta Garnelo, Kai Arulkumaran, and Murray Shanahan. Towards deep symbolic reinforcement learning. arXiv preprint arXiv:1609.05518, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1609.05518"
        },
        {
            "id": "Gilmer_et+al_2017_a",
            "entry": "Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural message passing for quantum chemistry. arXiv preprint arXiv:1704.01212, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.01212"
        },
        {
            "id": "Guez_et+al_2018_a",
            "entry": "Arthur Guez, Th\u00e9ophane Weber, Ioannis Antonoglou, Karen Simonyan, Oriol Vinyals, Daan Wierstra, R\u00e9mi Munos, and David Silver. Learning to search with mctsnets. arXiv preprint arXiv:1802.04697, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.04697"
        },
        {
            "id": "Hamrick_et+al_2017_a",
            "entry": "Jessica B Hamrick, Andrew J Ballard, Razvan Pascanu, Oriol Vinyals, Nicolas Heess, and Peter W Battaglia. Metacontrol for adaptive imagination-based optimization. arXiv preprint arXiv:1705.02670, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.02670"
        },
        {
            "id": "Hamrick_et+al_2018_a",
            "entry": "Jessica B Hamrick, Kelsey R Allen, Victor Bapst, Tina Zhu, Kevin R McKee, Joshua B Tenenbaum, and Peter W Battaglia. Relational inductive bias for physical construction in humans and machines. arXiv preprint arXiv:1806.01203, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1806.01203"
        },
        {
            "id": "Horgan_et+al_2018_a",
            "entry": "Dan Horgan, John Quan, David Budden, Gabriel Barth-Maron, Matteo Hessel, Hado Van Hasselt, and David Silver. Distributed prioritized experience replay. arXiv preprint arXiv:1803.00933, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.00933"
        },
        {
            "id": "Hoshen_2017_a",
            "entry": "Yedid Hoshen. Vain: Attentional multi-agent predictive modeling. In Advances in Neural Information Processing Systems, pp. 2701\u20132711, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Hoshen%2C%20Yedid%20Vain%3A%20Attentional%20multi-agent%20predictive%20modeling%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Hoshen%2C%20Yedid%20Vain%3A%20Attentional%20multi-agent%20predictive%20modeling%202017"
        },
        {
            "id": "Huang_et+al_2018_a",
            "entry": "De-An Huang, Suraj Nair, Danfei Xu, Yuke Zhu, Animesh Garg, Li Fei-Fei, Silvio Savarese, and Juan Carlos Niebles. Neural task graphs: Generalizing to unseen tasks from a single video demonstration. arXiv preprint arXiv:1807.03480, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1807.03480"
        },
        {
            "id": "Jaderberg_et+al_2017_a",
            "entry": "Max Jaderberg, Valentin Dalibard, Simon Osindero, Wojciech M Czarnecki, Jeff Donahue, Ali Razavi, Oriol Vinyals, Tim Green, Iain Dunning, Karen Simonyan, et al. Population based training of neural networks. arXiv preprint arXiv:1711.09846, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.09846"
        },
        {
            "id": "Kansky_et+al_2017_a",
            "entry": "Ken Kansky, Tom Silver, David A M\u00e9ly, Mohamed Eldawy, Miguel L\u00e1zaro-Gredilla, Xinghua Lou, Nimrod Dorfman, Szymon Sidor, Scott Phoenix, and Dileep George. Schema networks: Zero-shot transfer with a generative causal model of intuitive physics. arXiv preprint arXiv:1706.04317, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.04317"
        },
        {
            "id": "Kipf_et+al_2018_a",
            "entry": "Thomas Kipf, Ethan Fetaya, Kuan-Chieh Wang, Max Welling, and Richard Zemel. Neural relational inference for interacting systems. arXiv preprint arXiv:1802.04687, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.04687"
        },
        {
            "id": "Lake_et+al_2017_a",
            "entry": "Brenden M Lake, Tomer D Ullman, Joshua B Tenenbaum, and Samuel J Gershman. Building machines that learn and think like people. Behavioral and Brain Sciences, 40, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lake%2C%20Brenden%20M.%20Ullman%2C%20Tomer%20D.%20Tenenbaum%2C%20Joshua%20B.%20Gershman%2C%20Samuel%20J.%20Building%20machines%20that%20learn%20and%20think%20like%20people%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lake%2C%20Brenden%20M.%20Ullman%2C%20Tomer%20D.%20Tenenbaum%2C%20Joshua%20B.%20Gershman%2C%20Samuel%20J.%20Building%20machines%20that%20learn%20and%20think%20like%20people%202017"
        },
        {
            "id": "Li_et+al_2015_a",
            "entry": "Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. Gated graph sequence neural networks. arXiv preprint arXiv:1511.05493, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.05493"
        },
        {
            "id": "Liang_et+al_2016_a",
            "entry": "Chen Liang, Jonathan Berant, Quoc Le, Kenneth D Forbus, and Ni Lao. Neural symbolic machines: Learning semantic parsers on freebase with weak supervision. arXiv preprint arXiv:1611.00020, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1611.00020"
        },
        {
            "id": "Malinowski_et+al_2018_a",
            "entry": "Mateusz Malinowski, Carl Doersch, Adam Santoro, and Peter Battaglia. Learning visual question answering by bootstrapping hard attention. In Proceedings of the European Conference on Computer Vision (ECCV), pp. 3\u201320, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Malinowski%2C%20Mateusz%20Doersch%2C%20Carl%20Santoro%2C%20Adam%20Battaglia%2C%20Peter%20Learning%20visual%20question%20answering%20by%20bootstrapping%20hard%20attention%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Malinowski%2C%20Mateusz%20Doersch%2C%20Carl%20Santoro%2C%20Adam%20Battaglia%2C%20Peter%20Learning%20visual%20question%20answering%20by%20bootstrapping%20hard%20attention%202018"
        },
        {
            "id": "Mnih_et+al_2015_a",
            "entry": "Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, et al. Human-level control through deep reinforcement learning. Nature, 518(7540):529, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mnih%2C%20Volodymyr%20Kavukcuoglu%2C%20Koray%20Silver%2C%20David%20Rusu%2C%20Andrei%20A.%20Human-level%20control%20through%20deep%20reinforcement%20learning%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mnih%2C%20Volodymyr%20Kavukcuoglu%2C%20Koray%20Silver%2C%20David%20Rusu%2C%20Andrei%20A.%20Human-level%20control%20through%20deep%20reinforcement%20learning%202015"
        },
        {
            "id": "Mnih_et+al_2016_a",
            "entry": "Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. Asynchronous methods for deep reinforcement learning. In International conference on machine learning, pp. 1928\u20131937, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mnih%2C%20Volodymyr%20Badia%2C%20Adria%20Puigdomenech%20Mirza%2C%20Mehdi%20Graves%2C%20Alex%20Asynchronous%20methods%20for%20deep%20reinforcement%20learning%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mnih%2C%20Volodymyr%20Badia%2C%20Adria%20Puigdomenech%20Mirza%2C%20Mehdi%20Graves%2C%20Alex%20Asynchronous%20methods%20for%20deep%20reinforcement%20learning%202016"
        },
        {
            "id": "Neelakantan_et+al_2015_a",
            "entry": "Arvind Neelakantan, Quoc V Le, and Ilya Sutskever. Neural programmer: Inducing latent programs with gradient descent. arXiv preprint arXiv:1511.04834, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.04834"
        },
        {
            "id": "Parisotto_et+al_2017_a",
            "entry": "Emilio Parisotto, Abdel-rahman Mohamed, Rishabh Singh, Lihong Li, Dengyong Zhou, and Pushmeet Kohli. Neuro-symbolic program synthesis. In Proceedings of the International Conference on Learning Representations (ICLR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Parisotto%2C%20Emilio%20Mohamed%2C%20Abdel-rahman%20Singh%2C%20Rishabh%20Li%2C%20Lihong%20Neuro-symbolic%20program%20synthesis%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Parisotto%2C%20Emilio%20Mohamed%2C%20Abdel-rahman%20Singh%2C%20Rishabh%20Li%2C%20Lihong%20Neuro-symbolic%20program%20synthesis%202017"
        },
        {
            "id": "Pascanu_et+al_2017_a",
            "entry": "Razvan Pascanu, Yujia Li, Oriol Vinyals, Nicolas Heess, Lars Buesing, Sebastien Racani\u00e8re, David Reichert, Th\u00e9ophane Weber, Daan Wierstra, and Peter Battaglia. Learning model-based planning from scratch. arXiv preprint arXiv:1707.06170, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1707.06170"
        },
        {
            "id": "Raposo_et+al_2017_a",
            "entry": "David Raposo, Adam Santoro, David Barrett, Razvan Pascanu, Timothy Lillicrap, and Peter Battaglia. Discovering objects and their relations from entangled scene representations. arXiv preprint arXiv:1702.05068, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1702.05068"
        },
        {
            "id": "Reed_2015_a",
            "entry": "Scott Reed and Nando De Freitas. Neural programmer-interpreters. arXiv preprint arXiv:1511.06279, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06279"
        },
        {
            "id": "Sanchez-Gonzalez_et+al_2018_a",
            "entry": "Alvaro Sanchez-Gonzalez, Nicolas Heess, Jost Tobias Springenberg, Josh Merel, Martin Riedmiller, Raia Hadsell, and Peter Battaglia. Graph networks as learnable physics engines for inference and control. arXiv preprint arXiv:1806.01242, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1806.01242"
        },
        {
            "id": "Santoro_et+al_2017_a",
            "entry": "Adam Santoro, David Raposo, David G Barrett, Mateusz Malinowski, Razvan Pascanu, Peter Battaglia, and Tim Lillicrap. A simple neural network module for relational reasoning. In Advances in neural information processing systems, pp. 4974\u20134983, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Santoro%2C%20Adam%20Raposo%2C%20David%20Barrett%2C%20David%20G.%20Malinowski%2C%20Mateusz%20A%20simple%20neural%20network%20module%20for%20relational%20reasoning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Santoro%2C%20Adam%20Raposo%2C%20David%20Barrett%2C%20David%20G.%20Malinowski%2C%20Mateusz%20A%20simple%20neural%20network%20module%20for%20relational%20reasoning%202017"
        },
        {
            "id": "Scarselli_et+al_2009_a",
            "entry": "Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. The graph neural network model. IEEE Transactions on Neural Networks, 20(1):61\u201380, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Scarselli%2C%20Franco%20Gori%2C%20Marco%20Tsoi%2C%20Ah%20Chung%20Hagenbuchner%2C%20Markus%20The%20graph%20neural%20network%20model%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Scarselli%2C%20Franco%20Gori%2C%20Marco%20Tsoi%2C%20Ah%20Chung%20Hagenbuchner%2C%20Markus%20The%20graph%20neural%20network%20model%202009"
        },
        {
            "id": "Selsam_et+al_2018_a",
            "entry": "Daniel Selsam, Matthew Lamm, Benedikt Bunz, Percy Liang, Leonardo de Moura, and David L Dill. Learning a sat solver from single-bit supervision. arXiv preprint arXiv:1802.03685, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.03685"
        },
        {
            "id": "Silver_et+al_2016_a",
            "entry": "David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van Den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, et al. Mastering the game of go with deep neural networks and tree search. nature, 529(7587):484\u2013489, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Silver%2C%20David%20Huang%2C%20Aja%20Maddison%2C%20Chris%20J.%20Guez%2C%20Arthur%20Mastering%20the%20game%20of%20go%20with%20deep%20neural%20networks%20and%20tree%20search%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Silver%2C%20David%20Huang%2C%20Aja%20Maddison%2C%20Chris%20J.%20Guez%2C%20Arthur%20Mastering%20the%20game%20of%20go%20with%20deep%20neural%20networks%20and%20tree%20search%202016"
        },
        {
            "id": "Vaswani_et+al_2017_a",
            "entry": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in Neural Information Processing Systems, pp. 6000\u20136010, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ashish%20Vaswani%20Noam%20Shazeer%20Niki%20Parmar%20Jakob%20Uszkoreit%20Llion%20Jones%20Aidan%20N%20Gomez%20%C5%81ukasz%20Kaiser%20and%20Illia%20Polosukhin%20Attention%20is%20all%20you%20need%20In%20Advances%20in%20Neural%20Information%20Processing%20Systems%20pp%2060006010%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ashish%20Vaswani%20Noam%20Shazeer%20Niki%20Parmar%20Jakob%20Uszkoreit%20Llion%20Jones%20Aidan%20N%20Gomez%20%C5%81ukasz%20Kaiser%20and%20Illia%20Polosukhin%20Attention%20is%20all%20you%20need%20In%20Advances%20in%20Neural%20Information%20Processing%20Systems%20pp%2060006010%202017"
        },
        {
            "id": "Velickovic_et+al_2017_a",
            "entry": "Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. Graph attention networks. arXiv preprint arXiv:1710.10903, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1710.10903"
        },
        {
            "id": "Vezhnevets_et+al_2017_a",
            "entry": "Alexander Sasha Vezhnevets, Simon Osindero, Tom Schaul, Nicolas Heess, Max Jaderberg, David Silver, and Koray Kavukcuoglu. Feudal networks for hierarchical reinforcement learning. arXiv preprint arXiv:1703.01161, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1703.01161"
        },
        {
            "id": "Vinyals_et+al_2017_a",
            "entry": "Oriol Vinyals, Timo Ewalds, Sergey Bartunov, Petko Georgiev, Alexander Sasha Vezhnevets, Michelle Yeo, Alireza Makhzani, Heinrich K\u00fcttler, John Agapiou, Julian Schrittwieser, et al. Starcraft ii: a new challenge for reinforcement learning. arXiv preprint arXiv:1708.04782, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1708.04782"
        },
        {
            "id": "Wang_et+al_2018_a",
            "entry": "Tingwu Wang, Renjie Liao, Jimmy Ba, and Sanja Fidler. Nervenet: Learning structured policy with graph neural networks. Proceedings of the International Conference on Learning Representations (ICLR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wang%2C%20Tingwu%20Liao%2C%20Renjie%20Ba%2C%20Jimmy%20Fidler%2C%20Sanja%20Nervenet%3A%20Learning%20structured%20policy%20with%20graph%20neural%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wang%2C%20Tingwu%20Liao%2C%20Renjie%20Ba%2C%20Jimmy%20Fidler%2C%20Sanja%20Nervenet%3A%20Learning%20structured%20policy%20with%20graph%20neural%20networks%202018"
        },
        {
            "id": "Wang_et+al_2017_a",
            "entry": "Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He. Non-local neural networks. arXiv preprint arXiv:1711.07971, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1711.07971"
        },
        {
            "id": "Watters_et+al_2017_a",
            "entry": "Nicholas Watters, Andrea Tacchetti, Theophane Weber, Razvan Pascanu, Peter Battaglia, and Daniel Zoran. Visual interaction networks. arXiv preprint arXiv:1706.01433, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1706.01433"
        },
        {
            "id": "Weber_et+al_2017_a",
            "entry": "Th\u00e9ophane Weber, S\u00e9bastien Racani\u00e8re, David P Reichert, Lars Buesing, Arthur Guez, Danilo Jimenez Rezende, Adria Puigdom\u00e8nech Badia, Oriol Vinyals, Nicolas Heess, Yujia Li, et al. Imagination-augmented agents for deep reinforcement learning. arXiv preprint arXiv:1707.06203, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1707.06203"
        },
        {
            "id": "Xu_et+al_2017_a",
            "entry": "Danfei Xu, Yuke Zhu, Christopher B Choy, and Li Fei-Fei. Scene graph generation by iterative message passing. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, volume 2, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xu%2C%20Danfei%20Zhu%2C%20Yuke%20Choy%2C%20Christopher%20B.%20Fei-Fei%2C%20Li%20Scene%20graph%20generation%20by%20iterative%20message%20passing%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xu%2C%20Danfei%20Zhu%2C%20Yuke%20Choy%2C%20Christopher%20B.%20Fei-Fei%2C%20Li%20Scene%20graph%20generation%20by%20iterative%20message%20passing%202017"
        },
        {
            "id": "Zhang_et+al_2018_a",
            "entry": "Chiyuan Zhang, Oriol Vinyals, Remi Munos, and Samy Bengio. A study on overfitting in deep reinforcement learning. arXiv preprint arXiv:1804.06893, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.06893"
        }
    ]
}

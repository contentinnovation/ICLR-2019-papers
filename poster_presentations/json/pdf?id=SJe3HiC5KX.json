{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION",
        "author": "Mahsa Baktashmotlagh Masoud Faraki, Tom Drummond, Mathieu Salzmann University of Queensland Monash University Monash University EPFL",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=SJe3HiC5KX"
        },
        "abstract": "Domain adaptation for visual recognition has undergone great progress in the past few years. Nevertheless, most existing methods work in the so-called closed-set scenario, assuming that the classes depicted by the target images are exactly the same as those of the source domain. In this paper, we tackle the more challenging, yet more realistic case of open-set domain adaptation, where new, unknown classes can be present in the target data. While, in the unsupervised scenario, one cannot expect to be able to identify each specific new class, we aim to automatically detect which samples belong to these new classes and discard them from the recognition process. To this end, we rely on the intuition that the source and target samples depicting the known classes can be generated by a shared subspace, whereas the target samples from unknown classes come from a different, private subspace. We therefore introduce a framework that factorizes the data into shared and private parts, while encouraging the shared representation to be discriminative. Our experiments on standard benchmarks evidence that our approach outperforms the state of the art in open-set domain adaptation."
    },
    "keywords": [
        {
            "term": "domain adaptation",
            "url": "https://en.wikipedia.org/wiki/domain_adaptation"
        },
        {
            "term": "open set",
            "url": "https://en.wikipedia.org/wiki/open_set"
        },
        {
            "term": "new class",
            "url": "https://en.wikipedia.org/wiki/new_class"
        }
    ],
    "abbreviations": {},
    "highlights": [
        "In many practical machine learning scenarios, the test samples are drawn from a different distribution from the training ones, due to varying acquisition conditions, such as different data sources, illumination conditions and cameras, in the context of visual recognition",
        "We exploit them in a different manner, based on the intuition that source samples and target samples from the known classes can be generated by a shared subspace, whereas target samples from unknown classes come from a private subspace",
        "The key idea behind our formulation is to find low-dimensional representations of the data, factorized into a subspace shared by the source samples and the target ones coming from known classes and another subspace specific to the target samples from unknown classes",
        "Note that we outperform the baselines in this open-set scenario. This includes the end-to-end AlexNet-based approach of <a class=\"ref-link\" id=\"cSaito_et+al_2018_a\" href=\"#rSaito_et+al_2018_a\">Saito et al (2018</a>) for open-set domain adaptation, as well as the state-of-the-art UDA methods of <a class=\"ref-link\" id=\"cTzeng_et+al_2017_a\" href=\"#rTzeng_et+al_2017_a\">Tzeng et al (2017</a>) and <a class=\"ref-link\" id=\"cBousmalis_et+al_2016_a\" href=\"#rBousmalis_et+al_2016_a\">Bousmalis et al (2016</a>), the latter of which is closest in spirit to our approach",
        "We have introduced a novel approach to open-set domain adaptation, based on the intuition that source and target samples coming from the same, known classes can be represented by a shared subspace, while target samples from unknown classes should be modeled with a private subspace",
        "As demonstrated by our experiments, our method outperforms the state of the art in open-set domain adaptation and is one order of magnitude faster than the technique of <a class=\"ref-link\" id=\"cBusto_2017_a\" href=\"#rBusto_2017_a\">Busto & Gall (2017</a>)"
    ],
    "key_statements": [
        "In many practical machine learning scenarios, the test samples are drawn from a different distribution from the training ones, due to varying acquisition conditions, such as different data sources, illumination conditions and cameras, in the context of visual recognition",
        "While one should not expect the model to recognize the specific class of such objects, at least in unsupervised domain adaptation where no target labels are provided, it would be beneficial to identify these objects as unknown instead of misclassifying them",
        "We introduce a novel approach to open-set domain adaptation based on learning a factorized representation of the source and target data",
        "Note that our approach is more intuitive than (<a class=\"ref-link\" id=\"cBousmalis_et+al_2016_a\" href=\"#rBousmalis_et+al_2016_a\">Bousmalis et al, 2016</a>) for the open-set DA scenario in the sense that we model each target sample as being generated by either the shared subspace or the private one, which is crucial to identify the target samples depicting unknown classes",
        "We exploit them in a different manner, based on the intuition that source samples and target samples from the known classes can be generated by a shared subspace, whereas target samples from unknown classes come from a private subspace",
        "The key idea behind our formulation is to find low-dimensional representations of the data, factorized into a subspace shared by the source samples and the target ones coming from known classes and another subspace specific to the target samples from unknown classes",
        "As a matter of fact, throughout the paper, we focus on the unsupervised domain adaptation scenario, where no target annotations are provided",
        "We further evaluate the robustness of our approach to the choice of threshold \u03b5 to separate the target samples from known/unknown classes",
        "Note that we outperform the baselines in this open-set scenario. This includes the end-to-end AlexNet-based approach of <a class=\"ref-link\" id=\"cSaito_et+al_2018_a\" href=\"#rSaito_et+al_2018_a\">Saito et al (2018</a>) for open-set domain adaptation, as well as the state-of-the-art UDA methods of <a class=\"ref-link\" id=\"cTzeng_et+al_2017_a\" href=\"#rTzeng_et+al_2017_a\">Tzeng et al (2017</a>) and <a class=\"ref-link\" id=\"cBousmalis_et+al_2016_a\" href=\"#rBousmalis_et+al_2016_a\">Bousmalis et al (2016</a>), the latter of which is closest in spirit to our approach",
        "We have introduced a novel approach to open-set domain adaptation, based on the intuition that source and target samples coming from the same, known classes can be represented by a shared subspace, while target samples from unknown classes should be modeled with a private subspace",
        "As demonstrated by our experiments, our method outperforms the state of the art in open-set domain adaptation and is one order of magnitude faster than the technique of <a class=\"ref-link\" id=\"cBusto_2017_a\" href=\"#rBusto_2017_a\">Busto & Gall (2017</a>)"
    ],
    "summary": [
        "In many practical machine learning scenarios, the test samples are drawn from a different distribution from the training ones, due to varying acquisition conditions, such as different data sources, illumination conditions and cameras, in the context of visual recognition.",
        "<a class=\"ref-link\" id=\"cSaito_et+al_2018_a\" href=\"#rSaito_et+al_2018_a\">Saito et al (2018</a>) introduced a deep learning framework for open-set domain adaptation, relying on adversarial training to separate the samples from the known classes from the unknown ones.",
        "We introduce a novel approach to open-set domain adaptation based on learning a factorized representation of the source and target data.",
        "Our method consistently and significantly outperforms the technique of <a class=\"ref-link\" id=\"cBusto_2017_a\" href=\"#rBusto_2017_a\"><a class=\"ref-link\" id=\"cBusto_2017_a\" href=\"#rBusto_2017_a\">Busto & Gall (2017</a></a>) on all benchmarks, as well as the end-to-end learning approach of <a class=\"ref-link\" id=\"cSaito_et+al_2018_a\" href=\"#rSaito_et+al_2018_a\">Saito et al (2018</a>) on the Office dataset, showing the benefits of learning shared and private representations corresponding to the known and unknown classes, respectively.",
        "A deep learning approach was proposed for open-set domain adaptation (<a class=\"ref-link\" id=\"cSaito_et+al_2018_a\" href=\"#rSaito_et+al_2018_a\"><a class=\"ref-link\" id=\"cSaito_et+al_2018_a\" href=\"#rSaito_et+al_2018_a\">Saito et al, 2018</a></a>), relying on adversarial training to separate the unknown target samples from the known ones.",
        "Our experiments evidence that our open-set domain adaptation approach, based on shared-private representations, is more effective than the one of <a class=\"ref-link\" id=\"cBusto_2017_a\" href=\"#rBusto_2017_a\"><a class=\"ref-link\" id=\"cBusto_2017_a\" href=\"#rBusto_2017_a\">Busto & Gall (2017</a></a>), consistently outperforming it on several datasets, and faster by an order of magnitude.",
        "The key idea behind our formulation is to find low-dimensional representations of the data, factorized into a subspace shared by the source samples and the target ones coming from known classes and another subspace specific to the target samples from unknown classes.",
        "Following <a class=\"ref-link\" id=\"cBusto_2017_a\" href=\"#rBusto_2017_a\"><a class=\"ref-link\" id=\"cBusto_2017_a\" href=\"#rBusto_2017_a\">Busto & Gall (2017</a></a>), we consider the samples from the first 10 classes as known instances, while the samples with class labels 11, 12, \u00b7 \u00b7 \u00b7 , 25 and 26, 27, \u00b7 \u00b7 \u00b7 , 40 are taken to be the unknown samples in the source and target domains, respectively.",
        "As in (<a class=\"ref-link\" id=\"cBusto_2017_a\" href=\"#rBusto_2017_a\"><a class=\"ref-link\" id=\"cBusto_2017_a\" href=\"#rBusto_2017_a\">Busto & Gall, 2017</a></a>), we take all the samples from the first 10 classes to represent the known ones, and all the samples with class labels 11, 12, \u00b7 \u00b7 \u00b7 , 20 and 21, 22, \u00b7 \u00b7 \u00b7 , 31 as unknown source and target data, respectively.",
        "Further discussion: The experimental setup used in (<a class=\"ref-link\" id=\"cSaito_et+al_2018_a\" href=\"#rSaito_et+al_2018_a\"><a class=\"ref-link\" id=\"cSaito_et+al_2018_a\" href=\"#rSaito_et+al_2018_a\">Saito et al, 2018</a></a>; <a class=\"ref-link\" id=\"cBusto_2017_a\" href=\"#rBusto_2017_a\"><a class=\"ref-link\" id=\"cBusto_2017_a\" href=\"#rBusto_2017_a\">Busto & Gall, 2017</a></a>) and our work for open-set DA relies on features extracted using a network pre-trained on ImageNet, which can be argued to already contain semantic information about some of the unknown classes.",
        "We have introduced a novel approach to open-set domain adaptation, based on the intuition that source and target samples coming from the same, known classes can be represented by a shared subspace, while target samples from unknown classes should be modeled with a private subspace.",
        "We will investigate ways to make better use of unknown source data, and to exploit more effective classifiers, such as SVM, directly within our D-FRODA formulation"
    ],
    "headline": "Our experiments on standard benchmarks evidence that our approach outperforms the state of the art in open-set domain adaptation",
    "reference_links": [
        {
            "id": "Baktashmotlagh_et+al_2013_a",
            "entry": "M. Baktashmotlagh, M. Harandi, B. Lovell, and M. Salzmann. Unsupervised domain adaptation by domain invariant projection. In Proc. Int. Conference on Computer Vision, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Baktashmotlagh%2C%20M.%20Harandi%2C%20M.%20Lovell%2C%20B.%20Salzmann%2C%20M.%20Unsupervised%20domain%20adaptation%20by%20domain%20invariant%20projection%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Baktashmotlagh%2C%20M.%20Harandi%2C%20M.%20Lovell%2C%20B.%20Salzmann%2C%20M.%20Unsupervised%20domain%20adaptation%20by%20domain%20invariant%20projection%202013"
        },
        {
            "id": "Baktashmotlagh_et+al_2014_a",
            "entry": "M. Baktashmotlagh, M. Harandi, B. Lovell, and M. Salzmann. Domain adaptation on statistical manifold. In Proc. IEEE Conference on Computer Vision and Pattern Recognition, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Baktashmotlagh%2C%20M.%20Harandi%2C%20M.%20Lovell%2C%20B.%20Salzmann%2C%20M.%20Domain%20adaptation%20on%20statistical%20manifold%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Baktashmotlagh%2C%20M.%20Harandi%2C%20M.%20Lovell%2C%20B.%20Salzmann%2C%20M.%20Domain%20adaptation%20on%20statistical%20manifold%202014"
        },
        {
            "id": "Bendale_2015_a",
            "entry": "A. Bendale and T. Boult. Towards open world recognition. In Proc. IEEE Conference on Computer Vision and Pattern Recognition, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bendale%2C%20A.%20Boult%2C%20T.%20Towards%20open%20world%20recognition%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bendale%2C%20A.%20Boult%2C%20T.%20Towards%20open%20world%20recognition%202015"
        },
        {
            "id": "Bousmalis_et+al_2016_a",
            "entry": "K. Bousmalis, G. Trigeorgis, N. Silberman, D. Krishnan, and D. Erhan. Domain separation networks. In Proc. Advances in Neural Information Processing Systems, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bousmalis%2C%20K.%20Trigeorgis%2C%20G.%20Silberman%2C%20N.%20Krishnan%2C%20D.%20Domain%20separation%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bousmalis%2C%20K.%20Trigeorgis%2C%20G.%20Silberman%2C%20N.%20Krishnan%2C%20D.%20Domain%20separation%20networks%202016"
        },
        {
            "id": "Busto_2017_a",
            "entry": "P. Busto and J. Gall. Open set domain adaptation. In Proc. Int. Conference on Computer Vision, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Busto%2C%20P.%20Gall%2C%20J.%20Open%20set%20domain%20adaptation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Busto%2C%20P.%20Gall%2C%20J.%20Open%20set%20domain%20adaptation%202017"
        },
        {
            "id": "Balakrishnan_2013_a",
            "entry": "Balakrishnan S. Chopra S. and Gopalan R. Dlid: Deep learning for domain adaptation by interpolating between domains. In ICML workshop on Challenges in Representation Learning, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=S.%2C%20Balakrishnan%20S.Chopra%20R%2C%20Gopalan%20Dlid%3A%20Deep%20learning%20for%20domain%20adaptation%20by%20interpolating%20between%20domains%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=S.%2C%20Balakrishnan%20S.Chopra%20R%2C%20Gopalan%20Dlid%3A%20Deep%20learning%20for%20domain%20adaptation%20by%20interpolating%20between%20domains%202013"
        },
        {
            "id": "Donahue_et+al_2013_a",
            "entry": "J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. In Proc. Int. Conference on Machine Learning, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Donahue%2C%20J.%20Jia%2C%20Y.%20Vinyals%2C%20O.%20Hoffman%2C%20J.%20Decaf%3A%20A%20deep%20convolutional%20activation%20feature%20for%20generic%20visual%20recognition%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Donahue%2C%20J.%20Jia%2C%20Y.%20Vinyals%2C%20O.%20Hoffman%2C%20J.%20Decaf%3A%20A%20deep%20convolutional%20activation%20feature%20for%20generic%20visual%20recognition%202013"
        },
        {
            "id": "Fernando_et+al_2013_a",
            "entry": "B. Fernando, A. Habrard, M. Sebban, and T. Tuytelaars. Unsupervised visual domain adaptation using subspace alignment. In Proc. Int. Conference on Computer Vision, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fernando%2C%20B.%20Habrard%2C%20A.%20Sebban%2C%20M.%20Tuytelaars%2C%20T.%20Unsupervised%20visual%20domain%20adaptation%20using%20subspace%20alignment%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fernando%2C%20B.%20Habrard%2C%20A.%20Sebban%2C%20M.%20Tuytelaars%2C%20T.%20Unsupervised%20visual%20domain%20adaptation%20using%20subspace%20alignment%202013"
        },
        {
            "id": "Ganin_2014_a",
            "entry": "Y. Ganin and V. Lempitsky. Unsupervised domain adaptation by backpropagation. arXiv preprint arXiv:1409.7495, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1409.7495"
        },
        {
            "id": "Ghifary_et+al_2016_a",
            "entry": "M. Ghifary, Bastiaan W. Kleijn, M. Zhang, D. Balduzzi, and W. Li. Deep reconstructionclassification networks for unsupervised domain adaptation. In Proc. European Conference on Computer Vision, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ghifary%2C%20M.%20Kleijn%2C%20Bastiaan%20W.%20Zhang%2C%20M.%20Balduzzi%2C%20D.%20Deep%20reconstructionclassification%20networks%20for%20unsupervised%20domain%20adaptation%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ghifary%2C%20M.%20Kleijn%2C%20Bastiaan%20W.%20Zhang%2C%20M.%20Balduzzi%2C%20D.%20Deep%20reconstructionclassification%20networks%20for%20unsupervised%20domain%20adaptation%202016"
        },
        {
            "id": "Gong_et+al_2012_a",
            "entry": "B. Gong, Y. Shi, F. Sha, and K. Grauman. Geodesic flow kernel for unsupervised domain adaptation. In Proc. IEEE Conference on Computer Vision and Pattern Recognition, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gong%2C%20B.%20Shi%2C%20Y.%20Sha%2C%20F.%20Grauman%2C%20K.%20Geodesic%20flow%20kernel%20for%20unsupervised%20domain%20adaptation%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gong%2C%20B.%20Shi%2C%20Y.%20Sha%2C%20F.%20Grauman%2C%20K.%20Geodesic%20flow%20kernel%20for%20unsupervised%20domain%20adaptation%202012"
        },
        {
            "id": "Gong_et+al_2013_a",
            "entry": "B. Gong, K. Grauman, and F. Sha. Connecting the dots with landmarks: Discriminatively learning domain-invariant features for unsupervised domain adaptation. In Proc. Int. Conference on Machine Learning, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gong%2C%20B.%20Grauman%2C%20K.%20Sha%2C%20F.%20Connecting%20the%20dots%20with%20landmarks%3A%20Discriminatively%20learning%20domain-invariant%20features%20for%20unsupervised%20domain%20adaptation%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gong%2C%20B.%20Grauman%2C%20K.%20Sha%2C%20F.%20Connecting%20the%20dots%20with%20landmarks%3A%20Discriminatively%20learning%20domain-invariant%20features%20for%20unsupervised%20domain%20adaptation%202013"
        },
        {
            "id": "Gopalan_et+al_2014_a",
            "entry": "R. Gopalan, R. Li, and R. Chellappa. Unsupervised adaptation across domain shifts by generating intermediate data representations. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gopalan%2C%20R.%20Li%2C%20R.%20Chellappa%2C%20R.%20Unsupervised%20adaptation%20across%20domain%20shifts%20by%20generating%20intermediate%20data%20representations%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gopalan%2C%20R.%20Li%2C%20R.%20Chellappa%2C%20R.%20Unsupervised%20adaptation%20across%20domain%20shifts%20by%20generating%20intermediate%20data%20representations%202014"
        },
        {
            "id": "Jia_et+al_2010_a",
            "entry": "Y. Jia, M. Salzmann, and T. Darrell. Factorized latent spaces with structured sparsity. In Proc. Advances in Neural Information Processing Systems, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jia%2C%20Y.%20Salzmann%2C%20M.%20Darrell%2C%20T.%20Factorized%20latent%20spaces%20with%20structured%20sparsity%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jia%2C%20Y.%20Salzmann%2C%20M.%20Darrell%2C%20T.%20Factorized%20latent%20spaces%20with%20structured%20sparsity%202010"
        },
        {
            "id": "Lee_et+al_2007_a",
            "entry": "H. Lee, A. Battle, R. Raina, and A. Ng. Efficient sparse coding algorithms. In Proc. Advances in Neural Information Processing Systems, 2007.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lee%2C%20H.%20Battle%2C%20A.%20Raina%2C%20R.%20Ng%2C%20A.%20Efficient%20sparse%20coding%20algorithms%202007",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lee%2C%20H.%20Battle%2C%20A.%20Raina%2C%20R.%20Ng%2C%20A.%20Efficient%20sparse%20coding%20algorithms%202007"
        },
        {
            "id": "Long_et+al_2015_a",
            "entry": "M. Long, Y. Cao, J. Wang, and M. Jordan. Learning transferable features with deep adaptation networks. arXiv preprint arXiv:1502.02791, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1502.02791"
        },
        {
            "id": "Long_et+al_0000_a",
            "entry": "M. Long, J. Wang, and M. Jordan. Deep transfer learning with joint adaptation networks. corr, vol. arXiv preprint arXiv:1605.06636, 2016a.",
            "arxiv_url": "https://arxiv.org/pdf/1605.06636"
        },
        {
            "id": "Long_et+al_2016_a",
            "entry": "M. Long, H. Zhu, J. Wang, and M. Jordan. Unsupervised domain adaptation with residual transfer networks. In Proc. Advances in Neural Information Processing Systems, 2016b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Long%2C%20M.%20Zhu%2C%20H.%20Wang%2C%20J.%20Jordan%2C%20M.%20Unsupervised%20domain%20adaptation%20with%20residual%20transfer%20networks%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Long%2C%20M.%20Zhu%2C%20H.%20Wang%2C%20J.%20Jordan%2C%20M.%20Unsupervised%20domain%20adaptation%20with%20residual%20transfer%20networks%202016"
        },
        {
            "id": "3",
            "entry": "3. URL http://spams-devel.gforge.inria.fr/downloads.html, 2014.",
            "url": "http://spams-devel.gforge.inria.fr/downloads.html"
        },
        {
            "id": "Pan_et+al_2011_a",
            "entry": "S. Pan, I. Tsang, J. Kwok, and Q. Yang. Domain adaptation via transfer component analysis. IEEE Transactions on Neural Networks, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pan%2C%20S.%20Tsang%2C%20I.%20Kwok%2C%20J.%20Yang%2C%20Q.%20Domain%20adaptation%20via%20transfer%20component%20analysis%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pan%2C%20S.%20Tsang%2C%20I.%20Kwok%2C%20J.%20Yang%2C%20Q.%20Domain%20adaptation%20via%20transfer%20component%20analysis%202011"
        },
        {
            "id": "J_et+al_2009_a",
            "entry": "J Qui\u00f1onero C., M. Sugiyama, A. Schwaighofer, and N. Lawrence. Covariate shift by kernel mean matching. Dataset Shift in Machine Learning, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=C.%2C%20J.Qui%C3%B1onero%20Sugiyama%2C%20M.%20Schwaighofer%2C%20A.%20Lawrence%2C%20N.%20Covariate%20shift%20by%20kernel%20mean%20matching%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=C.%2C%20J.Qui%C3%B1onero%20Sugiyama%2C%20M.%20Schwaighofer%2C%20A.%20Lawrence%2C%20N.%20Covariate%20shift%20by%20kernel%20mean%20matching%202009"
        },
        {
            "id": "Rozantsev_et+al_2018_a",
            "entry": "A. Rozantsev, M. Salzmann, and P. Fua. Beyond sharing weights for deep domain adaptation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Rozantsev%2C%20A.%20Salzmann%2C%20M.%20Fua%2C%20P.%20Beyond%20sharing%20weights%20for%20deep%20domain%20adaptation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Rozantsev%2C%20A.%20Salzmann%2C%20M.%20Fua%2C%20P.%20Beyond%20sharing%20weights%20for%20deep%20domain%20adaptation%202018"
        },
        {
            "id": "Saenko_et+al_2010_a",
            "entry": "K. Saenko, B. Kulis, M. Fritz, and T. Darrell. Adapting visual category models to new domains. In Proc. European Conference on Computer Vision, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Saenko%2C%20K.%20Kulis%2C%20B.%20Fritz%2C%20M.%20Darrell%2C%20T.%20Adapting%20visual%20category%20models%20to%20new%20domains%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Saenko%2C%20K.%20Kulis%2C%20B.%20Fritz%2C%20M.%20Darrell%2C%20T.%20Adapting%20visual%20category%20models%20to%20new%20domains%202010"
        },
        {
            "id": "Saito_et+al_2018_a",
            "entry": "K. Saito, S. Yamamoto, Y. Ushiku, and T. Harada. Open set domain adaptation by backpropagation. Proc. European Conference on Computer Vision, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Saito%2C%20K.%20Yamamoto%2C%20S.%20Ushiku%2C%20Y.%20Harada%2C%20T.%20Open%20set%20domain%20adaptation%20by%20backpropagation%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Saito%2C%20K.%20Yamamoto%2C%20S.%20Ushiku%2C%20Y.%20Harada%2C%20T.%20Open%20set%20domain%20adaptation%20by%20backpropagation%202018"
        },
        {
            "id": "Scheirer_et+al_2014_a",
            "entry": "W. J Scheirer, L. Jain, and T. Boult. Probability models for open set recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Scheirer%2C%20W.J.%20Jain%2C%20L.%20Boult%2C%20T.%20Probability%20models%20for%20open%20set%20recognition%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Scheirer%2C%20W.J.%20Jain%2C%20L.%20Boult%2C%20T.%20Probability%20models%20for%20open%20set%20recognition%202014"
        },
        {
            "id": "Published_2019_a",
            "entry": "Published as a conference paper at ICLR 2019 B. Sun and K. Saenko. Deep coral: Correlation alignment for deep domain adaptation. In Proc.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Published%20as%20a%20conference%20paper%20at%20ICLR%202019%20B%20Sun%20and%20K%20Saenko%20Deep%20coral%20Correlation%20alignment%20for%20deep%20domain%20adaptation%20In%20Proc",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Published%20as%20a%20conference%20paper%20at%20ICLR%202019%20B%20Sun%20and%20K%20Saenko%20Deep%20coral%20Correlation%20alignment%20for%20deep%20domain%20adaptation%20In%20Proc"
        },
        {
            "id": "European_2016_a",
            "entry": "European Conference on Computer Vision, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=European%20Conference%20on%20Computer%20Vision%202016"
        },
        {
            "id": "Sun_et+al_2016_a",
            "entry": "B. Sun, J. Feng, and K. Saenko. Return of frustratingly easy domain adaptation. In AAAI Conference on Artificial Intelligence, 2016. T. Tommasi and T. Tuytelaars. A testbed for cross-dataset analysis. In Proc. European Conference on Computer Vision, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sun%2C%20B.%20Feng%2C%20J.%20Saenko%2C%20K.%20Return%20of%20frustratingly%20easy%20domain%20adaptation%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sun%2C%20B.%20Feng%2C%20J.%20Saenko%2C%20K.%20Return%20of%20frustratingly%20easy%20domain%20adaptation%202016"
        },
        {
            "id": "Tzeng_et+al_2014_a",
            "entry": "E. Tzeng, J. Hoffman, N. Zhang, K. Saenko, and T. Darrell. Deep domain confusion: Maximizing for domain invariance. arXiv preprint arXiv:1412.3474, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1412.3474"
        },
        {
            "id": "Tzeng_et+al_2015_a",
            "entry": "E. Tzeng, J. Hoffman, T. Darrell, and K. Saenko. Simultaneous deep transfer across domains and tasks. In Proc. Int. Conference on Computer Vision, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tzeng%2C%20E.%20Hoffman%2C%20J.%20Darrell%2C%20T.%20Saenko%2C%20K.%20Simultaneous%20deep%20transfer%20across%20domains%20and%20tasks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tzeng%2C%20E.%20Hoffman%2C%20J.%20Darrell%2C%20T.%20Saenko%2C%20K.%20Simultaneous%20deep%20transfer%20across%20domains%20and%20tasks%202015"
        },
        {
            "id": "Tzeng_et+al_2017_a",
            "entry": "E. Tzeng, J. Hoffman, K. Saenko, and T. Darrell. Adversarial discriminative domain adaptation. In Proc. IEEE Conference on Computer Vision and Pattern Recognition, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tzeng%2C%20E.%20Hoffman%2C%20J.%20Saenko%2C%20K.%20Darrell%2C%20T.%20Adversarial%20discriminative%20domain%20adaptation%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tzeng%2C%20E.%20Hoffman%2C%20J.%20Saenko%2C%20K.%20Darrell%2C%20T.%20Adversarial%20discriminative%20domain%20adaptation%202017"
        },
        {
            "id": "Yan_et+al_2017_a",
            "entry": "H. Yan, Y. Ding, P. Li, Q. Wang, Y. Xu, and W. Zuo. Mind the class weight bias: Weighted maximum mean discrepancy for unsupervised domain adaptation. arXiv preprint arXiv:1705.00609, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1705.00609"
        }
    ]
}

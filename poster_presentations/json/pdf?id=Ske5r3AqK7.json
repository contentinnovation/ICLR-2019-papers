{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "Linguistic Regularities in Sparse and Explicit Word Representations",
        "author": "Omer Levy, Yoav Goldberg",
        "date": 2015,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=Ske5r3AqK7",
            "doi": "10.3115/v1/w14-1618"
        },
        "journal": "Proceedings of the Eighteenth Conference on Computational Natural Language Learning",
        "abstract": "Words are not created equal. In fact, they form an aristocratic graph with a latent hierarchical structure that the next generation of unsupervised learned word embeddings should reveal. In this paper, justified by the notion of delta-hyperbolicity or tree-likeliness of a space, we propose to embed words in a Cartesian product of hyperbolic spaces which we theoretically connect to the Gaussian word embeddings and their Fisher geometry. This connection allows us to introduce a novel principled hypernymy score for word embeddings. Moreover, we adapt the well-known Glove algorithm to learn unsupervised word embeddings in this type of Riemannian manifolds. We further explain how to solve the analogy task using the Riemannian parallel transport that generalizes vector arithmetics to this new type of geometry. Empirically, based on extensive experiments, we prove that our embeddings, trained unsupervised, are the first to simultaneously outperform strong and popular baselines on the tasks of similarity, analogy and hypernymy detection. In particular, for word hypernymy, we obtain new state-of-the-art on fully unsupervised WBLESS classification accuracy."
    },
    "keywords": [
        {
            "term": "analogy",
            "url": "https://en.wikipedia.org/wiki/analogy"
        },
        {
            "term": "geometry",
            "url": "https://en.wikipedia.org/wiki/geometry"
        },
        {
            "term": "word embedding",
            "url": "https://en.wikipedia.org/wiki/word_embedding"
        },
        {
            "term": "natural language",
            "url": "https://en.wikipedia.org/wiki/natural_language"
        },
        {
            "term": "gaussian distribution",
            "url": "https://en.wikipedia.org/wiki/gaussian_distribution"
        },
        {
            "term": "hyperbolic space",
            "url": "https://en.wikipedia.org/wiki/hyperbolic_space"
        },
        {
            "term": "order embedding",
            "url": "https://en.wikipedia.org/wiki/order_embedding"
        },
        {
            "term": "hyperbolic geometry",
            "url": "https://en.wikipedia.org/wiki/hyperbolic_geometry"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "riemannian manifold",
            "url": "https://en.wikipedia.org/wiki/riemannian_manifold"
        },
        {
            "term": "word vector",
            "url": "https://en.wikipedia.org/wiki/word_vector"
        }
    ],
    "abbreviations": {
        "PDFs": "probability distribution functions"
    },
    "highlights": [
        "<strong>INTRODUCTION & MOTIVATION</strong><br/><br/>Word embeddings are ubiquitous nowadays as first layers in neural network and deep learning models for natural language processing",
        "We propose to take the best from both worlds: we embed words as points in a Cartesian product of hyperbolic spaces and, explain how they are bijectively mapped to Gaussian embeddings with diagonal covariance matrices, where the hyperbolic distance between two points becomes the Fisher distance between the corresponding probability distribution functions (PDFs)",
        "One could object that WORD2GAUSS is trained using a KL divergence, while hyperbolic embeddings relate to Gaussian distributions via the Fisher distance dF , let us remind that KL and dF define the same local geometry",
        "We use the connection explained in section 5 to introduce a novel principled score that can be applied on top of our unsupervised learned Poincare Glove embeddings to address the task of hypernymy detection, i.e. to predict relations of type is-a(v,w) such as is-a",
        "We propose to adapt the GloVe algorithm to hyperbolic spaces and to leverage a connection between statistical manifolds of Gaussian distributions and hyperbolic geometry, in order to better interpret entailment relations between hyperbolic embeddings"
    ],
    "key_statements": [
        "<strong>INTRODUCTION & MOTIVATION</strong><br/><br/>Word embeddings are ubiquitous nowadays as first layers in neural network and deep learning models for natural language processing",
        "We propose to take the best from both worlds: we embed words as points in a Cartesian product of hyperbolic spaces and, explain how they are bijectively mapped to Gaussian embeddings with diagonal covariance matrices, where the hyperbolic distance between two points becomes the Fisher distance between the corresponding probability distribution functions (PDFs)",
        "One could object that WORD2GAUSS is trained using a KL divergence, while hyperbolic embeddings relate to Gaussian distributions via the Fisher distance dF , let us remind that KL and dF define the same local geometry",
        "We use the connection explained in section 5 to introduce a novel principled score that can be applied on top of our unsupervised learned Poincare Glove embeddings to address the task of hypernymy detection, i.e. to predict relations of type is-a(v,w) such as is-a",
        "We propose to adapt the GloVe algorithm to hyperbolic spaces and to leverage a connection between statistical manifolds of Gaussian distributions and hyperbolic geometry, in order to better interpret entailment relations between hyperbolic embeddings"
    ],
    "summary": [
        "<strong>INTRODUCTION & MOTIVATION</strong><br/><br/>Word embeddings are ubiquitous nowadays as first layers in neural network and deep learning models for natural language processing.",
        "These hyperbolic embeddings outperform Euclidean Glove on word similarity benchmarks.",
        "One could object that WORD2GAUSS is trained using a KL divergence, while hyperbolic embeddings relate to Gaussian distributions via the Fisher distance dF , let us remind that KL and dF define the same local geometry.",
        "We use the connection explained in section 5 to introduce a novel principled score that can be applied on top of our unsupervised learned Poincare Glove embeddings to address the task of hypernymy detection, i.e. to predict relations of type is-a(v,w) such as is-a.",
        "We first explain how learned hyperbolic word embeddings are mapped to Gaussian embeddings, and subsequently we define our hypernymy score.",
        "As shown in section 5, the space of Gaussians endorsed with the Fisher distance is naturally mapped to the hyperbolic upper half-plane H2, where the variance \u03c3 corresponds to the second coordinate in H2 = R \u00d7 R\u2217+.",
        "We note that the vast majority of our models outperform the vanilla Glove baselines, with the 100D hyperbolic embeddings being the absolute best.",
        "Figure 4: (4a): This plot describes how the Gaussian variances of our learned hyperbolic embeddings correlate with WordNet levels; (4b): This plot shows how the performance of our embeddings on hypernymy (HyperLex dataset) evolve when we increase the amount of supervision x used to find the correct isometry in the model WN x + x.",
        "While there is no single model that outperforms all the baselines on all presented tasks, one can remark that the model 50x2D, h(x) = x2, with the initialization trick obtains state-of-the-art results on hypernymy detection and is close to the best models for similarity and analogy, but almost constantly outperforming the vanilla Glove baseline on these.",
        "This is the first model that can achieve competitive results on all these three tasks, offering interpretability via the connection to Gaussian word embeddings.",
        "We propose to adapt the GloVe algorithm to hyperbolic spaces and to leverage a connection between statistical manifolds of Gaussian distributions and hyperbolic geometry, in order to better interpret entailment relations between hyperbolic embeddings.",
        "We justify the choice of products of hyperbolic spaces via this connection to Gaussian distributions and via computations of the hyperbolicity of the symbolic data upon which GloVe is based.",
        "We present the first model that can simultaneously obtain state-of-the-art results or close on the three tasks of word similarity, analogy and hypernymy detection."
    ],
    "headline": "In this paper, justified by the notion of delta-hyperbolicity or tree-likeliness of a space, we propose to embed words in a Cartesian product of hyperbolic spaces which we theoretically connect to the Gaussian word embeddings and their Fisher geometry",
    "reference_links": [
        {
            "id": "Albert_et+al_2014_a",
            "entry": "Reka Albert, Bhaskar DasGupta, and Nasim Mobasheri. Topological implications of negative curvature for biological and social networks. Physical Review E, 89(3):032811, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Albert%2C%20Reka%20DasGupta%2C%20Bhaskar%20Mobasheri%2C%20Nasim%20Topological%20implications%20of%20negative%20curvature%20for%20biological%20and%20social%20networks%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Albert%2C%20Reka%20DasGupta%2C%20Bhaskar%20Mobasheri%2C%20Nasim%20Topological%20implications%20of%20negative%20curvature%20for%20biological%20and%20social%20networks%202014"
        },
        {
            "id": "Arora_et+al_2016_a",
            "entry": "Sanjeev Arora, Yuanzhi Li, Yingyu Liang, Tengyu Ma, and Andrej Risteski. A latent variable model approach to pmi-based word embeddings. Transactions of the Association for Computational Linguistics, 4:385\u2013399, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Arora%2C%20Sanjeev%20Li%2C%20Yuanzhi%20Liang%2C%20Yingyu%20Ma%2C%20Tengyu%20A%20latent%20variable%20model%20approach%20to%20pmi-based%20word%20embeddings%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Arora%2C%20Sanjeev%20Li%2C%20Yuanzhi%20Liang%2C%20Yingyu%20Ma%2C%20Tengyu%20A%20latent%20variable%20model%20approach%20to%20pmi-based%20word%20embeddings%202016"
        },
        {
            "id": "Athiwaratkun_2017_a",
            "entry": "Ben Athiwaratkun and Andrew Wilson. Multimodal word distributions. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), volume 1, pp. 1645\u20131656, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Athiwaratkun%2C%20Ben%20Wilson%2C%20Andrew%20Multimodal%20word%20distributions%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Athiwaratkun%2C%20Ben%20Wilson%2C%20Andrew%20Multimodal%20word%20distributions%202017"
        },
        {
            "id": "Athiwaratkun_2018_a",
            "entry": "Ben Athiwaratkun and Andrew Gordon Wilson. Hierarchical density order embeddings. arXiv preprint arXiv:1804.09843, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.09843"
        },
        {
            "id": "Baroni_2011_a",
            "entry": "Marco Baroni and Alessandro Lenci. How we blessed distributional semantic evaluation. In Proceedings of the GEMS 2011 Workshop on GEometrical Models of Natural Language Semantics, pp. 1\u201310. Association for Computational Linguistics, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Baroni%2C%20Marco%20Lenci%2C%20Alessandro%20How%20we%20blessed%20distributional%20semantic%20evaluation%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Baroni%2C%20Marco%20Lenci%2C%20Alessandro%20How%20we%20blessed%20distributional%20semantic%20evaluation%202011"
        },
        {
            "id": "Becigneul_2018_a",
            "entry": "Gary Becigneul and Octavian-Eugen Ganea. Riemannian adaptive optimization methods. arXiv preprint arxiv:1810.00760, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1810.00760"
        },
        {
            "id": "Bojanowski_et+al_2016_a",
            "entry": "Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. Enriching word vectors with subword information. arXiv preprint arXiv:1607.04606, 2016.",
            "arxiv_url": "https://arxiv.org/pdf/1607.04606"
        },
        {
            "id": "Bonnabel_2013_a",
            "entry": "Silvere Bonnabel. Stochastic gradient descent on riemannian manifolds. IEEE Transactions on Automatic Control, 58(9):2217\u20132229, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bonnabel%2C%20Silvere%20Stochastic%20gradient%20descent%20on%20riemannian%20manifolds%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bonnabel%2C%20Silvere%20Stochastic%20gradient%20descent%20on%20riemannian%20manifolds%202013"
        },
        {
            "id": "Borassi_et+al_2015_a",
            "entry": "Michele Borassi, Alessandro Chessa, and Guido Caldarelli. Hyperbolicity measures democracy in real-world networks. Physical Review E, 92(3):032812, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Borassi%2C%20Michele%20Chessa%2C%20Alessandro%20Caldarelli%2C%20Guido%20Hyperbolicity%20measures%20democracy%20in%20real-world%20networks%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Borassi%2C%20Michele%20Chessa%2C%20Alessandro%20Caldarelli%2C%20Guido%20Hyperbolicity%20measures%20democracy%20in%20real-world%20networks%202015"
        },
        {
            "id": "Bowman_et+al_2015_a",
            "entry": "Samuel R Bowman, Gabor Angeli, Christopher Potts, and Christopher D Manning. A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 632\u2013642, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bowman%2C%20Samuel%20R.%20Angeli%2C%20Gabor%20Potts%2C%20Christopher%20Manning%2C%20Christopher%20D.%20A%20large%20annotated%20corpus%20for%20learning%20natural%20language%20inference%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bowman%2C%20Samuel%20R.%20Angeli%2C%20Gabor%20Potts%2C%20Christopher%20Manning%2C%20Christopher%20D.%20A%20large%20annotated%20corpus%20for%20learning%20natural%20language%20inference%202015"
        },
        {
            "id": "Chang_et+al_2018_a",
            "entry": "Haw-Shiuan Chang, Ziyun Wang, Luke Vilnis, and Andrew McCallum. Distributional inclusion vector embedding for unsupervised hypernymy detection. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), volume 1, pp. 485\u2013495, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chang%2C%20Haw-Shiuan%20Wang%2C%20Ziyun%20Vilnis%2C%20Luke%20McCallum%2C%20Andrew%20Distributional%20inclusion%20vector%20embedding%20for%20unsupervised%20hypernymy%20detection%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chang%2C%20Haw-Shiuan%20Wang%2C%20Ziyun%20Vilnis%2C%20Luke%20McCallum%2C%20Andrew%20Distributional%20inclusion%20vector%20embedding%20for%20unsupervised%20hypernymy%20detection%202018"
        },
        {
            "id": "Chen_et+al_2013_a",
            "entry": "Wei Chen, Wenjie Fang, Guangda Hu, and Michael W Mahoney. On the hyperbolicity of small-world and treelike random graphs. Internet Mathematics, 9(4):434\u2013491, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Wei%20Fang%2C%20Wenjie%20Hu%2C%20Guangda%20Mahoney%2C%20Michael%20W.%20On%20the%20hyperbolicity%20of%20small-world%20and%20treelike%20random%20graphs%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Wei%20Fang%2C%20Wenjie%20Hu%2C%20Guangda%20Mahoney%2C%20Michael%20W.%20On%20the%20hyperbolicity%20of%20small-world%20and%20treelike%20random%20graphs%202013"
        },
        {
            "id": "Costa_et+al_2015_a",
            "entry": "Sueli IR Costa, Sandra A Santos, and Joao E Strapasson. Fisher information distance: a geometrical reading. Discrete Applied Mathematics, 197:59\u201369, 2015. URL https://arxiv.org/pdf/1210.2354.pdf.",
            "url": "https://arxiv.org/pdf/1210.2354.pdf",
            "arxiv_url": "https://arxiv.org/pdf/1210.2354"
        },
        {
            "id": "Sa_et+al_2018_a",
            "entry": "Christopher De Sa, Albert Gu, Christopher Re, and Frederic Sala. Representation tradeoffs for hyperbolic embeddings. In International Conference on Machine Learning, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Sa%2C%20Christopher%20De%20Gu%2C%20Albert%20Re%2C%20Christopher%20Sala%2C%20Frederic%20Representation%20tradeoffs%20for%20hyperbolic%20embeddings%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Sa%2C%20Christopher%20De%20Gu%2C%20Albert%20Re%2C%20Christopher%20Sala%2C%20Frederic%20Representation%20tradeoffs%20for%20hyperbolic%20embeddings%202018"
        },
        {
            "id": "Dhingra_et+al_2018_a",
            "entry": "Bhuwan Dhingra, Christopher Shallue, Mohammad Norouzi, Andrew Dai, and George Dahl. Embedding text in hyperbolic spaces. In Proceedings of the Twelfth Workshop on Graph-Based Methods for Natural Language Processing (TextGraphs-12), pp. 59\u201369, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dhingra%2C%20Bhuwan%20Shallue%2C%20Christopher%20Norouzi%2C%20Mohammad%20Dai%2C%20Andrew%20Embedding%20text%20in%20hyperbolic%20spaces%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dhingra%2C%20Bhuwan%20Shallue%2C%20Christopher%20Norouzi%2C%20Mohammad%20Dai%2C%20Andrew%20Embedding%20text%20in%20hyperbolic%20spaces%202018"
        },
        {
            "id": "Duchi_et+al_2011_a",
            "entry": "John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research, 12(Jul):2121\u20132159, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Duchi%2C%20John%20Hazan%2C%20Elad%20Singer%2C%20Yoram%20Adaptive%20subgradient%20methods%20for%20online%20learning%20and%20stochastic%20optimization%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Duchi%2C%20John%20Hazan%2C%20Elad%20Singer%2C%20Yoram%20Adaptive%20subgradient%20methods%20for%20online%20learning%20and%20stochastic%20optimization%202011"
        },
        {
            "id": "Ganea_et+al_2018_a",
            "entry": "Octavian-Eugen Ganea, Gary Becigneul, and Thomas Hofmann. Hyperbolic entailment cones for learning hierarchical embeddings. In International Conference on Machine Learning, 2018a.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ganea%2C%20Octavian-Eugen%20Becigneul%2C%20Gary%20Hofmann%2C%20Thomas%20Hyperbolic%20entailment%20cones%20for%20learning%20hierarchical%20embeddings%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ganea%2C%20Octavian-Eugen%20Becigneul%2C%20Gary%20Hofmann%2C%20Thomas%20Hyperbolic%20entailment%20cones%20for%20learning%20hierarchical%20embeddings%202018"
        },
        {
            "id": "Ganea_et+al_2018_b",
            "entry": "Octavian-Eugen Ganea, Gary Becigneul, and Thomas Hofmann. Hyperbolic neural networks. In Advances in Neural Information Processing Systems, 2018b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ganea%2C%20Octavian-Eugen%20Becigneul%2C%20Gary%20Hofmann%2C%20Thomas%20Hyperbolic%20neural%20networks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ganea%2C%20Octavian-Eugen%20Becigneul%2C%20Gary%20Hofmann%2C%20Thomas%20Hyperbolic%20neural%20networks%202018"
        },
        {
            "id": "Jeffreys_1946_a",
            "entry": "Harold Jeffreys. An invariant form for the prior probability in estimation problems. Proc. R. Soc. Lond. A, 186(1007):453\u2013461, 1946.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Jeffreys%2C%20Harold%20An%20invariant%20form%20for%20the%20prior%20probability%20in%20estimation%20problems%201946",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Jeffreys%2C%20Harold%20An%20invariant%20form%20for%20the%20prior%20probability%20in%20estimation%20problems%201946"
        },
        {
            "id": "Krioukov_et+al_2010_a",
            "entry": "Dmitri Krioukov, Fragkiskos Papadopoulos, Maksim Kitsak, Amin Vahdat, and Marian Boguna. Hyperbolic geometry of complex networks. Physical Review E, 82(3):036106, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krioukov%2C%20Dmitri%20Papadopoulos%2C%20Fragkiskos%20Kitsak%2C%20Maksim%20Vahdat%2C%20Amin%20Hyperbolic%20geometry%20of%20complex%20networks%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Krioukov%2C%20Dmitri%20Papadopoulos%2C%20Fragkiskos%20Kitsak%2C%20Maksim%20Vahdat%2C%20Amin%20Hyperbolic%20geometry%20of%20complex%20networks%202010"
        },
        {
            "id": "Leimeister_2018_a",
            "entry": "Matthias Leimeister and Benjamin J Wilson. Skip-gram word embeddings in hyperbolic space. arXiv preprint arXiv:1809.01498, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1809.01498"
        },
        {
            "id": "Levy_2014_a",
            "entry": "Omer Levy and Yoav Goldberg. Linguistic regularities in sparse and explicit word representations. In Proceedings of the Eighteenth Conference on Computational Natural Language Learning, pp. 171\u2013180. Association for Computational Linguistics, 2014. doi: 10.3115/v1/W14-1618. URL http://www.aclweb.org/anthology/W14-1618.",
            "crossref": "https://dx.doi.org/10.3115/v1/W14-1618",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.3115/v1/W14-1618"
        },
        {
            "id": "Levy_et+al_2015_a",
            "entry": "Omer Levy, Yoav Goldberg, and Ido Dagan. Improving distributional similarity with lessons learned from word embeddings. Transactions of the Association for Computational Linguistics, 3:211\u2013 225, 2015. ISSN 2307-387X. URL https://transacl.org/ojs/index.php/tacl/article/view/570.",
            "url": "https://transacl.org/ojs/index.php/tacl/article/view/570",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Levy%2C%20Omer%20Goldberg%2C%20Yoav%20Dagan%2C%20Ido%20Improving%20distributional%20similarity%20with%20lessons%20learned%20from%20word%20embeddings.%20Transactions%20of%20the%20Association%20for%202015"
        },
        {
            "id": "Mikolov_et+al_0000_a",
            "entry": "Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781, 2013a.",
            "arxiv_url": "https://arxiv.org/pdf/1301.3781"
        },
        {
            "id": "Mikolov_et+al_2013_a",
            "entry": "Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems, pp. 3111\u20133119, 2013b.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mikolov%2C%20Tomas%20Sutskever%2C%20Ilya%20Chen%2C%20Kai%20Corrado%2C%20Greg%20S.%20Distributed%20representations%20of%20words%20and%20phrases%20and%20their%20compositionality%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mikolov%2C%20Tomas%20Sutskever%2C%20Ilya%20Chen%2C%20Kai%20Corrado%2C%20Greg%20S.%20Distributed%20representations%20of%20words%20and%20phrases%20and%20their%20compositionality%202013"
        },
        {
            "id": "Miller_et+al_1990_a",
            "entry": "George A Miller, Richard Beckwith, Christiane Fellbaum, Derek Gross, and Katherine J Miller. Introduction to wordnet: An on-line lexical database. International journal of lexicography, 3(4): 235\u2013244, 1990.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Miller%2C%20George%20A.%20Beckwith%2C%20Richard%20Fellbaum%2C%20Christiane%20Gross%2C%20Derek%20Introduction%20to%20wordnet%3A%20An%20on-line%20lexical%20database%201990",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Miller%2C%20George%20A.%20Beckwith%2C%20Richard%20Fellbaum%2C%20Christiane%20Gross%2C%20Derek%20Introduction%20to%20wordnet%3A%20An%20on-line%20lexical%20database%201990"
        },
        {
            "id": "Muzellec_2018_a",
            "entry": "Boris Muzellec and Marco Cuturi. Generalizing point embeddings using the wasserstein space of elliptical distributions. arXiv preprint arXiv:1805.07594, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1805.07594"
        },
        {
            "id": "Nguyen_2017_a",
            "entry": "Kim Anh Nguyen, Maximilian Koper, Sabine Schulte im Walde, and Ngoc Thang Vu. Hierarchical embeddings for hypernymy detection and directionality. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 233\u2013243, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nguyen%2C%20Kim%20Anh%20Koper%2C%20Maximilian%20Sabine%20Schulte%20im%20Walde%2C%20and%20Ngoc%20Thang%20Vu.%20Hierarchical%20embeddings%20for%20hypernymy%20detection%20and%20directionality%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nguyen%2C%20Kim%20Anh%20Koper%2C%20Maximilian%20Sabine%20Schulte%20im%20Walde%2C%20and%20Ngoc%20Thang%20Vu.%20Hierarchical%20embeddings%20for%20hypernymy%20detection%20and%20directionality%202017"
        },
        {
            "id": "Nickel_2018_a",
            "entry": "Maximilian Nickel and Douwe Kiela. Learning continuous hierarchies in the lorentz model of hyperbolic geometry. In International Conference on Machine Learning, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nickel%2C%20Maximilian%20Kiela%2C%20Douwe%20Learning%20continuous%20hierarchies%20in%20the%20lorentz%20model%20of%20hyperbolic%20geometry%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nickel%2C%20Maximilian%20Kiela%2C%20Douwe%20Learning%20continuous%20hierarchies%20in%20the%20lorentz%20model%20of%20hyperbolic%20geometry%202018"
        },
        {
            "id": "Nickel_2017_a",
            "entry": "Maximillian Nickel and Douwe Kiela. Poincareembeddings for learning hierarchical representations. In Advances in Neural Information Processing Systems, pp. 6341\u20136350, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Nickel%2C%20Maximillian%20Kiela%2C%20Douwe%20Poincareembeddings%20for%20learning%20hierarchical%20representations%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Nickel%2C%20Maximillian%20Kiela%2C%20Douwe%20Poincareembeddings%20for%20learning%20hierarchical%20representations%202017"
        },
        {
            "id": "Pennington_et+al_2014_a",
            "entry": "Jeffrey Pennington, Richard Socher, and Christopher D Manning. Glove: Global vectors for word representation. In EMNLP, volume 14, pp. 1532\u201343, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pennington%2C%20Jeffrey%20Socher%2C%20Richard%20Manning%2C%20Christopher%20D.%20Glove%3A%20Global%20vectors%20for%20word%20representation%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pennington%2C%20Jeffrey%20Socher%2C%20Richard%20Manning%2C%20Christopher%20D.%20Glove%3A%20Global%20vectors%20for%20word%20representation%202014"
        },
        {
            "id": "Singh_et+al_2018_a",
            "entry": "Sidak Pal Singh, Andreas Hug, Aymeric Dieuleveut, and Martin Jaggi. Wasserstein is all you need. arXiv preprint arXiv:1808.09663, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1808.09663"
        },
        {
            "id": "Ungar_2012_a",
            "entry": "Abraham A Ungar. Beyond the Einstein addition law and its gyroscopic Thomas precession: The theory of gyrogroups and gyrovector spaces, volume 117. Springer Science & Business Media, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ungar%2C%20Abraham%20A.%20Beyond%20the%20Einstein%20addition%20law%20and%20its%20gyroscopic%20Thomas%20precession%3A%20The%20theory%20of%20gyrogroups%20and%20gyrovector%20spaces%2C%20volume%20117%202012"
        },
        {
            "id": "Ungar_2008_a",
            "entry": "Abraham Albert Ungar. A gyrovector space approach to hyperbolic geometry. Synthesis Lectures on Mathematics and Statistics, 1(1):1\u2013194, 2008.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ungar%2C%20Abraham%20Albert%20A%20gyrovector%20space%20approach%20to%20hyperbolic%20geometry%202008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ungar%2C%20Abraham%20Albert%20A%20gyrovector%20space%20approach%20to%20hyperbolic%20geometry%202008"
        },
        {
            "id": "Vendrov_et+al_2015_a",
            "entry": "Ivan Vendrov, Ryan Kiros, Sanja Fidler, and Raquel Urtasun. Order-embeddings of images and language. arXiv preprint arXiv:1511.06361, 2015.",
            "arxiv_url": "https://arxiv.org/pdf/1511.06361"
        },
        {
            "id": "Vilnis_2015_a",
            "entry": "Luke Vilnis and Andrew McCallum. Word representations via gaussian embedding. ICLR, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vilnis%2C%20Luke%20McCallum%2C%20Andrew%20Word%20representations%20via%20gaussian%20embedding%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vilnis%2C%20Luke%20McCallum%2C%20Andrew%20Word%20representations%20via%20gaussian%20embedding%202015"
        },
        {
            "id": "Vilnis_et+al_2018_a",
            "entry": "Luke Vilnis, Xiang Li, Shikhar Murty, and Andrew McCallum. Probabilistic embedding of knowledge graphs with box lattice measures. arXiv preprint arXiv:1805.06627, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1805.06627"
        },
        {
            "id": "Under_2019_a",
            "entry": "Under review as a conference paper at ICLR 2019 Ivan Vulicand Nikola Mrksic. Specialising word vectors for lexical entailment. In Proceedings of the",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Under%20review%20as%20a%20conference%20paper%20at%20ICLR%202019%20Ivan%20Vulicand%20Nikola%20Mrksic%20Specialising%20word%20vectors%20for%20lexical%20entailment%20In%20Proceedings%20of%20the",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Under%20review%20as%20a%20conference%20paper%20at%20ICLR%202019%20Ivan%20Vulicand%20Nikola%20Mrksic%20Specialising%20word%20vectors%20for%20lexical%20entailment%20In%20Proceedings%20of%20the"
        },
        {
            "id": "Vulic_et+al_2018_a",
            "entry": "2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), volume 1, pp. 1134\u20131145, 2018. Ivan Vulic, Daniela Gerz, Douwe Kiela, Felix Hill, and Anna Korhonen. Hyperlex: A large-scale evaluation of graded lexical entailment. Computational Linguistics, 43(4):781\u2013835, 2017. Julie Weeds, Daoud Clarke, Jeremy Reffin, David Weir, and Bill Keller. Learning to distinguish hypernyms and co-hyponyms. In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pp. 2249\u20132259. Dublin City University and Association for Computational Linguistics, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vulic%2C%20Ivan%20Gerz%2C%20Daniela%20Kiela%2C%20Douwe%20Hill%2C%20Felix%20Conference%20of%20the%20North%20American%20Chapter%20of%20the%20Association%20for%20Computational%20Linguistics%3A%20Human%20Language%20Technologies%202018-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vulic%2C%20Ivan%20Gerz%2C%20Daniela%20Kiela%2C%20Douwe%20Hill%2C%20Felix%20Conference%20of%20the%20North%20American%20Chapter%20of%20the%20Association%20for%20Computational%20Linguistics%3A%20Human%20Language%20Technologies%202018-07"
        }
    ]
}

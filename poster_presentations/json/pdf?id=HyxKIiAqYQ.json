{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "CONTEXT-ADAPTIVE ENTROPY MODEL FOR END-TOEND OPTIMIZED IMAGE COMPRESSION",
        "author": "Jooyoung Lee, Seunghyun Cho & Seung-Kwon Beack Broadcasting Media Research Laboratory Electronics and Telecommunications Research Institute Daejeon, Korea {leejy1003,shcho,skbeack}@etri.re.kr",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=HyxKIiAqYQ"
        },
        "journal": "Figure",
        "volume": "1",
        "abstract": "We propose a context-adaptive entropy model for use in end-to-end optimized image compression. Our model exploits two types of contexts, bit-consuming contexts and bit-free contexts, distinguished based upon whether additional bit allocation is required. Based on these contexts, we allow the model to more accurately estimate the distribution of each latent representation with a more generalized form of the approximation models, which accordingly leads to an enhanced compression performance. Based on the experimental results, the proposed method outperforms the traditional image codecs, such as BPG and JPEG2000, as well as other previous artificial-neural-network (ANN) based approaches, in terms of the peak signal-to-noise ratio (PSNR) and multi-scale structural similarity (MS-SSIM) index. The test code is publicly available at https://github.com/JooyoungLeeETRI/CA_Entropy_Model."
    },
    "keywords": [
        {
            "term": "generative adversarial network",
            "url": "https://en.wikipedia.org/wiki/generative_adversarial_network"
        },
        {
            "term": "image compression",
            "url": "https://en.wikipedia.org/wiki/image_compression"
        },
        {
            "term": "structural similarity",
            "url": "https://en.wikipedia.org/wiki/structural_similarity"
        },
        {
            "term": "recurrent neural network",
            "url": "https://en.wikipedia.org/wiki/recurrent_neural_network"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        },
        {
            "term": "artificial neural networks",
            "url": "https://en.wikipedia.org/wiki/artificial_neural_networks"
        },
        {
            "term": "bits per pixel",
            "url": "https://en.wikipedia.org/wiki/bits_per_pixel"
        },
        {
            "term": "mean squared error",
            "url": "https://en.wikipedia.org/wiki/mean_squared_error"
        },
        {
            "term": "probability density function",
            "url": "https://en.wikipedia.org/wiki/probability_density_function"
        },
        {
            "term": "probability mass function",
            "url": "https://en.wikipedia.org/wiki/probability_mass_function"
        },
        {
            "term": "peak signal-to-noise ratio",
            "url": "https://en.wikipedia.org/wiki/peak_signal-to-noise_ratio"
        }
    ],
    "abbreviations": {
        "PSNR": "peak signal-to-noise ratio",
        "MS-SSIM": "multi-scale structural similarity",
        "ANNs": "artificial neural networks",
        "PDF": "probability density function",
        "PMF": "probability mass function",
        "MSE": "mean squared error",
        "BPP": "bits per pixel",
        "IITP": "Information & communications Technology Promotion"
    },
    "highlights": [
        "Artificial neural networks (ANNs) have been applied in various areas and have achieved a number of breakthroughs resulting from their superior optimization and representation learning performance",
        "It is indisputable that artifact reduction is one of the most promising areas exploiting the advantages of artificial neural networks, such approaches can be viewed as a type of post-processing, rather than image compression itself",
        "We propose a new entropy model that exploits two types of contexts, bit-consuming and bit-free contexts, distinguished according to whether additional bit allocation is required",
        "In Section 2, we introduce the key approaches of end-to-end optimized image compression and propose the context-adaptive entropy model",
        "Even when setting aside the case of multi-scale structural similarity, our results can be viewed as one concrete evidence supporting that artificial neural networks-based image compression can outperform the existing traditional image codecs in terms of the compression performance"
    ],
    "key_statements": [
        "Artificial neural networks (ANNs) have been applied in various areas and have achieved a number of breakthroughs resulting from their superior optimization and representation learning performance",
        "Certain approaches (<a class=\"ref-link\" id=\"cDong_et+al_2015_a\" href=\"#rDong_et+al_2015_a\">Dong et al, 2015</a>; <a class=\"ref-link\" id=\"cSvoboda_et+al_2016_a\" href=\"#rSvoboda_et+al_2016_a\">Svoboda et al, 2016</a>; <a class=\"ref-link\" id=\"cZhang_et+al_2017_a\" href=\"#rZhang_et+al_2017_a\">Zhang et al, 2017</a>) have been proposed to reduce artifacts caused by image compression, relying on the superior image restoration capability of an artificial neural networks",
        "It is indisputable that artifact reduction is one of the most promising areas exploiting the advantages of artificial neural networks, such approaches can be viewed as a type of post-processing, rather than image compression itself",
        "We propose a new entropy model that exploits two types of contexts, bit-consuming and bit-free contexts, distinguished according to whether additional bit allocation is required",
        "We propose a new context-adaptive entropy model framework that incorporates the two different types of contexts",
        "We provide the test results that outperform the widely used conventional image codec BPG in terms of the peak signal-to-noise ratio and multi-scale structural similarity",
        "In Section 2, we introduce the key approaches of end-to-end optimized image compression and propose the context-adaptive entropy model",
        "Since they were first proposed by Balleet al. (2017) and <a class=\"ref-link\" id=\"cTheis_et+al_2017_a\" href=\"#rTheis_et+al_2017_a\">Theis et al (2017</a>), entropy models, which approximate the distribution of discrete latent representations, have noticeably improved the image compression performance of artificial neural networks-based approaches",
        "Note that actual entropy coding or decoding processes are not necessarily required for training or encoding because the rate term is not the amount of real bits, but an estimation calculated from the entropy models, as mentioned previously",
        "The lightweight entropy model assumes that the representations follow a zero-mean Gaussian model with the estimated standard deviations, which is very similar with Balleet al. (2018)\u2019s approach",
        "Even when setting aside the case of multi-scale structural similarity, our results can be viewed as one concrete evidence supporting that artificial neural networks-based image compression can outperform the existing traditional image codecs in terms of the compression performance",
        "Based on previous artificial neural networks-based image compression approaches utilizing entropy models (Balleet al., 2017; <a class=\"ref-link\" id=\"cTheis_et+al_2017_a\" href=\"#rTheis_et+al_2017_a\">Theis et al, 2017</a>; Balleet al., 2018), we extended the entropy model to exploit two different types of contexts"
    ],
    "summary": [
        "Artificial neural networks (ANNs) have been applied in various areas and have achieved a number of breakthroughs resulting from their superior optimization and representation learning performance.",
        "When an input image x is transformed into a latent representation y and uniformly quantized into y, the simple entropy model can be represented by py(y), as described by Balleet al.",
        "We allow the model to more accurately estimate the distribution of each latent representation through the use of a more generalized form of the entropy models, and more effectively reduce the spatial dependencies among the adjacent latent representations.",
        "In Section 2, we introduce the key approaches of end-to-end optimized image compression and propose the context-adaptive entropy model.",
        "(2017) and <a class=\"ref-link\" id=\"cTheis_et+al_2017_a\" href=\"#rTheis_et+al_2017_a\">Theis et al (2017</a>), entropy models, which approximate the distribution of discrete latent representations, have noticeably improved the image compression performance of ANN-based approaches.",
        "Note that actual entropy coding or decoding processes are not necessarily required for training or encoding because the rate term is not the amount of real bits, but an estimation calculated from the entropy models, as mentioned previously.",
        "An input image is transformed into latent representations, quantized, and entropy-coded using the trained entropy models.",
        "In the case of approaches based on the entropy models, unlike traditional codecs, tuning the quantization steps is usually unnecessary because the scales of the representations are optimized together through training.",
        "The lightweight entropy model assumes that the representations follow a zero-mean Gaussian model with the estimated standard deviations, which is very similar with Balleet al.",
        "We utilize this hybrid approach for the top four cases, in bit-rate descending order, of the nine \u03bb configurations, based on the assumption that for the higher-quality compression, the number of sparse representations having a very low spatial dependency increases, and a direct scale estimation provides sufficient performance for these added representations.",
        "Based on previous ANN-based image compression approaches utilizing entropy models (Balleet al., 2017; <a class=\"ref-link\" id=\"cTheis_et+al_2017_a\" href=\"#rTheis_et+al_2017_a\">Theis et al, 2017</a>; Balleet al., 2018), we extended the entropy model to exploit two different types of contexts.",
        "These contexts allow the entropy models to more accurately estimate the distribution of the representations with a more generalized form having both mean and standard deviation parameters.",
        "(2018) or Oord et al (2016), are combined with the context-adaptivity proposed in this paper, they would provide better results by reducing the mismatch between the actual distributions and the approximation models."
    ],
    "headline": "We propose a context-adaptive entropy model for use in end-to-end optimized image compression",
    "reference_links": [
        {
            "id": "Agustsson_et+al_2018_a",
            "entry": "Eirikur Agustsson, Michael Tschannen, Fabian Mentzer, Radu Timofte, and Luc Van Gool. Generative adversarial networks for extreme learned image compression. arXiv preprint arXiv:1804.02958, 2018. URL http://arxiv.org/abs/1804.02958.",
            "url": "http://arxiv.org/abs/1804.02958",
            "arxiv_url": "https://arxiv.org/pdf/1804.02958"
        },
        {
            "id": "Balle_et+al_2017_a",
            "entry": "Johannes Balle, Valero Laparra, and Eero P. Simoncelli. End-to-end optimized image compression. In the 5th Int. Conf. on Learning Representations, 2017. URL http://arxiv.org/abs/1611.01704.",
            "url": "http://arxiv.org/abs/1611.01704",
            "arxiv_url": "https://arxiv.org/pdf/1611.01704"
        },
        {
            "id": "Balle_et+al_2018_a",
            "entry": "Johannes Balle, David Minnen, Saurabh Singh, Sung Jin Hwang, and Nick Johnston. Variational image compression with a scale hyperprior. In the 6th Int. Conf. on Learning Representations, 2018. URL http://arxiv.org/abs/1802.01436.",
            "url": "http://arxiv.org/abs/1802.01436",
            "arxiv_url": "https://arxiv.org/pdf/1802.01436"
        },
        {
            "id": "Bellard_2014_a",
            "entry": "Fabrice Bellard. Bpg image format, 2014. URL http://bellard.org/bpg/.",
            "url": "http://bellard.org/bpg/"
        },
        {
            "id": "Dong_et+al_2015_a",
            "entry": "Chao Dong, Yubin Deng, Chen Change Loy, and Xiaoou Tang Tang. Compression artifacts reduction by a deep convolutional network. In IEEE International Conference on Computer Vision (ICCV), 2015. URL http://arxiv.org/abs/1504.06993.",
            "url": "http://arxiv.org/abs/1504.06993",
            "arxiv_url": "https://arxiv.org/pdf/1504.06993"
        },
        {
            "id": "Goodfellow_et+al_2014_a",
            "entry": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger (eds.), Advances in Neural Information Processing Systems 27, pp. 2672\u20132680. Curran Associates, Inc., 2014. URL http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf.",
            "url": "http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Goodfellow%2C%20Ian%20Pouget-Abadie%2C%20Jean%20Mirza%2C%20Mehdi%20Xu%2C%20Bing%20Generative%20adversarial%20nets%202014"
        },
        {
            "id": "ISO/IEC_2013_a",
            "entry": "ISO/IEC 23008-2, ITU-T H.265. Information technology \u2013 high efficiency coding and media delivery in heterogeneous environments \u2013 part 2: High efficiency video coding. Standard, ISO/IEC, 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=ISOIEC%20230082%20ITUT%20H265%20Information%20technology%20%20high%20efficiency%20coding%20and%20media%20delivery%20in%20heterogeneous%20environments%20%20part%202%20High%20efficiency%20video%20coding%20Standard%20ISOIEC%202013"
        },
        {
            "id": "Johnston_et+al_2018_a",
            "entry": "Nick Johnston, Damien Vincent, David Minnen, Michele Covell, Saurabh Singh, Troy Chinen, Sung Jin Hwang, Joel Shor, and George Toderici. Improved lossy image compression with priming and spatially adaptive bit rates for recurrent networks. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Johnston%2C%20Nick%20Vincent%2C%20Damien%20Minnen%2C%20David%20Covell%2C%20Michele%20Improved%20lossy%20image%20compression%20with%20priming%20and%20spatially%20adaptive%20bit%20rates%20for%20recurrent%20networks%202018-06",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Johnston%2C%20Nick%20Vincent%2C%20Damien%20Minnen%2C%20David%20Covell%2C%20Michele%20Improved%20lossy%20image%20compression%20with%20priming%20and%20spatially%20adaptive%20bit%20rates%20for%20recurrent%20networks%202018-06"
        },
        {
            "id": "Kingma_2015_a",
            "entry": "Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In the 3rd Int. Conf. on Learning Representations, 2015. URL http://arxiv.org/abs/1412.6980.",
            "url": "http://arxiv.org/abs/1412.6980",
            "arxiv_url": "https://arxiv.org/pdf/1412.6980"
        },
        {
            "id": "Kingma_2014_a",
            "entry": "Diederik P Kingma and Max Welling. Auto-encoding variational bayes. In the 2nd Int. Conf. on Learning Representations, 2014. URL http://arxiv.org/abs/1312.6114.",
            "url": "http://arxiv.org/abs/1312.6114",
            "arxiv_url": "https://arxiv.org/pdf/1312.6114"
        },
        {
            "id": "Kodak_0992_a",
            "entry": "Eastman Kodak. Kodak lossless true color image suite (photocd pcd0992), 1993. URL http://r0k.us/graphics/kodak/.",
            "url": "http://r0k.us/graphics/kodak/"
        },
        {
            "id": "Van_et+al_2016_a",
            "entry": "Aaron van den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu. Pixel recurrent neural networks. In the 33 rd International Conference on Machine Learning, 2016. URL http://arxiv.org/abs/1601.06759.",
            "url": "http://arxiv.org/abs/1601.06759",
            "arxiv_url": "https://arxiv.org/pdf/1601.06759"
        },
        {
            "id": "Pathak_et+al_2016_a",
            "entry": "Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and Alexei A. Efros. Context encoders: Feature learning by inpainting. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pathak%2C%20Deepak%20Krahenbuhl%2C%20Philipp%20Donahue%2C%20Jeff%20Darrell%2C%20Trevor%20Context%20encoders%3A%20Feature%20learning%20by%20inpainting%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pathak%2C%20Deepak%20Krahenbuhl%2C%20Philipp%20Donahue%2C%20Jeff%20Darrell%2C%20Trevor%20Context%20encoders%3A%20Feature%20learning%20by%20inpainting%202016"
        },
        {
            "id": "Radford_et+al_2016_a",
            "entry": "Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. In the 4th Int. Conf. on Learning Representations, 2016. URL http://arxiv.org/abs/1511.06434.",
            "url": "http://arxiv.org/abs/1511.06434",
            "arxiv_url": "https://arxiv.org/pdf/1511.06434"
        },
        {
            "id": "Rezende_et+al_2014_a",
            "entry": "Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models. In the 31st Int. Conf. on Machine Learning, 2014. URL http://arxiv.org/abs/1401.4082.",
            "url": "http://arxiv.org/abs/1401.4082",
            "arxiv_url": "https://arxiv.org/pdf/1401.4082"
        },
        {
            "id": "Rippel_2017_a",
            "entry": "Oren Rippel and Lubomir Bourdev. Real-time adaptive image compression. In International Conference on Machine Learning, 2017. URL http://arxiv.org/abs/1705.05823.",
            "url": "http://arxiv.org/abs/1705.05823",
            "arxiv_url": "https://arxiv.org/pdf/1705.05823"
        },
        {
            "id": "Santurkar_et+al_2018_a",
            "entry": "Shibani Santurkar, David M. Budden, and Nir Shavit. Generative compression. In The 33rd Picture Coding Symposium, 2018. URL http://arxiv.org/abs/1703.01467.",
            "url": "http://arxiv.org/abs/1703.01467",
            "arxiv_url": "https://arxiv.org/pdf/1703.01467"
        },
        {
            "id": "Svoboda_et+al_2016_a",
            "entry": "Pavel Svoboda, Michal Hradis, David Barina, and Pavel Zemc\u0131k. Compression artifacts removal using convolutional neural networks. In WSCG 24th International Conference on Computer Graphics, Visualization and Computer Vision, 2016. URL http://arxiv.org/abs/1605.00366.",
            "url": "http://arxiv.org/abs/1605.00366",
            "arxiv_url": "https://arxiv.org/pdf/1605.00366"
        },
        {
            "id": "Theis_et+al_2017_a",
            "entry": "Lucas Theis, Wenzhe Shi, Andrew Cunningham, and Ferenc Huszar. Lossy image compression with compressive autoencoders. In the 5th Int. Conf. on Learning Representations, 2017. URL http://arxiv.org/abs/1703.00395.",
            "url": "http://arxiv.org/abs/1703.00395",
            "arxiv_url": "https://arxiv.org/pdf/1703.00395"
        },
        {
            "id": "Thomee_et+al_2016_a",
            "entry": "Bart Thomee, David A. Shamma, Gerald Friedland, Benjamin Elizalde, Karl Ni, Douglas Poland, Damian Borth, and Li-Jia Li. The new data in multimedia research. Communications of the ACM, 59(2):64\u201373, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Thomee%2C%20Bart%20Shamma%2C%20David%20A.%20Friedland%2C%20Gerald%20Elizalde%2C%20Benjamin%20The%20new%20data%20in%20multimedia%20research%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Thomee%2C%20Bart%20Shamma%2C%20David%20A.%20Friedland%2C%20Gerald%20Elizalde%2C%20Benjamin%20The%20new%20data%20in%20multimedia%20research%202016"
        },
        {
            "id": "Toderici_et+al_2017_a",
            "entry": "George Toderici, Damien Vincent, Nick Johnston, Sung Jin Hwang, David Minnen, Joel Shor, and Michele Covell. Full resolution image compression with recurrent neural networks. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2017. doi: 10.1109/CVPR.2017.577. URL http://arxiv.org/abs/1608.05148.",
            "crossref": "https://dx.doi.org/10.1109/CVPR.2017.577",
            "arxiv_url": "https://arxiv.org/pdf/1608.05148"
        },
        {
            "id": "Wang_et+al_2003_a",
            "entry": "Zhou Wang, Eero P. Simoncelli, and Alan C. Bovik. Multiscale structural similarity for image quality assessment. In The Thrity-Seventh Asilomar Conference on Signals, Systems & Computers, 2003. doi: 10.1109/ACSSC.2003.1292216.",
            "crossref": "https://dx.doi.org/10.1109/ACSSC.2003.1292216",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/ACSSC.2003.1292216"
        },
        {
            "id": "Yang_et+al_2017_a",
            "entry": "Chao Yang, Xin Lu, Zhe Lin, Eli Shechtman, Oliver Wang, and Hao Li. High-resolution image inpainting using multi-scale neural patch synthesis. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yang%2C%20Chao%20Lu%2C%20Xin%20Lin%2C%20Zhe%20Shechtman%2C%20Eli%20High-resolution%20image%20inpainting%20using%20multi-scale%20neural%20patch%20synthesis%202017-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yang%2C%20Chao%20Lu%2C%20Xin%20Lin%2C%20Zhe%20Shechtman%2C%20Eli%20High-resolution%20image%20inpainting%20using%20multi-scale%20neural%20patch%20synthesis%202017-07"
        },
        {
            "id": "Yeh_et+al_2017_a",
            "entry": "Raymond A. Yeh, Chen Chen, Teck-Yian Lim, Alexander G. Schwing, Mark Hasegawa-Johnson, and Minh N. Do. Semantic image inpainting with deep generative models. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 6882\u20136890. IEEE Computer Society, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Yeh%2C%20Raymond%20A.%20Chen%2C%20Chen%20Lim%2C%20Teck-Yian%20Schwing%2C%20Alexander%20G.%20Semantic%20image%20inpainting%20with%20deep%20generative%20models%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Yeh%2C%20Raymond%20A.%20Chen%2C%20Chen%20Lim%2C%20Teck-Yian%20Schwing%2C%20Alexander%20G.%20Semantic%20image%20inpainting%20with%20deep%20generative%20models%202017"
        },
        {
            "id": "Zhang_et+al_2017_a",
            "entry": "Kai Zhang, Wangmeng Zuo, Yunjin Chen, Deyu Meng, and Lei Zhang. Beyond a gaussian denoiser: Residual learning of deep CNN for image denoising. IEEE Transactions on Image Processing, 26(7):3142\u20133155, 2017. doi: 10.1109/TIP.2017.2662206. URL http://arxiv.org/abs/1608.03981.",
            "crossref": "https://dx.doi.org/10.1109/TIP.2017.2662206",
            "arxiv_url": "https://arxiv.org/pdf/1608.03981"
        },
        {
            "id": "Zhao_et+al_2017_a",
            "entry": "Junbo Jake Zhao, Michael Mathieu, and Yann LeCun. Energy-based generative adversarial network. In the 5th Int. Conf. on Learning Representations, 2017. URL http://arxiv.org/abs/1609.03126.",
            "url": "http://arxiv.org/abs/1609.03126",
            "arxiv_url": "https://arxiv.org/pdf/1609.03126"
        }
    ]
}

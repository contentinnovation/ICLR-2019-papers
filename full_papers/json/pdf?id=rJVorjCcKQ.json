{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "SLALOM: FAST, VERIFIABLE AND PRIVATE EXECUTION OF NEURAL NETWORKS IN TRUSTED HARDWARE",
        "author": "Florian Tram\u00e8r Stanford University tramer@cs.stanford.edu",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=rJVorjCcKQ"
        },
        "abstract": "As Machine Learning (ML) gets applied to security-critical or sensitive domains, there is a growing need for integrity and privacy for outsourced ML computations. A pragmatic solution comes from Trusted Execution Environments (TEEs), which use hardware and software protections to isolate sensitive computations from the untrusted software stack. However, these isolation guarantees come at a price in performance, compared to untrusted alternatives. This paper initiates the study of high performance execution of Deep Neural Networks (DNNs) in TEEs by efficiently partitioning DNN computations between trusted and untrusted devices. Building upon an efficient outsourcing scheme for matrix multiplication, we propose Slalom, a framework that securely delegates execution of all linear layers in a DNN from a TEE (e.g., Intel SGX or Sanctum) to a faster, yet untrusted, co-located processor. We evaluate Slalom by running DNNs in an Intel SGX enclave, which selectively delegates work to an untrusted GPU. For canonical DNNs (VGG16, MobileNet and ResNet variants) we obtain 6\u00d7 to 20\u00d7 increases in throughput for verifiable inference, and 4\u00d7 to 11\u00d7 for verifiable and private inference."
    },
    "keywords": [
        {
            "term": "speculative execution",
            "url": "https://en.wikipedia.org/wiki/speculative_execution"
        },
        {
            "term": "Machine Learning",
            "url": "https://en.wikipedia.org/wiki/Machine_Learning"
        },
        {
            "term": "Pseudo Random Number Generator",
            "url": "https://en.wikipedia.org/wiki/Pseudo_Random_Number_Generator"
        },
        {
            "term": "neural network",
            "url": "https://en.wikipedia.org/wiki/neural_network"
        }
    ],
    "abbreviations": {
        "ML": "Machine Learning",
        "TEEs": "Trusted Execution Environments",
        "DNNs": "Deep Neural Networks",
        "DNN": "Deep Neural Network",
        "TEES": "TRUSTED EXECUTION ENVIRONMENTS",
        "TEE": "Trusted Execution Environment",
        "PRM": "Processor Reserved Memory",
        "PRNG": "Pseudo Random Number Generator"
    },
    "highlights": [
        "Machine learning is increasingly used in sensitive decision making and security-critical settings",
        "This paper explores a novel approach to this challenge, wherein a Deep Neural Network (DNN) execution is partially outsourced from a Trusted Execution Environments to a co-located, untrusted but faster device",
        "This paper has studied the efficiency of evaluating a Deep Neural Networks in a Trusted Execution Environment (TEE) to provide strong integrity and privacy guarantees",
        "We designed Slalom, a framework for efficient Deep Neural Networks evaluation that outsources all linear layers from a Trusted Execution Environments to a GPU",
        "Slalom can work with any Trusted Execution Environments and we evaluated its performance using Intel SGX on various workloads",
        "For canonical Deep Neural Networks (VGG16, MobileNet and ResNet variants), we have shown that Slalom boosts inference throughput without compromising security"
    ],
    "key_statements": [
        "Machine learning is increasingly used in sensitive decision making and security-critical settings",
        "This paper explores a novel approach to this challenge, wherein a Deep Neural Network (DNN) execution is partially outsourced from a Trusted Execution Environments to a co-located, untrusted but faster device",
        "Trusted Execution Environments offer an efficient solution for Machine Learning outsourcing: The server runs an enclave that initiates a secure communication with C and evaluates a model F on C\u2019s input data",
        "We introduce Slalom, a three-step approach for outsourcing Deep Neural Networks from a Trusted Execution Environments to an untrusted but faster device: (1) Inputs and weights are quantized and embedded in a field F; (2) Linear layers are outsourced and verified using Freivalds\u2019 algorithm; (3) Inputs of linear layers are encrypted with a pre-computed pseudorandom stream to guarantee privacy",
        "Our micro-benchmark suite consists of square matrix products of increasing dimensions, convolutional operations performed by VGG16, and separable convolutions performed by MobileNet",
        "This paper has studied the efficiency of evaluating a Deep Neural Networks in a Trusted Execution Environment (TEE) to provide strong integrity and privacy guarantees",
        "We explored new approaches for segmenting a Deep Neural Networks evaluation to securely outsource work from a trusted environment to a faster co-located but untrusted processor",
        "We designed Slalom, a framework for efficient Deep Neural Networks evaluation that outsources all linear layers from a Trusted Execution Environments to a GPU",
        "Slalom can work with any Trusted Execution Environments and we evaluated its performance using Intel SGX on various workloads",
        "For canonical Deep Neural Networks (VGG16, MobileNet and ResNet variants), we have shown that Slalom boosts inference throughput without compromising security",
        "Our general approach of outsourcing work from a Trusted Execution Environments to a faster co-processor could be applied to other problems which have fast verification algorithms, e.g., those considered in (<a class=\"ref-link\" id=\"cMcconnell_et+al_2011_a\" href=\"#rMcconnell_et+al_2011_a\">McConnell et al, 2011</a>; <a class=\"ref-link\" id=\"cZhang_et+al_2014_a\" href=\"#rZhang_et+al_2014_a\">Zhang et al, 2014</a>)"
    ],
    "summary": [
        "Machine learning is increasingly used in sensitive decision making and security-critical settings.",
        "TEEs offer an efficient solution for ML outsourcing: The server runs an enclave that initiates a secure communication with C and evaluates a model F on C\u2019s input data.",
        "We verify integrity of outsourced linear layers using variants of an algorithm by <a class=\"ref-link\" id=\"cFreivalds_1977_a\" href=\"#rFreivalds_1977_a\">Freivalds (1977</a>).",
        "Using Freivalds\u2019 algorithm and symmetric encryption for each linear layer in a DNN incurs high interaction and communication between the TEE and untrusted co-processor.",
        "We introduce Slalom, a three-step approach for outsourcing DNNs from a TEE to an untrusted but faster device: (1) Inputs and weights are quantized and embedded in a field F; (2) Linear layers are outsourced and verified using Freivalds\u2019 algorithm; (3) Inputs of linear layers are encrypted with a pre-computed pseudorandom stream to guarantee privacy.",
        "We leverage two facts: (1) DNN weights are fixed at inference time, so part of Freivalds\u2019 check can be precomputed; (2) the TEE can keep secrets from the host S, so the random values s can be re-used across layers or inputs.",
        "Slalom is a secure outsourcing scheme for F between a TEE and an untrusted co-processor S with privacy and t-integrity for t = n/|S|k \u2212 negl(\u03bb).",
        "Assuming the TEE is secure, Slalom is a secure outsourcing scheme between a remote client C and server S with privacy and t-integrity for t = n/|S|k \u2212 negl(\u03bb).",
        "Our aim is to show that, compared to a baseline that runs inference fully in the TEE, outsourcing linear layers increases performance without sacrificing security.",
        "Figure 3 shows the throughout of end-to-end forward passes in two neural networks, VGG16 and MobileNet. For integrity, we compare the secure baseline to two variants of the Slalom algorithm in Figure 1.",
        "This paper has studied the efficiency of evaluating a DNN in a Trusted Execution Environment (TEE) to provide strong integrity and privacy guarantees.",
        "We explored new approaches for segmenting a DNN evaluation to securely outsource work from a trusted environment to a faster co-located but untrusted processor.",
        "We designed Slalom, a framework for efficient DNN evaluation that outsources all linear layers from a TEE to a GPU.",
        "Slalom leverage Freivalds\u2019 algorithm for verifying correctness of linear operators, and encrypts inputs with precomputed blinding factors to preserve privacy.",
        "Our general approach of outsourcing work from a TEE to a faster co-processor could be applied to other problems which have fast verification algorithms, e.g., those considered in (<a class=\"ref-link\" id=\"cMcconnell_et+al_2011_a\" href=\"#rMcconnell_et+al_2011_a\"><a class=\"ref-link\" id=\"cMcconnell_et+al_2011_a\" href=\"#rMcconnell_et+al_2011_a\">McConnell et al, 2011</a></a>; <a class=\"ref-link\" id=\"cZhang_et+al_2014_a\" href=\"#rZhang_et+al_2014_a\"><a class=\"ref-link\" id=\"cZhang_et+al_2014_a\" href=\"#rZhang_et+al_2014_a\">Zhang et al, 2014</a></a>)."
    ],
    "headline": "Building upon an efficient outsourcing scheme for matrix multiplication, we propose Slalom, a framework that securely delegates execution of all linear layers in a Deep Neural Networks from a Trusted Execution Environments to a faster, yet untrusted, co-located processor",
    "reference_links": [
        {
            "id": "Alves_2004_a",
            "entry": "Tiago Alves and Don Felton. Trustzone: Integrated hardware and software security-enabling trusted computing in embedded systems. Technical report, ARM, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Alves%2C%20Tiago%20Felton%2C%20Don%20Trustzone%3A%20Integrated%20hardware%20and%20software%20security-enabling%20trusted%20computing%20in%20embedded%20systems%202004"
        },
        {
            "id": "Ferdinand_2017_a",
            "entry": "Ferdinand Brasser, Urs M\u00fcller, Alexandra Dmitrienko, Kari Kostiainen, Srdjan Capkun, and Ahmad-Reza Sadeghi. Software grand exposure: SGX cache attacks are practical. In USENIX Workshop on Offensive Technologies, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ferdinand%20Brasser%20Urs%20M%C3%BCller%20Alexandra%20Dmitrienko%20Kari%20Kostiainen%20Srdjan%20Capkun%20and%20AhmadReza%20Sadeghi%20Software%20grand%20exposure%20SGX%20cache%20attacks%20are%20practical%20In%20USENIX%20Workshop%20on%20Offensive%20Technologies%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ferdinand%20Brasser%20Urs%20M%C3%BCller%20Alexandra%20Dmitrienko%20Kari%20Kostiainen%20Srdjan%20Capkun%20and%20AhmadReza%20Sadeghi%20Software%20grand%20exposure%20SGX%20cache%20attacks%20are%20practical%20In%20USENIX%20Workshop%20on%20Offensive%20Technologies%202017"
        },
        {
            "id": "Canetti_et+al_2002_a",
            "entry": "Ran Canetti, Yehuda Lindell, Rafail Ostrovsky, and Amit Sahai. Universally composable two-party and multi-party secure computation. In Proceedings of the thiry-fourth annual ACM symposium on Theory of computing, pp. 494\u2013503. ACM, 2002.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Canetti%2C%20Ran%20Lindell%2C%20Yehuda%20Ostrovsky%2C%20Rafail%20Sahai%2C%20Amit%20Universally%20composable%20two-party%20and%20multi-party%20secure%20computation%202002",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Canetti%2C%20Ran%20Lindell%2C%20Yehuda%20Ostrovsky%2C%20Rafail%20Sahai%2C%20Amit%20Universally%20composable%20two-party%20and%20multi-party%20secure%20computation%202002"
        },
        {
            "id": "Chen_et+al_2018_a",
            "entry": "Guoxing Chen, Sanchuan Chen, Yuan Xiao, Yinqian Zhang, Zhiqiang Lin, and Ten H Lai. SGXPECTRE attacks: Leaking enclave secrets via speculative execution. arXiv preprint arXiv:1802.09085, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1802.09085"
        },
        {
            "id": "Chen_et+al_2017_a",
            "entry": "Sanchuan Chen, Xiaokuan Zhang, Michael K Reiter, and Yinqian Zhang. Detecting privileged side-channel attacks in shielded execution with d\u00e9j\u00e1 vu. In ACM Asia Conference on Computer and Communications Security (ASIACCS), pp. 7\u201318. ACM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chen%2C%20Sanchuan%20Zhang%2C%20Xiaokuan%20Reiter%2C%20Michael%20K.%20Zhang%2C%20Yinqian%20Detecting%20privileged%20side-channel%20attacks%20in%20shielded%20execution%20with%20d%C3%A9j%C3%A1%20vu%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chen%2C%20Sanchuan%20Zhang%2C%20Xiaokuan%20Reiter%2C%20Michael%20K.%20Zhang%2C%20Yinqian%20Detecting%20privileged%20side-channel%20attacks%20in%20shielded%20execution%20with%20d%C3%A9j%C3%A1%20vu%202017"
        },
        {
            "id": "Cheng_et+al_2018_a",
            "entry": "Raymond Cheng, Fan Zhang, Jernej Kos, Warren He, Nicholas Hynes, Noah Johnson, Ari Juels, Andrew Miller, and Dawn Song. Ekiden: A platform for confidentiality-preserving, trustworthy, and performant smart contract execution. arXiv preprint arXiv:1804.05141, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1804.05141"
        },
        {
            "id": "Chollet_2015_a",
            "entry": "Fran\u00e7ois Chollet et al. Keras. https://keras.io, 2015.",
            "url": "https://keras.io"
        },
        {
            "id": "Chollet_2017_a",
            "entry": "Fran\u00e7ois Chollet. Xception: Deep learning with depthwise separable convolutions. In Conference on Computer Vision and Pattern Recognition (CVPR), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chollet%2C%20Fran%C3%A7ois%20Xception%3A%20Deep%20learning%20with%20depthwise%20separable%20convolutions%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chollet%2C%20Fran%C3%A7ois%20Xception%3A%20Deep%20learning%20with%20depthwise%20separable%20convolutions%202017"
        },
        {
            "id": "Costan_2016_a",
            "entry": "Victor Costan and Srinivas Devadas. Intel SGX explained. https://eprint.iacr.org/2016/086, 2016.",
            "url": "https://eprint.iacr.org/2016/086"
        },
        {
            "id": "Costan_et+al_2016_b",
            "entry": "Victor Costan, Ilia Lebedev, and Srinivas Devadas. Sanctum: Minimal hardware extensions for strong software isolation. In USENIX Security Symposium, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Costan%2C%20Victor%20Lebedev%2C%20Ilia%20Devadas%2C%20Srinivas%20Sanctum%3A%20Minimal%20hardware%20extensions%20for%20strong%20software%20isolation%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Costan%2C%20Victor%20Lebedev%2C%20Ilia%20Devadas%2C%20Srinivas%20Sanctum%3A%20Minimal%20hardware%20extensions%20for%20strong%20software%20isolation%202016"
        },
        {
            "id": "Dall_et+al_2018_a",
            "entry": "Fergus Dall, Gabrielle De Micheli, Thomas Eisenbarth, Daniel Genkin, Nadia Heninger, Ahmad Moghimi, and Yuval Yarom. Cachequote: Efficiently recovering long-term secrets of sgx epid via cache attacks. IACR Transactions on Cryptographic Hardware and Embedded Systems, 2018(2):171\u2013191, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dall%2C%20Fergus%20Micheli%2C%20Gabrielle%20De%20Eisenbarth%2C%20Thomas%20Genkin%2C%20Daniel%20Cachequote%3A%20Efficiently%20recovering%20long-term%20secrets%20of%20sgx%20epid%20via%20cache%20attacks%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dall%2C%20Fergus%20Micheli%2C%20Gabrielle%20De%20Eisenbarth%2C%20Thomas%20Genkin%2C%20Daniel%20Cachequote%3A%20Efficiently%20recovering%20long-term%20secrets%20of%20sgx%20epid%20via%20cache%20attacks%202018"
        },
        {
            "id": "Deng_et+al_2009_a",
            "entry": "Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In Conference on Computer Vision and Pattern Recognition (CVPR), pp. 248\u2013255. IEEE, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Deng%2C%20Jia%20Dong%2C%20Wei%20Socher%2C%20Richard%20Li%2C%20Li-Jia%20Imagenet%3A%20A%20large-scale%20hierarchical%20image%20database%202009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Deng%2C%20Jia%20Dong%2C%20Wei%20Socher%2C%20Richard%20Li%2C%20Li-Jia%20Imagenet%3A%20A%20large-scale%20hierarchical%20image%20database%202009"
        },
        {
            "id": "Fiore_2012_a",
            "entry": "Dario Fiore and Rosario Gennaro. Publicly verifiable delegation of large polynomials and matrix computations, with applications. In Proceedings of the 2012 ACM conference on Computer and communications security, pp. 501\u2013512. ACM, 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fiore%2C%20Dario%20Gennaro%2C%20Rosario%20Publicly%20verifiable%20delegation%20of%20large%20polynomials%20and%20matrix%20computations%2C%20with%20applications%202012",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fiore%2C%20Dario%20Gennaro%2C%20Rosario%20Publicly%20verifiable%20delegation%20of%20large%20polynomials%20and%20matrix%20computations%2C%20with%20applications%202012"
        },
        {
            "id": "Fisch_et+al_2017_a",
            "entry": "Ben Fisch, Dhinakaran Vinayagamurthy, Dan Boneh, and Sergey Gorbunov. Iron: functional encryption using intel sgx. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 765\u2013782. ACM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Fisch%2C%20Ben%20Vinayagamurthy%2C%20Dhinakaran%20Boneh%2C%20Dan%20Gorbunov%2C%20Sergey%20Iron%3A%20functional%20encryption%20using%20intel%20sgx%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Fisch%2C%20Ben%20Vinayagamurthy%2C%20Dhinakaran%20Boneh%2C%20Dan%20Gorbunov%2C%20Sergey%20Iron%3A%20functional%20encryption%20using%20intel%20sgx%202017"
        },
        {
            "id": "Freivalds_1977_a",
            "entry": "Rusins Freivalds. Probabilistic machines can use less running time. In IFIP congress, volume 839, pp. 842, 1977.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Freivalds%2C%20Rusins%20Probabilistic%20machines%20can%20use%20less%20running%20time%201977",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Freivalds%2C%20Rusins%20Probabilistic%20machines%20can%20use%20less%20running%20time%201977"
        },
        {
            "id": "Ghodsi_et+al_2017_a",
            "entry": "Zahra Ghodsi, Tianyu Gu, and Siddharth Garg. Safetynets: Verifiable execution of deep neural networks on an untrusted cloud. In Advances In Neural Information Processing Systems (NIPS), pp. 4675\u20134684, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ghodsi%2C%20Zahra%20Gu%2C%20Tianyu%20Garg%2C%20Siddharth%20Safetynets%3A%20Verifiable%20execution%20of%20deep%20neural%20networks%20on%20an%20untrusted%20cloud%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ghodsi%2C%20Zahra%20Gu%2C%20Tianyu%20Garg%2C%20Siddharth%20Safetynets%3A%20Verifiable%20execution%20of%20deep%20neural%20networks%20on%20an%20untrusted%20cloud%202017"
        },
        {
            "id": "Gilad-Bachrach_et+al_2016_a",
            "entry": "Ran Gilad-Bachrach, Nathan Dowlin, Kim Laine, Kristin Lauter, Michael Naehrig, and John Wernsing. Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy. In International Conference on Machine Learning (ICML), pp. 201\u2013210, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gilad-Bachrach%2C%20Ran%20Dowlin%2C%20Nathan%20Laine%2C%20Kim%20Lauter%2C%20Kristin%20Cryptonets%3A%20Applying%20neural%20networks%20to%20encrypted%20data%20with%20high%20throughput%20and%20accuracy%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gilad-Bachrach%2C%20Ran%20Dowlin%2C%20Nathan%20Laine%2C%20Kim%20Lauter%2C%20Kristin%20Cryptonets%3A%20Applying%20neural%20networks%20to%20encrypted%20data%20with%20high%20throughput%20and%20accuracy%202016"
        },
        {
            "id": "Goetzfried_et+al_2017_a",
            "entry": "Johannes G\u00f6tzfried, Moritz Eckert, Sebastian Schinzel, and Tilo M\u00fcller. Cache attacks on Intel SGX. In European Workshop on Systems Security, pp. 2. ACM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=G%C3%B6tzfried%2C%20Johannes%20Eckert%2C%20Moritz%20Schinzel%2C%20Sebastian%20M%C3%BCller%2C%20Tilo%20Cache%20attacks%20on%20Intel%20SGX%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=G%C3%B6tzfried%2C%20Johannes%20Eckert%2C%20Moritz%20Schinzel%2C%20Sebastian%20M%C3%BCller%2C%20Tilo%20Cache%20attacks%20on%20Intel%20SGX%202017"
        },
        {
            "id": "Gupta_et+al_2015_a",
            "entry": "Suyog Gupta, Ankur Agrawal, Kailash Gopalakrishnan, and Pritish Narayanan. Deep learning with limited numerical precision. In International Conference on Machine Learning (ICML), pp. 1737\u20131746, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Gupta%2C%20Suyog%20Agrawal%2C%20Ankur%20Gopalakrishnan%2C%20Kailash%20Narayanan%2C%20Pritish%20Deep%20learning%20with%20limited%20numerical%20precision%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Gupta%2C%20Suyog%20Agrawal%2C%20Ankur%20Gopalakrishnan%2C%20Kailash%20Narayanan%2C%20Pritish%20Deep%20learning%20with%20limited%20numerical%20precision%202015"
        },
        {
            "id": "Hanzlik_et+al_2018_a",
            "entry": "Lucjan Hanzlik, Yang Zhang, Kathrin Grosse, Ahmed Salem, Max Augustin, Michael Backes, and Mario Fritz. Mlcapsule: Guarded offline deployment of machine learning as a service. arXiv preprint arXiv:1808.00590, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1808.00590"
        },
        {
            "id": "Harnik_2017_a",
            "entry": "Danny Harnik and Eliad Tsfadia. Impressions of Intel SGX performance. https://medium.com/@danny_harnik/impressions-of-intel-sgx-performance-22442093595a, 2017. Accessed on May 17, 2018.",
            "url": "https://medium.com/@danny_harnik/impressions-of-intel-sgx-performance-22442093595a"
        },
        {
            "id": "He_et+al_2016_a",
            "entry": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770\u2013778, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=He%2C%20Kaiming%20Zhang%2C%20Xiangyu%20Ren%2C%20Shaoqing%20Sun%2C%20Jian%20Deep%20residual%20learning%20for%20image%20recognition%202016"
        },
        {
            "id": "Howard_et+al_2017_a",
            "entry": "Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1704.04861"
        },
        {
            "id": "Hunt_et+al_2018_a",
            "entry": "Tyler Hunt, Congzheng Song, Reza Shokri, Vitaly Shmatikov, and Emmett Witchel. Chiron: Privacy-preserving machine learning as a service. arXiv preprint arXiv:1803.05961, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.05961"
        },
        {
            "id": "Corp_2015_a",
            "entry": "Intel Corp. Intel Software Guard Extensions Evaluation SDK. https://software.intel.com/en-us/sgx-sdk, 2015.",
            "url": "https://software.intel.com/en-us/sgx-sdk"
        },
        {
            "id": "Corp_2018_a",
            "entry": "Intel Corp. Intel software guard extensions (sgx) SW development guidance for potential bounds check bypass (CVE2017-5753) side channel exploits. https://software.intel.com/sites/default/files/180204_SGX_ SDK_Developer_Guidance_v1.0.pdf, 2018.",
            "url": "https://software.intel.com/sites/default/files/180204_SGX_SDK_Developer_Guidance_v1.0.pdf"
        },
        {
            "id": "Juvekar_et+al_2018_a",
            "entry": "Chiraag Juvekar, Vinod Vaikuntanathan, and Anantha Chandrakasan. Gazelle: A low latency framework for secure neural network inference. arXiv preprint arXiv:1801.05507, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1801.05507"
        },
        {
            "id": "Kocher_et+al_2018_a",
            "entry": "Paul Kocher, Daniel Genkin, Daniel Gruss, Werner Haas, Mike Hamburg, Moritz Lipp, Stefan Mangard, Thomas Prescher, Michael Schwarz, and Yuval Yarom. Spectre attacks: Exploiting speculative execution. arXiv preprint arXiv:1801.01203, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1801.01203"
        },
        {
            "id": "Lee_et+al_2017_a",
            "entry": "Sangho Lee, Ming-Wei Shih, Prasun Gera, Taesoo Kim, Hyesoon Kim, and Marcus Peinado. Inferring fine-grained control flow inside SGX enclaves with branch shadowing. In USENIX Security Symposium, pp. 16\u201318, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Lee%2C%20Sangho%20Shih%2C%20Ming-Wei%20Gera%2C%20Prasun%20Kim%2C%20Taesoo%20Inferring%20fine-grained%20control%20flow%20inside%20SGX%20enclaves%20with%20branch%20shadowing%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Lee%2C%20Sangho%20Shih%2C%20Ming-Wei%20Gera%2C%20Prasun%20Kim%2C%20Taesoo%20Inferring%20fine-grained%20control%20flow%20inside%20SGX%20enclaves%20with%20branch%20shadowing%202017"
        },
        {
            "id": "Mcconnell_et+al_2011_a",
            "entry": "Ross M McConnell, Kurt Mehlhorn, Stefan N\u00e4her, and Pascal Schweitzer. Certifying algorithms. Computer Science Review, 5(2):119\u2013161, 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=McConnell%2C%20Ross%20M.%20Mehlhorn%2C%20Kurt%20N%C3%A4her%2C%20Stefan%20Schweitzer%2C%20Pascal%20Certifying%20algorithms%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=McConnell%2C%20Ross%20M.%20Mehlhorn%2C%20Kurt%20N%C3%A4her%2C%20Stefan%20Schweitzer%2C%20Pascal%20Certifying%20algorithms%202011"
        },
        {
            "id": "Mckeen_et+al_2013_a",
            "entry": "Frank McKeen, Ilya Alex, Alex Berenzon, Carlos Rozas, Hisham Shafi, Vedvyas Shanbhogue, and Uday Savagaonkar. Innovative instructions and software model for isolated execution. In International Workshop on Hardware and Architectural Support for Security and Privacy (HASP), 2013.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=McKeen%2C%20Frank%20Alex%2C%20Ilya%20Berenzon%2C%20Alex%20Rozas%2C%20Carlos%20Innovative%20instructions%20and%20software%20model%20for%20isolated%20execution%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=McKeen%2C%20Frank%20Alex%2C%20Ilya%20Berenzon%2C%20Alex%20Rozas%2C%20Carlos%20Innovative%20instructions%20and%20software%20model%20for%20isolated%20execution%202013"
        },
        {
            "id": "Micikevicius_et+al_2018_a",
            "entry": "Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaev, Ganesh Venkatesh, et al. Mixed precision training. In International Conference on Learning Representations (ICLR), 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Micikevicius%2C%20Paulius%20Narang%2C%20Sharan%20Alben%2C%20Jonah%20Diamos%2C%20Gregory%20Mixed%20precision%20training%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Micikevicius%2C%20Paulius%20Narang%2C%20Sharan%20Alben%2C%20Jonah%20Diamos%2C%20Gregory%20Mixed%20precision%20training%202018"
        },
        {
            "id": "Mohassel_2017_a",
            "entry": "Payman Mohassel and Yupeng Zhang. SecureML: A system for scalable privacy-preserving machine learning. In IEEE Symposium on Security and Privacy, pp. 19\u201338. IEEE, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Mohassel%2C%20Payman%20Zhang%2C%20Yupeng%20SecureML%3A%20A%20system%20for%20scalable%20privacy-preserving%20machine%20learning%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Mohassel%2C%20Payman%20Zhang%2C%20Yupeng%20SecureML%3A%20A%20system%20for%20scalable%20privacy-preserving%20machine%20learning%202017"
        },
        {
            "id": "Ohrimenko_et+al_2016_a",
            "entry": "Olga Ohrimenko, Felix Schuster, Cdric Fournet, Aastha Mehta, Sebastian Nowozin, Kapil Vaswani, and Manuel Costa. Oblivious multi-party machine learning on trusted processors. In USENIX Security Symposium, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Ohrimenko%2C%20Olga%20Schuster%2C%20Felix%20Fournet%2C%20Cdric%20Mehta%2C%20Aastha%20Oblivious%20multi-party%20machine%20learning%20on%20trusted%20processors%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Ohrimenko%2C%20Olga%20Schuster%2C%20Felix%20Fournet%2C%20Cdric%20Mehta%2C%20Aastha%20Oblivious%20multi-party%20machine%20learning%20on%20trusted%20processors%202016"
        },
        {
            "id": "Orenbach_et+al_2017_a",
            "entry": "Meni Orenbach, Pavel Lifshits, Marina Minkin, and Mark Silberstein. Eleos: Exitless os services for sgx enclaves. In Proceedings of the Twelfth European Conference on Computer Systems, pp. 238\u2013253. ACM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Orenbach%2C%20Meni%20Lifshits%2C%20Pavel%20Minkin%2C%20Marina%20Silberstein%2C%20Mark%20Eleos%3A%20Exitless%20os%20services%20for%20sgx%20enclaves%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Orenbach%2C%20Meni%20Lifshits%2C%20Pavel%20Minkin%2C%20Marina%20Silberstein%2C%20Mark%20Eleos%3A%20Exitless%20os%20services%20for%20sgx%20enclaves%202017"
        },
        {
            "id": "Pass_et+al_2017_a",
            "entry": "Rafael Pass, Elaine Shi, and Florian Tram\u00e8r. Formal abstractions for attested execution secure processors. In EUROCRYPT\u201917, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Pass%2C%20Rafael%20Shi%2C%20Elaine%20Tram%C3%A8r%2C%20Florian%20Formal%20abstractions%20for%20attested%20execution%20secure%20processors%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Pass%2C%20Rafael%20Shi%2C%20Elaine%20Tram%C3%A8r%2C%20Florian%20Formal%20abstractions%20for%20attested%20execution%20secure%20processors%202017"
        },
        {
            "id": "Sheng_et+al_2018_a",
            "entry": "Tao Sheng, Chen Feng, Shaojie Zhuo, Xiaopeng Zhang, Liang Shen, and Mickey Aleksic. A quantization-friendly separable convolution for mobilenets. arXiv preprint arXiv:1803.08607, 2018.",
            "arxiv_url": "https://arxiv.org/pdf/1803.08607"
        },
        {
            "id": "Shih_et+al_2017_a",
            "entry": "Ming-Wei Shih, Sangho Lee, Taesoo Kim, and Marcus Peinado. T-SGX: Eradicating controlled-channel attacks against enclave programs. In Network and Distributed System Security Symposium (NDSS), 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shih%2C%20Ming-Wei%20Lee%2C%20Sangho%20Kim%2C%20Taesoo%20Peinado%2C%20Marcus%20T-SGX%3A%20Eradicating%20controlled-channel%20attacks%20against%20enclave%20programs%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shih%2C%20Ming-Wei%20Lee%2C%20Sangho%20Kim%2C%20Taesoo%20Peinado%2C%20Marcus%20T-SGX%3A%20Eradicating%20controlled-channel%20attacks%20against%20enclave%20programs%202017"
        },
        {
            "id": "Shinde_et+al_2016_a",
            "entry": "Shweta Shinde, Zheng Leong Chua, Viswesh Narayanan, and Prateek Saxena. Preventing page faults from telling your secrets. In ACM Asia Conference on Computer and Communications Security (ASIACCS), pp. 317\u2013328. ACM, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Shinde%2C%20Shweta%20Chua%2C%20Zheng%20Leong%20Narayanan%2C%20Viswesh%20Saxena%2C%20Prateek%20faults%20from%20telling%20your%20secrets%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Shinde%2C%20Shweta%20Chua%2C%20Zheng%20Leong%20Narayanan%2C%20Viswesh%20Saxena%2C%20Prateek%20faults%20from%20telling%20your%20secrets%202016"
        },
        {
            "id": "Simonyan_2014_a",
            "entry": "Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.",
            "arxiv_url": "https://arxiv.org/pdf/1409.1556"
        },
        {
            "id": "Stoica_et+al_2017_a",
            "entry": "Ion Stoica, Dawn Song, Raluca Ada Popa, David Patterson, Michael W Mahoney, Randy Katz, Anthony D Joseph, Michael Jordan, Joseph M Hellerstein, Joseph E Gonzalez, et al. A Berkeley view of systems challenges for AI. arXiv preprint arXiv:1712.05855, 2017.",
            "arxiv_url": "https://arxiv.org/pdf/1712.05855"
        },
        {
            "id": "Subramanyan_et+al_2017_a",
            "entry": "Pramod Subramanyan, Rohit Sinha, Ilia Lebedev, Srinivas Devadas, and Sanjit A Seshia. A formal foundation for secure remote execution of enclaves. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 2435\u20132450. ACM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Subramanyan%2C%20Pramod%20Sinha%2C%20Rohit%20Lebedev%2C%20Ilia%20Srinivas%20Devadas%2C%20and%20Sanjit%20A%20Seshia.%20A%20formal%20foundation%20for%20secure%20remote%20execution%20of%20enclaves%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Subramanyan%2C%20Pramod%20Sinha%2C%20Rohit%20Lebedev%2C%20Ilia%20Srinivas%20Devadas%2C%20and%20Sanjit%20A%20Seshia.%20A%20formal%20foundation%20for%20secure%20remote%20execution%20of%20enclaves%202017"
        },
        {
            "id": "Thaler_2013_a",
            "entry": "Justin Thaler. Time-optimal interactive proofs for circuit evaluation. In Advances in Cryptology\u2013CRYPTO 2013, pp. 71\u201389.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Thaler%2C%20Justin%20Time-optimal%20interactive%20proofs%20for%20circuit%20evaluation%202013",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Thaler%2C%20Justin%20Time-optimal%20interactive%20proofs%20for%20circuit%20evaluation%202013"
        },
        {
            "id": "Tram_et+al_2017_a",
            "entry": "Florian Tram\u00e8r, Fan Zhang, Huang Lin, Jean-Pierre Hubaux, Ari Juels, and Elaine Shi. Sealed-Glass Proofs: Using transparent enclaves to prove and sell knowledge. In IEEE European Symposium on Security and Privacy, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Tram%C3%A8r%2C%20Florian%20Zhang%2C%20Fan%20Lin%2C%20Huang%20Hubaux%2C%20Jean-Pierre%20Sealed-Glass%20Proofs%3A%20Using%20transparent%20enclaves%20to%20prove%20and%20sell%20knowledge%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Tram%C3%A8r%2C%20Florian%20Zhang%2C%20Fan%20Lin%2C%20Huang%20Hubaux%2C%20Jean-Pierre%20Sealed-Glass%20Proofs%3A%20Using%20transparent%20enclaves%20to%20prove%20and%20sell%20knowledge%202017"
        },
        {
            "id": "Bulck_et+al_2017_a",
            "entry": "Jo Van Bulck, Nico Weichbrodt, R\u00fcdiger Kapitza, Frank Piessens, and Raoul Strackx. Telling your secrets without page faults: Stealthy page table-based attacks on enclaved execution. In USENIX Security Symposium, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bulck%2C%20Jo%20Van%20Weichbrodt%2C%20Nico%20Kapitza%2C%20R%C3%BCdiger%20Piessens%2C%20Frank%20Telling%20your%20secrets%20without%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bulck%2C%20Jo%20Van%20Weichbrodt%2C%20Nico%20Kapitza%2C%20R%C3%BCdiger%20Piessens%2C%20Frank%20Telling%20your%20secrets%20without%202017"
        },
        {
            "id": "Bulck_et+al_2018_a",
            "entry": "Jo Van Bulck, Marina Minkin, Ofir Weisse, Daniel Genkin, Baris Kasikci, Frank Piessens, Mark Silberstein, Thomas F. Wenisch, Yuval Yarom, and Raoul Strackx. Foreshadow: Extracting the keys to the Intel SGX kingdom with transient out-of-order execution. In Proceedings of the 27th USENIX Security Symposium, 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bulck%2C%20Jo%20Van%20Minkin%2C%20Marina%20Weisse%2C%20Ofir%20Genkin%2C%20Daniel%20Foreshadow%3A%20Extracting%20the%20keys%20to%20the%20Intel%20SGX%20kingdom%20with%20transient%20out-of-order%20execution%202018",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bulck%2C%20Jo%20Van%20Minkin%2C%20Marina%20Weisse%2C%20Ofir%20Genkin%2C%20Daniel%20Foreshadow%3A%20Extracting%20the%20keys%20to%20the%20Intel%20SGX%20kingdom%20with%20transient%20out-of-order%20execution%202018"
        },
        {
            "id": "Wahby_et+al_2016_a",
            "entry": "Riad S Wahby, Max Howald, Siddharth Garg, Abhi Shelat, and Michael Walfish. Verifiable ASICs. In IEEE Symposium on Security and Privacy, pp. 759\u2013778. IEEE, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wahby%2C%20Riad%20S.%20Howald%2C%20Max%20Garg%2C%20Siddharth%20Shelat%2C%20Abhi%20Verifiable%20ASICs%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wahby%2C%20Riad%20S.%20Howald%2C%20Max%20Garg%2C%20Siddharth%20Shelat%2C%20Abhi%20Verifiable%20ASICs%202016"
        },
        {
            "id": "Wahby_et+al_2017_a",
            "entry": "Riad S Wahby, Ye Ji, Andrew J Blumberg, Abhi Shelat, Justin Thaler, Michael Walfish, and Thomas Wies. Full accounting for verifiable outsourcing. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 2071\u20132086. ACM, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Wahby%2C%20Riad%20S.%20Ji%2C%20Ye%20Blumberg%2C%20Andrew%20J.%20Shelat%2C%20Abhi%20Full%20accounting%20for%20verifiable%20outsourcing%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Wahby%2C%20Riad%20S.%20Ji%2C%20Ye%20Blumberg%2C%20Andrew%20J.%20Shelat%2C%20Abhi%20Full%20accounting%20for%20verifiable%20outsourcing%202017"
        },
        {
            "id": "Xu_et+al_2015_a",
            "entry": "Yuanzhong Xu, Weidong Cui, and Marcus Peinado. Controlled-channel attacks: Deterministic side channels for untrusted operating systems. In S&P\u201915, pp. 640\u2013656. IEEE, 2015.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Xu%2C%20Yuanzhong%20Cui%2C%20Weidong%20Peinado%2C%20Marcus%20Controlled-channel%20attacks%3A%20Deterministic%20side%20channels%20for%20untrusted%20operating%20systems%202015",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Xu%2C%20Yuanzhong%20Cui%2C%20Weidong%20Peinado%2C%20Marcus%20Controlled-channel%20attacks%3A%20Deterministic%20side%20channels%20for%20untrusted%20operating%20systems%202015"
        },
        {
            "id": "Zhang_et+al_2014_a",
            "entry": "Yupeng Zhang, Charalampos Papamanthou, and Jonathan Katz. Alitheia: Towards practical verifiable graph processing. In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, pp. 856\u2013867. ACM, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Zhang%2C%20Yupeng%20Papamanthou%2C%20Charalampos%20Katz%2C%20Jonathan%20Alitheia%3A%20Towards%20practical%20verifiable%20graph%20processing%202014",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Zhang%2C%20Yupeng%20Papamanthou%2C%20Charalampos%20Katz%2C%20Jonathan%20Alitheia%3A%20Towards%20practical%20verifiable%20graph%20processing%202014"
        },
        {
            "id": "SGX_2016_a",
            "entry": "SGX enclaves isolate execution of a program from all other processes on a same host, including a potentially malicious OS. In particular, enclave memory is fully encrypted and authenticated. When a word is read from memory into a CPU register, a Memory Management Engine handles the decryption (Costan & Devadas, 2016).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=SGX%20enclaves%20isolate%20execution%20of%20a%20program%20from%20all%20other%20processes%20on%20a%20same%20host%20including%20a%20potentially%20malicious%20OS%20In%20particular%20enclave%20memory%20is%20fully%20encrypted%20and%20authenticated%20When%20a%20word%20is%20read%20from%20memory%20into%20a%20CPU%20register%20a%20Memory%20Management%20Engine%20handles%20the%20decryption%20Costan%20%20Devadas%202016"
        },
        {
            "id": "While_2016_b",
            "entry": "While SGX covers many software and hardware attack vectors, there is a large and prominent class of sidechannel attacks that it explicitly does not address (Costan & Devadas, 2016; Tram\u00e8r et al., 2017). In the past years, many attacks have been proposed, with the goal of undermining privacy of enclave computations (Xu et al., 2015; Brasser et al., 2017; Moghimi et al., 2017; G\u00f6tzfried et al., 2017; Van Bulck et al., 2017; Lee et al., 2017). Most of these attacks rely on data dependent code behavior in an enclave (e.g., branching or memory access) that can be partially observed by other processes running on the same host. These side-channels are a minor concern for the DNN computations considered in this paper, as the standard computations in a DNN are data-oblivious (i.e., the same operations are applied regardless of the input data) (Ohrimenko et al., 2016).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=While%20SGX%20covers%20many%20software%20and%20hardware%20attack%20vectors%20there%20is%20a%20large%20and%20prominent%20class%20of%20sidechannel%20attacks%20that%20it%20explicitly%20does%20not%20address%20Costan%20%20Devadas%202016%20Tram%C3%A8r%20et%20al%202017%20In%20the%20past%20years%20many%20attacks%20have%20been%20proposed%20with%20the%20goal%20of%20undermining%20privacy%20of%20enclave%20computations%20Xu%20et%20al%202015%20Brasser%20et%20al%202017%20Moghimi%20et%20al%202017%20G%C3%B6tzfried%20et%20al%202017%20Van%20Bulck%20et%20al%202017%20Lee%20et%20al%202017%20Most%20of%20these%20attacks%20rely%20on%20data%20dependent%20code%20behavior%20in%20an%20enclave%20eg%20branching%20or%20memory%20access%20that%20can%20be%20partially%20observed%20by%20other%20processes%20running%20on%20the%20same%20host%20These%20sidechannels%20are%20a%20minor%20concern%20for%20the%20DNN%20computations%20considered%20in%20this%20paper%20as%20the%20standard%20computations%20in%20a%20DNN%20are%20dataoblivious%20ie%20the%20same%20operations%20are%20applied%20regardless%20of%20the%20input%20data%20Ohrimenko%20et%20al%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=While%20SGX%20covers%20many%20software%20and%20hardware%20attack%20vectors%20there%20is%20a%20large%20and%20prominent%20class%20of%20sidechannel%20attacks%20that%20it%20explicitly%20does%20not%20address%20Costan%20%20Devadas%202016%20Tram%C3%A8r%20et%20al%202017%20In%20the%20past%20years%20many%20attacks%20have%20been%20proposed%20with%20the%20goal%20of%20undermining%20privacy%20of%20enclave%20computations%20Xu%20et%20al%202015%20Brasser%20et%20al%202017%20Moghimi%20et%20al%202017%20G%C3%B6tzfried%20et%20al%202017%20Van%20Bulck%20et%20al%202017%20Lee%20et%20al%202017%20Most%20of%20these%20attacks%20rely%20on%20data%20dependent%20code%20behavior%20in%20an%20enclave%20eg%20branching%20or%20memory%20access%20that%20can%20be%20partially%20observed%20by%20other%20processes%20running%20on%20the%20same%20host%20These%20sidechannels%20are%20a%20minor%20concern%20for%20the%20DNN%20computations%20considered%20in%20this%20paper%20as%20the%20standard%20computations%20in%20a%20DNN%20are%20dataoblivious%20ie%20the%20same%20operations%20are%20applied%20regardless%20of%20the%20input%20data%20Ohrimenko%20et%20al%202016"
        },
        {
            "id": "Dall_2018_b",
            "entry": "The recent Spectre attacks on speculative execution (Kocher et al., 2018) also prove damaging to SGX (as well as to most other processors), as recently shown (Chen et al., 2018; Dall et al., 2018; Van Bulck et al., 2018). Mitigations for these side-channel attacks are being developed (Shinde et al., 2016; Shih et al., 2017; Chen et al., 2017; Intel Corp., 2018) but a truly secure solution might require some architectural changes, e.g., as in the proposed Sanctum processor (Costan et al., 2016).",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=The%20recent%20Spectre%20attacks%20on%20speculative%20execution%20Kocher%20et%20al%202018%20also%20prove%20damaging%20to%20SGX%20as%20well%20as%20to%20most%20other%20processors%20as%20recently%20shown%20Chen%20et%20al%202018%20Dall%20et%20al%202018%20Van%20Bulck%20et%20al%202018%20Mitigations%20for%20these%20sidechannel%20attacks%20are%20being%20developed%20Shinde%20et%20al%202016%20Shih%20et%20al%202017%20Chen%20et%20al%202017%20Intel%20Corp%202018%20but%20a%20truly%20secure%20solution%20might%20require%20some%20architectural%20changes%20eg%20as%20in%20the%20proposed%20Sanctum%20processor%20Costan%20et%20al%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=The%20recent%20Spectre%20attacks%20on%20speculative%20execution%20Kocher%20et%20al%202018%20also%20prove%20damaging%20to%20SGX%20as%20well%20as%20to%20most%20other%20processors%20as%20recently%20shown%20Chen%20et%20al%202018%20Dall%20et%20al%202018%20Van%20Bulck%20et%20al%202018%20Mitigations%20for%20these%20sidechannel%20attacks%20are%20being%20developed%20Shinde%20et%20al%202016%20Shih%20et%20al%202017%20Chen%20et%20al%202017%20Intel%20Corp%202018%20but%20a%20truly%20secure%20solution%20might%20require%20some%20architectural%20changes%20eg%20as%20in%20the%20proposed%20Sanctum%20processor%20Costan%20et%20al%202016"
        },
        {
            "id": "We_2017_a",
            "entry": "We refrain from formally modeling SGX\u2019s (or other TEE\u2019s) security in this paper, as Slalom is mostly concerned with outsourcing protocols wherein the TEE acts as a client. We refer the interested reader to (Pass et al., 2017; Fisch et al., 2017; Subramanyan et al., 2017) for different attempts at such formalisms.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=We%20refrain%20from%20formally%20modeling%20SGXs%20or%20other%20TEEs%20security%20in%20this%20paper%20as%20Slalom%20is%20mostly%20concerned%20with%20outsourcing%20protocols%20wherein%20the%20TEE%20acts%20as%20a%20client%20We%20refer%20the%20interested%20reader%20to%20Pass%20et%20al%202017%20Fisch%20et%20al%202017%20Subramanyan%20et%20al%202017%20for%20different%20attempts%20at%20such%20formalisms",
            "oa_query": "https://api.scholarcy.com/oa_version?query=We%20refrain%20from%20formally%20modeling%20SGXs%20or%20other%20TEEs%20security%20in%20this%20paper%20as%20Slalom%20is%20mostly%20concerned%20with%20outsourcing%20protocols%20wherein%20the%20TEE%20acts%20as%20a%20client%20We%20refer%20the%20interested%20reader%20to%20Pass%20et%20al%202017%20Fisch%20et%20al%202017%20Subramanyan%20et%20al%202017%20for%20different%20attempts%20at%20such%20formalisms"
        },
        {
            "id": "As_2002_a",
            "entry": "As noted in Section 2.1, a meaningful model-privacy guarantee with respect to C requires that S first commit to a specific DNN F, and then convinces C that her outputs were produced with the same model as all other clients\u2019. We refer the reader to Canetti et al. (2002) for formal definitions for such commit-and-prove schemes, and to Tram\u00e8r et al. (2017) who show how to trivially instantiate them using a TEE.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=As%20noted%20in%20Section%2021%20a%20meaningful%20modelprivacy%20guarantee%20with%20respect%20to%20C%20requires%20that%20S%20first%20commit%20to%20a%20specific%20DNN%20F%20and%20then%20convinces%20C%20that%20her%20outputs%20were%20produced%20with%20the%20same%20model%20as%20all%20other%20clients%20We%20refer%20the%20reader%20to%20Canetti%20et%20al%202002%20for%20formal%20definitions%20for%20such%20commitandprove%20schemes%20and%20to%20Tram%C3%A8r%20et%20al%202017%20who%20show%20how%20to%20trivially%20instantiate%20them%20using%20a%20TEE",
            "oa_query": "https://api.scholarcy.com/oa_version?query=As%20noted%20in%20Section%2021%20a%20meaningful%20modelprivacy%20guarantee%20with%20respect%20to%20C%20requires%20that%20S%20first%20commit%20to%20a%20specific%20DNN%20F%20and%20then%20convinces%20C%20that%20her%20outputs%20were%20produced%20with%20the%20same%20model%20as%20all%20other%20clients%20We%20refer%20the%20reader%20to%20Canetti%20et%20al%202002%20for%20formal%20definitions%20for%20such%20commitandprove%20schemes%20and%20to%20Tram%C3%A8r%20et%20al%202017%20who%20show%20how%20to%20trivially%20instantiate%20them%20using%20a%20TEE"
        },
        {
            "id": "Safetynets_2017_a",
            "entry": "SafetyNets (Ghodsi et al., 2017) and Gazelle (Juvekar et al., 2018) are two representative works that achieve respectively integrity and privacy using purely cryptographic approaches (without a TEE). SafetyNets does not hide the model from either party, while Gazelle leaks some architectural details to the client. The cryptographic techniques used by these systems incur large computation and communication overheads in practice. The largest model evaluated by SafetyNets is a 4-layer TIMIT model with quadratic activations which runs at about 13 images/sec (on a notebook CPU). In our baseline enclave, the same model runs at over 3,500 images/sec. The largest model evaluated by Gazelle is an 8-layer CIFAR10 model. In the enclave, we can evaluate 450 images/sec whereas Gazelle evaluates a single image in 3.5 sec with 300MB of communication between client and server.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=SafetyNets%20Ghodsi%20et%20al%202017%20and%20Gazelle%20Juvekar%20et%20al%202018%20are%20two%20representative%20works%20that%20achieve%20respectively%20integrity%20and%20privacy%20using%20purely%20cryptographic%20approaches%20without%20a%20TEE%20SafetyNets%20does%20not%20hide%20the%20model%20from%20either%20party%20while%20Gazelle%20leaks%20some%20architectural%20details%20to%20the%20client%20The%20cryptographic%20techniques%20used%20by%20these%20systems%20incur%20large%20computation%20and%20communication%20overheads%20in%20practice%20The%20largest%20model%20evaluated%20by%20SafetyNets%20is%20a%204layer%20TIMIT%20model%20with%20quadratic%20activations%20which%20runs%20at%20about%2013%20imagessec%20on%20a%20notebook%20CPU%20In%20our%20baseline%20enclave%20the%20same%20model%20runs%20at%20over%203500%20imagessec%20The%20largest%20model%20evaluated%20by%20Gazelle%20is%20an%208layer%20CIFAR10%20model%20In%20the%20enclave%20we%20can%20evaluate%20450%20imagessec%20whereas%20Gazelle%20evaluates%20a%20single%20image%20in%2035%20sec%20with%20300MB%20of%20communication%20between%20client%20and%20server"
        },
        {
            "id": "Table_2015_a",
            "entry": "Table 3 provides details about the two DNNs we use in our evaluation (all pre-trained models are taken from Keras Chollet et al. (2015)). We report top 1 and top 5 accuracy on ImageNet with and without the simple quantization scheme described in Section 3.1. Quantization results in at most a 0.5% drop in top 1 and top 5 accuracy. More elaborate quantization schemes exist (e.g., Micikevicius et al. (2018)) that we have not experimented with in this work.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Table%203%20provides%20details%20about%20the%20two%20DNNs%20we%20use%20in%20our%20evaluation%20all%20pretrained%20models%20are%20taken%20from%20Keras%20Chollet%20et%20al%202015%20We%20report%20top%201%20and%20top%205%20accuracy%20on%20ImageNet%20with%20and%20without%20the%20simple%20quantization%20scheme%20described%20in%20Section%2031%20Quantization%20results%20in%20at%20most%20a%2005%20drop%20in%20top%201%20and%20top%205%20accuracy%20More%20elaborate%20quantization%20schemes%20exist%20eg%20Micikevicius%20et%20al%202018%20that%20we%20have%20not%20experimented%20with%20in%20this%20work",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Table%203%20provides%20details%20about%20the%20two%20DNNs%20we%20use%20in%20our%20evaluation%20all%20pretrained%20models%20are%20taken%20from%20Keras%20Chollet%20et%20al%202015%20We%20report%20top%201%20and%20top%205%20accuracy%20on%20ImageNet%20with%20and%20without%20the%20simple%20quantization%20scheme%20described%20in%20Section%2031%20Quantization%20results%20in%20at%20most%20a%2005%20drop%20in%20top%201%20and%20top%205%20accuracy%20More%20elaborate%20quantization%20schemes%20exist%20eg%20Micikevicius%20et%20al%202018%20that%20we%20have%20not%20experimented%20with%20in%20this%20work"
        }
    ]
}

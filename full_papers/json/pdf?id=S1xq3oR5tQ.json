{
    "filename": "pdf.pdf",
    "metadata": {
        "title": "A UNIFIED THEORY OF EARLY VISUAL REPRESENTATIONS FROM RETINA TO CORTEX THROUGH ANATOMICALLY CONSTRAINED DEEP CNNS",
        "author": "Jack Lindsey, Samuel A. Ocko, Surya Ganguli, Stephane Deny, Department of Applied Physics, Stanford and 1Google Brain, Mountain View, CA",
        "date": 2019,
        "identifiers": {
            "url": "https://openreview.net/pdf?id=S1xq3oR5tQ"
        },
        "abstract": "The vertebrate visual system is hierarchically organized to process visual information in successive stages. Neural representations vary drastically across the first stages of visual processing: at the output of the retina, ganglion cell receptive fields (RFs) exhibit a clear antagonistic center-surround structure, whereas in the primary visual cortex (V1), typical RFs are sharply tuned to a precise orientation. There is currently no unified theory explaining these differences in representations across layers. Here, using a deep convolutional neural network trained on image recognition as a model of the visual system, we show that such differences in representation can emerge as a direct consequence of different neural resource constraints on the retinal and cortical networks, and for the first time we find a single model from which both geometries spontaneously emerge at the appropriate stages of visual processing. The key constraint is a reduced number of neurons at the retinal output, consistent with the anatomy of the optic nerve as a stringent bottleneck. Second, we find that, for simple downstream cortical networks, visual representations at the retinal output emerge as nonlinear and lossy feature detectors, whereas they emerge as linear and faithful encoders of the visual scene for more complex cortical networks. This result predicts that the retinas of small vertebrates (e.g. salamander, frog) should perform sophisticated nonlinear computations, extracting features directly relevant to behavior, whereas retinas of large animals such as primates should mostly encode the visual scene linearly and respond to a much broader range of stimuli. These predictions could reconcile the two seemingly incompatible views of the retina as either performing feature extraction or efficient coding of natural scenes, by suggesting that all vertebrates lie on a spectrum between these two objectives, depending on the degree of neural resources allocated to their visual system."
    },
    "keywords": [
        {
            "term": "geometries",
            "url": "https://en.wikipedia.org/wiki/geometries"
        },
        {
            "term": "visual system",
            "url": "https://en.wikipedia.org/wiki/visual_system"
        },
        {
            "term": "ganglion cell",
            "url": "https://en.wikipedia.org/wiki/ganglion_cell"
        },
        {
            "term": "receptive field",
            "url": "https://en.wikipedia.org/wiki/receptive_field"
        },
        {
            "term": "cell type",
            "url": "https://en.wikipedia.org/wiki/cell_type"
        },
        {
            "term": "visual cortex",
            "url": "https://en.wikipedia.org/wiki/visual_cortex"
        }
    ],
    "abbreviations": {
        "RFs": "receptive fields",
        "VVS-net": "ventral visual system network"
    },
    "highlights": [
        "Why did natural selection shape our visual representations to be the way they are? Traditionally, the properties of the early visual system have been explained with theories of efficient coding, which are based on the premise that the neural representations are optimal at preserving information about the visual scene, under a set of metabolic constraints such as total firing rate or total number of synapses",
        "<a class=\"ref-link\" id=\"cVincent_et+al_2005_a\" href=\"#rVincent_et+al_2005_a\">Vincent et al (2005</a>) propose a different set of constraints for the retina and V1, in which the retina optimizes for a metabolic constraint on total number of synapses, whereas V1 optimizes for a constraint on total firing rate",
        "We show that these two representations can emerge from the requirement to perform a biologically relevant task with a bottleneck constraint on the dimensionality of the retinal output",
        "This constraint differs from the ones used previously to account for center-surround receptive fields",
        "In our framework in many ways), the receptive fields of the retina-net without bottleneck remained oriented across the full range of orders of magnitude of noise and L1 regularization that permitted successful task performance"
    ],
    "key_statements": [
        "Why did natural selection shape our visual representations to be the way they are? Traditionally, the properties of the early visual system have been explained with theories of efficient coding, which are based on the premise that the neural representations are optimal at preserving information about the visual scene, under a set of metabolic constraints such as total firing rate or total number of synapses",
        "These theories can successfully account for the antagonistic center-surround structure of receptive fields (RFs) found in the retina (<a class=\"ref-link\" id=\"cAtick_1990_a\" href=\"#rAtick_1990_a\">Atick & Redlich, 1990</a>; 1992; <a class=\"ref-link\" id=\"cVincent_2003_a\" href=\"#rVincent_2003_a\">Vincent & Baddeley, 2003</a>; <a class=\"ref-link\" id=\"cKarklin_2011_a\" href=\"#rKarklin_2011_a\">Karklin & Simoncelli, 2011</a>; <a class=\"ref-link\" id=\"cDoi_et+al_2012_a\" href=\"#rDoi_et+al_2012_a\">Doi et al, 2012</a>), as well as for the oriented structure of receptive fields found in the primary visual cortex V1 (<a class=\"ref-link\" id=\"cOlshausen_1996_a\" href=\"#rOlshausen_1996_a\">Olshausen & Field, 1996</a>; 1997; <a class=\"ref-link\" id=\"cBell_1997_a\" href=\"#rBell_1997_a\">Bell & Sejnowski, 1997</a>)",
        "It is unclear why receptive fields geometries would be so different in the retina and V1",
        "There is a great diversity of ganglion cell types at the output the retina (<a class=\"ref-link\" id=\"cGollisch_2010_a\" href=\"#rGollisch_2010_a\">Gollisch & Meister, 2010</a>), with each cell type tiling the entire visual field and performing a specific computation. Some of these types perform a highly nonlinear computation, extracting specific, behaviorally-relevant cues from the visual scene, whereas other types are better approximated by a quasi-linear model, and respond to a broad range of stimuli and quasi-linear pixel-encoders in the mouse (<a class=\"ref-link\" id=\"cJohnson_et+al_2018_a\" href=\"#rJohnson_et+al_2018_a\">Johnson et al, 2018</a>))",
        "Quasi-linear and more nonlinear types exist in species of all sizes), the proportion of cells performing a rather linear encoding versus a nonlinear feature detection seems to vary across species",
        "The most common ganglion cell type in the primate retina is fairly well approximated by a quasi-linear pixel-encoder), whereas the most common cell type in mouse acts as a specific feature detector, thought to serve as an alarm system for overhead predators (W3 cells, 13% of all ganglion cells (<a class=\"ref-link\" id=\"cZhang_et+al_2012_a\" href=\"#rZhang_et+al_2012_a\">Zhang et al, 2012</a>))",
        "Theories of efficient coding have not been able to account for this diversity of computations found across cell types and across species",
        "We modeled the visual system with a series of two convolutional networks, one corresponding to the retina and one downstream network corresponding to the ventral visual system in the brain",
        "We modeled the ventral visual system \u2013 the system associated with object recognition in the brain (Hubel, 1995) \u2013 as a convolutional neural network taking its inputs from the retina-net",
        "The receptive fields geometries did not depend qualitatively on the ventral visual system network depth DV V S, except for the shallowest ventral visual system network tested (DV V S = 0, no convolutional layer, and no dimensionality expansion), for which the shape of emergent retinal receptive fields were variable across trials and difficult to interpret. These results are in good agreement with the organization of the biological visual system, where retinal receptive fields are center-surround and most downstream receptive fields in primary visual cortex (V1) are sharply oriented (Hubel, 1995), suggesting that the dimensionality bottleneck at the output of the retina is sufficient to explain these differences in representations",
        "We found that orientation-selective neurons in the ventral visual system network typically draw primarily from center-surround neurons in the retina-net that are aligned with the direction of the edge, with positive or negative weights corresponding to whether the polarity of the two neurons are consistent or inconsistent (fig. 2C, and App",
        "We found that most neurons in the first layer of the ventral visual system network behaved as simple cells, whereas most neurons in the second layer of the ventral visual system network behaved as complex cells",
        "We found that receptive fields still emerged as center-surround in the retina-net, and as oriented in our model of V1",
        "Even in the untied retina-net, in which each neuron is effectively its own channel, we found that centersurround receptive fields emerged, indicating that center-surround receptive fields are the network\u2019s preferred strategy for passing information through a dimensionality bottleneck even when no constraint on the number of cell types is imposed",
        "To what extent are retinal representations in our model shaped by the degree of neural resources allocated to downstream processing? To investigate this question, we studied the effects of varying the degree of neural resources in the ventral visual system network, on emergent visual representations in the retina-net.\n4.1",
        "As we increased the number of layers in the ventral visual system network, the retinal computation became more linear, as measured by the ability of the raw image to linearly map onto the neural representation at the retinal output (see methods, and App",
        "We found that the prediction error of the linear model was partly explained by both stages of nonlinearity in the retina-net model, predicting that both inner retinal nonlinear processing and ganglion cell rectifications should be more pronounced in animals with fewer neural resources in their visual cortices.\n4.2",
        "We showed that a ventral visual system network consisting of two fully connected layers only equipped and trained end-to-end with a retina with a tight bottleneck NBN = 1 performed better at image recognition than the same ventral visual system network trained without a retina-net, taking raw images as input",
        "<a class=\"ref-link\" id=\"cVincent_et+al_2005_a\" href=\"#rVincent_et+al_2005_a\">Vincent et al (2005</a>) propose a different set of constraints for the retina and V1, in which the retina optimizes for a metabolic constraint on total number of synapses, whereas V1 optimizes for a constraint on total firing rate",
        "We show that these two representations can emerge from the requirement to perform a biologically relevant task with a bottleneck constraint on the dimensionality of the retinal output",
        "This constraint differs from the ones used previously to account for center-surround receptive fields",
        "In our framework in many ways), the receptive fields of the retina-net without bottleneck remained oriented across the full range of orders of magnitude of noise and L1 regularization that permitted successful task performance",
        "We show that our model of the visual system, trained on the same task and with the same input statistics, can exhibit different retinal representations depending on the degree of neural resources allocated to downstream processing by the ventral visual stream"
    ],
    "summary": [
        "Why did natural selection shape our visual representations to be the way they are? Traditionally, the properties of the early visual system have been explained with theories of efficient coding, which are based on the premise that the neural representations are optimal at preserving information about the visual scene, under a set of metabolic constraints such as total firing rate or total number of synapses.",
        "These results are in good agreement with the organization of the biological visual system, where retinal RFs are center-surround and most downstream RFs in primary visual cortex (V1) are sharply oriented (Hubel, 1995), suggesting that the dimensionality bottleneck at the output of the retina is sufficient to explain these differences in representations.",
        "Even in the untied retina-net, in which each neuron is effectively its own channel, we found that centersurround RFs emerged, indicating that center-surround RFs are the network\u2019s preferred strategy for passing information through a dimensionality bottleneck even when no constraint on the number of cell types is imposed.",
        "As we increased the number of layers in the VVS-net, the retinal computation became more linear, as measured by the ability of the raw image to linearly map onto the neural representation at the retinal output.",
        "We found that the prediction error of the linear model was partly explained by both stages of nonlinearity in the retina-net model, predicting that both inner retinal nonlinear processing and ganglion cell rectifications should be more pronounced in animals with fewer neural resources in their visual cortices.",
        "To estimate the information about the input image retained by the retinal output representation, we fit a linear model to reconstruct the image from the outputs of the trained retina-net of interest.",
        "This constraint differs from the ones used previously to account for center-surround RFs. It is worth noting that we unsuccessfully tried to reproduce the result of <a class=\"ref-link\" id=\"cKarklin_2011_a\" href=\"#rKarklin_2011_a\">Karklin & Simoncelli (2011</a>) in our network, by adding noise to the image and applying an L1 regularization to the retina-net activations.",
        "We show that our model of the visual system, trained on the same task and with the same input statistics, can exhibit different retinal representations depending on the degree of neural resources allocated to downstream processing by the ventral visual stream.",
        "In this study we allowed only a limited number of cell types at the retinal output (1 to 4), in order to have a dimensionality expansion between the retinal representation and the representation in the ventral visual stream (32 channels), an important condition to see the retinal center-surround representation emerge.",
        "By studying emergent representations learned by a deep network trained on a biologically relevant task, we found that striking differences in retinal and cortical representations of visual information could be a consequence of the anatomical constraint of transmitting visual information through a low-dimensional communication channel, the optic nerve."
    ],
    "headline": "Using a deep convolutional neural network trained on image recognition as a model of the visual system, we show that such differences in representation can emerge as a direct consequence of different neural resource constraints on the retinal and cortical networks, and for the first time we find a single model from which both geometries spontaneously emerge at the appropriate stages of visual processing",
    "reference_links": [
        {
            "id": "Atick_1990_a",
            "entry": "Joseph J. Atick and A. Norman Redlich. Towards a theory of early visual processing. Neural Computation, 2(3):308\u2013320, 1990.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Atick%2C%20Joseph%20J.%20Redlich%2C%20A.Norman%20Towards%20a%20theory%20of%20early%20visual%20processing%201990",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Atick%2C%20Joseph%20J.%20Redlich%2C%20A.Norman%20Towards%20a%20theory%20of%20early%20visual%20processing%201990"
        },
        {
            "id": "Atick_1992_a",
            "entry": "Joseph J. Atick and A. Norman Redlich. What does the retina know about natural scenes? Neural computation, 4(2):196\u2013210, 1992.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Atick%2C%20Joseph%20J.%20Redlich%2C%20A.Norman%20What%20does%20the%20retina%20know%20about%20natural%20scenes%3F%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Atick%2C%20Joseph%20J.%20Redlich%2C%20A.Norman%20What%20does%20the%20retina%20know%20about%20natural%20scenes%3F%201992"
        },
        {
            "id": "Barlow_1961_a",
            "entry": "HB Barlow. Possible principles underlying the transformations of sensory messages. In WA Rosenblith (ed.), Sensory Communication, pp. 217\u2013234. MIT Press, 1961.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Barlow%2C%20H.B.%20Possible%20principles%20underlying%20the%20transformations%20of%20sensory%20messages%201961",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Barlow%2C%20H.B.%20Possible%20principles%20underlying%20the%20transformations%20of%20sensory%20messages%201961"
        },
        {
            "id": "Bell_1997_a",
            "entry": "A. J. Bell and T. J. Sejnowski. The \u201dindependent components\u201d of natural scenes are edge filters. Vision Research, 37(23):3327\u20133338, December 1997. ISSN 0042-6989.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Bell%2C%20A.J.%20Sejnowski%2C%20T.J.%20The%E2%80%9Dindependent%20components%E2%80%9D%20of%20natural%20scenes%20are%20edge%20filters%201997-12",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Bell%2C%20A.J.%20Sejnowski%2C%20T.J.%20The%E2%80%9Dindependent%20components%E2%80%9D%20of%20natural%20scenes%20are%20edge%20filters%201997-12"
        },
        {
            "id": "Cadena_et+al_2017_a",
            "entry": "Santiago A. Cadena, George H. Denfield, Edgar Y. Walker, Leon A. Gatys, Andreas S. Tolias, Matthias Bethge, and Alexander S. Ecker. Deep convolutional models improve predictions of macaque V1 responses to natural images. bioRxiv, pp. 201764, October 2017. doi: 10.1101/ 201764.",
            "crossref": "https://dx.doi.org/10.1101/201764"
        },
        {
            "id": "Chalk_et+al_2016_a",
            "entry": "Matthew Chalk, Olivier Marre, and Gasper Tkacik. Relevant sparse codes with variational information bottleneck. In D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett (eds.), Advances in Neural Information Processing Systems 29, pp. 1957\u20131965. Curran Associates, Inc., 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chalk%2C%20Matthew%20Marre%2C%20Olivier%20Tkacik%2C%20Gasper%20Relevant%20sparse%20codes%20with%20variational%20information%20bottleneck%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chalk%2C%20Matthew%20Marre%2C%20Olivier%20Tkacik%2C%20Gasper%20Relevant%20sparse%20codes%20with%20variational%20information%20bottleneck%202016"
        },
        {
            "id": "Chalk_et+al_2018_a",
            "entry": "Matthew Chalk, Olivier Marre, and Gaper Tkaik. Toward a unified theory of efficient, predictive, and sparse coding. Proceedings of the National Academy of Sciences of the United States of America, 115(1):186\u2013191, 2018. ISSN 1091-6490. doi: 10.1073/pnas.1711114115.",
            "crossref": "https://dx.doi.org/10.1073/pnas.1711114115",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1073/pnas.1711114115"
        },
        {
            "id": "Chichilnisky_2001_a",
            "entry": "E. J. Chichilnisky. A simple white noise analysis of neuronal light responses. Network (Bristol, England), 12(2):199\u2013213, May 2001. ISSN 0954-898X.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chichilnisky%2C%20E.J.%20A%20simple%20white%20noise%20analysis%20of%20neuronal%20light%20responses.%20Network%202001-05",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chichilnisky%2C%20E.J.%20A%20simple%20white%20noise%20analysis%20of%20neuronal%20light%20responses.%20Network%202001-05"
        },
        {
            "id": "Chung_et+al_2018_a",
            "entry": "SueYeon Chung, Uri Cohen, Haim Sompolinsky, and Daniel D. Lee. Learning Data Manifolds with a Cutting Plane Method. Neural Computation, 30(10):2593\u20132615, October 2018a. ISSN 0899-7667, 1530-888X. doi: 10.1162/neco a 01119.",
            "crossref": "https://dx.doi.org/10.1162/neco",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1162/neco"
        },
        {
            "id": "Chung_et+al_2018_b",
            "entry": "SueYeon Chung, Daniel D. Lee, and Haim Sompolinsky. Classification and Geometry of General Perceptual Manifolds. Physical Review X, 8(3), July 2018b. ISSN 2160-3308. doi: 10.1103/ PhysRevX.8.031003.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Chung%2C%20SueYeon%20Lee%2C%20Daniel%20D.%20Sompolinsky%2C%20Haim%20Classification%20and%20Geometry%20of%20General%20Perceptual%20Manifolds%202018-07",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Chung%2C%20SueYeon%20Lee%2C%20Daniel%20D.%20Sompolinsky%2C%20Haim%20Classification%20and%20Geometry%20of%20General%20Perceptual%20Manifolds%202018-07"
        },
        {
            "id": "Crook_et+al_2008_a",
            "entry": "Joanna D. Crook, Beth B. Peterson, Orin S. Packer, Farrel R. Robinson, John B. Troy, and Dennis M. Dacey. Y-cell receptive field and collicular projection of parasol ganglion cells in macaque monkey retina. The Journal of Neuroscience: The Official Journal of the Society for Neuroscience, 28 (44):11277\u201311291, October 2008. ISSN 1529-2401. doi: 10.1523/JNEUROSCI.2982-08.2008.",
            "crossref": "https://dx.doi.org/10.1523/JNEUROSCI.2982-08.2008",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1523/JNEUROSCI.2982-08.2008"
        },
        {
            "id": "Dacey_2004_a",
            "entry": "Dennis Dacey. Origins of perception: retinal ganglion cell diversity and the creation of parallel visual pathways. In The cognitive neuroscience (2004), pp. 281\u2013301, 2004.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Dacey%2C%20Dennis%20Origins%20of%20perception%3A%20retinal%20ganglion%20cell%20diversity%20and%20the%20creation%20of%20parallel%20visual%20pathways%202004",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Dacey%2C%20Dennis%20Origins%20of%20perception%3A%20retinal%20ganglion%20cell%20diversity%20and%20the%20creation%20of%20parallel%20visual%20pathways%202004"
        },
        {
            "id": "Deny_et+al_2017_a",
            "entry": "Stephane Deny, Ulisse Ferrari, Emilie Mace, Pierre Yger, Romain Caplette, Serge Picaud, Gaper Tkaik, and Olivier Marre. Multiplexed computations in retinal ganglion cells of a single type. Nature communications, 8(1):1964, 2017.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Deny%2C%20Stephane%20Ferrari%2C%20Ulisse%20Mace%2C%20Emilie%20Yger%2C%20Pierre%20Multiplexed%20computations%20in%20retinal%20ganglion%20cells%20of%20a%20single%20type%202017",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Deny%2C%20Stephane%20Ferrari%2C%20Ulisse%20Mace%2C%20Emilie%20Yger%2C%20Pierre%20Multiplexed%20computations%20in%20retinal%20ganglion%20cells%20of%20a%20single%20type%202017"
        },
        {
            "id": "Doi_et+al_2012_a",
            "entry": "Eizaburo Doi, Jeffrey L. Gauthier, Greg D. Field, Jonathon Shlens, Alexander Sher, Martin Greschner, Timothy A. Machado, Lauren H. Jepson, Keith Mathieson, Deborah E. Gunning, Alan M. Litke, Liam Paninski, E. J. Chichilnisky, and Eero P. Simoncelli. Efficient coding of spatial information in the primate retina. The Journal of Neuroscience, 32(46):16256\u201316264, November 2012.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Doi%2C%20Eizaburo%20Gauthier%2C%20Jeffrey%20L.%20Field%2C%20Greg%20D.%20Shlens%2C%20Jonathon%20Efficient%20coding%20of%20spatial%20information%20in%20the%20primate%20retina%202012-11",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Doi%2C%20Eizaburo%20Gauthier%2C%20Jeffrey%20L.%20Field%2C%20Greg%20D.%20Shlens%2C%20Jonathon%20Efficient%20coding%20of%20spatial%20information%20in%20the%20primate%20retina%202012-11"
        },
        {
            "id": "Eberhardt_et+al_2016_a",
            "entry": "Sven Eberhardt, Jonah G Cader, and Thomas Serre. How Deep is the Feature Analysis underlying Rapid Visual Categorization? pp. 9, 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Eberhardt%2C%20Sven%20Cader%2C%20Jonah%20G.%20Serre%2C%20Thomas%20How%20Deep%20is%20the%20Feature%20Analysis%20underlying%20Rapid%20Visual%20Categorization%3F%202016"
        },
        {
            "id": "Geisler_1992_a",
            "entry": "Wilson S. Geisler and Duane G. Albrecht. Cortical neurons: isolation of contrast gain control. Vision research, 32(8):1409\u20131410, 1992.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Geisler%2C%20Wilson%20S.%20Albrecht%2C%20Duane%20G.%20Cortical%20neurons%3A%20isolation%20of%20contrast%20gain%20control%201992",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Geisler%2C%20Wilson%20S.%20Albrecht%2C%20Duane%20G.%20Cortical%20neurons%3A%20isolation%20of%20contrast%20gain%20control%201992"
        },
        {
            "id": "Glorot_2010_a",
            "entry": "Xavier Glorot and Yoshua Bengio. Understanding the difficulty of training deep feedforward neural networks. In Proceedings of the thirteenth international conference on artificial intelligence and statistics, pp. 249\u2013256, 2010.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Glorot%2C%20Xavier%20Bengio%2C%20Yoshua%20Understanding%20the%20difficulty%20of%20training%20deep%20feedforward%20neural%20networks%202010",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Glorot%2C%20Xavier%20Bengio%2C%20Yoshua%20Understanding%20the%20difficulty%20of%20training%20deep%20feedforward%20neural%20networks%202010"
        },
        {
            "id": "Gollisch_2010_a",
            "entry": "Tim Gollisch and Markus Meister. Eye smarter than scientists believed: neural computations in circuits of the retina. Neuron, 65(2):150\u2013164, January 2010. ISSN 1097-4199. doi: 10.1016/j. neuron.2009.12.009.",
            "crossref": "https://dx.doi.org/10.1016/j.neuron.2009.12.009",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1016/j.neuron.2009.12.009"
        },
        {
            "id": "Heeger_1992_a",
            "entry": "D. J. Heeger. Normalization of cell responses in cat striate cortex. Visual Neuroscience, 9(2):181\u2013 197, August 1992. ISSN 0952-5238.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Heeger%2C%20D.J.%20Normalization%20of%20cell%20responses%20in%20cat%20striate%20cortex%201992-08",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Heeger%2C%20D.J.%20Normalization%20of%20cell%20responses%20in%20cat%20striate%20cortex%201992-08"
        },
        {
            "id": "Eye_1995_a",
            "entry": "David H. Hubel. Eye, brain, and vision. Scientific American Library/Scientific American Books, 1995.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Eye%2C%20David%20H.Hubel%20brain%20and%20vision%201995"
        },
        {
            "id": "Johnson_et+al_2018_a",
            "entry": "Keith P. Johnson, Lei Zhao, and Daniel Kerschensteiner. A Pixel-Encoder Retinal Ganglion Cell with Spatially Offset Excitatory and Inhibitory Receptive Fields. Cell Reports, 22(6):1462\u20131472, February 2018. ISSN 22111247. doi: 10.1016/j.celrep.2018.01.037.",
            "crossref": "https://dx.doi.org/10.1016/j.celrep.2018.01.037",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1016/j.celrep.2018.01.037"
        },
        {
            "id": "Karklin_2011_a",
            "entry": "Yan Karklin and Eero P. Simoncelli. Efficient coding of natural images with a population of noisy Linear-Nonlinear neurons. In J. Shawe-Taylor, R. S. Zemel, P. L. Bartlett, F. Pereira, and K. Q. Weinberger (eds.), Advances in Neural Information Processing Systems 24, pp. 999\u20131007. Curran Associates, Inc., 2011.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Karklin%2C%20Yan%20Simoncelli%2C%20Eero%20P.%20Efficient%20coding%20of%20natural%20images%20with%20a%20population%20of%20noisy%20Linear-Nonlinear%20neurons%202011",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Karklin%2C%20Yan%20Simoncelli%2C%20Eero%20P.%20Efficient%20coding%20of%20natural%20images%20with%20a%20population%20of%20noisy%20Linear-Nonlinear%20neurons%202011"
        },
        {
            "id": "Koelling_2008_a",
            "entry": "Melinda E. Koelling and Duane Q. Nykamp. Computing linear approximations to nonlinear neuronal response. Network (Bristol, England), 19(4):286\u2013313, 2008. ISSN 1361-6536. doi: 10.1080/09548980802503139.",
            "crossref": "https://dx.doi.org/10.1080/09548980802503139",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1080/09548980802503139"
        },
        {
            "id": "Krizhevsky_2009_a",
            "entry": "Alex Krizhevsky. Learning Multiple Layers of Features from Tiny Images. pp. 60, 2009.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Krizhevsky%2C%20Alex%20Learning%20Multiple%20Layers%20of%20Features%20from%20Tiny%20Images%202009"
        },
        {
            "id": "Lecun_et+al_2015_a",
            "entry": "Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 521(7553):436\u2013444, May 2015. ISSN 1476-4687. doi: 10.1038/nature14539.",
            "crossref": "https://dx.doi.org/10.1038/nature14539",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1038/nature14539"
        },
        {
            "id": "Lettvin_et+al_1959_a",
            "entry": "J. Y. Lettvin, H. R. Maturana, W. S. McCulloch, and W. H. Pitts. What the Frog\u2019s Eye Tells the Frog\u2019s Brain. Proceedings of the IRE, 47(11):1940\u20131951, November 1959. ISSN 0096-8390. doi: 10.1109/JRPROC.1959.287207.",
            "crossref": "https://dx.doi.org/10.1109/JRPROC.1959.287207",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1109/JRPROC.1959.287207"
        },
        {
            "id": "Maheswaranathan_et+al_2018_a",
            "entry": "Niru Maheswaranathan, David B. Kastner, Stephen A. Baccus, and Surya Ganguli. Inferring hidden structure in multilayered neural circuits. PLoS computational biology, 14(8):e1006291, August 2018. ISSN 1553-7358. doi: 10.1371/journal.pcbi.1006291.",
            "crossref": "https://dx.doi.org/10.1371/journal.pcbi.1006291",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1371/journal.pcbi.1006291"
        },
        {
            "id": "Masland_2001_a",
            "entry": "Richard H. Masland. The fundamental plan of the retina. Nature Neuroscience, 4(9):877\u2013886, September 2001. ISSN 1546-1726. doi: 10.1038/nn0901-877.",
            "crossref": "https://dx.doi.org/10.1038/nn0901-877",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1038/nn0901-877"
        },
        {
            "id": "Mcintosh_et+al_2016_a",
            "entry": "Lane McIntosh, Niru Maheswaranathan, Aran Nayebi, Surya Ganguli, and Stephen Baccus. Deep Learning Models of the Retinal Response to Natural Scenes. In D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett (eds.), Advances in Neural Information Processing Systems 29, pp. 1369\u20131377. Curran Associates, Inc., 2016.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=McIntosh%2C%20Lane%20Maheswaranathan%2C%20Niru%20Nayebi%2C%20Aran%20Ganguli%2C%20Surya%20Deep%20Learning%20Models%20of%20the%20Retinal%20Response%20to%20Natural%20Scenes%202016",
            "oa_query": "https://api.scholarcy.com/oa_version?query=McIntosh%2C%20Lane%20Maheswaranathan%2C%20Niru%20Nayebi%2C%20Aran%20Ganguli%2C%20Surya%20Deep%20Learning%20Models%20of%20the%20Retinal%20Response%20to%20Natural%20Scenes%202016"
        },
        {
            "id": "Ocko_et+al_2018_a",
            "entry": "Samuel A. Ocko, Jack Lindsey, Surya Ganguli, and Stephane Deny. The emergence of multiple retinal cell types through efficient coding of natural movies. bioRxiv, pp. 458737, October 2018. doi: 10.1101/458737. URL https://www.biorxiv.org/content/early/2018/10/31/458737.",
            "crossref": "https://dx.doi.org/10.1101/458737"
        },
        {
            "id": "Olshausen_1996_a",
            "entry": "B. A. Olshausen and D. J. Field. Emergence of simple-cell receptive field properties by learning a sparse code for natural images. Nature, 381(6583):607\u2013609, June 1996. ISSN 0028-0836. doi: 10.1038/381607a0.",
            "crossref": "https://dx.doi.org/10.1038/381607a0",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1038/381607a0"
        },
        {
            "id": "Olshausen_1997_a",
            "entry": "B. A. Olshausen and D. J. Field. Sparse coding with an overcomplete basis set: a strategy employed by V1? Vision Research, 37(23):3311\u20133325, December 1997. ISSN 0042-6989.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Olshausen%2C%20B.A.%20Field%2C%20D.J.%20Sparse%20coding%20with%20an%20overcomplete%20basis%20set%3A%20a%20strategy%20employed%20by%20V1%3F%201997-12",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Olshausen%2C%20B.A.%20Field%2C%20D.J.%20Sparse%20coding%20with%20an%20overcomplete%20basis%20set%3A%20a%20strategy%20employed%20by%20V1%3F%201997-12"
        },
        {
            "id": "Roska_0000_a",
            "entry": "Botond Roska and Markus Meister. The Retina Dissects the Visual Scene into Distinct Features. In The New Visual Neurosciences (Werner, JS, Chalupa, LM, eds), pp 163182., pp. 20.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Roska%2C%20Botond%20Meister%2C%20Markus%20The%20Retina%20Dissects%20the%20Visual%20Scene%20into%20Distinct%20Features.%20In%20The%20New%20Visual%20Neurosciences"
        },
        {
            "id": "Cambridge,_2014_a",
            "entry": "Cambridge, MA: MIT Press, 2014.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Cambridge%20MA%20MIT%20Press%202014"
        },
        {
            "id": "Schwartz_et+al_2006_a",
            "entry": "Odelia Schwartz, Jonathan W. Pillow, Nicole C. Rust, and Eero P. Simoncelli. Spike-triggered neural characterization. Journal of Vision, 6(4):13, July 2006. ISSN 1534-7362. doi: 10.1167/6.4.13.",
            "crossref": "https://dx.doi.org/10.1167/6.4.13",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1167/6.4.13"
        },
        {
            "id": "Singer_et+al_2018_a",
            "entry": "Yosef Singer, Yayoi Teramoto, Ben DB Willmore, Jan WH Schnupp, Andrew J. King, and Nicol S. Harper. Sensory cortex is optimized for prediction of future input, June 2018.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Singer%2C%20Yosef%20Teramoto%2C%20Yayoi%20Willmore%2C%20Ben%20D.B.%20Schnupp%2C%20Jan%20W.H.%20Sensory%20cortex%20is%20optimized%20for%20prediction%20of%20future%20input%202018-06"
        },
        {
            "id": "Vincent_2003_a",
            "entry": "Benjamin T. Vincent and Roland J. Baddeley. Synaptic energy efficiency in retinal processing. Vision Research, 43(11):1283\u20131290, May 2003. ISSN 0042-6989.",
            "scholar_url": "https://scholar.google.co.uk/scholar?q=Vincent%2C%20Benjamin%20T.%20Baddeley%2C%20Roland%20J.%20Synaptic%20energy%20efficiency%20in%20retinal%20processing%202003-05",
            "oa_query": "https://api.scholarcy.com/oa_version?query=Vincent%2C%20Benjamin%20T.%20Baddeley%2C%20Roland%20J.%20Synaptic%20energy%20efficiency%20in%20retinal%20processing%202003-05"
        },
        {
            "id": "Vincent_et+al_2005_a",
            "entry": "Benjamin T. Vincent, Roland J. Baddeley, Tom Troscianko, and Iain D. Gilchrist. Is the early visual system optimised to be energy efficient? Network: Computation in Neural Systems, 16(2-3): 175\u2013190, January 2005. ISSN 0954-898X. doi: 10.1080/09548980500290047.",
            "crossref": "https://dx.doi.org/10.1080/09548980500290047",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1080/09548980500290047"
        },
        {
            "id": "Yamins_et+al_2014_a",
            "entry": "Daniel L. K. Yamins, Ha Hong, Charles F. Cadieu, Ethan A. Solomon, Darren Seibert, and James J. DiCarlo. Performance-optimized hierarchical models predict neural responses in higher visual cortex. Proceedings of the National Academy of Sciences of the United States of America, 111 (23):8619\u20138624, June 2014. ISSN 1091-6490. doi: 10.1073/pnas.1403112111.",
            "crossref": "https://dx.doi.org/10.1073/pnas.1403112111",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1073/pnas.1403112111"
        },
        {
            "id": "Zhang_et+al_2012_a",
            "entry": "Yifeng Zhang, In-Jung Kim, Joshua R. Sanes, and Markus Meister. The most numerous ganglion cell type of the mouse retina is a selective feature detector. Proceedings of the National Academy of Sciences, pp. 201211547, August 2012. ISSN 0027-8424, 1091-6490. doi: 10.1073/pnas. 1211547109.",
            "crossref": "https://dx.doi.org/10.1073/pnas.1211547109",
            "oa_query": "https://api.scholarcy.com/oa_version?query=https%3A//dx.doi.org/10.1073/pnas.1211547109"
        }
    ]
}
